{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.tf_transform import *\n",
    "from pkg.tf_robot import *\n",
    "from pkg.constraint import *\n",
    "from pkg.info import *\n",
    "from pkg.tf_utils import *\n",
    "from pkg.rotation_utils import *\n",
    "from pkg.utils import *\n",
    "from pkg.ur10 import *\n",
    "from pkg.geometry import *\n",
    "from pkg.collision import *\n",
    "from pkg.distance import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load urdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urdf_parser_py.urdf import URDF\n",
    "from pkg.ur10 import URDF_PATH, JOINT_NAMES, LINK_NAMES, ZERO_JOINT_POSE\n",
    "from pkg.joint_utils import *\n",
    "urdf_content = URDF.from_xml_file(URDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_names = LINK_NAMES\n",
    "base_name = LINK_NAMES[0]\n",
    "joint_names = JOINT_NAMES\n",
    "link_info_list = get_link_info_list(link_names, urdf_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n",
      "publication OK - base_capsule\n",
      "publication OK - shoulder_capsule\n",
      "publication OK - upper_arm_capsule\n",
      "publication OK - forearm_capsule\n",
      "publication OK - wrist_1_capsule\n",
      "publication OK - wrist_2_capsule\n",
      "publication OK - wrist_3_capsule\n",
      "publication OK - tool_mesh\n",
      "publication OK - box1\n"
     ]
    }
   ],
   "source": [
    "from pkg.ros_rviz import *\n",
    "pub, joints, rate = get_publisher(JOINT_NAMES)\n",
    "\n",
    "gitem_list, gframe_dict= get_link_items_offsets(color=(0,1,0,0.5), display=True)\n",
    "gitem_list += [\n",
    "    GeometryItem(name='box1', gtype=GeoType.BOX, dims=[0.1,0.1,0.1], color=(0,1,0,1), display=True, collision=True)\n",
    "]\n",
    "gframe_dict.update({\"box1\":GeometryFrame(SE3(Rot_zyx(0,0,0),(0.5,0,0)), \"world\")\n",
    "                   })\n",
    "marker_list = set_markers(gitem_list, gframe_dict, urdf_content)\n",
    "show_motion([np.array([0]*6)], marker_list, \n",
    "            [[gframe_dict[gitem.name] for gitem in gitem_list]], \n",
    "            pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectLayer(layers.Layer):\n",
    "    def __init__(self, gitem, N_sim, *args, **kwargs):\n",
    "        self.gitem, self.N_sim = gitem, N_sim\n",
    "        super(ObjectLayer, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def set_frame(self, Toff_list, link_idx_list, N_link):\n",
    "        self.Toff_list = tf.constant(Toff_list) # (N_sim, 4,4)\n",
    "        self.link_one_hot = tf.reshape(tf.one_hot(link_idx_list, N_link), (N_sim,N_link,1,1)) # (N_sim, N_link)\n",
    "        \n",
    "    # 변수를 만듭니다.\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "    \n",
    "    @tf.function\n",
    "    def get_vertice(self):\n",
    "        return self.vertice\n",
    "\n",
    "    # call 메서드가 그래프 모드에서 사용되면\n",
    "    # training 변수는 텐서가 됩니다.\n",
    "    @tf.function\n",
    "    def call(self, input=None):\n",
    "        T_all = input # (N_sim, N_link, 4,4)\n",
    "        T_act = K.sum(T_all*self.link_one_hot, axis=1) # (N_sim, 4,4)\n",
    "        T_bo = tf.matmul(T_act, self.Toff_list) # (N_sim, 4,4)\n",
    "        return T_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceCalculator:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.N_sim = graph.N_sim\n",
    "        self.prepare_collision_dat()\n",
    "            \n",
    "    def prepare_collision_dat(self):\n",
    "        pair_all = []\n",
    "        for col_case in self.graph.pair_cases:\n",
    "            setattr(self, \"vtx1_\"+col_case, self.graph.col_vtx1_dict[col_case])\n",
    "            setattr(self, \"vtx2_\"+col_case, self.graph.col_vtx2_dict[col_case])\n",
    "            setattr(self, \"dist1_\"+col_case, self.graph.col_dist1_dict[col_case])\n",
    "            setattr(self, \"dist2_\"+col_case, self.graph.col_dist2_dict[col_case])\n",
    "            setattr(self, \"zeros_\"+col_case, tf.constant(get_zero_points(self.N_sim, self.graph.N_col_dict[col_case]), dtype=tf.float32))\n",
    "            setattr(self, \"N_col_\"+col_case, self.graph.N_col_dict[col_case])\n",
    "            setattr(self, \"flag_default_\"+col_case, \n",
    "                    tf.constant(get_flag_default(self.N_sim, self.graph.N_col_dict[col_case]), dtype=tf.bool))\n",
    "            setattr(self, \"dist_default_\"+col_case, \n",
    "                    tf.constant(get_dist_default(self.N_sim, self.graph.N_col_dict[col_case]), dtype=tf.float32))\n",
    "            x_batch, y_batch = get_xy_batch(self.N_sim, self.graph.N_col_dict[col_case])\n",
    "            setattr(self, \"x_batch_\"+col_case, \n",
    "                    tf.constant(x_batch, dtype=tf.float32))\n",
    "            setattr(self, \"y_batch_\"+col_case, \n",
    "                    tf.constant(y_batch, dtype=tf.float32))\n",
    "            setattr(self, \"test_\"+col_case, self.graph.col_vtx1_dict[col_case].shape[1]>0)\n",
    "            \n",
    "            pair_list = self.graph.col_pair_dict[col_case]\n",
    "            pair_all += pair_list\n",
    "        pair_all = np.array(pair_all)\n",
    "        self.pair_obj1 = pair_all[:,0]\n",
    "        self.pair_obj2 = pair_all[:,1]\n",
    "            \n",
    "    def apply_col_mask(self):\n",
    "        for col_case in self.graph.pair_cases:\n",
    "            setattr(self, \"mask_\"+col_case, self.graph.col_mask_dict[col_case])\n",
    "    \n",
    "    @tf.function\n",
    "    def pt_pt_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_pt, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_pt, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_pt, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_pt_pt(vtx1_all, vtx2_all, self.dist1_pt_pt, self.dist2_pt_pt)\n",
    "        return dist, flag, vec, self.mask_pt_pt\n",
    "\n",
    "    @tf.function\n",
    "    def pt_ln_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_ln, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_pt_ln(vtx1_all, vtx2_all, self.dist1_pt_ln, self.dist2_pt_ln)\n",
    "        return dist, flag, vec, self.mask_pt_ln\n",
    "\n",
    "    @tf.function\n",
    "    def pt_pl_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_pl, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_pt_pl(vtx1_all, vtx2_all, self.dist1_pt_pl, self.dist2_pt_pl, self.N_sim, self.N_col_pt_pl)\n",
    "        return dist, flag, vec, self.mask_pt_pl\n",
    "\n",
    "    @tf.function\n",
    "    def pt_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_pt_bx(vtx1_all, vtx2_all, self.dist1_pt_bx, self.dist2_pt_bx, self.N_sim, self.N_col_pt_bx)\n",
    "        return dist, flag, vec, self.mask_pt_bx\n",
    "\n",
    "    @tf.function\n",
    "    def ln_ln_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_ln_ln, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_ln_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_ln_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_ln_ln(vtx1_all, vtx2_all, self.dist1_ln_ln, self.dist2_ln_ln, \n",
    "                                    self.N_sim, self.N_col_ln_ln, self.zeros_ln_ln)\n",
    "        return dist, flag, vec, self.mask_ln_ln\n",
    "\n",
    "    @tf.function\n",
    "    def ln_pl_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_ln_pl, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_ln_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_ln_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_ln_pl(vtx1_all, vtx2_all, self.dist1_ln_pl, self.dist2_ln_pl, \n",
    "                                    self.N_sim, self.N_col_ln_pl, self.zeros_ln_pl)\n",
    "        return dist, flag, vec, self.mask_ln_pl\n",
    "\n",
    "    @tf.function\n",
    "    def ln_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_ln_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_ln_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_ln_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_ln_bx(vtx1_all, vtx2_all, self.dist1_ln_bx, self.dist2_ln_bx, \n",
    "                                    self.N_sim, self.N_col_ln_bx, self.zeros_ln_bx\n",
    "                                   )\n",
    "        return dist, flag, vec, self.mask_ln_bx\n",
    "\n",
    "    @tf.function\n",
    "    def pl_pl_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pl_pl, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pl_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pl_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_pl_pl(vtx1_all, vtx2_all, self.dist1_pl_pl, self.dist2_pl_pl, \n",
    "                                    self.flag_default_pl_pl, self.dist_default_pl_pl,\n",
    "                                    self.x_batch_pl_pl, self.y_batch_pl_pl,\n",
    "                                    4\n",
    "                                   )\n",
    "        return dist, flag, vec, self.mask_pl_pl\n",
    "\n",
    "    @tf.function\n",
    "    def pl_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pl_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pl_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pl_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_pl_bx(vtx1_all, vtx2_all, self.dist1_pl_bx, self.dist2_pl_bx, \n",
    "                                    self.flag_default_pl_bx, self.dist_default_pl_bx,\n",
    "                                    self.x_batch_pl_bx, self.y_batch_pl_bx,\n",
    "                                    4\n",
    "                                   )\n",
    "        return dist, flag, vec, self.mask_pl_bx\n",
    "\n",
    "    @tf.function\n",
    "    def bx_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_bx_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_bx_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_bx_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, vec, flag = distance_bx_bx(vtx1_all, vtx2_all, self.dist1_bx_bx, self.dist2_bx_bx, \n",
    "                                    self.flag_default_bx_bx, self.dist_default_bx_bx,\n",
    "                                    self.x_batch_bx_bx, self.y_batch_bx_bx,\n",
    "                                    4\n",
    "                                   )\n",
    "        return dist, flag, vec, self.mask_bx_bx\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_all(self, Tbo_all_res):\n",
    "        dist_all = []\n",
    "        flag_all = []\n",
    "        vec_all = []\n",
    "        mask_all = []\n",
    "        if self.test_pt_pt:\n",
    "            dist_pt_pt, flag_pt_pt, vec_pt_pt, mask_pt_pt = self.pt_pt_dist(Tbo_all_res)\n",
    "            dist_all += [dist_pt_pt]\n",
    "            flag_all += [flag_pt_pt]\n",
    "            vec_all += [vec_pt_pt]\n",
    "            mask_all += [mask_pt_pt]\n",
    "            \n",
    "        if self.test_pt_ln:\n",
    "            dist_pt_ln, flag_pt_ln, vec_pt_ln, mask_pt_ln = self.pt_ln_dist(Tbo_all_res)\n",
    "            dist_all += [dist_pt_ln]\n",
    "            flag_all += [flag_pt_ln]\n",
    "            vec_all += [vec_pt_ln]\n",
    "            mask_all += [mask_pt_ln]\n",
    "            \n",
    "        if self.test_pt_pl:\n",
    "            dist_pt_pl, flag_pt_pl, vec_pt_pl, mask_pt_pl = self.pt_pl_dist(Tbo_all_res)\n",
    "            dist_all += [dist_pt_pl]\n",
    "            flag_all += [flag_pt_pl]\n",
    "            vec_all += [vec_pt_pl]\n",
    "            mask_all += [mask_pt_pl]\n",
    "            \n",
    "        if self.test_pt_bx:\n",
    "            dist_pt_bx, flag_pt_bx, vec_pt_bx, mask_pt_bx = self.pt_bx_dist(Tbo_all_res)\n",
    "            dist_all += [dist_pt_bx]\n",
    "            flag_all += [flag_pt_bx]\n",
    "            vec_all += [vec_pt_bx]\n",
    "            mask_all += [mask_pt_bx]\n",
    "            \n",
    "        if self.test_ln_ln:\n",
    "            dist_ln_ln, flag_ln_ln, vec_ln_ln, mask_ln_ln = self.ln_ln_dist(Tbo_all_res)\n",
    "            dist_all += [dist_ln_ln]\n",
    "            flag_all += [flag_ln_ln]\n",
    "            vec_all += [vec_ln_ln]\n",
    "            mask_all += [mask_ln_ln]\n",
    "            \n",
    "        if self.test_ln_pl:\n",
    "            dist_ln_pl, flag_ln_pl, vec_ln_pl, mask_ln_pl = self.ln_pl_dist(Tbo_all_res)\n",
    "            dist_all += [dist_ln_pl]\n",
    "            flag_all += [flag_ln_pl]\n",
    "            vec_all += [vec_ln_pl]\n",
    "            mask_all += [mask_ln_pl]\n",
    "            \n",
    "        if self.test_ln_bx:\n",
    "            dist_ln_bx, flag_ln_bx, vec_ln_bx, mask_ln_bx = self.ln_bx_dist(Tbo_all_res)\n",
    "            dist_all += [dist_ln_bx]\n",
    "            flag_all += [flag_ln_bx]\n",
    "            vec_all += [vec_ln_bx]\n",
    "            mask_all += [mask_ln_bx]\n",
    "            \n",
    "        if self.test_pl_pl:\n",
    "            dist_pl_pl, flag_pl_pl, vec_pl_pl, mask_pl_pl = self.pl_pl_dist(Tbo_all_res)\n",
    "            dist_all += [dist_pl_pl]\n",
    "            flag_all += [flag_pl_pl]\n",
    "            vec_all += [vec_pl_pl]\n",
    "            mask_all += [mask_pl_pl]\n",
    "            \n",
    "        if self.test_pl_bx:\n",
    "            dist_pl_bx, flag_pl_bx, vec_pl_bx, mask_pl_bx = self.pl_bx_dist(Tbo_all_res)\n",
    "            dist_all += [dist_pl_bx]\n",
    "            flag_all += [flag_pl_bx]\n",
    "            vec_all += [vec_pl_bx]\n",
    "            mask_all += [mask_pl_bx]\n",
    "            \n",
    "        if self.test_bx_bx:\n",
    "            dist_bx_bx, flag_bx_bx, vec_bx_bx, mask_bx_bx = self.bx_bx_dist(Tbo_all_res)\n",
    "            dist_all += [dist_bx_bx]\n",
    "            flag_all += [flag_bx_bx]\n",
    "            vec_all += [vec_bx_bx]\n",
    "            mask_all += [mask_bx_bx]\n",
    "\n",
    "        dist_all = tf.concat(dist_all, axis=-2)\n",
    "        flag_all = tf.concat(flag_all, axis=-2)\n",
    "        vec_all = tf.concat(vec_all, axis=-2)\n",
    "        mask_all = tf.concat(mask_all, axis=-2)\n",
    "        \n",
    "        return dist_all, flag_all, vec_all, mask_all\n",
    "    \n",
    "    @tf.function\n",
    "    def jacobian(self, jac_o, vec_all):\n",
    "        jac_op = tf.gather(jac_o, [0,1,2], axis=-1)\n",
    "        jac_dp1 = tf.gather(jac_op, self.pair_obj1, axis=-3)\n",
    "        jac_dp2 = tf.gather(jac_op, self.pair_obj2, axis=-3)\n",
    "        vec_all = tf.expand_dims(vec_all, axis=-2)\n",
    "        jac_d = K.sum(vec_all*(jac_dp1 - jac_dp2), axis=-1)\n",
    "        return jac_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphModel(tf.keras.Model):\n",
    "    def __init__(self, robot_info, gitem_list, urdf_content, N_sim, \n",
    "                 alpha_jc=5, alpha_fc=200, alpha_jl=1, alpha_cl=1,alpha_cs=0, \n",
    "                 LIM=np.pi, LIM_BOUND=1e-1, COL_BOUND=1e-2, learning_rate=5e-3, col_iteration = 20):\n",
    "        super(GraphModel, self).__init__()\n",
    "        self.alpha_jc = alpha_jc\n",
    "        self.alpha_fc = alpha_fc\n",
    "        self.alpha_jl = alpha_jl\n",
    "        self.alpha_cl = alpha_cl\n",
    "        self.alpha_cs = alpha_cs\n",
    "        self.N_sim = N_sim\n",
    "        self.LIM = LIM\n",
    "        self.LIM_BOUND = LIM_BOUND\n",
    "        self.COL_BOUND = COL_BOUND\n",
    "        self.learning_rate = learning_rate\n",
    "        self.col_iteration = col_iteration\n",
    "        self.robot_info = robot_info\n",
    "        self.robot = RobotLayer(\n",
    "            robot_info, dim=N_sim)\n",
    "        self.joint_constraint = JointConstraintLoss(self.robot)\n",
    "        self.frame_constraint = FrameConstraintLoss()\n",
    "        self.robot_base = [robot_info.base_frame]*N_sim\n",
    "        self.set_custom_loss(lambda *args: tf.constant(0.0), 0)\n",
    "        self.link_name_list = self.robot.link_name_list\n",
    "        self.link_idx_dict = self.robot.link_idx_dict\n",
    "        self.adjacency_list = self.robot.adjacency_list\n",
    "        self.adjacency_mat = self.robot.adjacency_mat\n",
    "        self.dependency_list = self.robot.dependency_list\n",
    "        self.dependency_mat = self.robot.dependency_mat\n",
    "            \n",
    "        self.object_dict = {}\n",
    "        self.object_name_list = []\n",
    "        self.object_vertice_list = []\n",
    "        self.object_link_idx_list = []\n",
    "        self.object_collision_flags = []\n",
    "        for gitem in gitem_list:\n",
    "            self.object_dict[gitem.name] = ObjectLayer(gitem, N_sim)\n",
    "            self.object_collision_flags += [gitem.collision]\n",
    "            self.object_name_list += [gitem.name]\n",
    "            self.object_vertice_list += [np.pad(gitem.get_vertice(),((0,0),(0,1)),'constant', constant_values=(1))]\n",
    "            self.object_link_idx_list += [0]\n",
    "        self.num_object = len(self.object_name_list)\n",
    "#         self.object_vertice_mat = tf.constant(self.object_vertice_list, dtype=\"float32\")\n",
    "        self.build_collision_combinations()\n",
    "        self.set_collision_vtx()\n",
    "        self.optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    def build_collision_combinations(self):\n",
    "        obj_idx_list = np.arange(len(self.object_name_list))\n",
    "        self.col_combinations = list(combinations(obj_idx_list,2))\n",
    "\n",
    "        for i_c in range(len(self.col_combinations)):\n",
    "            i_c_back = len(self.col_combinations)-1-i_c\n",
    "            cmb = self.col_combinations[i_c_back]\n",
    "            if not(self.object_collision_flags[cmb[0]] \n",
    "                   and self.object_collision_flags[cmb[1]]):\n",
    "                del self.col_combinations[i_c_back]\n",
    "\n",
    "        self.pair_cases = ['pt_pt', 'pt_ln', 'pt_pl', 'pt_bx',\n",
    "                           'ln_ln', 'ln_pl', 'ln_bx',\n",
    "                           'pl_pl', 'pl_bx','bx_bx']\n",
    "        self.col_pair_dict = defaultdict(lambda:[])\n",
    "        for comb in self.col_combinations:\n",
    "            obj1 = self.object_dict[self.object_name_list[comb[0]]]\n",
    "            obj2 = self.object_dict[self.object_name_list[comb[1]]]\n",
    "            if obj1.gitem.gtype == GeoType.SPHERE:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_pt'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['pt_ln'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['pt_pl'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['pt_bx'] += [comb]\n",
    "            elif obj1.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_ln'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['ln_ln'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['ln_pl'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['ln_bx'] += [comb]\n",
    "            elif obj1.gitem.gtype == GeoType.PLANE:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_pl'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['ln_pl'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['pl_pl'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['pl_bx'] += [comb]\n",
    "            elif obj1.gitem.gtype == GeoType.BOX:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_bx'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['ln_bx'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['pl_bx'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['bx_bx'] += [comb]\n",
    "            \n",
    "    def assign_frame_dict(self, gframeset_list):\n",
    "        frame_dict = {k: [] for k in self.object_dict.keys()}\n",
    "        link_dict = {k: [] for k in self.object_dict.keys()}\n",
    "        for gframeset in gframeset_list:\n",
    "            for k, gframe in gframeset.items():\n",
    "                frame_dict[k] += [gframe.Toff]\n",
    "                link_dict[k] += [self.robot.link_name_list.index(gframe.link_name)]\n",
    "        for k in frame_dict.keys():\n",
    "            self.object_dict[k].set_frame(np.array(frame_dict[k]), np.array(link_dict[k]), self.robot.num_link)\n",
    "            i_obj = self.get_object_index(k)\n",
    "            self.object_link_idx_list[i_obj] = np.array(link_dict[k])\n",
    "        self.object_link_idx_mat = np.transpose(self.object_link_idx_list)\n",
    "        self.apply_col_mask()\n",
    "\n",
    "        self.object_depend_mask = tf.reshape(\n",
    "            tf.gather(self.robot.mask_depend, self.object_link_idx_mat, axis=-3), \n",
    "            (self.N_sim, self.num_object, self.robot.DOF, 1))\n",
    "            \n",
    "    def get_object_index(self, name):\n",
    "        return graph.object_name_list.index(name)\n",
    "            \n",
    "    @tf.function\n",
    "    def assign_Q(self, Q):\n",
    "        self.robot.assign_Q(Q)\n",
    "            \n",
    "    @tf.function\n",
    "    def get_Q(self):\n",
    "        return self.robot.get_Q()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs=None):\n",
    "        T_all = self.robot(self.robot_base)\n",
    "        Tbo_all = []\n",
    "        for obj_name in self.object_name_list:\n",
    "            Tbo_all += [self.object_dict[obj_name](T_all)] #(Nobj,N_sim,4,4)\n",
    "        Tbo_all = K.stack(Tbo_all, axis=1) #(N_sim,Nobj,4,4)\n",
    "        return T_all, Tbo_all\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_joint_limit(self):\n",
    "        Q = self.get_Q()\n",
    "        return K.sum(1/((K.min(((self.LIM-Q), (self.LIM+Q)), axis=-1)/self.LIM_BOUND)**3))\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_loss(self, T_all, Tbo_all, Qtar, binQ, Ttar, binT):\n",
    "        jl_loss = self.calc_joint_limit()\n",
    "        jc_loss = self.joint_constraint((Qtar, binQ))\n",
    "        fc_loss = self.frame_constraint((T_all[:,-1,:,:],Ttar, binT))\n",
    "        cl_loss = self.calc_collision_loss(T_all, Tbo_all)\n",
    "        return self.alpha_jc*jc_loss + self.alpha_fc*fc_loss + \\\n",
    "                self.alpha_jl*jl_loss + self.alpha_cs*self.calc_custom_loss(T_all, Tbo_all) \\\n",
    "                + self.alpha_cl*cl_loss \n",
    "                \n",
    "    \n",
    "    @tf.function\n",
    "    def forward(self, Qtar, binQ, Ttar, binT):\n",
    "        T_all, Tbo_all= graph(None)\n",
    "        loss = self.calc_loss(T_all, Tbo_all, Qtar, binQ, Ttar, binT)\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def update_once(self, Qtar, binQ, Ttar, binT, max_gradient):\n",
    "        with tf.GradientTape() as g:\n",
    "            # Forward pass.\n",
    "            loss = self.forward(Qtar, binQ, Ttar, binT)\n",
    "\n",
    "        # Variables to update, i.e. trainable variables.\n",
    "        trainable_variables = self.trainable_variables\n",
    "\n",
    "        # Compute gradients.\n",
    "        gradients = g.gradient(loss, trainable_variables)\n",
    "        gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "    \n",
    "        # Update W and b following gradients.\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    def set_custom_loss(self, custom_loss, alpha_cs, *args, **kwargs):\n",
    "        self.custom_loss = custom_loss\n",
    "        self.alpha_cs = alpha_cs\n",
    "        self.cl_args = args\n",
    "        self.cl_kwargs = kwargs\n",
    "        \n",
    "    def calc_custom_loss(self, T_all, Tbo_all):\n",
    "        return self.custom_loss(self, T_all, Tbo_all, *self.cl_args, **self.cl_kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def test_collision(self, T_all, Tbo_all):\n",
    "        Pbo_all = tf.gather(tf.gather(Tbo_all, [0,1,2], axis=-2), 3, axis=-1)\n",
    "        col_combs_masked_batch = self.get_collision_combination()\n",
    "        batch_flat = tf.repeat(np.reshape(np.arange(self.N_sim), (self.N_sim, 1)), (self.N_col,)*self.N_sim,axis=0)\n",
    "        col_combs_masked_flat = tf.concat([batch_flat, col_combs_masked_batch], axis=-1)\n",
    "        vtx_tf = tf.gather(\n",
    "            K.sum(tf.expand_dims(Tbo_all, axis=-3)*tf.expand_dims(self.object_vertice_mat, axis=-2), axis=-1), \n",
    "            [0,1,2], axis=-1)\n",
    "        vtx_tf_1 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "        vtx_tf_2 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "        Pbo_all_1 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col,3))\n",
    "        Pbo_all_2 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col,3))\n",
    "        v_batch = tf.expand_dims(Pbo_all_1-Pbo_all_2, axis=-2)\n",
    "        v_batch = tf.stop_gradient(tf.linalg.cross(v_batch, self.x_batch)+tf.linalg.cross(v_batch, self.y_batch))\n",
    "        dist, flag = test_collision_batch(vtx_tf_1, vtx_tf_2, \n",
    "                             v_batch, self.flag_default, self.dist_default, IterationAllowed=self.col_iteration)\n",
    "        return dist, flag, col_combs_masked_flat \n",
    "    \n",
    "    @tf.function\n",
    "    def calc_collision_loss(self, T_all, Tbo_all):\n",
    "        dist, flag, _  = self.test_collision(T_all, Tbo_all)\n",
    "        return K.sum(1/((dist/self.COL_BOUND)**3))\n",
    "    \n",
    "    def get_collision_combination_names(self):\n",
    "        comb_names = []\n",
    "        for comb in self.get_collision_combination():\n",
    "            comb_names += [\"{} - {}\".format(self.object_name_list[comb[0]], graph.object_name_list[comb[1]])]\n",
    "            \n",
    "    def get_vtx_pair(self, pair_list, N_vtx1, N_vtx2):\n",
    "        N_col = len(pair_list)\n",
    "        pair_vtx1 = np.zeros((1, len(pair_list), len(self.object_name_list), N_vtx1, 1, 4)) # (N_sim, N_col, N_obj, N_vtx, 1, 4)\n",
    "        pair_vtx2 = np.zeros((1, len(pair_list), len(self.object_name_list), N_vtx2, 1, 4))\n",
    "        pair_dist1 = np.zeros((1, len(pair_list), 1))\n",
    "        pair_dist2 = np.zeros((1, len(pair_list), 1))\n",
    "        for i_c, comb in zip(range(len(pair_list)), pair_list):\n",
    "            pair_vtx1[0,i_c,comb[0],:,0] = np.pad(self.object_dict[self.object_name_list[comb[0]]].gitem.get_vertice(),((0,0),(0,1)),'constant', constant_values=(1))\n",
    "            pair_vtx2[0,i_c,comb[1],:,0] = np.pad(self.object_dict[self.object_name_list[comb[1]]].gitem.get_vertice(),((0,0),(0,1)),'constant', constant_values=(1))\n",
    "            pair_dist1[0,i_c, 0] = self.object_dict[self.object_name_list[comb[0]]].gitem.get_radius()\n",
    "            pair_dist2[0,i_c, 0] = self.object_dict[self.object_name_list[comb[1]]].gitem.get_radius()\n",
    "        pair_vtx1 = tf.constant(pair_vtx1, dtype=tf.float32)\n",
    "        pair_vtx2 = tf.constant(pair_vtx2, dtype=tf.float32)\n",
    "        pair_dist1 = tf.constant(pair_dist1, dtype=tf.float32)\n",
    "        pair_dist2 = tf.constant(pair_dist2, dtype=tf.float32)\n",
    "        return pair_vtx1, pair_vtx2, pair_dist1, pair_dist2, N_col\n",
    "    \n",
    "    def set_collision_vtx(self):\n",
    "        self.col_vtx1_dict = {}\n",
    "        self.col_vtx2_dict = {}\n",
    "        self.col_dist1_dict = {}\n",
    "        self.col_dist2_dict = {}\n",
    "        self.N_col_dict = {}\n",
    "        self.N_vtx_dict = {\"pt\":1, \"ln\":2, \"pl\":4, \"bx\":8}\n",
    "        for col_case in self.pair_cases:\n",
    "            self.col_vtx1_dict[col_case], self.col_vtx2_dict[col_case], \\\n",
    "                self.col_dist1_dict[col_case], self.col_dist2_dict[col_case], self.N_col_dict[col_case] = \\\n",
    "                    self.get_vtx_pair(\n",
    "                        self.col_pair_dict[col_case], self.N_vtx_dict[col_case[:2]], self.N_vtx_dict[col_case[3:]])\n",
    "        self.dcal = DistanceCalculator(self)\n",
    "        \n",
    "    def apply_col_mask(self):\n",
    "        self.col_mask_dict = {}\n",
    "        for col_case in self.pair_cases:\n",
    "            N_col = self.N_col_dict[col_case]\n",
    "            mask = np.zeros((self.N_sim, N_col, 1), dtype=np.float32)\n",
    "            for i_col, comb in zip(range(N_col), self.col_pair_dict[col_case]):\n",
    "                mask[:, i_col, 0] = tf.gather_nd(self.adjacency_mat, self.object_link_idx_mat[:, comb])\n",
    "            self.col_mask_dict[col_case] = 1-mask\n",
    "        self.dcal.apply_col_mask()\n",
    "        \n",
    "    def jacobian_object(self, Tbo_all):\n",
    "        RP_all = tf.gather(Tbo_all, [0,1,2], axis=-2) # N_sim, N_obj, 3,4\n",
    "        R_all = tf.gather(RP_all, [0,1,2], axis=-1)\n",
    "        P_all = tf.gather(RP_all, [3], axis=-1)\n",
    "        R_jnt = tf.gather(R_all, self.robot.idx_var, axis=-3)\n",
    "        P_jnt = tf.gather(P_all, self.robot.idx_var, axis=-3)\n",
    "        axis_jnt = K.sum(R_jnt*self.robot._axis_prism, axis=-1)\n",
    "        axis_jnt_rep = tf.tile(tf.expand_dims(axis_jnt, axis=-3), [1,self.num_object,1,1])\n",
    "\n",
    "        jac_prism_ = tf.pad(axis_jnt, [[0,0], [0,0], [0,3]]) # N_sim, DOF, 6\n",
    "        jac_prism = tf.expand_dims(jac_prism_, axis=-3) * self.object_depend_mask# N_sim, N_obj, DOF, 6\n",
    "\n",
    "        pij = tf.reshape(tf.expand_dims(P_all, axis=-3)-tf.expand_dims(P_jnt, axis=-4), \n",
    "                         (self.N_sim, self.num_object, self.robot.DOF, 3)) # N_sim, N_link, DOF, 3, 1\n",
    "        jac_p_rev = tf.linalg.cross(pij, axis_jnt_rep)\n",
    "        jac_revol = tf.concat([jac_p_rev, axis_jnt_rep], axis=-1) * self.object_depend_mask# N_sim, N_link, DOF, 6\n",
    "\n",
    "        jacobian = self.robot.mask_prism*jac_prism + self.robot.mask_revol*jac_revol\n",
    "        return jacobian\n",
    "    \n",
    "    def jacobian(self, T_all, Tbo_all):\n",
    "        return self.robot.jacobian(T_all), self.jacobian_object(Tbo_all)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize: \t5120.0 ms/1 = 5119.558 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_sim = 50\n",
    "N_joints = 9\n",
    "DOF = 6\n",
    "gtimer = GlobalTimer()\n",
    "\n",
    "\n",
    "gtimer.tic(\"initialize\")\n",
    "robot_info = RobotInfo(link_info_list, rname = \"rbt1\", base_frame=np.identity(4,dtype=np.float32))\n",
    "graph = GraphModel(robot_info=robot_info, gitem_list=gitem_list, urdf_content=urdf_content, \n",
    "                   N_sim=N_sim, learning_rate=5e-3, \n",
    "                   alpha_cl=0.001)\n",
    "Q_ = np.array([tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100) for _ in range(N_sim)], dtype=np.float32)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,0.00)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "T_all, Tbo_all = graph(None)\n",
    "Tbo_all_res = tf.reshape(Tbo_all, (graph.N_sim, 1, graph.num_object, 1, 4,4))\n",
    "res = graph.dcal.calc_all(Tbo_all_res)\n",
    "gtimer.toc(\"initialize\")\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assign: \t6.0 ms/1 = 5.77 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "Q_ = np.array([tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100) for _ in range(N_sim)], dtype=np.float32)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,0.00)).astype(np.float32)\n",
    "gtimer.tic(\"assign\")\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "gtimer.toc(\"assign\")\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc: \t215.0 ms/100 = 2.151 ms \n",
      "jacobian: \t157.0 ms/100 = 1.573 ms \n",
      "collision: \t526.0 ms/100 = 5.257 ms \n",
      "col_jacobian: \t41.0 ms/100 = 0.408 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,0.00)).astype(np.float32)\n",
    "\n",
    "gtimer.reset()\n",
    "res_vec = []\n",
    "for _ in range(100):\n",
    "    gtimer.tic(\"calc\")\n",
    "    T_all, Tbo_all = graph(None)\n",
    "    gtimer.toc(\"calc\")\n",
    "    gtimer.tic(\"jacobian\")\n",
    "    jac_r, jac_o = graph.jacobian(T_all, Tbo_all)\n",
    "    gtimer.toc(\"jacobian\")\n",
    "    gtimer.tic(\"collision\")\n",
    "    Tbo_all_res = tf.reshape(Tbo_all, (graph.N_sim, 1, graph.num_object, 1, 4,4))\n",
    "    dist_all, flag_all, vec_all, mask_all = graph.dcal.calc_all(Tbo_all_res)\n",
    "    gtimer.toc(\"collision\")\n",
    "    gtimer.tic(\"col_jacobian\")\n",
    "    jac_d = graph.dcal.jacobian(jac_o, vec_all)\n",
    "    gtimer.toc(\"col_jacobian\")\n",
    "    res_vec += [res]\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test full loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=434183.62>,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def _loop(value):\n",
    "    T_all, Tbo_all = graph(None)\n",
    "    Tbo_all_res = tf.reshape(Tbo_all, (graph.N_sim, 1, graph.num_object, 1, 4,4))\n",
    "    jac_r, jac_o = graph.jacobian(T_all, Tbo_all)\n",
    "    dist_all, flag_all, vec_all, mask_all = graph.dcal.calc_all(Tbo_all_res)\n",
    "    jac_d = graph.dcal.jacobian(jac_o, vec_all)\n",
    "    return K.sum(dist_all)*K.sum(mask_all)+K.sum(jac_r)+K.sum(jac_o)+K.sum(jac_d)\n",
    "@tf.function\n",
    "def run_test(N_loop):\n",
    "    res = tf.while_loop(\n",
    "        lambda value: True, _loop, (tf.constant(0.0),), \n",
    "        parallel_iterations=10, maximum_iterations=N_loop\n",
    "    )\n",
    "    return res\n",
    "run_test(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop100: \t474.0 ms/1 = 474.198 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "gtimer.tic(\"loop100\")\n",
    "res = run_test(100)\n",
    "gtimer.toc(\"loop100\")\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func: \t3054.0 ms/1 = 3053.651 ms \n",
      "grad: \t0.0 ms/1 = 0.02 ms \n",
      "apply: \t0.0 ms/1 = 0.016 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "gtimer.tic(\"func\")\n",
    "with tf.GradientTape() as g:\n",
    "    # Forward pass.\n",
    "    T_all, Tbo_all = graph(None)\n",
    "    Tbo_all_res = tf.reshape(Tbo_all, (graph.N_sim, 1, graph.num_object, 1, 4,4))\n",
    "    dist, flag, mask = graph.dcal.calc_all(Tbo_all_res)\n",
    "    loss = dist\n",
    "#     loss = K.sum(dist[6])\n",
    "# Variables to update, i.e. trainable variables.\n",
    "trainable_variables = graph.trainable_variables\n",
    "\n",
    "gtimer.toc(\"func\")\n",
    "gtimer.tic(\"grad\")\n",
    "# Compute gradients.\n",
    "# gradients = g.gradient(loss, trainable_variables)\n",
    "# jacobian = g.batch_jacobian(loss, trainable_variables[0])\n",
    "gtimer.toc(\"grad\")\n",
    "# gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "\n",
    "# # Update W and b following gradients.\n",
    "gtimer.tic(\"apply\")\n",
    "# graph.optimizer.apply_gradients(zip(gradients, graph.trainable_variables))\n",
    "gtimer.toc(\"apply\")\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_jacobian: \t0.0 ms/1 = 0.019 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "gtimer.tic(\"batch_jacobian\")\n",
    "# bjac = g.batch_jacobian(dist, graph.trainable_variables[0])\n",
    "gtimer.toc(\"batch_jacobian\")\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test full gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Got error while pfor was converting op name: \"gradients/PartitionedCall_grad/PartitionedCall_146\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradients/grad_ys_0\"\n",
      "input: \"gradients/zeros_like\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_1\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_2\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_3\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_4\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_5\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_6\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_7\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_8\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_9\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_10\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_11\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_12\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_13\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_14\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_15\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_16\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_17\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_18\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_19\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_20\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_21\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_22\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_23\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_24\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_25\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_26\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_27\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_28\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_29\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_30\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_31\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_32\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_33\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_34\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_35\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_36\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_37\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_38\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_39\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_40\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_41\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_42\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_43\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_44\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_45\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_46\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_47\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_48\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_49\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_50\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_51\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_52\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_53\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_54\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_55\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_56\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_57\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_58\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_59\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_60\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_61\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_62\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_63\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_64\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_65\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_66\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_67\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_68\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_69\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_70\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_71\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_72\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_73\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_74\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_75\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_76\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_77\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_78\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_79\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_80\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_81\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_82\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_83\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_84\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_85\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_86\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_87\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_88\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_89\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_90\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_91\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_92\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_93\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_94\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_95\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_96\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_97\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_98\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_99\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_100\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_101\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_102\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_103\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_104\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_105\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_106\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_107\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_108\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_109\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_110\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_111\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_112\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_113\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_114\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_115\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_116\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_117\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_118\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_119\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_120\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_121\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_122\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_123\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_124\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_125\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_126\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_127\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_128\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_129\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_130\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_131\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_132\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_133\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_134\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_135\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_136\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_137\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_138\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_139\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_140\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_141\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_142\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_143\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_144\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_145\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_distance_ln_bx_20227_22984\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "with inputs (<tf.Tensor 'gradients/grad_ys_0:0' shape=(50, 7, 1) dtype=float32>, <tf.Tensor 'gradients/zeros_like:0' shape=(50, 7, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_1:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_2:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_3:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_4:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_5:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_6:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_7:0' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_8:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_9:0' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_10:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_11:0' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_12:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_13:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_14:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_15:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_16:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_17:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_18:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_19:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_20:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_21:0' shape=(50, 14, 6, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_22:0' shape=(50, 168, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_23:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_24:0' shape=(50, 168, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_25:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_26:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_27:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_28:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_29:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_30:0' shape=(8400, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_31:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_32:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_33:0' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_34:0' shape=(50, 168, 2, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_35:0' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_36:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_37:0' shape=(8400, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_38:0' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_39:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_40:0' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_41:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_42:0' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_43:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_44:0' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_45:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_46:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_47:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_48:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_49:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_50:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_51:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_52:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_53:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_54:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_55:0' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_56:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_57:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_58:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_59:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_60:0' shape=(12,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_61:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_62:0' shape=(12,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_63:0' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_64:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_65:0' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_66:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_67:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_68:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_69:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_70:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_71:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_72:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_73:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_74:0' shape=(24,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_75:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_76:0' shape=(24,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_77:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_78:0' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_79:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_80:0' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_81:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_82:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_83:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_84:0' shape=(4200, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_85:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_86:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_87:0' shape=(4200, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_88:0' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_89:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_90:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_91:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_92:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_93:0' shape=(50, 336, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_94:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_95:0' shape=(50, 336, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_96:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_97:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_98:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_99:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_100:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_101:0' shape=(16800, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_102:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_103:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_104:0' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_105:0' shape=(50, 336, 2, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_106:0' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_107:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_108:0' shape=(16800, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_109:0' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_110:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_111:0' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_112:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_113:0' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_114:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_115:0' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_116:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_117:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_118:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_119:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_120:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_121:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_122:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_123:0' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_124:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_125:0' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_126:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_127:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_128:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_129:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_130:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_131:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_132:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_133:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_134:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_135:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_136:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_137:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_138:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_139:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_140:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_141:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_142:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_143:0' shape=(12,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_144:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_grad/PartitionedCall_145:0' shape=(12,) dtype=int32>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'gradients/grad_ys_0/pfor/Identity:0' shape=(28, 50, 7, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/zeros_like/pfor/ZerosLike:0' shape=(50, 7, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_3:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_4:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_5:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_6:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_7:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_8:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_9:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_10:0' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_11:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_12:0' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_13:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_14:0' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_15:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_16:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_17:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_18:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_19:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_20:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_21:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_22:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_23:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_24:0' shape=(50, 14, 6, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_25:0' shape=(50, 168, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_26:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_27:0' shape=(50, 168, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_28:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_29:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_30:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_31:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_32:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_33:0' shape=(8400, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_34:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_35:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_36:0' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_37:0' shape=(50, 168, 2, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_38:0' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_39:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_40:0' shape=(8400, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_41:0' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_42:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_43:0' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_44:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_45:0' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_46:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_47:0' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_48:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_49:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_50:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_51:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_52:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_53:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_54:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_55:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_56:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_57:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_58:0' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_59:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_60:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_61:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_62:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_63:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_64:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_65:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_66:0' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_67:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_68:0' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_69:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_70:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_71:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_72:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_73:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_74:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_75:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_76:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_77:0' shape=(24,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_78:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_79:0' shape=(24,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_80:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_81:0' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_82:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_83:0' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_84:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_85:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_86:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_87:0' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_88:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_89:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_90:0' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_91:0' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_92:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_93:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_94:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_95:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_96:0' shape=(50, 336, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_97:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_98:0' shape=(50, 336, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_99:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_100:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_101:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_102:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_103:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_104:0' shape=(16800, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_105:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_106:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_107:0' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_108:0' shape=(50, 336, 2, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_109:0' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_110:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_111:0' shape=(16800, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_112:0' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_113:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_114:0' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_115:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_116:0' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_117:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_118:0' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_119:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_120:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_121:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_122:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_123:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_124:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_125:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_126:0' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_127:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_128:0' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_129:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_130:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_131:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_132:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_133:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_134:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_135:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_136:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_137:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_138:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_139:0' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_140:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_141:0' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_142:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_143:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_144:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_145:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_146:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_147:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_148:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]\n",
      "in user code:\n",
      "\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n",
      "        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n",
      "        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n",
      "        wrapped(_sys.argv)\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n",
      "        name, value, suggestions=suggestions)\n",
      "\n",
      "    UnrecognizedFlagError: Unknown command line flag 'f'\n",
      "\n",
      "Here are the pfor conversion stack traces:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:name: \"gradients/PartitionedCall_grad/PartitionedCall_146\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradients/grad_ys_0\"\n",
      "input: \"gradients/zeros_like\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_1\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_2\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_3\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_4\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_5\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_6\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_7\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_8\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_9\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_10\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_11\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_12\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_13\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_14\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_15\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_16\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_17\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_18\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_19\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_20\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_21\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_22\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_23\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_24\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_25\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_26\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_27\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_28\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_29\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_30\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_31\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_32\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_33\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_34\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_35\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_36\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_37\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_38\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_39\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_40\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_41\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_42\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_43\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_44\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_45\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_46\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_47\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_48\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_49\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_50\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_51\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_52\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_53\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_54\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_55\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_56\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_57\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_58\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_59\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_60\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_61\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_62\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_63\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_64\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_65\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_66\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_67\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_68\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_69\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_70\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_71\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_72\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_73\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_74\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_75\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_76\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_77\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_78\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_79\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_80\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_81\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_82\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_83\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_84\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_85\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_86\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_87\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_88\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_89\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_90\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_91\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_92\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_93\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_94\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_95\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_96\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_97\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_98\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_99\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_100\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_101\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_102\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_103\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_104\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_105\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_106\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_107\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_108\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_109\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_110\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_111\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_112\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_113\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_114\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_115\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_116\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_117\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_118\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_119\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_120\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_121\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_122\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_123\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_124\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_125\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_126\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_127\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_128\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_129\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_130\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_131\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_132\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_133\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_134\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_135\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_136\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_137\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_138\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_139\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_140\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_141\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_142\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_143\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_144\"\n",
      "input: \"gradients/PartitionedCall_grad/PartitionedCall_145\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_distance_ln_bx_20227_22984\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "    File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"<ipython-input-16-30787d0d77a7>\", line 7, in <module>\n",
      "    dist, flag, mask = graph.dcal.calc_all(Tbo_all_res)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 618, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1751, in _call_flat\n",
      "    forward_function, args_with_tangents = forward_backward.forward()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1477, in forward\n",
      "    self._inference_args, self._input_tangents)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1233, in forward\n",
      "    self._forward_and_backward_functions(inference_args, input_tangents))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1385, in _forward_and_backward_functions\n",
      "    outputs, inference_args, input_tangents)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 943, in _build_functions_for_outputs\n",
      "    src_graph=self._func_graph)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 669, in _GradientsHelper\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 336, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 669, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 760, in _rewrite_forward_and_call_backward\n",
      "    forward_function, backwards_function = self.forward_backward(len(doutputs))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 669, in forward_backward\n",
      "    forward, backward = self._construct_forward_backward(num_doutputs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 717, in _construct_forward_backward\n",
      "    func_graph=backwards_graph)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 707, in _backprop_function\n",
      "    src_graph=self._func_graph)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 669, in _GradientsHelper\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 336, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 669, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 796, in _rewrite_forward_and_call_backward\n",
      "    cleaned_doutputs, remapped_captures)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1760, in _call_flat\n",
      "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 627, in call\n",
      "    executor_type=executor_type)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 1180, in partitioned_call\n",
      "    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3258, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 595, in _create_op_internal\n",
      "    compute_device)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3327, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1791, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Got error while pfor was converting op name: \"gradients/PartitionedCall_6_grad/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradients/concat_3_grad/Slice_1\"\n",
      "input: \"gradients/concat_5_grad/Slice_1\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_1\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_2\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_3\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_4\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_5\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_6\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_7\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_8\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_9\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_10\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_11\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_12\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_13\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_14\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_15\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_16\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_17\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_18\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_19\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_20\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_21\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_22\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_23\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_24\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_25\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_26\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_27\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_28\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_29\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_30\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_31\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_32\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_33\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_34\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_35\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_36\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_37\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_38\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_39\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_40\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_41\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_42\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_43\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_44\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_45\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_46\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_47\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_48\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_49\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_50\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_51\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_52\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_53\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_54\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_55\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_56\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_57\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_58\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_59\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_60\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_61\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_62\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_63\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_64\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_65\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_66\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_67\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_68\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_69\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_70\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_71\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_72\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_73\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_74\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_75\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_76\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_77\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_78\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_79\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_80\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_81\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_82\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_83\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_84\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_85\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_86\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_87\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_88\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_89\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_90\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_91\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_92\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_93\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_94\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_95\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_96\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_97\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_98\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_99\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_100\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_101\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_102\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_103\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_104\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_105\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_106\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_107\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_108\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_109\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_110\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_111\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_112\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_113\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_114\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_115\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_116\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_117\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_118\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_119\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_120\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_121\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_122\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_123\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_124\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_125\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_126\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_127\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_128\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_129\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_130\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_131\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_132\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_133\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_134\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_135\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_136\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_137\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_138\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_139\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_140\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_141\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_142\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_143\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_144\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_145\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_146\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_147\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_148\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_149\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_150\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_151\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_152\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_153\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_154\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_ln_bx_dist_20219_23532\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "with inputs (<tf.Tensor 'gradients/concat_3_grad/Slice_1:0' shape=(50, 7, 1) dtype=float32>, <tf.Tensor 'gradients/concat_5_grad/Slice_1:0' shape=(50, 7, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6:0' shape=(50, 7, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_1:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_2:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_3:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_4:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_5:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_6:0' shape=(350, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_7:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_8:0' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_9:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_10:0' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_11:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_12:0' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_13:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_14:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_15:0' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_16:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_17:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_18:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_19:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_20:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_21:0' shape=(700, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_22:0' shape=(50, 14, 6, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_23:0' shape=(50, 168, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_24:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_25:0' shape=(50, 168, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_26:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_27:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_28:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_29:0' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_30:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_31:0' shape=(8400, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_32:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_33:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_34:0' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_35:0' shape=(50, 168, 2, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_36:0' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_37:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_38:0' shape=(8400, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_39:0' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_40:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_41:0' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_42:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_43:0' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_44:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_45:0' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_46:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_47:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_48:0' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_49:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_50:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_51:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_52:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_53:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_54:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_55:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_56:0' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_57:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_58:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_59:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_60:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_61:0' shape=(12,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_62:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_63:0' shape=(12,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_64:0' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_65:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_66:0' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_67:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_68:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_69:0' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_70:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_71:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_72:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_73:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_74:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_75:0' shape=(24,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_76:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_77:0' shape=(24,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_78:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_79:0' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_80:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_81:0' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_82:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_83:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_84:0' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_85:0' shape=(4200, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_86:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_87:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_88:0' shape=(4200, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_89:0' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_90:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_91:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_92:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_93:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_94:0' shape=(50, 336, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_95:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_96:0' shape=(50, 336, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_97:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_98:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_99:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_100:0' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_101:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_102:0' shape=(16800, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_103:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_104:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_105:0' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_106:0' shape=(50, 336, 2, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_107:0' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_108:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_109:0' shape=(16800, 3) dtype=int64>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_110:0' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_111:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_112:0' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_113:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_114:0' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_115:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_116:0' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_117:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_118:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_119:0' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_120:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_121:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_122:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_123:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_124:0' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_125:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_126:0' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_127:0' shape=() dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_128:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_129:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_130:0' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_131:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_132:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_133:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_134:0' shape=(1,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_135:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_136:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_137:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_138:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_139:0' shape=(4,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_140:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_141:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_142:0' shape=(5,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_143:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_144:0' shape=(12,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_145:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_146:0' shape=(12,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_147:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_148:0' shape=(3,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_149:0' shape=() dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_150:0' shape=(3,) dtype=int32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_151:0' shape=(1, 7, 9, 2, 1, 4) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_152:0' shape=(50, 7, 9, 1, 4, 4) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_153:0' shape=(1, 7, 9, 8, 1, 4) dtype=float32>, <tf.Tensor 'gradients/PartitionedCall_6_grad/PartitionedCall_6_154:0' shape=(6,) dtype=int32>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'gradients/concat_3_grad/Slice_1/pfor/Slice:0' shape=(28, 50, 7, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'gradients/concat_5_grad/Slice_1/pfor/Slice:0' shape=(50, 7, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_75:0' shape=(50, 7, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_76:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_77:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_78:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_79:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_80:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_81:0' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_82:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_83:0' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_84:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_85:0' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_86:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_87:0' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_88:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_89:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_90:0' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_91:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_92:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_93:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_94:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_95:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_96:0' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_97:0' shape=(50, 14, 6, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_98:0' shape=(50, 168, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_99:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_100:0' shape=(50, 168, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_101:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_102:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_103:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_104:0' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_105:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_106:0' shape=(8400, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_107:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_108:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_109:0' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_110:0' shape=(50, 168, 2, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_111:0' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_112:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_113:0' shape=(8400, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_114:0' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_115:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_116:0' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_117:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_118:0' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_119:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_120:0' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_121:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_122:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_123:0' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_124:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_125:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_126:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_127:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_128:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_129:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_130:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_131:0' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_132:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_133:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_134:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_135:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_136:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_137:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_138:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_139:0' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_140:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_141:0' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_142:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_143:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_144:0' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_145:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_146:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_147:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_148:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_149:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_150:0' shape=(24,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_151:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_152:0' shape=(24,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_153:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_154:0' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_155:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_156:0' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_157:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_158:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_159:0' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_160:0' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_161:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_162:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_163:0' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_164:0' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_165:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_166:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_167:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_168:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_169:0' shape=(50, 336, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_170:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_171:0' shape=(50, 336, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_172:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_173:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_174:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_175:0' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_176:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_177:0' shape=(16800, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_178:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_179:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_180:0' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_181:0' shape=(50, 336, 2, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_182:0' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_183:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_184:0' shape=(16800, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_185:0' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_186:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_187:0' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_188:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_189:0' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_190:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_191:0' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_192:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_193:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_194:0' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_195:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_196:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_197:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_198:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_199:0' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_200:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_201:0' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_202:0' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_203:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_204:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_205:0' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_206:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_207:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_208:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_209:0' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_210:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_211:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_212:0' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_213:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_214:0' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_215:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_216:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_217:0' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_218:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_219:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_220:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_221:0' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_222:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_223:0' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_224:0' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_225:0' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_226:0' shape=(1, 7, 9, 2, 1, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_227:0' shape=(50, 7, 9, 1, 4, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_228:0' shape=(1, 7, 9, 8, 1, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'args_229:0' shape=(6,) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]\n",
      "in user code:\n",
      "\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n",
      "        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n",
      "        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n",
      "        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n",
      "        wrapped(_sys.argv)\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n",
      "        name, value, suggestions=suggestions)\n",
      "\n",
      "    UnrecognizedFlagError: Unknown command line flag 'f'\n",
      "\n",
      "Here are the pfor conversion stack traces:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:name: \"gradients/PartitionedCall_6_grad/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradients/concat_3_grad/Slice_1\"\n",
      "input: \"gradients/concat_5_grad/Slice_1\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_1\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_2\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_3\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_4\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_5\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_6\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_7\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_8\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_9\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_10\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_11\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_12\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_13\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_14\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_15\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_16\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_17\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_18\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_19\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_20\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_21\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_22\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_23\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_24\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_25\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_26\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_27\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_28\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_29\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_30\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_31\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_32\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_33\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_34\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_35\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_36\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_37\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_38\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_39\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_40\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_41\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_42\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_43\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_44\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_45\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_46\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_47\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_48\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_49\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_50\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_51\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_52\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_53\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_54\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_55\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_56\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_57\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_58\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_59\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_60\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_61\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_62\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_63\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_64\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_65\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_66\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_67\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_68\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_69\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_70\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_71\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_72\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_73\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_74\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_75\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_76\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_77\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_78\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_79\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_80\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_81\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_82\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_83\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_84\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_85\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_86\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_87\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_88\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_89\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_90\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_91\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_92\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_93\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_94\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_95\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_96\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_97\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_98\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_99\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_100\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_101\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_102\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_103\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_104\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_105\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_106\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_107\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_108\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_109\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_110\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_111\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_112\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_113\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_114\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_115\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_116\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_117\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_118\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_119\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_120\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_121\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_122\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_123\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_124\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_125\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_126\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_127\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_128\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_129\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_130\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_131\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_132\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_133\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_134\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_135\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_136\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_137\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_138\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_139\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_140\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_141\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_142\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_143\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_144\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_145\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_146\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_147\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_148\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_149\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_150\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_151\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_152\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_153\"\n",
      "input: \"gradients/PartitionedCall_6_grad/PartitionedCall_6_154\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_ln_bx_dist_20219_23532\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "    File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"<ipython-input-20-2c4d78f41612>\", line 18, in <module>\n",
      "    gradients = test_grad(0)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 627, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\n",
      "    *args, **kwds))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 964, in wrapper\n",
      "    user_requested=True,\n",
      "    File \"<ipython-input-20-2c4d78f41612>\", line 14, in test_grad\n",
      "    jacobian = g.batch_jacobian(dist, graph.trainable_variables[0])\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1257, in batch_jacobian\n",
      "    parallel_iterations=parallel_iterations)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 198, in pfor\n",
      "    outputs = f()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 183, in f\n",
      "    return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 237, in _pfor_impl\n",
      "    loop_fn_outputs = loop_fn(loop_var)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1252, in loop_fn\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1048, in gradient\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\", line 77, in imperative_grad\n",
      "    compat.as_str(unconnected_gradients.value))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 841, in _backward_function\n",
      "    return self._rewrite_forward_and_call_backward(call_op, *args)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 760, in _rewrite_forward_and_call_backward\n",
      "    forward_function, backwards_function = self.forward_backward(len(doutputs))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 669, in forward_backward\n",
      "    forward, backward = self._construct_forward_backward(num_doutputs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 717, in _construct_forward_backward\n",
      "    func_graph=backwards_graph)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 707, in _backprop_function\n",
      "    src_graph=self._func_graph)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 669, in _GradientsHelper\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 336, in _MaybeCompile\n",
      "    return grad_fn()  # Exit early\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_util.py\", line 669, in <lambda>\n",
      "    lambda: grad_fn(op, *out_grads))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 796, in _rewrite_forward_and_call_backward\n",
      "    cleaned_doutputs, remapped_captures)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1760, in _call_flat\n",
      "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 627, in call\n",
      "    executor_type=executor_type)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 1180, in partitioned_call\n",
      "    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3258, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 595, in _create_op_internal\n",
      "    compute_device)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3327, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1791, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Got error while pfor was converting op name: \"loop_body/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradient_tape/Reshape\"\n",
      "input: \"loop_body/zeros_1\"\n",
      "input: \"PartitionedCall:3\"\n",
      "input: \"PartitionedCall:4\"\n",
      "input: \"PartitionedCall:5\"\n",
      "input: \"PartitionedCall:6\"\n",
      "input: \"PartitionedCall:7\"\n",
      "input: \"PartitionedCall:8\"\n",
      "input: \"PartitionedCall:9\"\n",
      "input: \"PartitionedCall:10\"\n",
      "input: \"PartitionedCall:11\"\n",
      "input: \"PartitionedCall:12\"\n",
      "input: \"PartitionedCall:13\"\n",
      "input: \"PartitionedCall:14\"\n",
      "input: \"PartitionedCall:15\"\n",
      "input: \"PartitionedCall:16\"\n",
      "input: \"PartitionedCall:17\"\n",
      "input: \"PartitionedCall:18\"\n",
      "input: \"PartitionedCall:19\"\n",
      "input: \"PartitionedCall:20\"\n",
      "input: \"PartitionedCall:21\"\n",
      "input: \"PartitionedCall:22\"\n",
      "input: \"PartitionedCall:23\"\n",
      "input: \"PartitionedCall:24\"\n",
      "input: \"PartitionedCall:25\"\n",
      "input: \"PartitionedCall:26\"\n",
      "input: \"PartitionedCall:27\"\n",
      "input: \"PartitionedCall:28\"\n",
      "input: \"PartitionedCall:29\"\n",
      "input: \"PartitionedCall:30\"\n",
      "input: \"PartitionedCall:31\"\n",
      "input: \"PartitionedCall:32\"\n",
      "input: \"PartitionedCall:33\"\n",
      "input: \"PartitionedCall:34\"\n",
      "input: \"PartitionedCall:35\"\n",
      "input: \"PartitionedCall:36\"\n",
      "input: \"PartitionedCall:37\"\n",
      "input: \"PartitionedCall:38\"\n",
      "input: \"PartitionedCall:39\"\n",
      "input: \"PartitionedCall:40\"\n",
      "input: \"PartitionedCall:41\"\n",
      "input: \"PartitionedCall:42\"\n",
      "input: \"PartitionedCall:43\"\n",
      "input: \"PartitionedCall:44\"\n",
      "input: \"PartitionedCall:45\"\n",
      "input: \"PartitionedCall:46\"\n",
      "input: \"PartitionedCall:47\"\n",
      "input: \"PartitionedCall:48\"\n",
      "input: \"PartitionedCall:49\"\n",
      "input: \"PartitionedCall:50\"\n",
      "input: \"PartitionedCall:51\"\n",
      "input: \"PartitionedCall:52\"\n",
      "input: \"PartitionedCall:53\"\n",
      "input: \"PartitionedCall:54\"\n",
      "input: \"PartitionedCall:55\"\n",
      "input: \"PartitionedCall:56\"\n",
      "input: \"PartitionedCall:57\"\n",
      "input: \"PartitionedCall:58\"\n",
      "input: \"PartitionedCall:59\"\n",
      "input: \"PartitionedCall:60\"\n",
      "input: \"PartitionedCall:61\"\n",
      "input: \"PartitionedCall:62\"\n",
      "input: \"PartitionedCall:63\"\n",
      "input: \"PartitionedCall:64\"\n",
      "input: \"PartitionedCall:65\"\n",
      "input: \"PartitionedCall:66\"\n",
      "input: \"PartitionedCall:67\"\n",
      "input: \"PartitionedCall:68\"\n",
      "input: \"PartitionedCall:69\"\n",
      "input: \"PartitionedCall:70\"\n",
      "input: \"PartitionedCall:71\"\n",
      "input: \"PartitionedCall:72\"\n",
      "input: \"PartitionedCall:73\"\n",
      "input: \"PartitionedCall:74\"\n",
      "input: \"PartitionedCall:75\"\n",
      "input: \"PartitionedCall:76\"\n",
      "input: \"PartitionedCall:77\"\n",
      "input: \"PartitionedCall:78\"\n",
      "input: \"PartitionedCall:79\"\n",
      "input: \"PartitionedCall:80\"\n",
      "input: \"PartitionedCall:81\"\n",
      "input: \"PartitionedCall:82\"\n",
      "input: \"PartitionedCall:83\"\n",
      "input: \"PartitionedCall:84\"\n",
      "input: \"PartitionedCall:85\"\n",
      "input: \"PartitionedCall:86\"\n",
      "input: \"PartitionedCall:87\"\n",
      "input: \"PartitionedCall:88\"\n",
      "input: \"PartitionedCall:89\"\n",
      "input: \"PartitionedCall:90\"\n",
      "input: \"PartitionedCall:91\"\n",
      "input: \"PartitionedCall:92\"\n",
      "input: \"PartitionedCall:93\"\n",
      "input: \"PartitionedCall:94\"\n",
      "input: \"PartitionedCall:95\"\n",
      "input: \"PartitionedCall:96\"\n",
      "input: \"PartitionedCall:97\"\n",
      "input: \"PartitionedCall:98\"\n",
      "input: \"PartitionedCall:99\"\n",
      "input: \"PartitionedCall:100\"\n",
      "input: \"PartitionedCall:101\"\n",
      "input: \"PartitionedCall:102\"\n",
      "input: \"PartitionedCall:103\"\n",
      "input: \"PartitionedCall:104\"\n",
      "input: \"PartitionedCall:105\"\n",
      "input: \"PartitionedCall:106\"\n",
      "input: \"PartitionedCall:107\"\n",
      "input: \"PartitionedCall:108\"\n",
      "input: \"PartitionedCall:109\"\n",
      "input: \"PartitionedCall:110\"\n",
      "input: \"PartitionedCall:111\"\n",
      "input: \"PartitionedCall:112\"\n",
      "input: \"PartitionedCall:113\"\n",
      "input: \"PartitionedCall:114\"\n",
      "input: \"PartitionedCall:115\"\n",
      "input: \"PartitionedCall:116\"\n",
      "input: \"PartitionedCall:117\"\n",
      "input: \"PartitionedCall:118\"\n",
      "input: \"PartitionedCall:119\"\n",
      "input: \"PartitionedCall:120\"\n",
      "input: \"PartitionedCall:121\"\n",
      "input: \"PartitionedCall:122\"\n",
      "input: \"PartitionedCall:123\"\n",
      "input: \"PartitionedCall:124\"\n",
      "input: \"PartitionedCall:125\"\n",
      "input: \"PartitionedCall:126\"\n",
      "input: \"PartitionedCall:127\"\n",
      "input: \"PartitionedCall:128\"\n",
      "input: \"PartitionedCall:129\"\n",
      "input: \"PartitionedCall:130\"\n",
      "input: \"PartitionedCall:131\"\n",
      "input: \"PartitionedCall:132\"\n",
      "input: \"PartitionedCall:133\"\n",
      "input: \"PartitionedCall:134\"\n",
      "input: \"PartitionedCall:135\"\n",
      "input: \"PartitionedCall:136\"\n",
      "input: \"PartitionedCall:137\"\n",
      "input: \"PartitionedCall:138\"\n",
      "input: \"PartitionedCall:139\"\n",
      "input: \"PartitionedCall:140\"\n",
      "input: \"PartitionedCall:141\"\n",
      "input: \"PartitionedCall:142\"\n",
      "input: \"PartitionedCall:143\"\n",
      "input: \"PartitionedCall:144\"\n",
      "input: \"PartitionedCall:145\"\n",
      "input: \"PartitionedCall:146\"\n",
      "input: \"PartitionedCall:147\"\n",
      "input: \"PartitionedCall:148\"\n",
      "input: \"PartitionedCall:149\"\n",
      "input: \"PartitionedCall:150\"\n",
      "input: \"PartitionedCall:151\"\n",
      "input: \"PartitionedCall:152\"\n",
      "input: \"PartitionedCall:153\"\n",
      "input: \"PartitionedCall:154\"\n",
      "input: \"PartitionedCall:155\"\n",
      "input: \"PartitionedCall:156\"\n",
      "input: \"PartitionedCall:157\"\n",
      "input: \"PartitionedCall:158\"\n",
      "input: \"PartitionedCall:159\"\n",
      "input: \"PartitionedCall:160\"\n",
      "input: \"PartitionedCall:161\"\n",
      "input: \"PartitionedCall:162\"\n",
      "input: \"PartitionedCall:163\"\n",
      "input: \"PartitionedCall:164\"\n",
      "input: \"PartitionedCall:165\"\n",
      "input: \"PartitionedCall:166\"\n",
      "input: \"PartitionedCall:167\"\n",
      "input: \"PartitionedCall:168\"\n",
      "input: \"PartitionedCall:169\"\n",
      "input: \"PartitionedCall:170\"\n",
      "input: \"PartitionedCall:171\"\n",
      "input: \"PartitionedCall:172\"\n",
      "input: \"PartitionedCall:173\"\n",
      "input: \"PartitionedCall:174\"\n",
      "input: \"PartitionedCall:175\"\n",
      "input: \"PartitionedCall:176\"\n",
      "input: \"PartitionedCall:177\"\n",
      "input: \"PartitionedCall:178\"\n",
      "input: \"PartitionedCall:179\"\n",
      "input: \"PartitionedCall:180\"\n",
      "input: \"PartitionedCall:181\"\n",
      "input: \"PartitionedCall:182\"\n",
      "input: \"PartitionedCall:183\"\n",
      "input: \"PartitionedCall:184\"\n",
      "input: \"PartitionedCall:185\"\n",
      "input: \"PartitionedCall:186\"\n",
      "input: \"PartitionedCall:187\"\n",
      "input: \"PartitionedCall:188\"\n",
      "input: \"PartitionedCall:189\"\n",
      "input: \"PartitionedCall:190\"\n",
      "input: \"PartitionedCall:191\"\n",
      "input: \"PartitionedCall:192\"\n",
      "input: \"PartitionedCall:193\"\n",
      "input: \"PartitionedCall:194\"\n",
      "input: \"PartitionedCall:195\"\n",
      "input: \"PartitionedCall:196\"\n",
      "input: \"PartitionedCall:197\"\n",
      "input: \"PartitionedCall:198\"\n",
      "input: \"PartitionedCall:199\"\n",
      "input: \"PartitionedCall:200\"\n",
      "input: \"PartitionedCall:201\"\n",
      "input: \"PartitionedCall:202\"\n",
      "input: \"PartitionedCall:203\"\n",
      "input: \"PartitionedCall:204\"\n",
      "input: \"PartitionedCall:205\"\n",
      "input: \"PartitionedCall:206\"\n",
      "input: \"PartitionedCall:207\"\n",
      "input: \"PartitionedCall:208\"\n",
      "input: \"PartitionedCall:209\"\n",
      "input: \"PartitionedCall:210\"\n",
      "input: \"PartitionedCall:211\"\n",
      "input: \"PartitionedCall:212\"\n",
      "input: \"PartitionedCall:213\"\n",
      "input: \"PartitionedCall:214\"\n",
      "input: \"PartitionedCall:215\"\n",
      "input: \"PartitionedCall:216\"\n",
      "input: \"PartitionedCall:217\"\n",
      "input: \"PartitionedCall:218\"\n",
      "input: \"PartitionedCall:219\"\n",
      "input: \"PartitionedCall:220\"\n",
      "input: \"PartitionedCall:221\"\n",
      "input: \"PartitionedCall:222\"\n",
      "input: \"PartitionedCall:223\"\n",
      "input: \"PartitionedCall:224\"\n",
      "input: \"PartitionedCall:225\"\n",
      "input: \"PartitionedCall:226\"\n",
      "input: \"PartitionedCall:227\"\n",
      "input: \"PartitionedCall:228\"\n",
      "input: \"PartitionedCall:229\"\n",
      "input: \"PartitionedCall:230\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_calc_all_27983_28484\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "with inputs (<tf.Tensor 'gradient_tape/Reshape:0' shape=(50, 28, 1) dtype=float32>, <tf.Tensor 'loop_body/zeros_1:0' shape=(50, 28, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:3' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:4' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:5' shape=(50, 21, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:6' shape=(50, 21, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:7' shape=(50, 21, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:8' shape=(50, 21, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:9' shape=(50, 21, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:10' shape=(50, 21, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:11' shape=(50, 21, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:12' shape=(50, 21, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:13' shape=(1050, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:14' shape=(50, 21, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:15' shape=(50, 21, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:16' shape=(1050, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:17' shape=(50, 21, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:18' shape=(50, 21, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:19' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:20' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:21' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:22' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:23' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:24' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:25' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:26' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:27' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:28' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:29' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:30' shape=(4200, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:31' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:32' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:33' shape=(50, 84, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:34' shape=(50, 84, 2, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:35' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:36' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:37' shape=(4200, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:38' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:39' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:40' shape=(50, 84, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:41' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:42' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:43' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:44' shape=(50, 84, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:45' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:46' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:47' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:48' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:49' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:50' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:51' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:52' shape=(50, 21, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:53' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:54' shape=(50, 21, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:55' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:56' shape=(5,) dtype=int32>, <tf.Tensor 'PartitionedCall:57' shape=(50, 21, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:58' shape=(50, 21, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:59' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:60' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:61' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:62' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:63' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:64' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:65' shape=(4,) dtype=int32>, <tf.Tensor 'PartitionedCall:66' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:67' shape=(4,) dtype=int32>, <tf.Tensor 'PartitionedCall:68' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:69' shape=(3,) dtype=int32>, <tf.Tensor 'PartitionedCall:70' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:71' shape=(3,) dtype=int32>, <tf.Tensor 'PartitionedCall:72' shape=(1, 21, 9, 2, 1, 4) dtype=float32>, <tf.Tensor 'PartitionedCall:73' shape=(50, 21, 9, 1, 4, 4) dtype=float32>, <tf.Tensor 'PartitionedCall:74' shape=(1, 21, 9, 2, 1, 4) dtype=float32>, <tf.Tensor 'PartitionedCall:75' shape=(6,) dtype=int32>, <tf.Tensor 'PartitionedCall:76' shape=(50, 7, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:77' shape=(350, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:78' shape=(350, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:79' shape=(350, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:80' shape=(350, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:81' shape=(350, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:82' shape=(350, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:83' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:84' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:85' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:86' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:87' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:88' shape=(50, 14, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:89' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:90' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:91' shape=(50, 14, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:92' shape=(700, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:93' shape=(700, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:94' shape=(700, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:95' shape=(700, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:96' shape=(700, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:97' shape=(700, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:98' shape=(50, 14, 6, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:99' shape=(50, 168, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:100' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:101' shape=(50, 168, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:102' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:103' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:104' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:105' shape=(50, 168, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:106' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:107' shape=(8400, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:108' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:109' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:110' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:111' shape=(50, 168, 2, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:112' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:113' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:114' shape=(8400, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:115' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:116' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:117' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:118' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:119' shape=(50, 168, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:120' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:121' shape=(50, 168, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:122' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:123' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:124' shape=(50, 168, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:125' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:126' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:127' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:128' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:129' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:130' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:131' shape=(5,) dtype=int32>, <tf.Tensor 'PartitionedCall:132' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:133' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:134' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:135' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:136' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:137' shape=(12,) dtype=int32>, <tf.Tensor 'PartitionedCall:138' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:139' shape=(12,) dtype=int32>, <tf.Tensor 'PartitionedCall:140' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:141' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:142' shape=(50, 14, 6, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:143' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:144' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:145' shape=(50, 14, 6, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:146' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:147' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:148' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:149' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:150' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:151' shape=(24,) dtype=int32>, <tf.Tensor 'PartitionedCall:152' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:153' shape=(24,) dtype=int32>, <tf.Tensor 'PartitionedCall:154' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:155' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:156' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:157' shape=(50, 84, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:158' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:159' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:160' shape=(50, 84, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:161' shape=(4200, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:162' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:163' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:164' shape=(4200, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:165' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:166' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:167' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:168' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:169' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:170' shape=(50, 336, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:171' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:172' shape=(50, 336, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:173' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:174' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:175' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:176' shape=(50, 336, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:177' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:178' shape=(16800, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:179' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:180' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:181' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:182' shape=(50, 336, 2, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:183' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:184' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:185' shape=(16800, 3) dtype=int64>, <tf.Tensor 'PartitionedCall:186' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:187' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:188' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:189' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:190' shape=(50, 336, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:191' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:192' shape=(50, 336, 2, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:193' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:194' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:195' shape=(50, 336, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:196' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:197' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:198' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:199' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:200' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:201' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:202' shape=(50, 84, 1, 1) dtype=float32>, <tf.Tensor 'PartitionedCall:203' shape=() dtype=float32>, <tf.Tensor 'PartitionedCall:204' shape=(5,) dtype=int32>, <tf.Tensor 'PartitionedCall:205' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:206' shape=(50, 84, 1, 3) dtype=float32>, <tf.Tensor 'PartitionedCall:207' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:208' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:209' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:210' shape=(1,) dtype=int32>, <tf.Tensor 'PartitionedCall:211' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:212' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:213' shape=(4,) dtype=int32>, <tf.Tensor 'PartitionedCall:214' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:215' shape=(4,) dtype=int32>, <tf.Tensor 'PartitionedCall:216' shape=(5,) dtype=int32>, <tf.Tensor 'PartitionedCall:217' shape=(5,) dtype=int32>, <tf.Tensor 'PartitionedCall:218' shape=(5,) dtype=int32>, <tf.Tensor 'PartitionedCall:219' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:220' shape=(12,) dtype=int32>, <tf.Tensor 'PartitionedCall:221' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:222' shape=(12,) dtype=int32>, <tf.Tensor 'PartitionedCall:223' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:224' shape=(3,) dtype=int32>, <tf.Tensor 'PartitionedCall:225' shape=() dtype=int32>, <tf.Tensor 'PartitionedCall:226' shape=(3,) dtype=int32>, <tf.Tensor 'PartitionedCall:227' shape=(1, 7, 9, 2, 1, 4) dtype=float32>, <tf.Tensor 'PartitionedCall:228' shape=(50, 7, 9, 1, 4, 4) dtype=float32>, <tf.Tensor 'PartitionedCall:229' shape=(1, 7, 9, 8, 1, 4) dtype=float32>, <tf.Tensor 'PartitionedCall:230' shape=(6,) dtype=int32>)\n",
      ", converted inputs [WrappedTensor(t=<tf.Tensor 'gradient_tape/Reshape/pfor/Reshape:0' shape=(28, 50, 28, 1) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/zeros_1:0' shape=(50, 28, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:3' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:4' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:5' shape=(50, 21, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:6' shape=(50, 21, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:7' shape=(50, 21, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:8' shape=(50, 21, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:9' shape=(50, 21, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:10' shape=(50, 21, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:11' shape=(50, 21, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:12' shape=(50, 21, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:13' shape=(1050, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:14' shape=(50, 21, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:15' shape=(50, 21, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:16' shape=(1050, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:17' shape=(50, 21, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:18' shape=(50, 21, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:19' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:20' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:21' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:22' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:23' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:24' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:25' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:26' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:27' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:28' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:29' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:30' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:31' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:32' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:33' shape=(50, 84, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:34' shape=(50, 84, 2, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:35' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:36' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:37' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:38' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:39' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:40' shape=(50, 84, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:41' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:42' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:43' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:44' shape=(50, 84, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:45' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:46' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:47' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:48' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:49' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:50' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:51' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:52' shape=(50, 21, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:53' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:54' shape=(50, 21, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:55' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:56' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:57' shape=(50, 21, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:58' shape=(50, 21, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:59' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:60' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:61' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:62' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:63' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:64' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:65' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:66' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:67' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:68' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:69' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:70' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:71' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:72' shape=(1, 21, 9, 2, 1, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:73' shape=(50, 21, 9, 1, 4, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:74' shape=(1, 21, 9, 2, 1, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:75' shape=(6,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:76' shape=(50, 7, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:77' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:78' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:79' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:80' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:81' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:82' shape=(350, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:83' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:84' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:85' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:86' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:87' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:88' shape=(50, 14, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:89' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:90' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:91' shape=(50, 14, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:92' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:93' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:94' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:95' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:96' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:97' shape=(700, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:98' shape=(50, 14, 6, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:99' shape=(50, 168, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:100' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:101' shape=(50, 168, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:102' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:103' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:104' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:105' shape=(50, 168, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:106' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:107' shape=(8400, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:108' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:109' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:110' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:111' shape=(50, 168, 2, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:112' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:113' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:114' shape=(8400, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:115' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:116' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:117' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:118' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:119' shape=(50, 168, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:120' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:121' shape=(50, 168, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:122' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:123' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:124' shape=(50, 168, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:125' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:126' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:127' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:128' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:129' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:130' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:131' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:132' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:133' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:134' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:135' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:136' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:137' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:138' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:139' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:140' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:141' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:142' shape=(50, 14, 6, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:143' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:144' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:145' shape=(50, 14, 6, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:146' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:147' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:148' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:149' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:150' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:151' shape=(24,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:152' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:153' shape=(24,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:154' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:155' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:156' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:157' shape=(50, 84, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:158' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:159' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:160' shape=(50, 84, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:161' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:162' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:163' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:164' shape=(4200, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:165' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:166' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:167' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:168' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:169' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:170' shape=(50, 336, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:171' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:172' shape=(50, 336, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:173' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:174' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:175' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:176' shape=(50, 336, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:177' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:178' shape=(16800, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:179' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:180' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:181' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:182' shape=(50, 336, 2, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:183' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:184' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:185' shape=(16800, 3) dtype=int64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:186' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:187' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:188' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:189' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:190' shape=(50, 336, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:191' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:192' shape=(50, 336, 2, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:193' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:194' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:195' shape=(50, 336, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:196' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:197' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:198' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:199' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:200' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:201' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:202' shape=(50, 84, 1, 1) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:203' shape=() dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:204' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:205' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:206' shape=(50, 84, 1, 3) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:207' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:208' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:209' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:210' shape=(1,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:211' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:212' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:213' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:214' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:215' shape=(4,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:216' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:217' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:218' shape=(5,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:219' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:220' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:221' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:222' shape=(12,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:223' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:224' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:225' shape=() dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:226' shape=(3,) dtype=int32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:227' shape=(1, 7, 9, 2, 1, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:228' shape=(50, 7, 9, 1, 4, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:229' shape=(1, 7, 9, 8, 1, 4) dtype=float32>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'PartitionedCall:230' shape=(6,) dtype=int32>, is_stacked=False, is_sparse_stacked=False)]\n",
      "in user code:\n",
      "\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n",
      "        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n",
      "        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n",
      "        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n",
      "        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n",
      "        wrapped(_sys.argv)\n",
      "    /home/junsu/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n",
      "        name, value, suggestions=suggestions)\n",
      "\n",
      "    UnrecognizedFlagError: Unknown command line flag 'f'\n",
      "\n",
      "Here are the pfor conversion stack traces:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:name: \"loop_body/PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"gradient_tape/Reshape\"\n",
      "input: \"loop_body/zeros_1\"\n",
      "input: \"PartitionedCall:3\"\n",
      "input: \"PartitionedCall:4\"\n",
      "input: \"PartitionedCall:5\"\n",
      "input: \"PartitionedCall:6\"\n",
      "input: \"PartitionedCall:7\"\n",
      "input: \"PartitionedCall:8\"\n",
      "input: \"PartitionedCall:9\"\n",
      "input: \"PartitionedCall:10\"\n",
      "input: \"PartitionedCall:11\"\n",
      "input: \"PartitionedCall:12\"\n",
      "input: \"PartitionedCall:13\"\n",
      "input: \"PartitionedCall:14\"\n",
      "input: \"PartitionedCall:15\"\n",
      "input: \"PartitionedCall:16\"\n",
      "input: \"PartitionedCall:17\"\n",
      "input: \"PartitionedCall:18\"\n",
      "input: \"PartitionedCall:19\"\n",
      "input: \"PartitionedCall:20\"\n",
      "input: \"PartitionedCall:21\"\n",
      "input: \"PartitionedCall:22\"\n",
      "input: \"PartitionedCall:23\"\n",
      "input: \"PartitionedCall:24\"\n",
      "input: \"PartitionedCall:25\"\n",
      "input: \"PartitionedCall:26\"\n",
      "input: \"PartitionedCall:27\"\n",
      "input: \"PartitionedCall:28\"\n",
      "input: \"PartitionedCall:29\"\n",
      "input: \"PartitionedCall:30\"\n",
      "input: \"PartitionedCall:31\"\n",
      "input: \"PartitionedCall:32\"\n",
      "input: \"PartitionedCall:33\"\n",
      "input: \"PartitionedCall:34\"\n",
      "input: \"PartitionedCall:35\"\n",
      "input: \"PartitionedCall:36\"\n",
      "input: \"PartitionedCall:37\"\n",
      "input: \"PartitionedCall:38\"\n",
      "input: \"PartitionedCall:39\"\n",
      "input: \"PartitionedCall:40\"\n",
      "input: \"PartitionedCall:41\"\n",
      "input: \"PartitionedCall:42\"\n",
      "input: \"PartitionedCall:43\"\n",
      "input: \"PartitionedCall:44\"\n",
      "input: \"PartitionedCall:45\"\n",
      "input: \"PartitionedCall:46\"\n",
      "input: \"PartitionedCall:47\"\n",
      "input: \"PartitionedCall:48\"\n",
      "input: \"PartitionedCall:49\"\n",
      "input: \"PartitionedCall:50\"\n",
      "input: \"PartitionedCall:51\"\n",
      "input: \"PartitionedCall:52\"\n",
      "input: \"PartitionedCall:53\"\n",
      "input: \"PartitionedCall:54\"\n",
      "input: \"PartitionedCall:55\"\n",
      "input: \"PartitionedCall:56\"\n",
      "input: \"PartitionedCall:57\"\n",
      "input: \"PartitionedCall:58\"\n",
      "input: \"PartitionedCall:59\"\n",
      "input: \"PartitionedCall:60\"\n",
      "input: \"PartitionedCall:61\"\n",
      "input: \"PartitionedCall:62\"\n",
      "input: \"PartitionedCall:63\"\n",
      "input: \"PartitionedCall:64\"\n",
      "input: \"PartitionedCall:65\"\n",
      "input: \"PartitionedCall:66\"\n",
      "input: \"PartitionedCall:67\"\n",
      "input: \"PartitionedCall:68\"\n",
      "input: \"PartitionedCall:69\"\n",
      "input: \"PartitionedCall:70\"\n",
      "input: \"PartitionedCall:71\"\n",
      "input: \"PartitionedCall:72\"\n",
      "input: \"PartitionedCall:73\"\n",
      "input: \"PartitionedCall:74\"\n",
      "input: \"PartitionedCall:75\"\n",
      "input: \"PartitionedCall:76\"\n",
      "input: \"PartitionedCall:77\"\n",
      "input: \"PartitionedCall:78\"\n",
      "input: \"PartitionedCall:79\"\n",
      "input: \"PartitionedCall:80\"\n",
      "input: \"PartitionedCall:81\"\n",
      "input: \"PartitionedCall:82\"\n",
      "input: \"PartitionedCall:83\"\n",
      "input: \"PartitionedCall:84\"\n",
      "input: \"PartitionedCall:85\"\n",
      "input: \"PartitionedCall:86\"\n",
      "input: \"PartitionedCall:87\"\n",
      "input: \"PartitionedCall:88\"\n",
      "input: \"PartitionedCall:89\"\n",
      "input: \"PartitionedCall:90\"\n",
      "input: \"PartitionedCall:91\"\n",
      "input: \"PartitionedCall:92\"\n",
      "input: \"PartitionedCall:93\"\n",
      "input: \"PartitionedCall:94\"\n",
      "input: \"PartitionedCall:95\"\n",
      "input: \"PartitionedCall:96\"\n",
      "input: \"PartitionedCall:97\"\n",
      "input: \"PartitionedCall:98\"\n",
      "input: \"PartitionedCall:99\"\n",
      "input: \"PartitionedCall:100\"\n",
      "input: \"PartitionedCall:101\"\n",
      "input: \"PartitionedCall:102\"\n",
      "input: \"PartitionedCall:103\"\n",
      "input: \"PartitionedCall:104\"\n",
      "input: \"PartitionedCall:105\"\n",
      "input: \"PartitionedCall:106\"\n",
      "input: \"PartitionedCall:107\"\n",
      "input: \"PartitionedCall:108\"\n",
      "input: \"PartitionedCall:109\"\n",
      "input: \"PartitionedCall:110\"\n",
      "input: \"PartitionedCall:111\"\n",
      "input: \"PartitionedCall:112\"\n",
      "input: \"PartitionedCall:113\"\n",
      "input: \"PartitionedCall:114\"\n",
      "input: \"PartitionedCall:115\"\n",
      "input: \"PartitionedCall:116\"\n",
      "input: \"PartitionedCall:117\"\n",
      "input: \"PartitionedCall:118\"\n",
      "input: \"PartitionedCall:119\"\n",
      "input: \"PartitionedCall:120\"\n",
      "input: \"PartitionedCall:121\"\n",
      "input: \"PartitionedCall:122\"\n",
      "input: \"PartitionedCall:123\"\n",
      "input: \"PartitionedCall:124\"\n",
      "input: \"PartitionedCall:125\"\n",
      "input: \"PartitionedCall:126\"\n",
      "input: \"PartitionedCall:127\"\n",
      "input: \"PartitionedCall:128\"\n",
      "input: \"PartitionedCall:129\"\n",
      "input: \"PartitionedCall:130\"\n",
      "input: \"PartitionedCall:131\"\n",
      "input: \"PartitionedCall:132\"\n",
      "input: \"PartitionedCall:133\"\n",
      "input: \"PartitionedCall:134\"\n",
      "input: \"PartitionedCall:135\"\n",
      "input: \"PartitionedCall:136\"\n",
      "input: \"PartitionedCall:137\"\n",
      "input: \"PartitionedCall:138\"\n",
      "input: \"PartitionedCall:139\"\n",
      "input: \"PartitionedCall:140\"\n",
      "input: \"PartitionedCall:141\"\n",
      "input: \"PartitionedCall:142\"\n",
      "input: \"PartitionedCall:143\"\n",
      "input: \"PartitionedCall:144\"\n",
      "input: \"PartitionedCall:145\"\n",
      "input: \"PartitionedCall:146\"\n",
      "input: \"PartitionedCall:147\"\n",
      "input: \"PartitionedCall:148\"\n",
      "input: \"PartitionedCall:149\"\n",
      "input: \"PartitionedCall:150\"\n",
      "input: \"PartitionedCall:151\"\n",
      "input: \"PartitionedCall:152\"\n",
      "input: \"PartitionedCall:153\"\n",
      "input: \"PartitionedCall:154\"\n",
      "input: \"PartitionedCall:155\"\n",
      "input: \"PartitionedCall:156\"\n",
      "input: \"PartitionedCall:157\"\n",
      "input: \"PartitionedCall:158\"\n",
      "input: \"PartitionedCall:159\"\n",
      "input: \"PartitionedCall:160\"\n",
      "input: \"PartitionedCall:161\"\n",
      "input: \"PartitionedCall:162\"\n",
      "input: \"PartitionedCall:163\"\n",
      "input: \"PartitionedCall:164\"\n",
      "input: \"PartitionedCall:165\"\n",
      "input: \"PartitionedCall:166\"\n",
      "input: \"PartitionedCall:167\"\n",
      "input: \"PartitionedCall:168\"\n",
      "input: \"PartitionedCall:169\"\n",
      "input: \"PartitionedCall:170\"\n",
      "input: \"PartitionedCall:171\"\n",
      "input: \"PartitionedCall:172\"\n",
      "input: \"PartitionedCall:173\"\n",
      "input: \"PartitionedCall:174\"\n",
      "input: \"PartitionedCall:175\"\n",
      "input: \"PartitionedCall:176\"\n",
      "input: \"PartitionedCall:177\"\n",
      "input: \"PartitionedCall:178\"\n",
      "input: \"PartitionedCall:179\"\n",
      "input: \"PartitionedCall:180\"\n",
      "input: \"PartitionedCall:181\"\n",
      "input: \"PartitionedCall:182\"\n",
      "input: \"PartitionedCall:183\"\n",
      "input: \"PartitionedCall:184\"\n",
      "input: \"PartitionedCall:185\"\n",
      "input: \"PartitionedCall:186\"\n",
      "input: \"PartitionedCall:187\"\n",
      "input: \"PartitionedCall:188\"\n",
      "input: \"PartitionedCall:189\"\n",
      "input: \"PartitionedCall:190\"\n",
      "input: \"PartitionedCall:191\"\n",
      "input: \"PartitionedCall:192\"\n",
      "input: \"PartitionedCall:193\"\n",
      "input: \"PartitionedCall:194\"\n",
      "input: \"PartitionedCall:195\"\n",
      "input: \"PartitionedCall:196\"\n",
      "input: \"PartitionedCall:197\"\n",
      "input: \"PartitionedCall:198\"\n",
      "input: \"PartitionedCall:199\"\n",
      "input: \"PartitionedCall:200\"\n",
      "input: \"PartitionedCall:201\"\n",
      "input: \"PartitionedCall:202\"\n",
      "input: \"PartitionedCall:203\"\n",
      "input: \"PartitionedCall:204\"\n",
      "input: \"PartitionedCall:205\"\n",
      "input: \"PartitionedCall:206\"\n",
      "input: \"PartitionedCall:207\"\n",
      "input: \"PartitionedCall:208\"\n",
      "input: \"PartitionedCall:209\"\n",
      "input: \"PartitionedCall:210\"\n",
      "input: \"PartitionedCall:211\"\n",
      "input: \"PartitionedCall:212\"\n",
      "input: \"PartitionedCall:213\"\n",
      "input: \"PartitionedCall:214\"\n",
      "input: \"PartitionedCall:215\"\n",
      "input: \"PartitionedCall:216\"\n",
      "input: \"PartitionedCall:217\"\n",
      "input: \"PartitionedCall:218\"\n",
      "input: \"PartitionedCall:219\"\n",
      "input: \"PartitionedCall:220\"\n",
      "input: \"PartitionedCall:221\"\n",
      "input: \"PartitionedCall:222\"\n",
      "input: \"PartitionedCall:223\"\n",
      "input: \"PartitionedCall:224\"\n",
      "input: \"PartitionedCall:225\"\n",
      "input: \"PartitionedCall:226\"\n",
      "input: \"PartitionedCall:227\"\n",
      "input: \"PartitionedCall:228\"\n",
      "input: \"PartitionedCall:229\"\n",
      "input: \"PartitionedCall:230\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT64\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0002\\002J\\0008\\001\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference___backward_calc_all_27983_28484\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "created at:\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "    File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n",
      "    self.io_loop.start()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "    File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "    File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"<ipython-input-20-2c4d78f41612>\", line 18, in <module>\n",
      "    gradients = test_grad(0)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 627, in _call\n",
      "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\n",
      "    *args, **kwds))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\n",
      "    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\n",
      "    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 964, in wrapper\n",
      "    user_requested=True,\n",
      "    File \"<ipython-input-20-2c4d78f41612>\", line 14, in test_grad\n",
      "    jacobian = g.batch_jacobian(dist, graph.trainable_variables[0])\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1257, in batch_jacobian\n",
      "    parallel_iterations=parallel_iterations)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 198, in pfor\n",
      "    outputs = f()\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 183, in f\n",
      "    return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py\", line 237, in _pfor_impl\n",
      "    loop_fn_outputs = loop_fn(loop_var)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1252, in loop_fn\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\", line 1048, in gradient\n",
      "    unconnected_gradients=unconnected_gradients)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\", line 77, in imperative_grad\n",
      "    compat.as_str(unconnected_gradients.value))\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 841, in _backward_function\n",
      "    return self._rewrite_forward_and_call_backward(call_op, *args)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 796, in _rewrite_forward_and_call_backward\n",
      "    cleaned_doutputs, remapped_captures)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 1760, in _call_flat\n",
      "    flat_outputs = forward_function.call(ctx, args_with_tangents)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\", line 627, in call\n",
      "    executor_type=executor_type)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 1180, in partitioned_call\n",
      "    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3258, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\", line 595, in _create_op_internal\n",
      "    compute_device)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3327, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "    File \"/home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1791, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    },
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    <ipython-input-20-2c4d78f41612>:14 test_grad  *\n        jacobian = g.batch_jacobian(dist, graph.trainable_variables[0])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n        wrapped(_sys.argv)\n    /home/junsu/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2c4d78f41612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     bjac = g.batch_jacobian(dist, graph.trainable_variables[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     return bjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    <ipython-input-20-2c4d78f41612>:14 test_grad  *\n        jacobian = g.batch_jacobian(dist, graph.trainable_variables[0])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *\n        [converter._convert_helper(x).t for x in func._func_graph_outputs])\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1457 _convert_helper  **\n        if flags.FLAGS.op_conversion_fallback_to_while_loop:\n    /home/junsu/.local/lib/python3.6/site-packages/tensorflow/python/platform/flags.py:85 __getattr__\n        wrapped(_sys.argv)\n    /home/junsu/.local/lib/python3.6/site-packages/absl/flags/_flagvalues.py:633 __call__\n        name, value, suggestions=suggestions)\n\n    UnrecognizedFlagError: Unknown command line flag 'f'\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_grad(res):\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        T_all, Tbo_all = graph(None)\n",
    "        Tbo_all_res = tf.reshape(Tbo_all, (graph.N_sim, 1, graph.num_object, 1, 4,4))\n",
    "        dist, flag, mask = graph.dcal.calc_all(Tbo_all_res)\n",
    "#         dist = dist*mask\n",
    "#         loss = [tf.gather(dist, i_sim) for i_sim in range(N_sim)]\n",
    "    #     loss = K.sum(dist[6])\n",
    "    # Variables to update, i.e. trainable variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    jacobian = g.batch_jacobian(dist, graph.trainable_variables[0])\n",
    "    return K.sum(jacobian)\n",
    "#     bjac = g.batch_jacobian(dist, graph.trainable_variables[0])\n",
    "#     return bjac\n",
    "gradients = test_grad(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ tf.function\n",
    "def loop_grad():\n",
    "    N_loop=100\n",
    "    res = tf.while_loop(\n",
    "        lambda value: True, test_grad, (tf.constant(0.0),), \n",
    "        parallel_iterations=10, maximum_iterations=N_loop\n",
    "    )\n",
    "    return res\n",
    "loop_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtimer.reset()\n",
    "gtimer.tic(\"func\")\n",
    "jacobian = loop_grad()\n",
    "gtimer.toc(\"func\")\n",
    "# gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "\n",
    "# # Update W and b following gradients.\n",
    "gtimer.tic(\"apply\")\n",
    "# graph.optimizer.apply_gradients(zip(gradients, graph.trainable_variables))\n",
    "gtimer.toc(\"apply\")\n",
    "print(gtimer)\n",
    "# print(gradients.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,0.00)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_vec = []\n",
    "Q_list = [list(map(lambda x: x.numpy(), graph.get_Q()))]\n",
    "# Tbo_all_list = [np.array([[gframe_dict[gitem.name].Toff for gitem in gitem_list]]*N_sim)]\n",
    "N_iter = 100\n",
    "# Run training for the given number of steps.\n",
    "Qtar, binQ, Ttar, binT = (np.zeros((N_sim, N_joints), dtype='float32'), np.zeros(N_sim, dtype='float32'),\n",
    "                      np.array([Ttar_]*N_sim), np.ones(N_sim, dtype='float32'))\n",
    "dist_list = []\n",
    "loss_list = []\n",
    "jl_loss_list = []\n",
    "jc_loss_list = []\n",
    "fc_loss_list = []\n",
    "cl_loss_list = []\n",
    "gradients_list = []\n",
    "gtimer.reset()\n",
    "for _ in range(N_iter):\n",
    "    # Run the optimization to update W and b values.\n",
    "    T_all, Tbo_all = graph(None)\n",
    "    dist_list += [K.min(graph.test_collision(T_all, Tbo_all)[0]).numpy()]\n",
    "    jl_loss = graph.calc_joint_limit()\n",
    "    jc_loss = graph.joint_constraint((Qtar, binQ))\n",
    "    fc_loss = graph.frame_constraint((T_all[:,-1,:,:],Ttar, binT))\n",
    "    cl_loss = graph.calc_collision_loss(T_all, Tbo_all)\n",
    "    gtimer.tic(\"update\")\n",
    "    loss = graph.update_once(Qtar, binQ, Ttar, binT, max_gradient=10)\n",
    "#     max_gradient=10\n",
    "\n",
    "#     with tf.GradientTape() as g:\n",
    "#         # Forward pass.\n",
    "#         loss = graph.forward(Qtar, binQ, Ttar, binT)\n",
    "\n",
    "#     # Variables to update, i.e. trainable variables.\n",
    "#     trainable_variables = graph.trainable_variables\n",
    "\n",
    "#     # Compute gradients.\n",
    "#     gradients = g.gradient(loss, trainable_variables)\n",
    "#     gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "\n",
    "#     # Update W and b following gradients.\n",
    "#     graph.optimizer.apply_gradients(zip(gradients, graph.trainable_variables))\n",
    "    gtimer.toc(\"update\")\n",
    "    gtimer.tic(\"record\")\n",
    "    Q_list += [graph.get_Q().numpy()]\n",
    "    loss_list += [loss]\n",
    "#     gradients_list += [gradients]\n",
    "    jl_loss_list += [jl_loss]\n",
    "    jc_loss_list += [jc_loss]\n",
    "    fc_loss_list += [fc_loss]\n",
    "    cl_loss_list += [cl_loss]\n",
    "    gtimer.toc(\"record\")\n",
    "    if isnan(dist_list[-1]) or dist_list[-1]<0:\n",
    "        break\n",
    "gtimer.print_time_log()\n",
    "print(\"loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_all = np.array(Q_list)\n",
    "Q_all_i = np.array([Q_all[i_iter, i_sim,:] for i_iter in range(len(Q_list))])\n",
    "plt.plot(Q_all_i,'-o')\n",
    "plt.plot(Q_all_i[1:,:]-Q_all_i[:-1,:],'-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dist_list, label=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list, label=\"total\")\n",
    "plt.plot(np.multiply(jl_loss_list, graph.alpha_jl), label=\"joint limit\")\n",
    "plt.plot(np.multiply(jc_loss_list, graph.alpha_jc), label=\"joint target\")\n",
    "plt.plot(np.multiply(fc_loss_list, graph.alpha_fc), label=\"frame target\")\n",
    "plt.plot(np.multiply(cl_loss_list, graph.alpha_cl), label=\"collision dist\")\n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "# axes.set_ylim([-1e1,5e1])\n",
    "# axes.set_xlim([0,1e1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show rviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Q_[0]\n",
    "gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "pose_list = [q[2:-1]]\n",
    "gframevec_list = [gframevec]\n",
    "show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_sim in range(1): # N_sim):\n",
    "    for i_iter in range(0,len(Q_list)):\n",
    "        q = Q_list[i_iter][i_sim]\n",
    "        gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "        pose_list = [q[2:-1]]\n",
    "        gframevec_list = [gframevec]\n",
    "        show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)\n",
    "        time.sleep(10e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision error case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_error = np.loadtxt(\"Q_error.csv\",delimiter=\",\",dtype=np.float32)\n",
    "graph.assign_Q(Q_error)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "\n",
    "T_all, Tbo_all = graph(None)\n",
    "dist = K.min(graph.test_collision(T_all, Tbo_all)[0]).numpy()\n",
    "cl_loss = graph.calc_collision_loss(T_all, Tbo_all)\n",
    "print(\"dist: {}\".format(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Q_error[0]\n",
    "gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "pose_list = [q[2:-1]]\n",
    "gframevec_list = [gframevec]\n",
    "show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sub = fig.add_subplot(1,1,1,projection=\"3d\")\n",
    "sub.plot(x,y,z)\n",
    "sub.set_xlabel('x')\n",
    "sub.set_ylabel('y')\n",
    "sub.set_zlabel('z')\n",
    "\n",
    "sub.view_init(elev=0., azim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
