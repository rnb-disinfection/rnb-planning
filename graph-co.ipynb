{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.tf_transform import *\n",
    "from pkg.tf_robot import *\n",
    "from pkg.constraint import *\n",
    "from pkg.info import *\n",
    "from pkg.tf_utils import *\n",
    "from pkg.rotation_utils import *\n",
    "from pkg.utils import *\n",
    "from pkg.ur10 import *\n",
    "from pkg.geometry import *\n",
    "from pkg.collision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load urdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urdf_parser_py.urdf import URDF\n",
    "from pkg.ur10 import URDF_PATH, JOINT_NAMES, LINK_NAMES, ZERO_JOINT_POSE\n",
    "from pkg.joint_utils import *\n",
    "urdf_content = URDF.from_xml_file(URDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_names = LINK_NAMES\n",
    "base_name = LINK_NAMES[0]\n",
    "joint_names = JOINT_NAMES\n",
    "link_info_list = get_link_info_list(link_names, urdf_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.ros_rviz import *\n",
    "pub, joints, rate = get_publisher(JOINT_NAMES)\n",
    "\n",
    "gitem_list, gframe_dict= get_link_items_offsets(color=(0,1,0,0.5), display=True)\n",
    "gitem_list += [\n",
    "    GeometryItem(name='box1', gtype=GeoType.BOX, dims=[0.1,0.1,0.1], color=(0,1,0,1), display=True, collision=True)\n",
    "]\n",
    "gframe_dict.update({\"box1\":GeometryFrame(SE3(Rot_zyx(0,0,0),(0.5,0,0)), \"world\")\n",
    "                   })\n",
    "marker_list = set_markers(gitem_list, gframe_dict, urdf_content)\n",
    "show_motion([np.array([0]*6)], marker_list, \n",
    "            [[gframe_dict[gitem.name] for gitem in gitem_list]], \n",
    "            pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacent_links(link_name, urdf_content):\n",
    "    adjacent_links = [link_name]\n",
    "    for k, v in urdf_content.joint_map.items():\n",
    "        if v.parent == link_name:\n",
    "            adjacent_links += [v.child]\n",
    "        if v.child == link_name:\n",
    "            adjacent_links += [v.parent]\n",
    "    return list(set(adjacent_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectLayer(layers.Layer):\n",
    "    def __init__(self, gitem, N_sim, *args, **kwargs):\n",
    "        self.gitem, self.N_sim = gitem, N_sim\n",
    "        super(ObjectLayer, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def set_frame(self, Toff_list, link_idx_list, N_link):\n",
    "        self.Toff_list = tf.constant(Toff_list) # (N_sim, 4,4)\n",
    "        self.link_one_hot = tf.reshape(tf.one_hot(link_idx_list, N_link), (N_sim,N_link,1,1)) # (N_sim, N_link)\n",
    "        \n",
    "    # 변수를 만듭니다.\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "    \n",
    "    @tf.function\n",
    "    def get_vertice(self):\n",
    "        return self.vertice\n",
    "\n",
    "    # call 메서드가 그래프 모드에서 사용되면\n",
    "    # training 변수는 텐서가 됩니다.\n",
    "    @tf.function\n",
    "    def call(self, input=None):\n",
    "        T_all = input # (N_sim, N_link, 4,4)\n",
    "        T_act = K.sum(T_all*self.link_one_hot, axis=1) # (N_sim, 4,4)\n",
    "        T_bo = tf.matmul(T_act, self.Toff_list) # (N_sim, 4,4)\n",
    "        return T_bo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphModel(tf.keras.Model):\n",
    "    def __init__(self, robot_info, gitem_list, urdf_content, N_sim, N_col,\n",
    "                 alpha_jc=5, alpha_fc=200, alpha_jl=1, alpha_cl=1,alpha_cs=0, \n",
    "                 LIM=np.pi, LIM_BOUND=1e-1, COL_BOUND=1e-1, learning_rate=5e-3):\n",
    "        super(GraphModel, self).__init__()\n",
    "        self.alpha_jc = alpha_jc\n",
    "        self.alpha_fc = alpha_fc\n",
    "        self.alpha_jl = alpha_jl\n",
    "        self.alpha_cl = alpha_cl\n",
    "        self.alpha_cs = alpha_cs\n",
    "        self.N_sim, self.N_col = N_sim, N_col\n",
    "        self.LIM = LIM\n",
    "        self.LIM_BOUND = LIM_BOUND\n",
    "        self.COL_BOUND = COL_BOUND\n",
    "        self.learning_rate = learning_rate\n",
    "        self.robot_info = robot_info\n",
    "        self.robot = RobotLayer(\n",
    "            robot_info.link_info_list, rname = robot_info.rname, dim=N_sim)\n",
    "        self.joint_constraint = JointConstraintLoss(self.robot)\n",
    "        self.frame_constraint = FrameConstraintLoss()\n",
    "        self.robot_base = [robot_info.base_frame]*N_sim\n",
    "        self.set_custom_loss(lambda *args: tf.constant(0.0), 0)\n",
    "        self.link_name_list = self.robot.link_name_list\n",
    "        self.link_idx_dict = {name: idx for name, idx in zip(self.link_name_list, range(len(self.link_name_list)))}\n",
    "        self.adjacency_list = [\n",
    "            list(map(\n",
    "                lambda x: self.link_idx_dict[x],\n",
    "                [lname for lname in get_adjacent_links(link_name, urdf_content) if lname in self.link_name_list]\n",
    "            )) for link_name in self.link_name_list\n",
    "        ]\n",
    "        link_num = len(self.adjacency_list)\n",
    "        self.adjacency_mat = np.zeros((link_num,link_num), dtype=np.bool)\n",
    "        for i_adj, adj in zip(range(link_num), self.adjacency_list):\n",
    "            self.adjacency_mat[i_adj, adj] = True\n",
    "            \n",
    "        self.object_dict = {}\n",
    "        self.object_name_list = []\n",
    "        self.object_vertice_list = []\n",
    "        self.object_link_idx_list = []\n",
    "        self.object_collision_flags = []\n",
    "        for gitem in gitem_list:\n",
    "            self.object_dict[gitem.name] = ObjectLayer(gitem, N_sim)\n",
    "            self.object_collision_flags += [gitem.collision]\n",
    "            self.object_name_list += [gitem.name]\n",
    "            self.object_vertice_list += [np.pad(gitem.get_vertice(),((0,0),(0,1)),'constant', constant_values=(1))]\n",
    "            self.object_link_idx_list += [0]\n",
    "        self.object_name_list = self.object_name_list\n",
    "        self.object_vertice_mat = tf.constant(self.object_vertice_list, dtype=\"float32\")\n",
    "        self.build_collision_combinatiosn()\n",
    "        self.optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "        self.flag_default = get_flag_default(N_sim, N_col)\n",
    "        self.dist_default = get_dist_default(N_sim, N_col)\n",
    "        self.x_batch, self.y_batch = get_xy_batch(N_sim, N_col)\n",
    "        \n",
    "    def build_collision_combinatiosn(self):\n",
    "        obj_idx_list = np.arange(len(self.object_name_list))\n",
    "        self.col_combinations = list(combinations(obj_idx_list,2))\n",
    "        for i_c in range(len(self.col_combinations)):\n",
    "            i_c_back = len(self.col_combinations)-1-i_c\n",
    "            cmb = self.col_combinations[i_c_back]\n",
    "            if not(self.object_collision_flags[cmb[0]] \n",
    "                   and self.object_collision_flags[cmb[1]]):\n",
    "                del self.col_combinations[i_c_back]\n",
    "        self.col_combinations = np.array(self.col_combinations)\n",
    "        self.len_combs = len(self.col_combinations)\n",
    "            \n",
    "    def assign_frame_dict(self, gframeset_list):\n",
    "        frame_dict = {k: [] for k in self.object_dict.keys()}\n",
    "        link_dict = {k: [] for k in self.object_dict.keys()}\n",
    "        for gframeset in gframeset_list:\n",
    "            for k, gframe in gframeset.items():\n",
    "                frame_dict[k] += [gframe.Toff]\n",
    "                link_dict[k] += [self.robot.link_name_list.index(gframe.link_name)]\n",
    "        for k in frame_dict.keys():\n",
    "            self.object_dict[k].set_frame(np.array(frame_dict[k]), np.array(link_dict[k]), self.robot.len_Q)\n",
    "            i_obj = self.get_object_index(k)\n",
    "            self.object_link_idx_list[i_obj] = np.array(link_dict[k])\n",
    "        self.object_link_idx_mat = np.transpose(self.object_link_idx_list)\n",
    "            \n",
    "    def get_object_index(self, name):\n",
    "        return graph.object_name_list.index(name)\n",
    "            \n",
    "    @tf.function\n",
    "    def assign_Q(self, Q):\n",
    "        self.robot.assign_Q(Q)\n",
    "            \n",
    "    @tf.function\n",
    "    def get_Q(self):\n",
    "        return self.robot.get_Q()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs=None):\n",
    "        T_all = self.robot(self.robot_base)\n",
    "        Tbo_all = []\n",
    "        for obj_name in self.object_name_list:\n",
    "            Tbo_all += [self.object_dict[obj_name](T_all)] #(Nobj,N_sim,4,4)\n",
    "        Tbo_all = K.stack(Tbo_all, axis=1) #(N_sim,Nobj,4,4)\n",
    "        return T_all, Tbo_all\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_joint_limit(self):\n",
    "        Q = self.get_Q()\n",
    "        return K.sum(1/((K.min(((self.LIM-Q), (self.LIM+Q)), axis=-1)/self.LIM_BOUND)**3))\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_loss(self, T_all, Tbo_all, Qtar, binQ, Ttar, binT):\n",
    "        jl_loss = self.calc_joint_limit()\n",
    "        jc_loss = self.joint_constraint((Qtar, binQ))\n",
    "        fc_loss = self.frame_constraint((T_all[:,-1,:,:],Ttar, binT))\n",
    "#         cl_loss = self.calc_collision_loss(T_all, Tbo_all)\n",
    "        return self.alpha_jc*jc_loss + self.alpha_fc*fc_loss + \\\n",
    "                self.alpha_jl*jl_loss + self.alpha_cs*self.calc_custom_loss(T_all, Tbo_all) #\n",
    "#                 + self.alpha_cl*cl_loss \n",
    "                \n",
    "    \n",
    "    @tf.function\n",
    "    def forward(self, Qtar, binQ, Ttar, binT):\n",
    "        T_all, Tbo_all= graph(None)\n",
    "        loss = self.calc_loss(T_all, Tbo_all, Qtar, binQ, Ttar, binT)\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def update_once(self, Qtar, binQ, Ttar, binT, max_gradient):\n",
    "        with tf.GradientTape() as g:\n",
    "            # Forward pass.\n",
    "            loss = self.forward(Qtar, binQ, Ttar, binT)\n",
    "\n",
    "        # Variables to update, i.e. trainable variables.\n",
    "        trainable_variables = self.trainable_variables\n",
    "\n",
    "        # Compute gradients.\n",
    "        gradients = g.gradient(loss, trainable_variables)\n",
    "        gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "    \n",
    "        # Update W and b following gradients.\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    def set_custom_loss(self, custom_loss, alpha_cs, *args, **kwargs):\n",
    "        self.custom_loss = custom_loss\n",
    "        self.alpha_cs = alpha_cs\n",
    "        self.cl_args = args\n",
    "        self.cl_kwargs = kwargs\n",
    "        \n",
    "    def calc_custom_loss(self, T_all, Tbo_all):\n",
    "        return self.custom_loss(self, T_all, Tbo_all, *self.cl_args, **self.cl_kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def collision_condition(self, col_comb):\n",
    "        link_comb = tf.gather(self.object_link_idx_mat, col_comb, axis=-1)\n",
    "        adjacency_masked = tf.logical_not(tf.gather_nd(self.adjacency_mat, link_comb))\n",
    "        return adjacency_masked\n",
    "    @tf.function\n",
    "    def _combination_cond(self, col_combs, col_mask, iter):\n",
    "        return True\n",
    "    @tf.function\n",
    "    def _combination_loop(self, col_combs, col_mask, iter):\n",
    "        col_comb = tf.gather(col_combs, iter, axis=0)\n",
    "        col_mask = tf.logical_or(col_mask, \n",
    "                                 tf.logical_and(tf.cast(tf.one_hot(iter, self.len_combs, axis=0), dtype=tf.bool),\n",
    "                                                tf.expand_dims(self.collision_condition(col_comb), axis=1)\n",
    "                                               )\n",
    "                                )\n",
    "        return col_combs, col_mask, iter+1\n",
    "\n",
    "    @tf.function\n",
    "    def test_collision(self, T_all, Tbo_all):\n",
    "        Pbo_all = tf.gather(tf.gather(Tbo_all, [0,1,2], axis=-2), 3, axis=-1)\n",
    "\n",
    "        col_combs = self.col_combinations\n",
    "        col_mask = tf.zeros((self.N_sim, self.len_combs),tf.bool)\n",
    "        col_combs, col_mask, iter = tf.while_loop(cond=self._combination_cond, body=self._combination_loop, \n",
    "                                                         loop_vars=(col_combs, col_mask, K.constant(0, tf.int64)), \n",
    "                                                         parallel_iterations=10,maximum_iterations=self.len_combs)\n",
    "        col_combs_masked_batch = tf.boolean_mask(\n",
    "                tf.tile(tf.expand_dims(col_combs,axis=0), [self.N_sim, 1, 1]), \n",
    "                col_mask, \n",
    "                axis=0)\n",
    "        batch_flat = tf.repeat(np.reshape(np.arange(self.N_sim), (self.N_sim, 1)), (self.N_col,)*self.N_sim,axis=0)\n",
    "        col_combs_masked_flat = tf.concat([batch_flat, col_combs_masked_batch], axis=-1)\n",
    "        vtx_tf = tf.gather(\n",
    "            K.sum(tf.expand_dims(Tbo_all, axis=-3)*tf.expand_dims(self.object_vertice_mat, axis=-2), axis=-1), \n",
    "            [0,1,2], axis=-1)\n",
    "        vtx_tf_1 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "        vtx_tf_2 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "        Pbo_all_1 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col,3))\n",
    "        Pbo_all_2 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col,3))\n",
    "        v_batch = tf.expand_dims(Pbo_all_1-Pbo_all_2, axis=-2)\n",
    "        v_batch = tf.linalg.cross(v_batch, self.x_batch)+tf.linalg.cross(v_batch, self.y_batch)\n",
    "        dist, flag = test_collision_batch(vtx_tf_1, vtx_tf_2, \n",
    "                             v_batch, self.flag_default, self.dist_default)\n",
    "        return dist, flag, col_combs_masked_flat \n",
    "    \n",
    "    @tf.function\n",
    "    def calc_collision_loss(self, T_all, Tbo_all):\n",
    "        dist, flag, _  = self.test_collision(T_all, Tbo_all)\n",
    "        return K.min(1/(dist/self.COL_BOUND)**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sim = 50\n",
    "N_col = 21\n",
    "N_joints = 9\n",
    "DOF = 6\n",
    "robot_info = RobotInfo(link_info_list, rname = \"rbt1\", base_frame=np.identity(4,dtype=np.float32))\n",
    "graph = GraphModel(robot_info=robot_info, gitem_list=gitem_list, urdf_content=urdf_content, \n",
    "                   N_sim=N_sim, N_col=N_col, learning_rate=5e-3, \n",
    "                   alpha_cl=1)\n",
    "gtimer = GlobalTimer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/3)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "graph.assign_Q(Q_)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_frame_dict(gframe_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,-0.05)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_vec = []\n",
    "Q_list = [list(map(lambda x: x.numpy(), graph.get_Q()))]\n",
    "# Tbo_all_list = [np.array([[gframe_dict[gitem.name].Toff for gitem in gitem_list]]*N_sim)]\n",
    "N_iter = 100\n",
    "# Run training for the given number of steps.\n",
    "Qtar, binQ, Ttar, binT = (np.zeros((N_sim, N_joints), dtype='float32'), np.zeros(N_sim, dtype='float32'),\n",
    "                      np.array([Ttar_]*N_sim), np.ones(N_sim, dtype='float32'))\n",
    "dist_list = []\n",
    "loss_list = []\n",
    "jl_loss_list = []\n",
    "jc_loss_list = []\n",
    "fc_loss_list = []\n",
    "cl_loss_list = []\n",
    "gradients_list = []\n",
    "gtimer.reset()\n",
    "for _ in range(N_iter):\n",
    "    # Run the optimization to update W and b values.\n",
    "    T_all, Tbo_all = graph(None)\n",
    "    dist_list += [K.min(graph.test_collision(T_all, Tbo_all)[0]).numpy()]\n",
    "    jl_loss = graph.calc_joint_limit()\n",
    "    jc_loss = graph.joint_constraint((Qtar, binQ))\n",
    "    fc_loss = graph.frame_constraint((T_all[:,-1,:,:],Ttar, binT))\n",
    "    cl_loss = graph.calc_collision_loss(T_all, Tbo_all)\n",
    "    gtimer.tic(\"update\")\n",
    "    loss = graph.update_once(Qtar, binQ, Ttar, binT, max_gradient=10)\n",
    "#     max_gradient=10\n",
    "\n",
    "#     with tf.GradientTape() as g:\n",
    "#         # Forward pass.\n",
    "#         loss = graph.forward(Qtar, binQ, Ttar, binT)\n",
    "\n",
    "#     # Variables to update, i.e. trainable variables.\n",
    "#     trainable_variables = graph.trainable_variables\n",
    "\n",
    "#     # Compute gradients.\n",
    "#     gradients = g.gradient(loss, trainable_variables)\n",
    "#     gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "\n",
    "#     # Update W and b following gradients.\n",
    "#     graph.optimizer.apply_gradients(zip(gradients, graph.trainable_variables))\n",
    "    gtimer.toc(\"update\")\n",
    "    gtimer.tic(\"record\")\n",
    "    Q_list += [graph.get_Q().numpy()]\n",
    "    loss_list += [loss]\n",
    "#     gradients_list += [gradients]\n",
    "    jl_loss_list += [jl_loss]\n",
    "    jc_loss_list += [jc_loss]\n",
    "    fc_loss_list += [fc_loss]\n",
    "    cl_loss_list += [cl_loss]\n",
    "    gtimer.toc(\"record\")\n",
    "gtimer.print_time_log()\n",
    "print(\"loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list, label=\"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list, label=\"total\")\n",
    "plt.plot(np.multiply(jl_loss_list, graph.alpha_jl), label=\"joint limit\")\n",
    "plt.plot(np.multiply(jc_loss_list, graph.alpha_jc), label=\"joint target\")\n",
    "plt.plot(np.multiply(fc_loss_list, graph.alpha_fc), label=\"frame target\")\n",
    "plt.plot(np.multiply(cl_loss_list, graph.alpha_cl), label=\"collision dist\")\n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "# axes.set_ylim([-1e1,5e1])\n",
    "# axes.set_xlim([0,1e1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_sim in range(1): # N_sim):\n",
    "    for i_iter in range(1,N_iter+1):\n",
    "        q = Q_list[i_iter][i_sim]\n",
    "        gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "        pose_list = [q[2:-1]]\n",
    "        gframevec_list = [gframevec]\n",
    "        show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)\n",
    "        time.sleep(10e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_all = np.array(Q_list)\n",
    "Q_all_i = np.array([Q_all[i_iter, i_sim,:] for i_iter in range(N_iter)])\n",
    "plt.plot(Q_all_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Q_all_i[1:,:]-Q_all_i[:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,-0.05)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "T_all, Tbo_all = graph(None)\n",
    "show_motion([graph.get_Q().numpy()[0][2:-1]], marker_list, [[gframe_dict[gitem.name] for gitem in gitem_list]], pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_all, Tbo_all = graph(None)\n",
    "gtimer.reset()\n",
    "for _ in range(10):\n",
    "    gtimer.tic(\"ctest\")\n",
    "    dist, flag, mask = graph.test_collision(T_all, Tbo_all)\n",
    "    gtimer.toc(\"ctest\")\n",
    "print(gtimer)\n",
    "# dist[0]\n",
    "# gtimer.reset()\n",
    "# for _ in range(100):\n",
    "#     gtimer.tic(\"col\")\n",
    "#     dist, flag = collision_loss_test(graph, T_all, Tbo_all, flag_default, dist_default)\n",
    "#     gtimer.toc(\"col\")\n",
    "# gtimer.print_time_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.calc_collision_loss(T_all, Tbo_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot([0, N_col],[0,0],'-ob')\n",
    "plt.grid()\n",
    "dist0 = dist[0]\n",
    "mask0 = mask[:N_col]\n",
    "for i_m in range(len(mask0)):\n",
    "    plt.plot([i_m, i_m],mask0[i_m,1:],'-o')\n",
    "plt.plot(dist0*10,'-ok',linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.object_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision error case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_error = np.loadtxt(\"Q_error.csv\",delimiter=\",\",dtype=np.float32)\n",
    "graph.assign_Q(Q_error)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "\n",
    "T_all, Tbo_all = graph(None)\n",
    "dist = K.min(graph.test_collision(T_all, Tbo_all)[0]).numpy()\n",
    "cl_loss = graph.calc_collision_loss(T_all, Tbo_all)\n",
    "print(\"dist: {}\".format(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Q_error[0]\n",
    "gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "pose_list = [q[2:-1]]\n",
    "gframevec_list = [gframevec]\n",
    "show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpl_toolkits.mplot3d as mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sub = fig.add_subplot(1,1,1,projection=\"3d\")\n",
    "sub.plot(x,y,z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,4*np.pi,500)\n",
    "x = np.sin(t)\n",
    "x = np.cos(t)\n",
    "y = np.sin(t)\n",
    "z = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
