{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.tf_transform import *\n",
    "from pkg.tf_robot import *\n",
    "from pkg.constraint import *\n",
    "from pkg.info import *\n",
    "from pkg.tf_utils import *\n",
    "from pkg.rotation_utils import *\n",
    "from pkg.utils import *\n",
    "from pkg.ur10 import *\n",
    "from pkg.geometry import *\n",
    "from pkg.collision import *\n",
    "from pkg.distance import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load urdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urdf_parser_py.urdf import URDF\n",
    "from pkg.ur10 import URDF_PATH, JOINT_NAMES, LINK_NAMES, ZERO_JOINT_POSE\n",
    "from pkg.joint_utils import *\n",
    "urdf_content = URDF.from_xml_file(URDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_names = LINK_NAMES\n",
    "base_name = LINK_NAMES[0]\n",
    "joint_names = JOINT_NAMES\n",
    "link_info_list = get_link_info_list(link_names, urdf_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n",
      "publication OK - base_capsule\n",
      "publication OK - shoulder_capsule\n",
      "publication OK - upper_arm_capsule\n",
      "publication OK - forearm_capsule\n",
      "publication OK - wrist_1_capsule\n",
      "publication OK - wrist_2_capsule\n",
      "publication OK - wrist_3_capsule\n",
      "publication OK - tool_mesh\n",
      "publication OK - box1\n"
     ]
    }
   ],
   "source": [
    "from pkg.ros_rviz import *\n",
    "pub, joints, rate = get_publisher(JOINT_NAMES)\n",
    "\n",
    "gitem_list, gframe_dict= get_link_items_offsets(color=(0,1,0,0.5), display=True)\n",
    "gitem_list += [\n",
    "    GeometryItem(name='box1', gtype=GeoType.BOX, dims=[0.1,0.1,0.1], color=(0,1,0,1), display=True, collision=True)\n",
    "]\n",
    "gframe_dict.update({\"box1\":GeometryFrame(SE3(Rot_zyx(0,0,0),(0.5,0,0)), \"world\")\n",
    "                   })\n",
    "marker_list = set_markers(gitem_list, gframe_dict, urdf_content)\n",
    "show_motion([np.array([0]*6)], marker_list, \n",
    "            [[gframe_dict[gitem.name] for gitem in gitem_list]], \n",
    "            pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacent_links(link_name, urdf_content):\n",
    "    adjacent_links = [link_name]\n",
    "    for k, v in urdf_content.joint_map.items():\n",
    "        if v.parent == link_name:\n",
    "            adjacent_links += [v.child]\n",
    "        if v.child == link_name:\n",
    "            adjacent_links += [v.parent]\n",
    "    return list(set(adjacent_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectLayer(layers.Layer):\n",
    "    def __init__(self, gitem, N_sim, *args, **kwargs):\n",
    "        self.gitem, self.N_sim = gitem, N_sim\n",
    "        super(ObjectLayer, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def set_frame(self, Toff_list, link_idx_list, N_link):\n",
    "        self.Toff_list = tf.constant(Toff_list) # (N_sim, 4,4)\n",
    "        self.link_one_hot = tf.reshape(tf.one_hot(link_idx_list, N_link), (N_sim,N_link,1,1)) # (N_sim, N_link)\n",
    "        \n",
    "    # 변수를 만듭니다.\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "    \n",
    "    @tf.function\n",
    "    def get_vertice(self):\n",
    "        return self.vertice\n",
    "\n",
    "    # call 메서드가 그래프 모드에서 사용되면\n",
    "    # training 변수는 텐서가 됩니다.\n",
    "    @tf.function\n",
    "    def call(self, input=None):\n",
    "        T_all = input # (N_sim, N_link, 4,4)\n",
    "        T_act = K.sum(T_all*self.link_one_hot, axis=1) # (N_sim, 4,4)\n",
    "        T_bo = tf.matmul(T_act, self.Toff_list) # (N_sim, 4,4)\n",
    "        return T_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceCalculator:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.N_sim = graph.N_sim\n",
    "        self.prepare_collision_dat()\n",
    "            \n",
    "    def prepare_collision_dat(self):\n",
    "        for col_case in self.graph.pair_cases:\n",
    "            setattr(self, \"vtx1_\"+col_case, self.graph.col_vtx1_dict[col_case])\n",
    "            setattr(self, \"vtx2_\"+col_case, self.graph.col_vtx2_dict[col_case])\n",
    "            setattr(self, \"dist1_\"+col_case, self.graph.col_dist1_dict[col_case])\n",
    "            setattr(self, \"dist2_\"+col_case, self.graph.col_dist2_dict[col_case])\n",
    "            setattr(self, \"zeros_\"+col_case, tf.constant(get_zero_points(self.N_sim, self.graph.N_col_dict[col_case]), dtype=tf.float32))\n",
    "            setattr(self, \"N_col_\"+col_case, self.graph.N_col_dict[col_case])\n",
    "            setattr(self, \"flag_default_\"+col_case, \n",
    "                    tf.constant(get_flag_default(self.N_sim, self.graph.N_col_dict[col_case]), dtype=tf.bool))\n",
    "            setattr(self, \"dist_default_\"+col_case, \n",
    "                    tf.constant(get_dist_default(self.N_sim, self.graph.N_col_dict[col_case]), dtype=tf.float32))\n",
    "            x_batch, y_batch = get_xy_batch(self.N_sim, self.graph.N_col_dict[col_case])\n",
    "            setattr(self, \"x_batch_\"+col_case, \n",
    "                    tf.constant(x_batch, dtype=tf.float32))\n",
    "            setattr(self, \"y_batch_\"+col_case, \n",
    "                    tf.constant(y_batch, dtype=tf.float32))\n",
    "            \n",
    "    def apply_col_mask(self):\n",
    "        for col_case in self.graph.pair_cases:\n",
    "            setattr(self, \"mask_\"+col_case, self.graph.col_mask_dict[col_case])\n",
    "    \n",
    "    @tf.function\n",
    "    def pt_pt_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_pt, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_pt, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_pt, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_pt_pt(vtx1_all, vtx2_all, self.dist1_pt_pt, self.dist2_pt_pt)\n",
    "        return dist, flag, self.mask_pt_pt\n",
    "\n",
    "    @tf.function\n",
    "    def pt_ln_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_ln, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_pt_ln(vtx1_all, vtx2_all, self.dist1_pt_ln, self.dist2_pt_ln)\n",
    "        return dist, flag, self.mask_pt_ln\n",
    "\n",
    "    @tf.function\n",
    "    def pt_pl_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_pl, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_pt_pl(vtx1_all, vtx2_all, self.dist1_pt_pl, self.dist2_pt_pl, self.N_sim, self.N_col_pt_pl)\n",
    "        return dist, flag, self.mask_pt_pl\n",
    "\n",
    "    @tf.function\n",
    "    def pt_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pt_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pt_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pt_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_pt_bx(vtx1_all, vtx2_all, self.dist1_pt_bx, self.dist2_pt_bx, self.N_sim, self.N_col_pt_bx)\n",
    "        return dist, flag, self.mask_pt_bx\n",
    "\n",
    "    @tf.function\n",
    "    def ln_ln_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_ln_ln, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_ln_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_ln_ln, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_ln_ln(vtx1_all, vtx2_all, self.dist1_ln_ln, self.dist2_ln_ln, \n",
    "                                    self.N_sim, self.N_col_ln_ln, self.zeros_ln_ln)\n",
    "        return dist, flag, self.mask_ln_ln\n",
    "\n",
    "    @tf.function\n",
    "    def ln_pl_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_ln_pl, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_ln_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_ln_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_ln_pl(vtx1_all, vtx2_all, self.dist1_ln_pl, self.dist2_ln_pl, \n",
    "                                    self.N_sim, self.N_col_ln_pl, self.zeros_ln_pl)\n",
    "        return dist, flag, self.mask_ln_pl\n",
    "\n",
    "    @tf.function\n",
    "    def ln_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_ln_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_ln_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_ln_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_ln_bx(vtx1_all, vtx2_all, self.dist1_ln_bx, self.dist2_ln_bx, \n",
    "                                    self.flag_default_ln_bx, self.dist_default_ln_bx,\n",
    "                                    self.x_batch_ln_bx, self.y_batch_ln_bx,\n",
    "                                    4\n",
    "                                   )\n",
    "        return dist, flag, self.mask_ln_bx\n",
    "\n",
    "    @tf.function\n",
    "    def pl_pl_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pl_pl, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pl_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pl_pl, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_pl_pl(vtx1_all, vtx2_all, self.dist1_pl_pl, self.dist2_pl_pl, \n",
    "                                    self.flag_default_pl_pl, self.dist_default_pl_pl,\n",
    "                                    self.x_batch_pl_pl, self.y_batch_pl_pl,\n",
    "                                    4\n",
    "                                   )\n",
    "        return dist, flag, self.mask_pl_pl\n",
    "\n",
    "    @tf.function\n",
    "    def pl_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_pl_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_pl_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_pl_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_pl_bx(vtx1_all, vtx2_all, self.dist1_pl_bx, self.dist2_pl_bx, \n",
    "                                    self.flag_default_pl_bx, self.dist_default_pl_bx,\n",
    "                                    self.x_batch_pl_bx, self.y_batch_pl_bx,\n",
    "                                    4\n",
    "                                   )\n",
    "        return dist, flag, self.mask_pl_bx\n",
    "\n",
    "    @tf.function\n",
    "    def bx_bx_dist(self, Tbo_all_res):\n",
    "        Tbo_all_res = tf.tile(Tbo_all_res, [1, self.N_col_bx_bx, 1,1,1,1])\n",
    "        vtx1_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx1_bx_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        vtx2_all = tf.gather(K.sum(K.sum(Tbo_all_res*self.vtx2_bx_bx, axis=-1), axis=-3), [0,1,2], axis=-1)\n",
    "        dist, flag = distance_bx_bx(vtx1_all, vtx2_all, self.dist1_bx_bx, self.dist2_bx_bx, \n",
    "                                    self.flag_default_bx_bx, self.dist_default_bx_bx,\n",
    "                                    self.x_batch_bx_bx, self.y_batch_bx_bx,\n",
    "                                    4\n",
    "                                   )\n",
    "        return dist, flag, self.mask_bx_bx\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_all(self, Tbo_all_res):\n",
    "        dist_pt_pt, flag_pt_pt, mask_pt_pt = self.pt_pt_dist(Tbo_all_res)\n",
    "        dist_pt_ln, flag_pt_ln, mask_pt_ln = self.pt_ln_dist(Tbo_all_res)\n",
    "        dist_pt_pl, flag_pt_pl, mask_pt_pl = self.pt_pl_dist(Tbo_all_res)\n",
    "        dist_pt_bx, flag_pt_bx, mask_pt_bx = self.pt_bx_dist(Tbo_all_res)\n",
    "        dist_ln_ln, flag_ln_ln, mask_ln_ln = self.ln_ln_dist(Tbo_all_res)\n",
    "        dist_ln_pl, flag_ln_pl, mask_ln_pl = self.ln_pl_dist(Tbo_all_res)\n",
    "        dist_ln_bx, flag_ln_bx, mask_ln_bx = self.ln_bx_dist(Tbo_all_res)\n",
    "        dist_pl_pl, flag_pl_pl, mask_pl_pl = self.pl_pl_dist(Tbo_all_res)\n",
    "        dist_pl_bx, flag_pl_bx, mask_pl_bx = self.pl_bx_dist(Tbo_all_res)\n",
    "        dist_bx_bx, flag_bx_bx, mask_bx_bx = self.bx_bx_dist(Tbo_all_res)\n",
    "        return (\n",
    "            dist_pt_pt, flag_pt_pt, mask_pt_pt,\n",
    "            dist_pt_ln, flag_pt_ln, mask_pt_ln,\n",
    "            dist_pt_pl, flag_pt_pl, mask_pt_pl,\n",
    "            dist_pt_bx, flag_pt_bx, mask_pt_bx,\n",
    "            dist_ln_ln, flag_ln_ln, mask_ln_ln,\n",
    "            dist_ln_pl, flag_ln_pl, mask_ln_pl,\n",
    "            dist_ln_bx, flag_ln_bx, mask_ln_bx,\n",
    "            dist_pl_pl, flag_pl_pl, mask_pl_pl,\n",
    "            dist_pl_bx, flag_pl_bx, mask_pl_bx,\n",
    "            dist_bx_bx, flag_bx_bx, mask_bx_bx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphModel(tf.keras.Model):\n",
    "    def __init__(self, robot_info, gitem_list, urdf_content, N_sim, \n",
    "                 alpha_jc=5, alpha_fc=200, alpha_jl=1, alpha_cl=1,alpha_cs=0, \n",
    "                 LIM=np.pi, LIM_BOUND=1e-1, COL_BOUND=1e-2, learning_rate=5e-3, col_iteration = 20):\n",
    "        super(GraphModel, self).__init__()\n",
    "        self.alpha_jc = alpha_jc\n",
    "        self.alpha_fc = alpha_fc\n",
    "        self.alpha_jl = alpha_jl\n",
    "        self.alpha_cl = alpha_cl\n",
    "        self.alpha_cs = alpha_cs\n",
    "        self.N_sim = N_sim\n",
    "        self.LIM = LIM\n",
    "        self.LIM_BOUND = LIM_BOUND\n",
    "        self.COL_BOUND = COL_BOUND\n",
    "        self.learning_rate = learning_rate\n",
    "        self.col_iteration = col_iteration\n",
    "        self.robot_info = robot_info\n",
    "        self.robot = RobotLayer(\n",
    "            robot_info.link_info_list, rname = robot_info.rname, dim=N_sim)\n",
    "        self.joint_constraint = JointConstraintLoss(self.robot)\n",
    "        self.frame_constraint = FrameConstraintLoss()\n",
    "        self.robot_base = [robot_info.base_frame]*N_sim\n",
    "        self.set_custom_loss(lambda *args: tf.constant(0.0), 0)\n",
    "        self.link_name_list = self.robot.link_name_list\n",
    "        self.link_idx_dict = {name: idx for name, idx in zip(self.link_name_list, range(len(self.link_name_list)))}\n",
    "        self.adjacency_list = [\n",
    "            list(map(\n",
    "                lambda x: self.link_idx_dict[x],\n",
    "                [lname for lname in get_adjacent_links(link_name, urdf_content) if lname in self.link_name_list]\n",
    "            )) for link_name in self.link_name_list\n",
    "        ]\n",
    "        link_num = len(self.adjacency_list)\n",
    "        self.adjacency_mat = np.zeros((link_num,link_num), dtype=np.bool)\n",
    "        for i_adj, adj in zip(range(link_num), self.adjacency_list):\n",
    "            self.adjacency_mat[i_adj, adj] = True\n",
    "            \n",
    "        self.object_dict = {}\n",
    "        self.object_name_list = []\n",
    "        self.object_vertice_list = []\n",
    "        self.object_link_idx_list = []\n",
    "        self.object_collision_flags = []\n",
    "        for gitem in gitem_list:\n",
    "            self.object_dict[gitem.name] = ObjectLayer(gitem, N_sim)\n",
    "            self.object_collision_flags += [gitem.collision]\n",
    "            self.object_name_list += [gitem.name]\n",
    "            self.object_vertice_list += [np.pad(gitem.get_vertice(),((0,0),(0,1)),'constant', constant_values=(1))]\n",
    "            self.object_link_idx_list += [0]\n",
    "        self.num_object = len(self.object_name_list)\n",
    "#         self.object_vertice_mat = tf.constant(self.object_vertice_list, dtype=\"float32\")\n",
    "        self.build_collision_combinations()\n",
    "        self.set_collision_vtx()\n",
    "        self.optimizer = tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    def build_collision_combinations(self):\n",
    "        obj_idx_list = np.arange(len(self.object_name_list))\n",
    "        self.col_combinations = list(combinations(obj_idx_list,2))\n",
    "\n",
    "        for i_c in range(len(self.col_combinations)):\n",
    "            i_c_back = len(self.col_combinations)-1-i_c\n",
    "            cmb = self.col_combinations[i_c_back]\n",
    "            if not(self.object_collision_flags[cmb[0]] \n",
    "                   and self.object_collision_flags[cmb[1]]):\n",
    "                del self.col_combinations[i_c_back]\n",
    "\n",
    "        self.pair_cases = ['pt_pt', 'pt_ln', 'pt_pl', 'pt_bx',\n",
    "                           'ln_ln', 'ln_pl', 'ln_bx',\n",
    "                           'pl_pl', 'pl_bx','bx_bx']\n",
    "        self.col_pair_dict = defaultdict(lambda:[])\n",
    "        for comb in self.col_combinations:\n",
    "            obj1 = self.object_dict[self.object_name_list[comb[0]]]\n",
    "            obj2 = self.object_dict[self.object_name_list[comb[1]]]\n",
    "            if obj1.gitem.gtype == GeoType.SPHERE:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_pt'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['pt_ln'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['pt_pl'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['pt_bx'] += [comb]\n",
    "            elif obj1.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_ln'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['ln_ln'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['ln_pl'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['ln_bx'] += [comb]\n",
    "            elif obj1.gitem.gtype == GeoType.PLANE:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_pl'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['ln_pl'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['pl_pl'] += [comb]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['pl_bx'] += [comb]\n",
    "            elif obj1.gitem.gtype == GeoType.BOX:\n",
    "                if obj2.gitem.gtype == GeoType.SPHERE:\n",
    "                    self.col_pair_dict['pt_bx'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.CYLINDER or obj2.gitem.gtype == GeoType.LINE:\n",
    "                    self.col_pair_dict['ln_bx'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.PLANE:\n",
    "                    self.col_pair_dict['pl_bx'] += [(comb[1],comb[0])]\n",
    "                elif obj2.gitem.gtype == GeoType.BOX:\n",
    "                    self.col_pair_dict['bx_bx'] += [comb]\n",
    "            \n",
    "    def assign_frame_dict(self, gframeset_list):\n",
    "        frame_dict = {k: [] for k in self.object_dict.keys()}\n",
    "        link_dict = {k: [] for k in self.object_dict.keys()}\n",
    "        for gframeset in gframeset_list:\n",
    "            for k, gframe in gframeset.items():\n",
    "                frame_dict[k] += [gframe.Toff]\n",
    "                link_dict[k] += [self.robot.link_name_list.index(gframe.link_name)]\n",
    "        for k in frame_dict.keys():\n",
    "            self.object_dict[k].set_frame(np.array(frame_dict[k]), np.array(link_dict[k]), self.robot.len_Q)\n",
    "            i_obj = self.get_object_index(k)\n",
    "            self.object_link_idx_list[i_obj] = np.array(link_dict[k])\n",
    "        self.object_link_idx_mat = np.transpose(self.object_link_idx_list)\n",
    "        self.apply_col_mask()\n",
    "            \n",
    "    def get_object_index(self, name):\n",
    "        return graph.object_name_list.index(name)\n",
    "            \n",
    "    @tf.function\n",
    "    def assign_Q(self, Q):\n",
    "        self.robot.assign_Q(Q)\n",
    "            \n",
    "    @tf.function\n",
    "    def get_Q(self):\n",
    "        return self.robot.get_Q()\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs=None):\n",
    "        T_all = self.robot(self.robot_base)\n",
    "        Tbo_all = []\n",
    "        for obj_name in self.object_name_list:\n",
    "            Tbo_all += [self.object_dict[obj_name](T_all)] #(Nobj,N_sim,4,4)\n",
    "        Tbo_all = K.stack(Tbo_all, axis=1) #(N_sim,Nobj,4,4)\n",
    "        return T_all, Tbo_all\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_joint_limit(self):\n",
    "        Q = self.get_Q()\n",
    "        return K.sum(1/((K.min(((self.LIM-Q), (self.LIM+Q)), axis=-1)/self.LIM_BOUND)**3))\n",
    "    \n",
    "    @tf.function\n",
    "    def calc_loss(self, T_all, Tbo_all, Qtar, binQ, Ttar, binT):\n",
    "        jl_loss = self.calc_joint_limit()\n",
    "        jc_loss = self.joint_constraint((Qtar, binQ))\n",
    "        fc_loss = self.frame_constraint((T_all[:,-1,:,:],Ttar, binT))\n",
    "        cl_loss = self.calc_collision_loss(T_all, Tbo_all)\n",
    "        return self.alpha_jc*jc_loss + self.alpha_fc*fc_loss + \\\n",
    "                self.alpha_jl*jl_loss + self.alpha_cs*self.calc_custom_loss(T_all, Tbo_all) \\\n",
    "                + self.alpha_cl*cl_loss \n",
    "                \n",
    "    \n",
    "    @tf.function\n",
    "    def forward(self, Qtar, binQ, Ttar, binT):\n",
    "        T_all, Tbo_all= graph(None)\n",
    "        loss = self.calc_loss(T_all, Tbo_all, Qtar, binQ, Ttar, binT)\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def update_once(self, Qtar, binQ, Ttar, binT, max_gradient):\n",
    "        with tf.GradientTape() as g:\n",
    "            # Forward pass.\n",
    "            loss = self.forward(Qtar, binQ, Ttar, binT)\n",
    "\n",
    "        # Variables to update, i.e. trainable variables.\n",
    "        trainable_variables = self.trainable_variables\n",
    "\n",
    "        # Compute gradients.\n",
    "        gradients = g.gradient(loss, trainable_variables)\n",
    "        gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "    \n",
    "        # Update W and b following gradients.\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    def set_custom_loss(self, custom_loss, alpha_cs, *args, **kwargs):\n",
    "        self.custom_loss = custom_loss\n",
    "        self.alpha_cs = alpha_cs\n",
    "        self.cl_args = args\n",
    "        self.cl_kwargs = kwargs\n",
    "        \n",
    "    def calc_custom_loss(self, T_all, Tbo_all):\n",
    "        return self.custom_loss(self, T_all, Tbo_all, *self.cl_args, **self.cl_kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def test_collision(self, T_all, Tbo_all):\n",
    "        Pbo_all = tf.gather(tf.gather(Tbo_all, [0,1,2], axis=-2), 3, axis=-1)\n",
    "        col_combs_masked_batch = self.get_collision_combination()\n",
    "        batch_flat = tf.repeat(np.reshape(np.arange(self.N_sim), (self.N_sim, 1)), (self.N_col,)*self.N_sim,axis=0)\n",
    "        col_combs_masked_flat = tf.concat([batch_flat, col_combs_masked_batch], axis=-1)\n",
    "        vtx_tf = tf.gather(\n",
    "            K.sum(tf.expand_dims(Tbo_all, axis=-3)*tf.expand_dims(self.object_vertice_mat, axis=-2), axis=-1), \n",
    "            [0,1,2], axis=-1)\n",
    "        vtx_tf_1 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "        vtx_tf_2 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "        Pbo_all_1 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col,3))\n",
    "        Pbo_all_2 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col,3))\n",
    "        v_batch = tf.expand_dims(Pbo_all_1-Pbo_all_2, axis=-2)\n",
    "        v_batch = tf.stop_gradient(tf.linalg.cross(v_batch, self.x_batch)+tf.linalg.cross(v_batch, self.y_batch))\n",
    "        dist, flag = test_collision_batch(vtx_tf_1, vtx_tf_2, \n",
    "                             v_batch, self.flag_default, self.dist_default, IterationAllowed=self.col_iteration)\n",
    "        return dist, flag, col_combs_masked_flat \n",
    "    \n",
    "    @tf.function\n",
    "    def calc_collision_loss(self, T_all, Tbo_all):\n",
    "        dist, flag, _  = self.test_collision(T_all, Tbo_all)\n",
    "        return K.sum(1/((dist/self.COL_BOUND)**3))\n",
    "    \n",
    "    def get_collision_combination_names(self):\n",
    "        comb_names = []\n",
    "        for comb in self.get_collision_combination():\n",
    "            comb_names += [\"{} - {}\".format(self.object_name_list[comb[0]], graph.object_name_list[comb[1]])]\n",
    "            \n",
    "    def get_vtx_pair(self, pair_list, N_vtx1, N_vtx2):\n",
    "        N_col = len(pair_list)\n",
    "        pair_vtx1 = np.zeros((1, len(pair_list), len(self.object_name_list), N_vtx1, 1, 4)) # (N_sim, N_col, N_obj, N_vtx, 1, 4)\n",
    "        pair_vtx2 = np.zeros((1, len(pair_list), len(self.object_name_list), N_vtx2, 1, 4))\n",
    "        pair_dist1 = np.zeros((1, len(pair_list), 1))\n",
    "        pair_dist2 = np.zeros((1, len(pair_list), 1))\n",
    "        for i_c, comb in zip(range(len(pair_list)), pair_list):\n",
    "            pair_vtx1[0,i_c,comb[0],:,0] = np.pad(self.object_dict[self.object_name_list[comb[0]]].gitem.get_vertice(),((0,0),(0,1)),'constant', constant_values=(1))\n",
    "            pair_vtx2[0,i_c,comb[1],:,0] = np.pad(self.object_dict[self.object_name_list[comb[1]]].gitem.get_vertice(),((0,0),(0,1)),'constant', constant_values=(1))\n",
    "            pair_dist1[0,i_c, 0] = self.object_dict[self.object_name_list[comb[0]]].gitem.get_radius()\n",
    "            pair_dist2[0,i_c, 0] = self.object_dict[self.object_name_list[comb[1]]].gitem.get_radius()\n",
    "        pair_vtx1 = tf.constant(pair_vtx1, dtype=tf.float32)\n",
    "        pair_vtx2 = tf.constant(pair_vtx2, dtype=tf.float32)\n",
    "        pair_dist1 = tf.constant(pair_dist1, dtype=tf.float32)\n",
    "        pair_dist2 = tf.constant(pair_dist2, dtype=tf.float32)\n",
    "        return pair_vtx1, pair_vtx2, pair_dist1, pair_dist2, N_col\n",
    "    \n",
    "    def set_collision_vtx(self):\n",
    "        self.col_vtx1_dict = {}\n",
    "        self.col_vtx2_dict = {}\n",
    "        self.col_dist1_dict = {}\n",
    "        self.col_dist2_dict = {}\n",
    "        self.N_col_dict = {}\n",
    "        self.N_vtx_dict = {\"pt\":1, \"ln\":2, \"pl\":4, \"bx\":8}\n",
    "        for col_case in self.pair_cases:\n",
    "            self.col_vtx1_dict[col_case], self.col_vtx2_dict[col_case], \\\n",
    "                self.col_dist1_dict[col_case], self.col_dist2_dict[col_case], self.N_col_dict[col_case] = \\\n",
    "                    self.get_vtx_pair(\n",
    "                        self.col_pair_dict[col_case], self.N_vtx_dict[col_case[:2]], self.N_vtx_dict[col_case[3:]])\n",
    "        self.dcal = DistanceCalculator(self)\n",
    "        \n",
    "    def apply_col_mask(self):\n",
    "        self.col_mask_dict = {}\n",
    "        for col_case in self.pair_cases:\n",
    "            N_col = self.N_col_dict[col_case]\n",
    "            mask = np.zeros((self.N_sim, N_col, 1), dtype=np.float32)\n",
    "            for i_col, comb in zip(range(N_col), self.col_pair_dict[col_case]):\n",
    "                mask[:, i_col, 0] = tf.gather_nd(self.adjacency_mat, self.object_link_idx_mat[:, comb])\n",
    "            self.col_mask_dict[col_case] = 1-mask\n",
    "        self.dcal.apply_col_mask()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sim = 50\n",
    "N_joints = 9\n",
    "DOF = 6\n",
    "gtimer = GlobalTimer()\n",
    "\n",
    "\n",
    "gtimer.tic(\"initialize\")\n",
    "robot_info = RobotInfo(link_info_list, rname = \"rbt1\", base_frame=np.identity(4,dtype=np.float32))\n",
    "graph = GraphModel(robot_info=robot_info, gitem_list=gitem_list, urdf_content=urdf_content, \n",
    "                   N_sim=N_sim, learning_rate=5e-3, \n",
    "                   alpha_cl=0.001)\n",
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,0.00)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "T_all, Tbo_all = graph(None)\n",
    "Tbo_all_res = tf.reshape(Tbo_all, (graph.N_sim, 1, graph.num_object, 1, 4,4))\n",
    "res = graph.dcal.calc_all(Tbo_all_res)\n",
    "gtimer.toc(\"initialize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assign: \t6.0 ms/1 = 5.556 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "gtimer.tic(\"assign\")\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "gtimer.toc(\"assign\")\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc: \t101.0 ms/50 = 2.018 ms \n",
      "collision: \t326.0 ms/50 = 6.519 ms \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,0.00)).astype(np.float32)\n",
    "\n",
    "gtimer.reset()\n",
    "res_vec = []\n",
    "for _ in range(50):\n",
    "    gtimer.tic(\"calc\")\n",
    "    T_all, Tbo_all = graph(None)\n",
    "    Tbo_all_res = tf.reshape(Tbo_all, (graph.N_sim, 1, graph.num_object, 1, 4,4))\n",
    "    gtimer.toc(\"calc\")\n",
    "    gtimer.tic(\"collision\")\n",
    "    res = graph.dcal.calc_all(Tbo_all_res)\n",
    "    gtimer.toc(\"collision\")\n",
    "    res_vec += [res]\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as mplot3d\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sub = fig.add_subplot(1,1,1,projection=\"3d\")\n",
    "# x, y, z = np.pad(np.transpose(pl2[0,0]), [[0,0],[1,0]])\n",
    "x,y,z = np.transpose(vtx1_all[0,10])\n",
    "sub.plot(x,y,z,'-d')\n",
    "x,y,z = np.transpose(vtx2_all[0,10])\n",
    "sub.plot(x,y,z,'-d')\n",
    "sub.plot([0],[0],[0],'+')\n",
    "sub.set_xlabel('x')\n",
    "sub.set_ylabel('y')\n",
    "sub.set_zlabel('z')\n",
    "\n",
    "# sub.view_init(elev=0., azim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Q_[0]\n",
    "gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "pose_list = [q[2:-1]]\n",
    "gframevec_list = [gframevec]\n",
    "show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist, flag = distance_pt_pl(zeros_pt, pl2, dist1, dist2, N_sim, N_col)\n",
    "dist = dist - (dist1+dist2)\n",
    "flag = tf.less_equal(dist, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,0.00)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_vec = []\n",
    "Q_list = [list(map(lambda x: x.numpy(), graph.get_Q()))]\n",
    "# Tbo_all_list = [np.array([[gframe_dict[gitem.name].Toff for gitem in gitem_list]]*N_sim)]\n",
    "N_iter = 100\n",
    "# Run training for the given number of steps.\n",
    "Qtar, binQ, Ttar, binT = (np.zeros((N_sim, N_joints), dtype='float32'), np.zeros(N_sim, dtype='float32'),\n",
    "                      np.array([Ttar_]*N_sim), np.ones(N_sim, dtype='float32'))\n",
    "dist_list = []\n",
    "loss_list = []\n",
    "jl_loss_list = []\n",
    "jc_loss_list = []\n",
    "fc_loss_list = []\n",
    "cl_loss_list = []\n",
    "gradients_list = []\n",
    "gtimer.reset()\n",
    "for _ in range(N_iter):\n",
    "    # Run the optimization to update W and b values.\n",
    "    T_all, Tbo_all = graph(None)\n",
    "    dist_list += [K.min(graph.test_collision(T_all, Tbo_all)[0]).numpy()]\n",
    "    jl_loss = graph.calc_joint_limit()\n",
    "    jc_loss = graph.joint_constraint((Qtar, binQ))\n",
    "    fc_loss = graph.frame_constraint((T_all[:,-1,:,:],Ttar, binT))\n",
    "    cl_loss = graph.calc_collision_loss(T_all, Tbo_all)\n",
    "    gtimer.tic(\"update\")\n",
    "    loss = graph.update_once(Qtar, binQ, Ttar, binT, max_gradient=10)\n",
    "#     max_gradient=10\n",
    "\n",
    "#     with tf.GradientTape() as g:\n",
    "#         # Forward pass.\n",
    "#         loss = graph.forward(Qtar, binQ, Ttar, binT)\n",
    "\n",
    "#     # Variables to update, i.e. trainable variables.\n",
    "#     trainable_variables = graph.trainable_variables\n",
    "\n",
    "#     # Compute gradients.\n",
    "#     gradients = g.gradient(loss, trainable_variables)\n",
    "#     gradients = tf.unstack(clip_gradient(gradients, max_gradient))\n",
    "\n",
    "#     # Update W and b following gradients.\n",
    "#     graph.optimizer.apply_gradients(zip(gradients, graph.trainable_variables))\n",
    "    gtimer.toc(\"update\")\n",
    "    gtimer.tic(\"record\")\n",
    "    Q_list += [graph.get_Q().numpy()]\n",
    "    loss_list += [loss]\n",
    "#     gradients_list += [gradients]\n",
    "    jl_loss_list += [jl_loss]\n",
    "    jc_loss_list += [jc_loss]\n",
    "    fc_loss_list += [fc_loss]\n",
    "    cl_loss_list += [cl_loss]\n",
    "    gtimer.toc(\"record\")\n",
    "    if isnan(dist_list[-1]) or dist_list[-1]<0:\n",
    "        break\n",
    "gtimer.print_time_log()\n",
    "print(\"loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_sim in range(1): # N_sim):\n",
    "    for i_iter in range(0,len(Q_list)):\n",
    "        q = Q_list[i_iter][i_sim]\n",
    "        gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "        pose_list = [q[2:-1]]\n",
    "        gframevec_list = [gframevec]\n",
    "        show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)\n",
    "        time.sleep(10e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _loop_pickTetrahedron_batch(a, b, c, d, v, dist, flag, FX1_batch, FX2_batch, iter):\n",
    "    a,b,c,v_,dist_ = pickClosestFace_batch(a,b,c,d)\n",
    "    v_ = tf.stop_gradient(v_)\n",
    "    a_,b_,c_,d_ = nearest_simplex4_batch(a,b,c,v_, dist_, FX1_batch,FX2_batch)\n",
    "    flag = tf.less_equal(dist_,0)\n",
    "    def_case = tf.stop_gradient(tf.cast(flag, tf.float32))\n",
    "    def_case_not = tf.stop_gradient(tf.cast(tf.logical_not(flag), tf.float32))\n",
    "    def_case_exp = tf.expand_dims(def_case,axis=-1)\n",
    "    def_case_not_exp = tf.expand_dims(def_case_not,axis=-1)\n",
    "    d = def_case_not*d_ + def_case*d\n",
    "    c = def_case_not*c_ + def_case*c\n",
    "    b = def_case_not*b_ + def_case*b\n",
    "    a = def_case_not*a_ + def_case*a\n",
    "    v = def_case_not_exp*v_ + def_case_exp*v\n",
    "    dist = def_case_not*dist_ + def_case*dist\n",
    "#     d = d_\n",
    "#     c = c_\n",
    "#     b = b_\n",
    "#     a = a_\n",
    "#     v = v_\n",
    "#     dist = dist_\n",
    "    iter += 1\n",
    "    return a, b, c, d, v, dist, flag, FX1_batch, FX2_batch, iter\n",
    "\n",
    "@tf.function\n",
    "def _cond_pickTetrahedron_batch(a, b, c, d, v, dist, flag, FX1_batch, FX2_batch, iter):\n",
    "    return tf.reduce_any(tf.logical_not(flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "Q_ = np.array([[ 0.        ,  0.        ,  0.00195152, -1.8906006 ,  1.90172   , -0.01040376, -0.00901779,  0.02714482,  0.]\n",
    "               for _ in range(N_sim)], dtype=np.float32)\n",
    "\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,-0.05)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_all, Tbo_all = graph(None)\n",
    "self = graph\n",
    "Pbo_all = tf.gather(tf.gather(Tbo_all, [0,1,2], axis=-2), 3, axis=-1)\n",
    "col_combs_masked_batch = self.get_collision_combination()\n",
    "batch_flat = tf.repeat(np.reshape(np.arange(self.N_sim), (self.N_sim, 1)), (self.N_col,)*self.N_sim,axis=0)\n",
    "col_combs_masked_flat = tf.concat([batch_flat, col_combs_masked_batch], axis=-1)\n",
    "vtx_tf = tf.gather(\n",
    "    K.sum(tf.expand_dims(Tbo_all, axis=-3)*tf.expand_dims(self.object_vertice_mat, axis=-2), axis=-1), \n",
    "    [0,1,2], axis=-1)\n",
    "vtx_tf_1 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "vtx_tf_2 = tf.reshape(tf.gather_nd(vtx_tf, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col, -1,3))\n",
    "Pbo_all_1 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,1], axis=1)), (self.N_sim, self.N_col,3))\n",
    "Pbo_all_2 = tf.reshape(tf.gather_nd(Pbo_all, tf.gather(col_combs_masked_flat, [0,2], axis=1)), (self.N_sim, self.N_col,3))\n",
    "v_batch = tf.expand_dims(Pbo_all_1-Pbo_all_2, axis=-2)\n",
    "v_batch = tf.linalg.cross(v_batch, self.x_batch)+tf.linalg.cross(v_batch, self.y_batch)\n",
    "# dist, flag = test_collision_batch(vtx_tf_1, vtx_tf_2, \n",
    "#                      v_batch, self.flag_default, self.dist_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FX1_batch, FX2_batch, v_batch,flag_default,dist_default, IterationAllowed = \\\n",
    "    vtx_tf_1, vtx_tf_2, v_batch, self.flag_default, self.dist_default, 10\n",
    "a, b = pickLineTF_batch(v_batch, FX2_batch, FX1_batch)\n",
    "a, b, c, flag = PickTriangleTF_batch(a,b,FX2_batch,FX1_batch,flag_default,IterationAllowed)\n",
    "# a,b,c,d,dist,flag, iter = pickTetrahedronTF_batch(a,b,c,FX2_batch,FX1_batch,flag_default,dist_default,IterationAllowed)\n",
    "\n",
    "a,b,c,FX1_batch,FX2_batch,flag_default,dist_default,IterationAllowed = \\\n",
    "    a,b,c,FX2_batch,FX1_batch,flag_default,dist_default,IterationAllowed\n",
    "    ab = b-a\n",
    "    ac = c-a\n",
    "\n",
    "    # Normal to face of triangle\n",
    "    abc = tf.linalg.cross(ab,ac)\n",
    "    v, abc_nm = tf.linalg.normalize(abc,axis=-1)\n",
    "    v = tf.stop_gradient(v)\n",
    "    dist = K.sum(v*a,axis=-1, keepdims=True)\n",
    "    v = tf.expand_dims(v, axis=-2)\n",
    "    v = tf.stop_gradient(v)\n",
    "\n",
    "    a,b,c,d = nearest_simplex4_batch(a,b,c,v,dist, FX1_batch,FX2_batch)\n",
    "\n",
    "\n",
    "    a, b, c, d, v, dist, flag, _, _, iter = tf.while_loop(\n",
    "        _cond_pickTetrahedron_batch, _loop_pickTetrahedron_batch, \n",
    "        (a,b,c,d,v,dist_default,flag_default, FX1_batch, FX2_batch, 0), \n",
    "        parallel_iterations=10, maximum_iterations=IterationAllowed\n",
    "    )\n",
    "    v = tf.stop_gradient(v)\n",
    "    v_, dist_ = direct(b,c,d,v,dist)\n",
    "    v_ = tf.stop_gradient(v_)\n",
    "    # v_ = tf.sign(tf.expand_dims(dist,axis=-1))*v_\n",
    "    # dist2 = tf.sign(dist)*dist_\n",
    "    a = support_batch(FX2_batch,FX1_batch,v_) # Tetrahedron new point\n",
    "    v_rs = tf.reduce_sum(v, axis=-2)\n",
    "    dist3_ = K.sum(-a*v_rs, axis=-1)\n",
    "    dotted = tf.reduce_sum(K.sum(v_*v, axis=-1), axis=-1)\n",
    "    dist = dist3_/dotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.sum(-a*tf.reduce_sum(v, axis=-2), axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[0,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.sum(-a[0,14]*v[0,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.sum(-b[0,14]*v[0,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.sum(-c[0,14]*v[0,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_bak = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a[0]-a_bak[0])\n",
    "plt.ylim([-1e-1, 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = (tf.reduce_sum(dist2,axis=-1)-dist3)[0]\n",
    "plt.plot(dd)\n",
    "# plt.plot(dotted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i_max_dd = K.argmax(dd)\n",
    "i_max_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[0, i_max_dd] #normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_[0, i_max_dd] # refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist2[0, i_max_dd] # resigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist[0, i_max_dd]/dotted[0, i_max_dd] # original rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist3_[0, i_max_dd] # new a normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist3[0, i_max_dd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[0, i_max_dd] # original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_[0, i_max_dd] # refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_max_dd = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = graph.get_collision_combination()[i_max_dd]\n",
    "print(graph.object_name_list[comb[0]])\n",
    "print(graph.object_name_list[comb[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = np.mean(FX1_batch[0][i_max_dd],axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as mplot3d\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "sub = fig.add_subplot(1,1,1,projection=\"3d\")\n",
    "x, y, z = np.transpose(FX1_batch[0][i_max_dd])\n",
    "sub.plot(x,y,z,'.')\n",
    "x, y, z = np.transpose(FX2_batch[0][i_max_dd])\n",
    "sub.plot(x,y,z,'.')\n",
    "x, y, z = np.transpose(offset + np.pad(v_[0,i_max_dd]/10, ((1,0),(0,0))))\n",
    "sub.plot(x,y,z,'-o')\n",
    "x, y, z = np.transpose(offset + np.pad(v[0,i_max_dd]/10, ((1,0),(0,0))))\n",
    "sub.plot(x,y,z,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[0,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_[0,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.argmin(dist[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.min(dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.min(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_collision_combination()[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.object_name_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.object_name_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Q_[0]\n",
    "gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "pose_list = [q[2:-1]]\n",
    "gframevec_list = [gframevec]\n",
    "show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list, label=\"total\")\n",
    "print(len(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list, label=\"total\")\n",
    "plt.plot(np.multiply(jl_loss_list, graph.alpha_jl), label=\"joint limit\")\n",
    "plt.plot(np.multiply(jc_loss_list, graph.alpha_jc), label=\"joint target\")\n",
    "plt.plot(np.multiply(fc_loss_list, graph.alpha_fc), label=\"frame target\")\n",
    "plt.plot(np.multiply(cl_loss_list, graph.alpha_cl), label=\"collision dist\")\n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "# axes.set_ylim([-1e1,5e1])\n",
    "# axes.set_xlim([0,1e1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_sim in range(1): # N_sim):\n",
    "    for i_iter in range(0,len(Q_list)):\n",
    "        q = Q_list[i_iter][i_sim]\n",
    "        gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "        pose_list = [q[2:-1]]\n",
    "        gframevec_list = [gframevec]\n",
    "        show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)\n",
    "        time.sleep(10e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_all = np.array(Q_list)\n",
    "Q_all_i = np.array([Q_all[i_iter, i_sim,:] for i_iter in range(len(Q_list))])\n",
    "plt.plot(Q_all_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Q_all_i[1:,:]-Q_all_i[:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_ = np.array([(0, 0,)+tuple(ZERO_JOINT_POSE+(np.random.rand(DOF)*2-1)*np.pi/100)+(0,) for _ in range(N_sim)], dtype=np.float32)\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ttar_ = SE3(Rot_zyx(0,0,np.pi),(0.5,0,-0.05)).astype(np.float32)\n",
    "gframe_dict_list = [gframe_dict]*N_sim\n",
    "graph.assign_Q(Q_)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "T_all, Tbo_all = graph(None)\n",
    "show_motion([graph.get_Q().numpy()[0][2:-1]], marker_list, [[gframe_dict[gitem.name] for gitem in gitem_list]], pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_all, Tbo_all = graph(None)\n",
    "gtimer.reset()\n",
    "for _ in range(10):\n",
    "    gtimer.tic(\"ctest\")\n",
    "    dist, flag, mask = graph.test_collision(T_all, Tbo_all)\n",
    "    gtimer.toc(\"ctest\")\n",
    "print(gtimer)\n",
    "# dist[0]\n",
    "# gtimer.reset()\n",
    "# for _ in range(100):\n",
    "#     gtimer.tic(\"col\")\n",
    "#     dist, flag = collision_loss_test(graph, T_all, Tbo_all, flag_default, dist_default)\n",
    "#     gtimer.toc(\"col\")\n",
    "# gtimer.print_time_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.calc_collision_loss(T_all, Tbo_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot([0, N_col],[0,0],'-ob')\n",
    "plt.grid()\n",
    "dist0 = dist[0]\n",
    "mask0 = mask[:N_col]\n",
    "for i_m in range(len(mask0)):\n",
    "    plt.plot([i_m, i_m],mask0[i_m,1:],'-o')\n",
    "plt.plot(dist0*10,'-ok',linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.object_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision error case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_error = np.loadtxt(\"Q_error.csv\",delimiter=\",\",dtype=np.float32)\n",
    "graph.assign_Q(Q_error)\n",
    "graph.assign_frame_dict(gframe_dict_list)\n",
    "\n",
    "T_all, Tbo_all = graph(None)\n",
    "dist = K.min(graph.test_collision(T_all, Tbo_all)[0]).numpy()\n",
    "cl_loss = graph.calc_collision_loss(T_all, Tbo_all)\n",
    "print(\"dist: {}\".format(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Q_error[0]\n",
    "gframevec = [gframe_dict[gitem.name] for gitem in gitem_list]\n",
    "pose_list = [q[2:-1]]\n",
    "gframevec_list = [gframevec]\n",
    "show_motion(pose_list, marker_list, gframevec_list, pub, joints, error_skip=1e-6, period=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpl_toolkits.mplot3d as mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sub = fig.add_subplot(1,1,1,projection=\"3d\")\n",
    "sub.plot(x,y,z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,4*np.pi,500)\n",
    "x = np.sin(t)\n",
    "x = np.cos(t)\n",
    "y = np.sin(t)\n",
    "z = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
