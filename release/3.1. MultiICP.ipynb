{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check List 3.1 - MultiICP Detector\n",
    "* **3.1.1 MultiICP**  \n",
    "  - initialize, set_config, get_config, get_image, detect, detect_and_register, disconnect  \n",
    "  \n",
    "  \n",
    "* **TBD**\n",
    "  - Auto initialization to estimate initial guess for ICP is not perfect\n",
    "  - Robust and reliable initial guess for gloabl registration will be done\n",
    "  - Multiple instance for the same class will be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set running directory to Project source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from pkg.geometry.geometry import GeometryItem\n",
    "from pkg.geometry.geotype import GEOTYPE\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "from pkg.detector.multiICP.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add camera geometry\n",
    "def add_cam(gscene, tool_link=\"indy0_tcp\"):\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"cam\", link_name=tool_link,\n",
    "                       dims=(0.061, 0.061, 0.026), center=(-0.0785, 0, 0.013), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.5), display=True, fixed=True, collision=False)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"cam_col\", link_name=tool_link,\n",
    "                       dims=(0.081, 0.081, 0.046), center=(-0.0785, 0, 0.013), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.2), display=True, fixed=True, collision=True)\n",
    "\n",
    "    viewpoint = gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"viewpoint\", link_name=tool_link,\n",
    "                                   dims=(0.01, 0.01, 0.01), center=(-0.013, 0, 0), rpy=(0, 0, -np.pi / 2),\n",
    "                                   color=(1, 0, 0, 0.3), display=True, fixed=True, collision=False, parent=\"cam\")\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"body\", link_name=tool_link,\n",
    "                       dims=(0.067, 0.067, 0.0335), center=(-0.0785, 0, -0.01675), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 1), display=True, fixed=True, collision=False)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"body_col\", link_name=tool_link,\n",
    "                       dims=(0.087, 0.087, 0.0535), center=(-0.0785, 0, -0.01675), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.2), display=True, fixed=True, collision=True)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"backhead\", link_name=tool_link,\n",
    "                       dims=(0.067, 0.067, 0.067), center=(-0.0785, 0, -0.0335), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 1), display=True, fixed=True, collision=False)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"backhead_col\", link_name=tool_link,\n",
    "                       dims=(0.087, 0.087, 0.087), center=(-0.0785, 0, -0.0335), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.2), display=True, fixed=True, collision=True)\n",
    "    return viewpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 MultiICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.multiICP import MultiICP, MultiICP_Obj\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create multiICP instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp = MultiICP(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is not set - skip initialization, use manually given camera configs\n"
     ]
    }
   ],
   "source": [
    "config_list, img_dim = load_pickle(RNB_PLANNING_DIR+\"release/multiICP_data/cam_configs.pkl\")\n",
    "micp.initialize(config_list=config_list, img_dim=img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create SceneBuilder instance and geometry scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "kmb0: False\n",
      "indy1: False\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    }
   ],
   "source": [
    "INDY_BASE_OFFSET = (0.172,0,0.439)\n",
    "INDY_BASE_RPY = (0,0,0)\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                \"{}/{}\".format(None, None))\n",
    "robot_config = RobotConfig(1, RobotType.indy7, \n",
    "                           (INDY_BASE_OFFSET, INDY_BASE_RPY),\n",
    "                           None, root_on=\"kmb0_platform\", \n",
    "                           specs={\"no_sdk\":True})\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[False, False])\n",
    "\n",
    "scene_builder = SceneBuilder.instance(detector=micp)\n",
    "gscene = scene_builder.create_gscene(crob)\n",
    "\n",
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "ROBOT_BASE = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][0]\n",
    "TIP_LINK = pscene.robot_chain_dict[ROBOT_NAME][\"tip_link\"]\n",
    "MOBILE_BASE = pscene.robot_chain_dict[MOBILE_NAME][\"tip_link\"]\n",
    "HOLD_LINK = MOBILE_BASE\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=TIP_LINK)\n",
    "VIEW_POSE = np.deg2rad([  0., 50.,  -70.,  -0.,  -90., 0])\n",
    "VIEW_LOC = [0]*6\n",
    "VIEW_POSE_EXT = np.array(VIEW_LOC + list(VIEW_POSE))\n",
    "T_bc = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "T_cb = SE3_inv(T_bc)\n",
    "gscene.show_pose(VIEW_POSE_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MultiICP configs\n",
    "* You have to make micp, hrule and grule for each object you want to detect\n",
    "\n",
    "* hrule means heuristic rule for special object which cannot be detected thorugh mask rcnn using COCO dataset\n",
    "\n",
    "* grule means initial guess(R,t) for ICP\n",
    "\n",
    "* Run shraed detector to detect object in color image\n",
    "\n",
    "##### Run shared detector for object detection on bash\n",
    "```bash\n",
    "python3 $RNB_PLANNING_DIR/src/pkg/detector/multiICP/shared_detector.py --dims='(720,1280,3)'\n",
    "```\n",
    "* change dims=(*) depending on your camera resolution\n",
    "\n",
    "#### Clearing shared detector channels if zombie memory remains\n",
    "```python\n",
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "\n",
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(micp.img_dim+(3,))()\n",
    "sd.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load example data (for bed, closet)\n",
    "* You need to prepare example data and stl model to test MultiICP detector \n",
    "* Use color image, depth image and csv file which has joint values Q with cam_intrins, depth_scale \n",
    "* file path: release/multiICP_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rdict(file_name):\n",
    "    rdict = {}\n",
    "    \n",
    "    rdict['color'] = cv2.imread(\n",
    "        os.path.join(RNB_PLANNING_DIR, 'release/multiICP_data/', file_name + '.jpg'), flags=cv2.IMREAD_UNCHANGED)\n",
    "    rdict['depth'] = cv2.imread(\n",
    "        os.path.join(RNB_PLANNING_DIR, 'release/multiICP_data/', file_name + '.png'), flags=cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    Q = np.loadtxt(os.path.join(RNB_PLANNING_DIR, 'release/multiICP_data/', file_name + '.csvd'), delimiter=\",\")\n",
    "    return rdict, np.array(Q)\n",
    "\n",
    "rdict, Qtest = load_rdict(\"test_1\")\n",
    "color_img = rdict['color']\n",
    "depth_img = rdict['depth']\n",
    "Tc = viewpoint.get_tf(Qtest)\n",
    "gscene.show_pose(Qtest)\n",
    "\n",
    "obj_info_dict = get_obj_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object items you want to detect\n",
    "# heuristic rule items, Initial guess rule items\n",
    "micp_bed = MultiICP_Obj(obj_info_dict[\"bed\"], None,\n",
    "                        OffsetOnModelCoord(\"bed\", R=np.matmul(T_cb[:3, :3], Rot_axis(3, np.pi)),\n",
    "                                          offset=np.matmul(T_cb[:3, :3], (1.1 * 0.5, 0, -0.5))))\n",
    "\n",
    "mrule_closet = MaskBoxRule(\"closet\", \"bed\", merge_rule=np.all)\n",
    "mrule_closet.update_rule = ClosetRuleFun(mrule_closet)\n",
    "micp_closet = MultiICP_Obj(obj_info_dict[\"closet\"], \n",
    "                           mrule_closet,\n",
    "                           OffsetOnModelCoord(\"closet\", \n",
    "                                             offset=(0, 1, 0.3),\n",
    "                                             use_median=True\n",
    "                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_dict = {\"bed\": micp_bed, \"closet\": micp_closet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### detect()\n",
    "* Object Detection through swin-transformer based mask rcnn using mmdet\n",
    "* To use test data(color, depth image and joint value Q), you have to call cache_sensor()\n",
    "* Detection result is the transformation w.r.t base coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.cache_sensor(color_img, depth_img, Qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is None\n",
      "===== Detected : handbag, 1 object(s) =====\n",
      "===== Detected : suitcase, 1 object(s) =====\n",
      "===== Detected : bowl, 3 object(s) =====\n",
      "===== Detected : bed, 1 object(s) =====\n",
      "===== Detected : clock, 1 object(s) =====\n",
      "\n",
      "'bed' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.427715e-01, inlier_rmse=6.878896e-02, and correspondence_set size of 5060\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82151496 -0.10241734  0.56091342 -0.5930757 ]\n",
      " [-0.22373454 -0.9627413   0.15189486  0.65864584]\n",
      " [ 0.52445784 -0.2502796  -0.81382068  4.62658037]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.477495e-01, inlier_rmse=4.377588e-02, and correspondence_set size of 2166\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82315056 -0.06585229  0.5639917  -0.57596027]\n",
      " [-0.15879798 -0.98031779  0.11730398  0.72365769]\n",
      " [ 0.54516636 -0.18611958 -0.81740635  4.61509931]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of bed\n",
      "===== Apply heuristic rule for closet =====\n",
      "CLOSET ON LEFT\n",
      "\n",
      "'closet' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=6.635616e-01, inlier_rmse=6.435333e-02, and correspondence_set size of 31628\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.55241442 -0.02079903 -0.83331013 -0.76970753]\n",
      " [ 0.13668452 -0.98389717  0.11516792  0.7097487 ]\n",
      " [-0.82228687 -0.17752101 -0.54067608  4.45277305]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.478928e-01, inlier_rmse=3.073342e-02, and correspondence_set size of 18646\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.53323531 -0.03681037 -0.84516576 -0.74155195]\n",
      " [ 0.14137397 -0.98112604  0.13192821  0.72407122]\n",
      " [-0.83407047 -0.18983322 -0.51796701  4.50733941]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of closet\n"
     ]
    }
   ],
   "source": [
    "pose_dict = micp.detect(visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reset_reference_coord()\n",
    "* **WARNING** MultiICP need pre-initialized CombinedRobot and GeometryScene: Should not call reset_reference_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### detect_and_register()\n",
    "* Detect items in the field of view and register them to the GeometryScene\n",
    "* They will appear in the RVIZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.cache_sensor(color_img, depth_img, Qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['closet', 'bed']\n",
      "===== Detected : bed, 1 object(s) =====\n",
      "\n",
      "'bed' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.372751e-01, inlier_rmse=6.896300e-02, and correspondence_set size of 5027\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82322285 -0.09780685  0.55922979 -0.58576874]\n",
      " [-0.21700862 -0.96445587  0.15077177  0.66013347]\n",
      " [ 0.52460595 -0.24547645 -0.81518704  4.62138416]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.428627e-01, inlier_rmse=4.210993e-02, and correspondence_set size of 2167\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82555468 -0.05574983  0.5615616  -0.57364343]\n",
      " [-0.15049297 -0.98082034  0.12386818  0.71511024]\n",
      " [ 0.54388541 -0.18677103 -0.81811078  4.61797162]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of bed\n",
      "===== Apply heuristic rule for closet =====\n",
      "CLOSET ON LEFT\n",
      "\n",
      "'closet' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=6.603516e-01, inlier_rmse=6.390734e-02, and correspondence_set size of 31475\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.5578189  -0.0200273  -0.829721   -0.77376876]\n",
      " [ 0.13508692 -0.98418713  0.11457425  0.71013284]\n",
      " [-0.81889533 -0.17599614 -0.54629276  4.45257041]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.484363e-01, inlier_rmse=3.050327e-02, and correspondence_set size of 18651\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.53295767 -0.03639933 -0.84535861 -0.74167719]\n",
      " [ 0.14177424 -0.98110888  0.13162624  0.7195925 ]\n",
      " [-0.83417992 -0.1900013  -0.51772902  4.50672109]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of closet\n",
      "\u001b[93m[WARN] Vertices for mesh should be have center point (0,0,0). Auto adjusting.\u001b[0m\n",
      "\u001b[93m[WARN] Vertices for mesh should be have center point (0,0,0). Auto adjusting.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gtem_dict = scene_builder.detect_and_register(level_mask=[DetectionLevel.ENVIRONMENT])\n",
    "# gtem_dict = scene_builder.detect_and_register(level_mask=[DetectionLevel.MOVABLE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
