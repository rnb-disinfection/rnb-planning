{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check List 3.2 - Combined Detector (ArucoStero, MultiICP)  \n",
    "\n",
    "* This test is for checking combined detection functionality with Aruco and MultiICP. Two cameras and one cup is used as shown below. \n",
    "\n",
    "\n",
    "* **3.2.1 Combined Detector**  \n",
    "  - initialize, set_config, detect_and_register, disconnect   \n",
    "\n",
    "* **Test setup**\n",
    "  - Camera: Kinect (Main), Realsense(Sub)\n",
    "  - Target: Cup\n",
    "<img src=\"./Figs/3.2.CupDetection.jpg\" width=\"80%\">\n",
    "  \n",
    "* **TBD**\n",
    "  - Auto initialization to estimate initial guess for ICP is not perfect\n",
    "  - Robust and reliable initial guess for gloabl registration will be done\n",
    "  - Multiple instance for the same class will be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set running directory to Project source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from pkg.geometry.geometry import GeometryItem\n",
    "from pkg.geometry.geotype import GEOTYPE\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "from pkg.detector.multiICP.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Combined Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.combined_detector import CombinedDetector\n",
    "from pkg.detector.multiICP.multiICP import MultiICP, MultiICP_Obj\n",
    "from pkg.detector.aruco.stereo import ArucoStereo\n",
    "from pkg.detector.aruco.marker_config import get_aruco_map\n",
    "from pkg.detector.camera.kinect import Kinect\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = Kinect()\n",
    "rs = RealSense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create ArucoStereo instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device configuration: \n",
      "\tcolor_format: 3 \n",
      "\t(0:JPG, 1:NV12, 2:YUY2, 3:BGRA32)\n",
      "\n",
      "\tcolor_resolution: 5 \n",
      "\t(0:OFF, 1:720p, 2:1080p, 3:1440p, 4:1536p, 5:2160p, 6:3072p)\n",
      "\n",
      "\tdepth_mode: 3 \n",
      "\t(0:OFF, 1:NFOV_2X2BINNED, 2:NFOV_UNBINNED,3:WFOV_2X2BINNED, 4:WFOV_UNBINNED, 5:Passive IR)\n",
      "\n",
      "\tcamera_fps: 2 \n",
      "\t(0:5 FPS, 1:15 FPS, 2:30 FPS)\n",
      "\n",
      "\tsynchronized_images_only: False \n",
      "\t(True of False). Drop images if the color and depth are not synchronized\n",
      "\n",
      "\tdepth_delay_off_color_usec: 0 ms. \n",
      "\tDelay between the color image and the depth image\n",
      "\n",
      "\twired_sync_mode: 0\n",
      "\t(0:Standalone mode, 1:Master mode, 2:Subordinate mode)\n",
      "\n",
      "\tsubordinate_delay_off_master_usec: 0 ms.\n",
      "\tThe external synchronization timing.\n",
      "\n",
      "\tdisable_streaming_indicator: False \n",
      "\t(True or False). Streaming indicator automatically turns on when the color or depth camera's are in use.\n",
      "\n",
      "\n",
      "Start streaming\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([[1.82983423e+03, 0.00000000e+00, 1.91572046e+03],\n",
       "         [0.00000000e+00, 1.82983423e+03, 1.09876086e+03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
       "  array([ 7.09966481e-01, -2.73409390e+00,  1.45804870e-03, -3.24774766e-04,\n",
       "          1.44911301e+00,  5.84310412e-01, -2.56374550e+00,  1.38472950e+00]),\n",
       "  0.001),\n",
       " (array([[1.39560388e+03, 0.00000000e+00, 9.62751587e+02],\n",
       "         [0.00000000e+00, 1.39531934e+03, 5.47687012e+02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]),\n",
       "  array([0., 0., 0., 0., 0.]),\n",
       "  0.0010000000474974513),\n",
       " array([[ 0.81117624, -0.03337384, -0.5838487 ,  0.7141189 ],\n",
       "        [ 0.14473428,  0.9787678 ,  0.14513993, -0.14857051],\n",
       "        [ 0.5666084 , -0.202237  ,  0.7987835 ,  0.05353302],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stereo = ArucoStereo(aruco_map=get_aruco_map(), \n",
    "                     camera_list=[kn, rs])\n",
    "stereo.initialize()\n",
    "\n",
    "time.sleep(1) # Let the camera have some time to get stable\n",
    "stereo.calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create multiICP instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device configuration: \n",
      "\tcolor_format: 3 \n",
      "\t(0:JPG, 1:NV12, 2:YUY2, 3:BGRA32)\n",
      "\n",
      "\tcolor_resolution: 5 \n",
      "\t(0:OFF, 1:720p, 2:1080p, 3:1440p, 4:1536p, 5:2160p, 6:3072p)\n",
      "\n",
      "\tdepth_mode: 3 \n",
      "\t(0:OFF, 1:NFOV_2X2BINNED, 2:NFOV_UNBINNED,3:WFOV_2X2BINNED, 4:WFOV_UNBINNED, 5:Passive IR)\n",
      "\n",
      "\tcamera_fps: 2 \n",
      "\t(0:5 FPS, 1:15 FPS, 2:30 FPS)\n",
      "\n",
      "\tsynchronized_images_only: False \n",
      "\t(True of False). Drop images if the color and depth are not synchronized\n",
      "\n",
      "\tdepth_delay_off_color_usec: 0 ms. \n",
      "\tDelay between the color image and the depth image\n",
      "\n",
      "\twired_sync_mode: 0\n",
      "\t(0:Standalone mode, 1:Master mode, 2:Subordinate mode)\n",
      "\n",
      "\tsubordinate_delay_off_master_usec: 0 ms.\n",
      "\tThe external synchronization timing.\n",
      "\n",
      "\tdisable_streaming_indicator: False \n",
      "\t(True or False). Streaming indicator automatically turns on when the color or depth camera's are in use.\n",
      "\n",
      "\n",
      "Initialize Done\n"
     ]
    }
   ],
   "source": [
    "micp = MultiICP(kn)\n",
    "micp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = CombinedDetector([stereo, micp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create SceneBuilder instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_builder = SceneBuilder.instance(detector=detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set reference coordinate and viewpoint (by StereoAruco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T_kn = stereo.ref_coord_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create geometry scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "indy0: False\n",
      "panda1: False\n",
      "name_mask is []\n",
      "\u001b[93m[WARN] CombinedRobot is not set: call set_config()\u001b[0m\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.99967021, -0.01577677, -0.02026191,  0.02112267],\n",
       "        [ 0.00505459, -0.65269959,  0.75759995, -0.51821285],\n",
       "        [-0.02517742, -0.75745255, -0.65240461,  0.5546183 ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  1.        ]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crob = CombinedRobot(\n",
    "    robots_on_scene=[\n",
    "        RobotConfig(0, RobotType.indy7, ((0,-0.3,0), (0,0,0)), None),\n",
    "        RobotConfig(1, RobotType.panda, ((0,0.3,0), (0,0,0)), None)], \n",
    "    connection_list=[False, False])\n",
    "\n",
    "xyz_rpy_robots = scene_builder.detect_items(level_mask=[DetectionLevel.ROBOT])\n",
    "crob.update_robot_pos_dict(xyz_rpy_robots=xyz_rpy_robots)\n",
    "gscene = scene_builder.create_gscene(crob)\n",
    "gscene.show_pose(crob.home_pose)\n",
    "viewpoint = gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"viewpoint\", link_name=\"base_link\",\n",
    "                               dims=(0.05, 0.05, 0.02), center=T_kn[:3,3], rpy=Rot2rpy(T_kn[:3,:3]),\n",
    "                               color=(1, 0, 0, 0.3), display=True, fixed=True, collision=False)\n",
    "viewpoint.draw_traj_coords([crob.home_pose])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MultiICP configs\n",
    "* You have to make micp, hrule and grule for each object you want to detect\n",
    "\n",
    "* hrule means heuristic rule for special object which cannot be detected thorugh mask rcnn using COCO dataset\n",
    "\n",
    "* grule means initial guess(R,t) for ICP\n",
    "\n",
    "* Run shraed detector to detect object in color image\n",
    "\n",
    "##### (FYI) Running shared detector for object detection on bash - only when you want to keep detector server for multiple program runs\n",
    "```bash\n",
    "python3 /home/jhkim/Projects/rnb-planning/src/pkg/detector/multiICP/shared_detector.py --dims='(720,1280,3)'\n",
    "```\n",
    "\n",
    "#### Clearing shared detector channels if zombie memory remains\n",
    "```python\n",
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Data size too big for shared function: 165888000 - shared_fun.inference.shareddetector.0\n"
     ]
    }
   ],
   "source": [
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "sd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_info_dict = get_obj_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object items you want to detect\n",
    "# heuristic rule items, Initial guess rule items\n",
    "micp_cup = MultiICP_Obj(obj_info_dict[\"cup\"], None,\n",
    "                        OffsetOnModelCoord(\"cup\", R=Rot_axis(1, np.pi/2), offset=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_dict = {\"cup\": micp_cup}\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### detect_and_register()\n",
    "* Detect items in the field of view and register them to the GeometryScene\n",
    "* They will appear in the RVIZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is []\n"
     ]
    }
   ],
   "source": [
    "gtem_dict = scene_builder.detect_and_register(level_mask=[DetectionLevel.ENVIRONMENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['cup']\n",
      "===== Detected : cup, 1 object(s) =====\n",
      "\n",
      "'cup' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.535097e-02, and correspondence_set size of 3881\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.61290073 -0.78971375 -0.02654972 -0.02437707]\n",
      " [-0.39108137 -0.27398116 -0.87862944 -0.08261382]\n",
      " [ 0.68659163  0.54889572 -0.47676559  0.64561296]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.61 -0.79 -0.03 -0.02]\n",
      " [-0.39 -0.27 -0.88 -0.08]\n",
      " [ 0.69  0.55 -0.48  0.65]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=5.653576e-03, and correspondence_set size of 1801\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.48073611 -0.86623679 -0.13611254 -0.01041573]\n",
      " [-0.50923985 -0.14943675 -0.84755144 -0.07405812]\n",
      " [ 0.71384002  0.47676251 -0.51296193  0.66897311]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.48 -0.87 -0.14 -0.01]\n",
      " [-0.51 -0.15 -0.85 -0.07]\n",
      " [ 0.71  0.48 -0.51  0.67]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of cup\n",
      "\u001b[93m[WARN] Vertices for mesh should be have center point (0,0,0). Auto adjusting.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gtem_dict = scene_builder.detect_and_register(level_mask=[DetectionLevel.MOVABLE], \n",
    "                                              visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
