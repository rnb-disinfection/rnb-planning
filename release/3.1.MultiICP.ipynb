{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check List 3.1 - MultiICP Detector\n",
    "\n",
    "This test is for checking functionality of MultiICP. All data are prepared as file, no HW required.\n",
    "\n",
    "* **3.1.1 MultiICP**  \n",
    "  - initialize, set_config, detect, detect_and_register, disconnect  \n",
    "  \n",
    "  \n",
    "* **TBD**\n",
    "  - Auto initialization to estimate initial guess for ICP is not perfect\n",
    "  - Robust and reliable initial guess for gloabl registration will be done\n",
    "  - Multiple instance for the same class will be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set running directory to Project source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from pkg.geometry.geometry import GeometryItem\n",
    "from pkg.geometry.geotype import GEOTYPE\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "from pkg.detector.multiICP.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add camera geometry\n",
    "def add_cam(gscene, tool_link=\"indy0_tcp\"):\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"cam\", link_name=tool_link,\n",
    "                       dims=(0.061, 0.061, 0.026), center=(-0.0785, 0, 0.013), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.5), display=True, fixed=True, collision=False)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"cam_col\", link_name=tool_link,\n",
    "                       dims=(0.081, 0.081, 0.046), center=(-0.0785, 0, 0.013), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.2), display=True, fixed=True, collision=True)\n",
    "\n",
    "    viewpoint = gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"viewpoint\", link_name=tool_link,\n",
    "                                   dims=(0.01, 0.01, 0.01), center=(-0.013, 0, 0), rpy=(0, 0, -np.pi / 2),\n",
    "                                   color=(1, 0, 0, 0.3), display=True, fixed=True, collision=False, parent=\"cam\")\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"body\", link_name=tool_link,\n",
    "                       dims=(0.067, 0.067, 0.0335), center=(-0.0785, 0, -0.01675), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 1), display=True, fixed=True, collision=False)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"body_col\", link_name=tool_link,\n",
    "                       dims=(0.087, 0.087, 0.0535), center=(-0.0785, 0, -0.01675), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.2), display=True, fixed=True, collision=True)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"backhead\", link_name=tool_link,\n",
    "                       dims=(0.067, 0.067, 0.067), center=(-0.0785, 0, -0.0335), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 1), display=True, fixed=True, collision=False)\n",
    "\n",
    "    gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"backhead_col\", link_name=tool_link,\n",
    "                       dims=(0.087, 0.087, 0.087), center=(-0.0785, 0, -0.0335), rpy=(0, 0, 0),\n",
    "                       color=(0.8, 0.8, 0.8, 0.2), display=True, fixed=True, collision=True)\n",
    "    return viewpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 MultiICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.multiICP import MultiICP, MultiICP_Obj\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create multiICP instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp = MultiICP(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is not set - skip initialization, use manually given camera configs\n"
     ]
    }
   ],
   "source": [
    "config_list, img_dim = load_pickle(RNB_PLANNING_DIR+\"release/multiICP_data/cam_configs.pkl\")\n",
    "micp.initialize(config_list, img_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create SceneBuilder instance and geometry scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "kmb0: False\n",
      "indy1: False\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    }
   ],
   "source": [
    "INDY_BASE_OFFSET = (0.172,0,0.439)\n",
    "INDY_BASE_RPY = (0,0,0)\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                \"{}/{}\".format(None, None))\n",
    "robot_config = RobotConfig(1, RobotType.indy7, \n",
    "                           (INDY_BASE_OFFSET, INDY_BASE_RPY),\n",
    "                           None, root_on=\"kmb0_platform\", \n",
    "                           specs={\"no_sdk\":True})\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[False, False])\n",
    "\n",
    "scene_builder = SceneBuilder.instance(detector=micp)\n",
    "gscene = scene_builder.create_gscene(crob)\n",
    "\n",
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "ROBOT_BASE = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][0]\n",
    "TIP_LINK = pscene.robot_chain_dict[ROBOT_NAME][\"tip_link\"]\n",
    "MOBILE_BASE = pscene.robot_chain_dict[MOBILE_NAME][\"tip_link\"]\n",
    "HOLD_LINK = MOBILE_BASE\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=TIP_LINK)\n",
    "VIEW_POSE = np.deg2rad([  0., 50.,  -70.,  -0.,  -90., 0])\n",
    "VIEW_LOC = [0]*6\n",
    "VIEW_POSE_EXT = np.array(VIEW_LOC + list(VIEW_POSE))\n",
    "T_bc = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "T_cb = SE3_inv(T_bc)\n",
    "gscene.show_pose(VIEW_POSE_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set MultiICP configs\n",
    "* You have to make micp, hrule and grule for each object you want to detect\n",
    "\n",
    "* hrule means heuristic rule for special object which cannot be detected thorugh mask rcnn using COCO dataset\n",
    "\n",
    "* grule means initial guess(R,t) for ICP\n",
    "\n",
    "* Run shared detector to detect object in color image\n",
    "\n",
    "##### Run shared detector for object detection on bash\n",
    "* To skip detector initiailzation, run shared detector on separate terminal as follows\n",
    "* set proper values to dims: desired size of MultiICP = reversed(micp.dsize)+(3,)\n",
    "```bash\n",
    "python3 $RNG_PLANNING_DIR/src/pkg/detector/multiICP/shared_detector.py --dims='(720,1280,3)'\n",
    "```\n",
    "\n",
    "\n",
    "#### Clearing shared detector channels if zombie memory remains\n",
    "```python\n",
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "\n",
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "sd.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load example data (for bed, closet)\n",
    "* You need to prepare example data and stl model to test MultiICP detector \n",
    "* Use color image, depth image and csv file which has joint values Q with cam_intrins, depth_scale \n",
    "* file path: release/multiICP_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rdict(file_name):\n",
    "    rdict = {}\n",
    "    \n",
    "    rdict['color'] = cv2.imread(\n",
    "        os.path.join('../release/multiICP_data/', file_name + '.jpg'), flags=cv2.IMREAD_UNCHANGED)\n",
    "    rdict['depth'] = cv2.imread(\n",
    "        os.path.join('../release/multiICP_data/', file_name + '.png'), flags=cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    Q = np.loadtxt(os.path.join('../release/multiICP_data/', file_name + '.csvd'), delimiter=\",\")\n",
    "    return rdict, np.array(Q)\n",
    "\n",
    "\n",
    "rdict, Qtest = load_rdict(\"test_1\")\n",
    "color_img = rdict['color']\n",
    "depth_img = rdict['depth']\n",
    "Tc = viewpoint.get_tf(Qtest)\n",
    "gscene.show_pose(Qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_cb = SE3_inv(Tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_info_dict = get_obj_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object items you want to detect\n",
    "# heuristic rule items, Initial guess rule items\n",
    "micp_bed = MultiICP_Obj(obj_info_dict[\"bed\"], None,\n",
    "                        OffsetOnModelCoord(\"bed\", R=np.matmul(T_cb[:3, :3], Rot_axis(3, np.pi)),\n",
    "                                          offset=np.matmul(T_cb[:3, :3], (1.1 * 0.5, 0, -0.5))))\n",
    "\n",
    "mrule_closet = MaskBoxRule(\"closet\", \"bed\", merge_rule=np.all)\n",
    "mrule_closet.update_rule = ClosetRuleFun(mrule_closet)\n",
    "micp_closet = MultiICP_Obj(obj_info_dict[\"closet\"], \n",
    "                           mrule_closet,\n",
    "                           OffsetOnModelCoord(\"closet\", \n",
    "                                             offset=(0, 1, 0.3),\n",
    "                                             use_median=True\n",
    "                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_dict = {\"bed\": micp_bed, \"closet\": micp_closet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### detect()\n",
    "* Object Detection through swin-transformer based mask rcnn using mmdet\n",
    "* To use test data(color, depth image and joint value Q), you have to call cache_sensor()\n",
    "* Detection result is the transformation w.r.t base coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.cache_sensor(color_img, depth_img, Qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is None\n",
      "===== Detected : handbag, 1 object(s) =====\n",
      "===== Detected : suitcase, 1 object(s) =====\n",
      "===== Detected : bowl, 3 object(s) =====\n",
      "===== Detected : bed, 1 object(s) =====\n",
      "===== Detected : clock, 1 object(s) =====\n",
      "\n",
      "'bed' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.364424e-01, inlier_rmse=6.819923e-02, and correspondence_set size of 5022\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82499418 -0.10027313  0.55617438 -0.58251586]\n",
      " [-0.22097802 -0.96301758  0.15416169  0.65528698]\n",
      " [ 0.52014745 -0.25008479 -0.81664205  4.63277458]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.555687e-01, inlier_rmse=4.215075e-02, and correspondence_set size of 2174\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82574995 -0.06843705  0.55986911 -0.56611926]\n",
      " [-0.15982027 -0.98032022  0.11588664  0.72468321]\n",
      " [ 0.54092009 -0.18517181 -0.820437    4.61911238]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of bed\n",
      "===== Apply heuristic rule for closet =====\n",
      "CLOSET ON LEFT\n",
      "\n",
      "'closet' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=6.610859e-01, inlier_rmse=6.393311e-02, and correspondence_set size of 31510\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.5550837  -0.02119794 -0.83152435 -0.77058789]\n",
      " [ 0.13625548 -0.98385439  0.11603856  0.70802252]\n",
      " [-0.82055869 -0.17771086 -0.54323321  4.45406669]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.466429e-01, inlier_rmse=3.041959e-02, and correspondence_set size of 18611\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.53351226 -0.03741054 -0.84496457 -0.74109643]\n",
      " [ 0.14097625 -0.98111281  0.13245116  0.72151883]\n",
      " [-0.83396067 -0.18978425 -0.51816172  4.50750408]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of closet\n"
     ]
    }
   ],
   "source": [
    "pose_dict = micp.detect(visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### detect_and_register()\n",
    "* Detect items in the field of view and register them to the GeometryScene\n",
    "* They will appear in the RVIZ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.cache_sensor(color_img, depth_img, Qtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['closet', 'bed']\n",
      "===== Detected : bed, 1 object(s) =====\n",
      "\n",
      "'bed' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.306129e-01, inlier_rmse=6.825225e-02, and correspondence_set size of 4987\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.8230461  -0.09851426  0.5593658  -0.58957713]\n",
      " [-0.22039279 -0.96307013  0.15467031  0.65483328]\n",
      " [ 0.52347127 -0.25058097 -0.81436294  4.62936601]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.402506e-01, inlier_rmse=4.257531e-02, and correspondence_set size of 2146\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82494329 -0.0577468   0.56225787 -0.57826874]\n",
      " [-0.15136579 -0.98100334  0.12132935  0.71698996]\n",
      " [ 0.54457048 -0.18519643 -0.81801301  4.61795167]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of bed\n",
      "===== Apply heuristic rule for closet =====\n",
      "CLOSET ON LEFT\n",
      "\n",
      "'closet' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=6.611699e-01, inlier_rmse=6.372863e-02, and correspondence_set size of 31514\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.55335793 -0.02112309 -0.83267575 -0.76897412]\n",
      " [ 0.13626574 -0.98391451  0.1155156   0.7078057 ]\n",
      " [-0.82172178 -0.17738664 -0.54157856  4.45248961]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.469966e-01, inlier_rmse=3.035816e-02, and correspondence_set size of 18635\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.53311733 -0.03565395 -0.84528976 -0.74295413]\n",
      " [ 0.14260812 -0.98102888  0.13132114  0.71259306]\n",
      " [-0.83393577 -0.19055475 -0.51791898  4.50648862]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Found 6DoF pose of closet\n",
      "\u001b[93m[WARN] Vertices for mesh should be have center point (0,0,0). Auto adjusting.\u001b[0m\n",
      "\u001b[93m[WARN] Vertices for mesh should be have center point (0,0,0). Auto adjusting.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gtem_dict = scene_builder.detect_and_register(level_mask=[DetectionLevel.ENVIRONMENT])\n",
    "# gtem_dict = scene_builder.detect_and_register(level_mask=[DetectionLevel.MOVABLE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
