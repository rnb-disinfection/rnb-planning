{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PC IP: 192.168.0.40\n",
      "Mobile ROB IP: 192.168.0.102\n",
      "CAM SERVER IP: 192.168.0.10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src'))\n",
    "sys.path.append(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/milestone_202110'))\n",
    "\n",
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "from utils.kiro_udp_send import start_mobile_udp_thread, send_pose_wait, get_xyzw_cur, get_reach_state\n",
    "from utils.streaming import *\n",
    "from utils.detection_util import *\n",
    "\n",
    "CONNECT_CAM = False # True\n",
    "ENABLE_DETECT = True\n",
    "CONNECT_INDY = False # True\n",
    "CONNECT_MOBILE = False # True \n",
    "SHOW_MOTION_RVIZ = False\n",
    "\n",
    "ip_cur =  get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "INDY_IP = \"192.168.0.3\"\n",
    "CAM_HOST = '192.168.0.10'\n",
    "\n",
    "print(\"Current PC IP: {}\".format(ip_cur))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))\n",
    "print(\"CAM SERVER IP: {}\".format(CAM_HOST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "indy0: False\n"
     ]
    }
   ],
   "source": [
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "\n",
    "\n",
    "# sock_mobile, server_thread = start_mobile_udp_thread(recv_ip=ip_cur)\n",
    "crob = CombinedRobot(robots_on_scene=[\n",
    "    RobotConfig(0, RobotType.indy7, None,\n",
    "                INDY_IP, specs={\"no_sdk\":True})]\n",
    "              , connection_list=[CONNECT_INDY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "s_builder = SceneBuilder(None)\n",
    "# s_builder.reset_reference_coord(ref_name=\"floor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to register with master node [http://localhost:11311]: master may not be running yet. Will keep trying.\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# xyz_rpy_robots = s_builder.detect_items(level_mask=[DetectionLevel.ROBOT])\n",
    "xyz_rpy_robots = {\"indy0\": ((0,0,0), (0,0,np.pi))}\n",
    "crob.update_robot_pos_dict(xyz_rpy_robots=xyz_rpy_robots)\n",
    "gscene = s_builder.create_gscene(crob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please create a subscriber to the marker\n"
     ]
    }
   ],
   "source": [
    "gtems = s_builder.add_robot_geometries(color=(0,1,0,0.5), display=True, collision=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://0.0.0.0:8050/\n",
      "\n",
      " * Serving Flask app \"pkg.ui.dash_launcher\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "from pkg.planning.pipeline import PlanningPipeline\n",
    "ppline = PlanningPipeline(pscene)\n",
    "\n",
    "from pkg.ui.ui_broker import *\n",
    "\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(ppline, s_builder)\n",
    "ui_broker.start_server()\n",
    "\n",
    "ui_broker.set_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geometry 추가\n",
    "mobile_base = gscene.create_safe(gtype=GEOTYPE.BOX, name=\"mobile_base\", link_name=\"base_link\", \n",
    "                   dims=(0.6,0.4,0.439), center=(0,0,-0.439/2), rpy=(0,0,0), \n",
    "                   color=(0.8,0.8,0.8,0.5), display=True, fixed=True, collision=False)\n",
    "floor = gscene.create_safe(gtype=GEOTYPE.BOX, name=\"floor\", link_name=\"base_link\", \n",
    "                   dims=(10,10,0.01), center=(0,0,-0.439), rpy=(0,0,0), \n",
    "                   color=(0.8,0.8,0.8,0.5), display=True, fixed=True, collision=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gtem in gscene:\n",
    "    round_it_str(gtem.dims)\n",
    "    round_it_str(gtem.center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pkg.geometry.geometry.GeometryItem at 0x7ff3d72c0250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pkg.geometry.geotype import GEOTYPE\n",
    "gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"cam\", link_name=\"indy0_tcp\", \n",
    "                   dims=(0.061,0.061,0.026), center=(-0.0785,0,0.013), rpy=(0,0,0), \n",
    "                   color=(0.8,0.8,0.8,0.5), display=True, fixed=True, collision=False)\n",
    "\n",
    "gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"cam_col\", link_name=\"indy0_tcp\", \n",
    "                   dims=(0.081,0.081,0.046), center=(-0.0785,0,0.013), rpy=(0,0,0), \n",
    "                   color=(0.0,1,0,0.3), display=True, fixed=True, collision=True)\n",
    "\n",
    "viewpoint = gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"viewpoint\", link_name=\"indy0_tcp\", \n",
    "                   dims=(0.01,0.01,0.01), center=(-0.014,0,0), rpy=(0,0,-np.pi/2), \n",
    "                   color=(1,0,0,0.3), display=True, fixed=True, collision=False, parent=\"cam\")\n",
    "\n",
    "gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"body\", link_name=\"indy0_tcp\", \n",
    "                   dims=(0.067,0.067,0.0335), center=(-0.0785,0,-0.01675), rpy=(0,0,0), \n",
    "                   color=(0.8,0.8,0.8,1), display=True, fixed=True, collision=False)\n",
    "\n",
    "gscene.create_safe(gtype=GEOTYPE.CYLINDER, name=\"body_col\", link_name=\"indy0_tcp\", \n",
    "                   dims=(0.087,0.087,0.0535), center=(-0.0785,0,-0.01675), rpy=(0,0,0), \n",
    "                   color=(0.0,1,0,0.3), display=True, fixed=True, collision=True)\n",
    "\n",
    "gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"backhead\", link_name=\"indy0_tcp\", \n",
    "                   dims=(0.067,0.067,0.067), center=(-0.0785,0,-0.0335), rpy=(0,0,0), \n",
    "                   color=(0.8,0.8,0.8,1), display=True, fixed=True, collision=False)\n",
    "\n",
    "gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"backhead_col\", link_name=\"indy0_tcp\", \n",
    "                   dims=(0.087,0.087,0.087), center=(-0.0785,0,-0.0335), rpy=(0,0,0), \n",
    "                   color=(0.0,1,0,0.3), display=True, fixed=True, collision=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## move indy to viewing pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_POSE = np.deg2rad([  0., -28.,  85.,  -0.,  57., -180])\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        indy.joint_move_to(np.rad2deg(VIEW_POSE))\n",
    "        time.sleep(0.5)\n",
    "        indy.wait_for_move_finish()\n",
    "        Qcur = np.deg2rad(indy.get_joint_pos())\n",
    "else:\n",
    "    Qcur = VIEW_POSE\n",
    "gscene.show_pose(Qcur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach to detection server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_DETECT:\n",
    "    attacth_to_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 침대 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate of stl model importing\n",
    "\n",
    "# bed_model = o3d.io.read_triangle_mesh(MODEL_DIR + '/bed/bed.STL')\n",
    "# # bed_model = o3d.io.read_triangle_mesh(MODEL_DIR + '/bed/bed_floor_centered_m_scale.stl')\n",
    "# bed_model.vertices = o3d.utility.Vector3dVector(\n",
    "#     np.asarray(bed_model.vertices) * np.array([1 / 1000.0, 1 / 1000.0, 1 / 1000.0]))\n",
    "# FOR_origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0, 0, 0])\n",
    "# o3d.visualization.draw_geometries([bed_model, FOR_origin])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAM_HOST = '192.168.0.40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_CAM:\n",
    "    # rdict = send_recv_demo_cam({1:1}, host=CAM_HOST)\n",
    "    rdict = stream_capture_image(ImageType.FirstView, 0, host=CAM_HOST)\n",
    "    cam_intrins, d_scale = [rdict[key] for key in [\"intrins\", \"depth_scale\"]]\n",
    "    set_cam_params(cam_intrins, d_scale)\n",
    "else:\n",
    "    cam_intrins = [1280, 720, 899.05322265625,  899.21044921875, 654.8836669921875, 352.9295654296875]\n",
    "    d_scale = 0.0002500000118743628\n",
    "    set_cam_params(cam_intrins, d_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.300.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.300.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.050,\n",
      "   we use a liberal distance threshold 0.075.\n",
      "[[ 0.80396147 -0.06237568 -0.62702311  0.5313216 ]\n",
      " [ 0.11889356 -0.98317962  0.25024969  0.44204891]\n",
      " [-0.61879967 -0.26994418 -0.76656368  4.67092195]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=5.336246e-01, inlier_rmse=3.183043e-02, and correspondence_set size of 32732\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.78644385 -0.02962281 -0.65117687  0.57932519]\n",
      " [ 0.12991653 -0.99282066  0.20206828  0.49964464]\n",
      " [-0.63877267 -0.23839543 -0.76061807  4.6504153 ]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CONNECT_CAM:\n",
    "    bed_color_path = SAVE_DIR + '/bed.jpg'\n",
    "    bed_depth_path = SAVE_DIR + '/bed.png'\n",
    "else:\n",
    "    bed_color_path = EXP_IMG_DIR + '/513.jpg'\n",
    "    bed_depth_path = EXP_IMG_DIR + '/513.png'\n",
    "\n",
    "# bed_color_path = \"scripts/milestone_202110/save_img/526.jpg\"\n",
    "# bed_depth_path = \"scripts/milestone_202110/save_img/526.png\"\n",
    "\n",
    "# Read color, depth image file, keep 16bit information\n",
    "color_img_read = cv2.imread(bed_color_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "depth_img_read = cv2.imread(bed_depth_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "# Output of inference(mask for detected table)\n",
    "mask_out = detect_from_server(color_img_read)\n",
    "\n",
    "if mask_out is not None:\n",
    "    plt.imshow(mask_out)\n",
    "    \n",
    "    # Crop masking part\n",
    "    vis_mask = (mask_out * 255).astype('uint8')\n",
    "    color_instance = cv2.bitwise_and(color_img_read, color_img_read, mask=vis_mask).astype(np.uint16)\n",
    "    depth_instance = cv2.bitwise_and(depth_img_read, depth_img_read, mask=vis_mask).astype(np.uint16)\n",
    "    cv2.imwrite(CROP_DIR + '/bed_crop.jpg', color_instance)\n",
    "    cv2.imwrite(CROP_DIR + '/bed_crop.png', depth_instance)\n",
    "    \n",
    "#     set_cam_params(cam_intrins, d_scale)\n",
    "    ICP_result_bed = process_bed_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'viewpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-596d2d692909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 인식한 결과를 바탕으로 geometry 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mT_co\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mICP_result_bed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mT_bc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mviewpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist2dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIEW_POSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgscene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mT_bo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_bc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_co\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'viewpoint' is not defined"
     ]
    }
   ],
   "source": [
    "# 인식한 결과를 바탕으로 geometry 추가\n",
    "T_co = ICP_result_bed\n",
    "T_bc = viewpoint.get_tf(list2dict(VIEW_POSE, gscene.joint_names))\n",
    "T_bo = np.matmul(T_bc, T_co)\n",
    "\n",
    "# geometry 추가\n",
    "# how to import gemoetry from stl file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상두대 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate of stl model importing\n",
    "\n",
    "# top_table_model = o3d.io.read_triangle_mesh(MODEL_DIR + '/top_table/top_table.STL')\n",
    "# top_table_model.vertices = o3d.utility.Vector3dVector(\n",
    "#     np.asarray(top_table_model.vertices) * np.array([1 / 1000.0, 1 / 1000.0, 1 / 1000.0]))\n",
    "# FOR_origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0, 0, 0])\n",
    "# o3d.visualization.draw_geometries([top_table_model, FOR_origin])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move and Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_CAM:\n",
    "    color_path = SAVE_DIR + '/bed.jpg'\n",
    "    depth_path = SAVE_DIR + '/bed.png'\n",
    "else:\n",
    "    color_path = EXP_IMG_DIR + '/513.jpg'\n",
    "    depth_path = EXP_IMG_DIR + '/513.jpg'\n",
    "\n",
    "# Robot이 어느쪽에서 찍었는 지 \"LEFT\" or \"RIGHT\"만 넣어주면 됨\n",
    "TOP_TABLE_LOCATION = check_location_top_table(color_path, depth_path, ROBOT_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if CONNECT_CAM:\n",
    "#     rdict = stream_capture_image(ImageType.FirstView, 1, host=CAM_HOST)\n",
    "#     check_color_path = SAVE_DIR + '/top_table_check.jpg'\n",
    "#     check_depth_path = SAVE_DIR + '/top_table_check.png'\n",
    "# else:\n",
    "#     check_color_path = EXP_IMG_DIR + '/top_table_check.jpg'\n",
    "#     check_depth_path = EXP_IMG_DIR + '/top_table_check.png'\n",
    "\n",
    "# # Check whether top table exist or not at scanning location\n",
    "# check_top_table = check_top_table_exist(check_color_path, check_depth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인식한 침대 결과를 기반으로 대략적인 위치로 모바일 로봇 이동하거나,적당한 위치로 이동한 후 \n",
    "# 스캔 결과를 treat 해서 여기에 상두대가 있는 지 없는지 판단\n",
    "# 인식한 침대 결과 기반으로 이동한 후, 위아래로 이미지 스캔하는 동작 + 스캔하면서 이미지 저장\n",
    "# 이미지 저장 시작 - 모션 시작 - 모션 끝 - 이미지 저장 끝 (위아래 왕복 모션이 필요 loop closure detection 때문)\n",
    "# for문 / while문으로 이미지 연속으로 저장 가능\n",
    "for i in range(50):\n",
    "    time.sleep(0.01)\n",
    "    rdict = stream_capture_image(ImageType.CloseView, i, host=CAM_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CONNECT_CAM:\n",
    "    COLOR_PATH = EXP_IMG_DIR + \"/top_table/color\"\n",
    "    DEPTH_PATH = EXP_IMG_DIR + \"/top_table/depth\"\n",
    "    INTRINSIC_PATH = EXP_IMG_DIR + \"/top_table\"\n",
    "\n",
    "save_intrinsic_as_json(INTRINSIC_PATH + \"/intrinsic.json\")\n",
    "INTRINSIC_PATH = INTRINSIC_PATH + \"/intrinsic.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'========= Complete 3D Reconstruction ========='"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from boost_reconstruction.reconstruction_interface import reconstruction_interface_py as rci\n",
    "rci.getReconstruction(COLOR_PATH, DEPTH_PATH, INTRINSIC_PATH, MILESTONE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_top_table = o3d.io.read_point_cloud(MILESTONE_DIR + \"/pcd_no.ply\")\n",
    "FOR_origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0, 0, 0])\n",
    "o3d.visualization.draw_geometries([pcd_top_table, FOR_origin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICP_result_top_table = process_top_table_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인식한 결과를 바탕으로 geometry 추가\n",
    "# 이때 pcd의 coordinate, 즉 카메라 시점은 첫번째 이미지를 찍었을 때의 시점임. 유의 필요\n",
    "T_co = ICP_result_top_table\n",
    "T_bc = viewpoint.get_tf(list2dict(VIEW_POSE, gscene.joint_names))\n",
    "T_bo = np.matmul(T_bc, T_co)\n",
    "\n",
    "# geometry 추가\n",
    "# how to import gemoetry from stl file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
