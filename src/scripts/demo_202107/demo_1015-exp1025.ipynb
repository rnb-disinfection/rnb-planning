{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Script for Milestone 10.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Prepare task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 prepare planning scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run camera server on the camera computer (192.168.0.10, use vnc viewer)\n",
    "```bash\n",
    "python stream_server.py --ip='192.168.0.10'\n",
    "```\n",
    "#### Run shared detector on bash\n",
    "```bash\n",
    "python3 /home/jhkim/Projects/rnb-planning/src/scripts/milestone_202110/utils/shared_detector.py\n",
    "```\n",
    "\n",
    "### Check IP request ip setting from mobile udp client (robot-side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PC IP: 192.168.0.8\n",
      "Mobile ROB IP: 192.168.0.102\n",
      "CAM SERVER IP: 192.168.0.10\n",
      "connection command:\n",
      "kmb0: False\n",
      "indy1: False\n",
      "Unable to register with master node [http://localhost:11311]: master may not be running yet. Will keep trying.\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n",
      "Dash is running on http://0.0.0.0:8050/\n",
      "\n",
      " * Serving Flask app \"pkg.ui.dash_launcher\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/milestone_202110'))\n",
    "\n",
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from demo_utils.kiro_udp_send import start_mobile_udp_thread, send_pose_wait, get_xyzw_cur, get_reach_state\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "from demo_utils.streaming import *\n",
    "from demo_utils.detect_table import *\n",
    "from demo_utils.area_select import *\n",
    "from pkg.detector.aruco.marker_config import get_aruco_map\n",
    "aruco_map = get_aruco_map()\n",
    "\n",
    "\n",
    "CONNECT_CAM = False # True\n",
    "ENABLE_DETECT = False\n",
    "# DETECT_MARKER = True\n",
    "CONNECT_INDY = False # True\n",
    "CONNECT_MOBILE = False # True \n",
    "VISUALIZE = True\n",
    "\n",
    "# Tool dimensions\n",
    "TOOL_DIM = [0.32, 0.08]\n",
    "TOOL_OFFSET = 0.01\n",
    "MARGIN = 0\n",
    "TRACK_THICKNESS = 0.001\n",
    "\n",
    "INDY_BASE_OFFSET = (0.172,0,0.439)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "\n",
    "ip_cur = \"192.168.0.8\"# get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "INDY_IP = \"192.168.0.3\"\n",
    "CAM_HOST = '192.168.0.10'\n",
    "\n",
    "print(\"Current PC IP: {}\".format(ip_cur))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))\n",
    "print(\"CAM SERVER IP: {}\".format(CAM_HOST))\n",
    "\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from demo_utils.environment import *\n",
    "\n",
    "from utils.streaming import *\n",
    "from utils.detection_util import *\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                MOBILE_IP)\n",
    "robot_config = RobotConfig(1, RobotType.indy7, (INDY_BASE_OFFSET, (0,0,0)),\n",
    "                INDY_IP, root_on=\"kmb0_platform\", \n",
    "                           specs={\"no_sdk\":True})\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[False, CONNECT_INDY])\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "\n",
    "gtems = s_builder.add_robot_geometries(color=(0,1,0,0.5), display=True, collision=True)\n",
    "gscene.set_workspace_boundary(-3, 7, -5, 5, -CLEARANCE, 3, thickness=WALL_THICKNESS)\n",
    "\n",
    "\n",
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "ROBOT_BASE = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][0]\n",
    "TIP_LINK = pscene.robot_chain_dict[ROBOT_NAME][\"tip_link\"]\n",
    "MOBILE_BASE = pscene.robot_chain_dict[MOBILE_NAME][\"tip_link\"]\n",
    "HOLD_LINK = MOBILE_BASE\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=TIP_LINK)\n",
    "# add_indy_tool_kiro(gscene, tool_link=TIP_LINK, face_name=TOOL_NAME, zoff=TOOL_OFFSET)\n",
    "\n",
    "HOME_POSE = -crob.home_pose\n",
    "HOME_DICT = list2dict(HOME_POSE, gscene.joint_names)\n",
    "\n",
    "from pkg.planning.pipeline import PlanningPipeline\n",
    "ppline = PlanningPipeline(pscene)\n",
    "\n",
    "# Set planner\n",
    "from pkg.planning.motion.moveit.moveit_planner import MoveitPlanner\n",
    "from pkg.planning.filtering.grasp_filter import GraspChecker\n",
    "mplan = MoveitPlanner(pscene, enable_dual=False, incremental_constraint_motion=True)\n",
    "mplan.motion_filters = [GraspChecker(pscene)]\n",
    "mplan.update_gscene()\n",
    "gcheck = GraspChecker(pscene)\n",
    "mplan.motion_filters = [gcheck]\n",
    "\n",
    "from pkg.planning.task.rrt import TaskRRT\n",
    "tplan = TaskRRT(pscene)\n",
    "tplan.prepare()\n",
    "ppline.set_motion_planner(mplan)\n",
    "ppline.set_task_planner(tplan)\n",
    "\n",
    "from pkg.ui.ui_broker import *\n",
    "\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(ppline, s_builder)\n",
    "ui_broker.start_server()\n",
    "\n",
    "ui_broker.set_tables()\n",
    "\n",
    "add_kiro_indytool_down(gscene, zoff=TOOL_OFFSET, tool_link=TIP_LINK, face_name=TOOL_NAME)\n",
    "\n",
    "# Register binders\n",
    "from pkg.planning.constraint.constraint_actor import VacuumTool, Gripper2Tool, PlacePlane, SweepFramer, WayFramer\n",
    "brush_face = pscene.create_binder(bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "                                  point=(-gscene.NAME_DICT['brush_face'].dims[0]/2-CLEARANCE,0,0), \n",
    "                                  rpy=(0,np.pi/2*1,0))\n",
    "\n",
    "# waypoint\n",
    "WP_DIMS = (0.6,0.4,WALL_THICKNESS)\n",
    "gscene.create_safe(gtype=GEOTYPE.BOX, name=\"wayframer\", link_name=HOLD_LINK,\n",
    "                   dims=WP_DIMS, center=(0,0,WP_DIMS[2]/2), rpy=(0,0,0), color=(1, 0, 0, 0.5), display=True,\n",
    "                   collision=False, fixed=True)\n",
    "wayframer = pscene.create_binder(bname=\"wayframer\", gname=\"wayframer\", _type=WayFramer, \n",
    "                                 point=(0,0,-WP_DIMS[2]/2-CLEARANCE), rpy=(0,0,0))\n",
    "\n",
    "indy = crob.robot_dict[\"indy1\"]\n",
    "\n",
    "if CONNECT_MOBILE:\n",
    "    sock_mobile, server_thread = start_mobile_udp_thread(recv_ip=ip_cur)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Wait task start queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Detect bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Get environment map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.ros_utils import Listener\n",
    "from demo_utils.map_converter import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET MAP\n",
    "# map_listener = Listener(topic_name=\"/map\", topic_type=OccupancyGrid)\n",
    "# cost_listener = Listener(topic_name=\"/move_base/global_costmap/costmap\", topic_type=OccupancyGrid)\n",
    "# map_data = map_listener.get_data()\n",
    "# cost_data = cost_listener.get_data()\n",
    "map_data = load_pickle(os.path.join(os.environ[\"RNB_PLANNING_DIR\"],\"data/map_data.pkl\"))\n",
    "cost_data = load_pickle(os.path.join(os.environ[\"RNB_PLANNING_DIR\"],\"data/cost_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET LINES\n",
    "map_im, resolution = convert_map(map_data)\n",
    "ret, map_bin = cv2.threshold(map_im, 100, 255, cv2.THRESH_BINARY)\n",
    "lines = cv2.HoughLinesP(map_bin, 1, 1 * np.pi / 180, 30, minLineLength = 10, maxLineGap = 50)\n",
    "map_shape = map_im.shape\n",
    "bound_px = int(round(10 * 0.01 / resolution))\n",
    "line_im_accum = np.zeros(map_shape, np.uint8)\n",
    "lines_maj = []\n",
    "idc_exc = set()\n",
    "line_bounds = np.array([line2im(line[0], map_shape, bound_px) for line in lines])\n",
    "line_ims = np.array([line2im(line[0], map_shape) for line in lines])\n",
    "for i_l, (line0, line0bd) in enumerate(zip(lines, line_bounds)):\n",
    "    if i_l in idc_exc:\n",
    "        continue\n",
    "    line_im_accum = np.max([line_im_accum, line0bd], axis=0)\n",
    "    lines_maj.append(line0)\n",
    "    idc_inbound = np.where(np.sum(np.sum(line_ims[i_l:] > line_im_accum[np.newaxis, :, :], -1), -1) == 0)[0] + i_l\n",
    "    idc_exc = idc_exc.union(list(idc_inbound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe0701b98d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dst = cv2.cvtColor(map_im, cv2.COLOR_GRAY2BGR)\n",
    "for i in lines_maj:\n",
    "    cv2.line(dst, (i[0][0], i[0][1]), (i[0][2], i[0][3]), (0, 0, 255), 2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_io_px = T_xyzquat(((lambda x: (x.x+map_shape[0]/2, x.y+map_shape[1]/2, x.z))(map_data.info.origin.position), \n",
    "                    (lambda x: (x.x, x.y, x.z, x.w))(map_data.info.origin.orientation)))\n",
    "T_io = T_io_px.copy()\n",
    "T_io[:3,3] *= resolution\n",
    "\n",
    "cur_xyzw = [ 0.8,   1.68, -0.15,  0.99]\n",
    "Q_CUR = np.copy(crob.home_pose)\n",
    "Q_CUR[:2] = cur_xyzw[:2]\n",
    "Q_CUR[2] = Rot2axis(Rotation.from_quat((0,0,cur_xyzw[2], cur_xyzw[3])).as_dcm(), 3)\n",
    "gscene.show_pose(Q_CUR)\n",
    "T_om = T_xyzquat(((tuple(cur_xyzw[:2])+(0,)), ((0,0)+tuple(cur_xyzw[2:]))))\n",
    "T_im = np.matmul(T_io, T_om)\n",
    "\n",
    "T_bm = wayframer.get_tf_handle(Q_CUR)\n",
    "\n",
    "T_bi = np.matmul(T_bm, SE3_inv(T_im))\n",
    "\n",
    "# for i_l, line in enumerate(lines_maj):\n",
    "#     ptx_px = line[0]\n",
    "#     pts = np.multiply(ptx_px, resolution)\n",
    "#     pt1, pt2 = map(lambda pt: np.matmul(T_bi[:2,:2], pt) + T_bi[:2,3], [pts[:2], pts[2:]])\n",
    "#     add_line_to_gscene(gscene, \"map_line_{}\".format(i_l), pt1, pt2, \n",
    "#                        thickness=bound_px*resolution*2, height=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Move to bed-seek pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_POSE = np.deg2rad([  0., 50.,  -70.,  -0.,  -90., 0])\n",
    "VIEW_LOC = [0,]*6\n",
    "VIEW_POSE_EXT = np.array(VIEW_LOC + list(VIEW_POSE))\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        indy.joint_move_to(np.rad2deg(VIEW_POSE))\n",
    "        time.sleep(0.5)\n",
    "        indy.wait_for_move_finish()\n",
    "        Qcur = np.deg2rad(indy.get_joint_pos())\n",
    "else:\n",
    "    Qcur = VIEW_POSE\n",
    "gscene.show_pose(VIEW_POSE_EXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **[TODO] rotate until bed is detected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_DETECT:\n",
    "    attacth_to_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect server not attached - call attach_to_server\n"
     ]
    }
   ],
   "source": [
    "# CAM_HOST = '192.168.0.40'\n",
    "if CONNECT_CAM:\n",
    "    # rdict = send_recv_demo_cam({1:1}, host=CAM_HOST)\n",
    "    rdict = stream_capture_image(ImageType.FirstView, obj_type=\"bed\", host=CAM_HOST)\n",
    "    cam_intrins, d_scale = [rdict[key] for key in [\"intrins\", \"depth_scale\"]]\n",
    "    set_cam_params(cam_intrins, d_scale)\n",
    "    cam_width, cam_height, cam_fx, cam_fy, cam_ppx, cam_ppy = cam_intrins\n",
    "    __d_scale = d_scale\n",
    "    bed_color_path = SAVE_DIR + '/bed.jpg'\n",
    "    bed_depth_path = SAVE_DIR + '/bed.png'\n",
    "else:\n",
    "#     cam_intrins = [1280, 720, 899.05322265625,  899.21044921875, 654.8836669921875, 352.9295654296875]\n",
    "#     d_scale = 0.0002500000118743628\n",
    "    cam_intrins = [1280, 720, 909.957763671875,  909.90283203125, 638.3824462890625, 380.0085144042969]\n",
    "    d_scale = 1 / 3999.999810010204\n",
    "    set_cam_params(cam_intrins, d_scale)\n",
    "    cam_width, cam_height, cam_fx, cam_fy, cam_ppx, cam_ppy = cam_intrins\n",
    "    __d_scale = d_scale\n",
    "    bed_color_path = SAVE_DIR + '/bed.jpg'\n",
    "    bed_depth_path = SAVE_DIR + '/bed.png'\n",
    "#     bed_color_path = EXP_IMG_DIR + '/bed.jpg'\n",
    "#     bed_depth_path = EXP_IMG_DIR + '/bed.png'\n",
    "#     bed_color_path = EXP_IMG_DIR + '/513.jpg'\n",
    "#     bed_depth_path = EXP_IMG_DIR + '/top_table_0024.png'\n",
    "\n",
    "# Read color, depth image file, keep 16bit information\n",
    "color_img_read = cv2.imread(bed_color_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "depth_img_read = cv2.imread(bed_depth_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Output of inference(mask for detected table)\n",
    "mask_out = detect_from_server(color_img_read)\n",
    "\n",
    "# If bed is not detected, then pass below detection part\n",
    "test = np.empty((720,1280), dtype=bool)\n",
    "test[:,:] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "while np.array_equal(mask_out, test):\n",
    "    if CONNECT_INDY:\n",
    "        with indy:\n",
    "            Qnow = indy.get_joint_pos()\n",
    "            Qto = np.add(Qnow, [10,0,0,0,0,0])\n",
    "            Qto[0] = (Qto[0]+np.pi/2)%np.pi-np.pi/2\n",
    "            indy.joint_move_to(Qto)\n",
    "            indy.wait_motion()\n",
    "    \n",
    "    \n",
    "    # Take a picture again after rotate\n",
    "    time.sleep(1)\n",
    "    rdict = stream_capture_image(ImageType.FirstView, obj_type=\"bed\", host=CAM_HOST)\n",
    "    \n",
    "    # Read color, depth image file, keep 16bit information\n",
    "    color_img_read = cv2.imread(bed_color_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "    depth_img_read = cv2.imread(bed_depth_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # Output of inference(mask for detected table)\n",
    "    mask_out = detect_from_server(color_img_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2  detect bed and add to the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bc = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "if ENABLE_DETECT:\n",
    "    # Try ICP1\n",
    "    if not np.array_equal(mask_out, test):\n",
    "        plt.imshow(mask_out)\n",
    "\n",
    "        # Crop masking part\n",
    "        vis_mask = (mask_out * 255).astype('uint8')\n",
    "        color_instance = cv2.bitwise_and(color_img_read, color_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        depth_instance = cv2.bitwise_and(depth_img_read, depth_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.jpg', color_instance)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.png', depth_instance)\n",
    "\n",
    "        ICP_result_bed1, fitness1 = process_bed_detection_front(T_bc, visualize=False)\n",
    "\n",
    "        # Try ICP2\n",
    "    if not np.array_equal(mask_out, test):\n",
    "        plt.imshow(mask_out)\n",
    "\n",
    "        # Crop masking part\n",
    "        vis_mask = (mask_out * 255).astype('uint8')\n",
    "        color_instance = cv2.bitwise_and(color_img_read, color_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        depth_instance = cv2.bitwise_and(depth_img_read, depth_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.jpg', color_instance)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.png', depth_instance)\n",
    "\n",
    "        ICP_result_bed2, fitness2 = process_bed_detection(visualize=False)\n",
    "        \n",
    "    # Better result is adopted\n",
    "    if fitness1 > fitness2:\n",
    "        ICP_result_bed = ICP_result_bed1\n",
    "    else:\n",
    "        ICP_result_bed = ICP_result_bed2        \n",
    "\n",
    "\n",
    "    # Coorinate offeset\n",
    "    T_toff_bed = np.identity(4)\n",
    "    T_toff_bed[:3,:3] = np.array([[0,1,0],[0,0,1],[1,0,0]])\n",
    "    T_toff_bed[:3,3] = np.array([0.455,0,1.02])\n",
    "\n",
    "    T_co_bed = np.matmul(ICP_result_bed, T_toff_bed)\n",
    "    T_bc = viewpoint.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "    T_bo_bed = np.matmul(T_bc, T_co_bed)\n",
    "\n",
    "    bed_center = T_bo_bed[:3,3]\n",
    "    bed_rpy = Rot2rpy(T_bo_bed[:3,:3])\n",
    "    # bed_center = (2,0,0)\n",
    "    # bed_rpy = (0,0,np.pi/2)\n",
    "    COLOR_BED_COL = (0,1,0,0.3)\n",
    "    # T_revis = np.identity(4)\n",
    "    # T_revis[:3,:3] = Rot_axis(3, Rot2axis(bed_vis.get_tf(VIEW_POSE_EXT)[:3,:3],3))\n",
    "    # bed_rpy = Rot2rpy(Rot_axis(3, Rot2axis(bed_vis.get_tf(VIEW_POSE_EXT)[:3,:3],3)\n",
    "    T_bo_new = align_z(T_bo_bed)\n",
    "    bed_rpy = Rot2rpy(T_bo_new[:3,:3])\n",
    "\n",
    "    # adjust\n",
    "    bed_center[2]=0\n",
    "    if Rot_rpy(bed_rpy)[0,0] > 0:\n",
    "        bed_rpy[2] += np.pi\n",
    "\n",
    "    bed_mat = add_bed(gscene, bed_center, bed_rpy, COLOR_BED_COL)\n",
    "    \n",
    "else:\n",
    "    T_bc = viewpoint.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "    bed_center = (2,0,0)\n",
    "    bed_rpy = (0,0,np.pi/2)\n",
    "    COLOR_BED_COL = (0,1,0,0.3)\n",
    "    bed_mat = add_bed(gscene, bed_center, bed_rpy, COLOR_BED_COL)\n",
    "\n",
    "bed_vis = gscene.NAME_DICT[\"bed_vis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Detect Closet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.0 set checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_task, wp_hdl = add_waypoint_task(pscene, \"waypoint\", WP_DIMS, (0,0,0), (0,0,0), \n",
    "                                    parent=\"floor_ws\", color=(0, 0, 1, 0.5))\n",
    "ccheck = CachedCollisionCheck(gcheck, wp_task, wp_hdl, wayframer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1  move to full view position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.2.1.1  decide closet side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_vis = gscene.NAME_DICT[\"bed_vis\"]\n",
    "T_bo = bed_vis.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_CAM:\n",
    "    color_path = SAVE_DIR + '/bed.jpg'\n",
    "    depth_path = SAVE_DIR + '/bed.png'\n",
    "else:\n",
    "    color_path = EXP_IMG_DIR + '/bed.jpg'\n",
    "    depth_path = EXP_IMG_DIR + '/bed.png'\n",
    "\n",
    "if ENABLE_DETECT:\n",
    "    # Determine the location of closet\n",
    "    CLOSET_LOCATION = check_location_top_table(color_path, depth_path, T_bc, T_bo, bed_dims=bed_mat.dims, \n",
    "                                               visualize=False)\n",
    "    print(\"CLOSET on {}\".format(CLOSET_LOCATION))\n",
    "\n",
    "#     T_bm_from = wayframer.get_tf_handle(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "#     T_bs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "\n",
    "#     if CLOSET_LOCATION == \"LEFT\":\n",
    "#         T_sm = SE3(Rot_axis(3, np.pi), [1.5, -1.33, 0])\n",
    "#     elif CLOSET_LOCATION == \"RIGHT\":       \n",
    "#         T_sm = SE3(Rot_axis(3, np.pi), [1.5, 1.33, 0])\n",
    "\n",
    "#     T_bm = np.matmul(T_bs, T_sm)\n",
    "\n",
    "#     x,y = T_bm[:2,3]\n",
    "#     theta = Rot2axis(T_bm[:3,:3], 3)\n",
    "else:\n",
    "    CLOSET_LOCATION = \"LEFT\"\n",
    "#     T_bs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "#     T_sm = SE3(Rot_axis(3, np.pi), [1.5, -1.33, 0])\n",
    "#     T_bm = np.matmul(T_bs, T_sm)\n",
    "\n",
    "#     x,y = T_bm[:2,3]\n",
    "#     theta = Rot2axis(T_bm[:3,:3], 3)\n",
    "    \n",
    "# VIEW_MOVED_EXT = np.add(VIEW_POSE_EXT, [x,y,theta]+[0]*9) \n",
    "# gscene.show_pose(VIEW_MOVED_EXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.2  decide full view position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLOSET_LOCATION == \"LEFT\":\n",
    "    angle_ref = 150\n",
    "elif CLOSET_LOCATION == \"RIGHT\":       \n",
    "    angle_ref = -150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_dim = np.linalg.norm(bed_mat.dims)\n",
    "h_fov_hf = np.arctan2(cam_intrins[0], 2*cam_intrins[2])\n",
    "x_z_ratio = np.tan(h_fov_hf)\n",
    "bed_dist = (bed_dim/2) / x_z_ratio * 3 \n",
    "while True:\n",
    "    angle_view = angle_ref + np.random.uniform(-10, 10)\n",
    "    dist_view = bed_dist + np.random.uniform(-0.5, 1)*bed_dist/4\n",
    "    Tbs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "    Tbs = np.matmul(Tbs, SE3(np.identity(3), (-bed_mat.dims[0]/2, 0,0)))\n",
    "    Tsc = np.matmul(SE3(Rot_axis(3, np.deg2rad(angle_view)), (0,)*3), \n",
    "                    SE3(np.identity(3), (-dist_view, 0,0)))\n",
    "    Tbc = np.matmul(Tbs, Tsc)\n",
    "    Tmc = viewpoint.get_tf(VIEW_POSE_EXT, from_link=MOBILE_BASE)\n",
    "    Tmc[:3,:3] = np.identity(3)\n",
    "    Tbm = np.matmul(Tbc, SE3_inv(Tmc))\n",
    "    full_view_ext = np.copy(VIEW_POSE_EXT)\n",
    "    full_view_ext[:2] = Tbm[:2,3]\n",
    "    full_view_ext[2] = Rot2axis(Tbm[:3, :3], 3)\n",
    "    gscene.show_pose(full_view_ext)\n",
    "    ccheck.clear()\n",
    "    res = ccheck(T_loal=Tbm, Q_dict=list2dict(full_view_ext, gscene.joint_names))\n",
    "    if res:\n",
    "        VIEW_MOVED_EXT = full_view_ext\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### move to full view position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_MOVED = np.deg2rad([  0., 50.,  -70.,  -0.,  -80., 0])\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        indy.joint_move_to(np.rad2deg(VIEW_MOVED))\n",
    "    \n",
    "VIEW_MOVED_EXT[crob.idx_dict[ROBOT_NAME]] = VIEW_MOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_MOBILE:\n",
    "    VIEW_MOVED_EXT = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, VIEW_POSE_EXT, VIEW_MOVED_EXT, \n",
    "                                              D_APPROACH=0)\n",
    "gscene.show_pose(VIEW_MOVED_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 redetect bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ce3af7760f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "#capture image\n",
    "if CONNECT_CAM:\n",
    "    rdict = stream_capture_image(ImageType.FullView, obj_type=\"full_view\", host=CAM_HOST)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3  detect and add closet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_DETECT:\n",
    "    if CONNECT_CAM:\n",
    "        rdict = stream_capture_image(ImageType.FirstView, obj_type=\"closet\", host=CAM_HOST)\n",
    "        closet_color_path = SAVE_DIR + '/top_table.jpg'\n",
    "        closet_depth_path = SAVE_DIR + '/top_table.png'\n",
    "    else:\n",
    "        closet_color_path = EXP_IMG_DIR + '/top_table_0024.jpg'\n",
    "        closet_depth_path = EXP_IMG_DIR + '/top_table_0024.png'\n",
    "\n",
    "    if CONNECT_CAM:\n",
    "        Qdict_scan = list2dict(VIEW_MOVED_EXT, gscene.joint_names)\n",
    "    else:\n",
    "        VIEW_POSE_MID = np.deg2rad([  0., 50.,  -70.,  -0.,  -75., 180])\n",
    "        VIEW_MOVED_EXT[6:] = VIEW_POSE_MID\n",
    "        Qdict_scan = list2dict(VIEW_MOVED_EXT, gscene.joint_names)\n",
    "    T_bc = viewpoint.get_tf(Qdict_scan)\n",
    "    T_bs = bed_vis.get_tf(Qdict_scan)\n",
    "    T_sc = np.matmul(SE3_inv(T_bs), T_bc)\n",
    "\n",
    "    ICP_result_top_table = process_top_table_detection(closet_color_path, closet_depth_path, T_sc=T_sc,\n",
    "                                                       bed_dims=bed_mat.dims, z_ceiling = 2.3,\n",
    "                                                       initial_offset=[0.3,1.1,0.6], floor_margin=0.1,\n",
    "                                                       visualize=False)\n",
    "\n",
    "    T_toff_top_table = np.identity(4)\n",
    "    T_toff_top_table[:3,:3] = np.array([[1,0,0],[0,0,1],[0,-1,0]])\n",
    "    T_toff_top_table[:3,3] = np.array([0.3,0,0.2725])\n",
    "\n",
    "    T_co = np.matmul(ICP_result_top_table, T_toff_top_table)\n",
    "    T_bc = viewpoint.get_tf(list2dict(VIEW_MOVED_EXT, gscene.joint_names))\n",
    "    T_bo = np.matmul(T_bc, T_co)\n",
    "    T_bo[:3,:3] = Rot_axis(3, Rot2axis(T_bo[:3,:3], 3))\n",
    "    T_bo[2,3] = 0\n",
    "else:\n",
    "    T_bo = T_xyzrpy((np.matmul(Rot_rpy(bed_rpy), (-0.75,-1.5,0))+bed_center, \n",
    "                     bed_rpy))\n",
    "\n",
    "closet_leftup, closet_rightup, closet_down = add_closet(\n",
    "    gscene, closet_center=T_bo[:3,3], closet_rpy=Rot2rpy(T_bo[:3,:3]), \n",
    "    COLOR_CLOSET_COL=(0,1,0,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Closet cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Make closet cleaning plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.constraint.constraint_common import *\n",
    "from pkg.planning.constraint.constraint_actor import *\n",
    "from pkg.planning.constraint.constraint_subject import *\n",
    "from pkg.utils.code_scraps import get_look_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_CUR = VIEW_MOVED_EXT\n",
    "HOME_POSE_SWEEP = np.copy(Q_CUR)\n",
    "# HOME_POSE_SWEEP[6:] = 0\n",
    "crob.home_pose = HOME_POSE_SWEEP\n",
    "crob.home_dict = list2dict(crob.home_pose, gscene.joint_names)\n",
    "floor_ws = gscene.NAME_DICT[\"floor_ws\"]    \n",
    "\n",
    "add_kiro_indytool_down(gscene, zoff=TOOL_OFFSET, tool_link=TIP_LINK, face_name=TOOL_NAME)\n",
    "brush_face = pscene.create_binder(bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "                                  point=(0,0,-gscene.NAME_DICT['brush_face'].dims[2]/2-CLEARANCE), \n",
    "                                  rpy=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250092/1635250089.62 s) ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250098/1635250095.36 s) ===============================\n",
      "=========================================================================================================\n",
      "Goal reached\n",
      "update 1th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "Goal reached\n"
     ]
    }
   ],
   "source": [
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(closet_leftup, brush_face, robot_config, \n",
    "                                          plane_val=None, tip_dir=\"up\", TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02)\n",
    "\n",
    "HOME_POSE_MOVE = np.copy(Q_CUR[6:])\n",
    "test_fun_cl = TestBaseDivFunc(ppline, floor_ws, closet_leftup, WP_DIMS, TOOL_DIM, crob.home_dict, tool_dir=1,\n",
    "                              multiprocess=False)\n",
    "test_fun_cl.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step, \n",
    "    test_fun=test_fun_cl)\n",
    "snode_schedule_list_leftup, idx_bases, idc_divs, scene_args_list_leftup, scene_kwargs_list_leftup = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, closet_leftup, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)\n",
    "test_fun_cl.clear()\n",
    "Q_CUR = snode_schedule_list_leftup[-1][-1].state.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "update 1th motion\n",
      "Goal reached\n"
     ]
    }
   ],
   "source": [
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(closet_rightup, brush_face, robot_config, \n",
    "                                          plane_val=None, tip_dir=\"up\", TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02)\n",
    "\n",
    "HOME_POSE_MOVE = np.copy(Q_CUR[6:])\n",
    "test_fun_cl = TestBaseDivFunc(ppline, floor_ws, closet_rightup, WP_DIMS, TOOL_DIM, crob.home_dict, tool_dir=1,\n",
    "                              multiprocess=False)\n",
    "test_fun_cl.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step, \n",
    "    test_fun=test_fun_cl)\n",
    "snode_schedule_list_rightup, idx_bases, idc_divs, scene_args_list_rightup, scene_kwargs_list_rightup = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, closet_rightup, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)\n",
    "test_fun_cl.clear()\n",
    "Q_CUR = snode_schedule_list_rightup[-1][-1].state.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250106/1635250103.57 s) ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250109/1635250106.67 s) ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250113/1635250109.93 s) ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "update 1th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "Goal reached\n"
     ]
    }
   ],
   "source": [
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(closet_down, brush_face, robot_config, \n",
    "                                          plane_val=None, tip_dir=\"down\", TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02)\n",
    "\n",
    "HOME_POSE_MOVE = np.copy(Q_CUR[6:])\n",
    "test_fun_cl = TestBaseDivFunc(ppline, floor_ws, closet_down, WP_DIMS, TOOL_DIM, crob.home_dict, tool_dir=-1,\n",
    "                              multiprocess=False)\n",
    "test_fun_cl.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step, \n",
    "    test_fun=test_fun_cl)\n",
    "snode_schedule_list_down, idx_bases, idc_divs, scene_args_list_down, scene_kwargs_list_down = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, closet_down, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)\n",
    "test_fun_cl.clear()\n",
    "Q_CUR = snode_schedule_list_rightup[-1][-1].state.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "snode_schedule_list = snode_schedule_list_leftup + snode_schedule_list_rightup + snode_schedule_list_down\n",
    "scene_args_list = scene_args_list_leftup + scene_args_list_rightup + scene_args_list_down\n",
    "scene_kwargs_list = scene_kwargs_list_leftup + scene_kwargs_list_rightup + scene_kwargs_list_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Execute closet cleaning sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_APPROACH = 0.4\n",
    "UPDATE_MOTION = False\n",
    "LOOK_ADJUST = True\n",
    "VEL_LEVEL = 1\n",
    "\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        vel_level_bak = indy.get_joint_vel_level()\n",
    "        print(\"vel_level_bak: {}\".format(vel_level_bak))\n",
    "\n",
    "    with indy:\n",
    "        indy.set_joint_vel_level(VEL_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "(0, 0)->(0, 1)\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n"
     ]
    }
   ],
   "source": [
    "swp_fin_list = []\n",
    "first_approach = True\n",
    "\n",
    "for i_s, (snode_schedule, sargs, skwargs) in enumerate(zip(snode_schedule_list, scene_args_list, scene_kwargs_list)):\n",
    "    print(\"motions: {}\".format(len(snode_schedule[:-1])-1))\n",
    "    set_base_sweep(*sargs, **skwargs)\n",
    "    for snode_pre, snode_nxt in zip(snode_schedule[:-1], snode_schedule[1:]):\n",
    "        snode_pre = snode_pre.copy(pscene)\n",
    "        snode_pre.traj = None\n",
    "        from_state = snode_pre.state\n",
    "        to_state = snode_nxt.state\n",
    "        subjects, ok = pscene.get_changing_subjects(from_state, to_state)\n",
    "        print(subjects)\n",
    "\n",
    "        if len(subjects) ==0 or subjects[0] == \"sweep\":\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "            if CONNECT_INDY:\n",
    "                if UPDATE_MOTION:\n",
    "                    print(\"try update trajectory\")\n",
    "                    traj, state_next, error, succ = \\\n",
    "                            ppline.test_connection(from_state=snode_pre.state, \n",
    "                                                   to_state=snode_nxt.state)\n",
    "                    if succ:\n",
    "                        snode_nxt.traj = traj\n",
    "                        snode_nxt.state = state_next\n",
    "            #         else:\n",
    "            #             raise(RuntimeError(\"Path update fail\"))\n",
    "                ppline.execute_schedule([snode_pre, snode_nxt], one_by_one=True)\n",
    "                with indy:\n",
    "                    time.sleep(0.5)\n",
    "                    indy.wait_for_move_finish()\n",
    "            else:\n",
    "                ppline.play_schedule([snode_pre, snode_nxt])\n",
    "\n",
    "        elif subjects[0] == \"waypoints\":\n",
    "            if CONNECT_MOBILE:\n",
    "                Qmoved = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, from_state.Q, to_state.Q, \n",
    "                                                  D_APPROACH=0)\n",
    "                Qref = to_state.Q\n",
    "                if LOOK_ADJUST and first_approach:\n",
    "                    first_approach = False\n",
    "                    ################ Look & adjust ######################\n",
    "                    target_point=closet_leftup.get_tf(Qref)[:3,3]\n",
    "                    traj, succ = get_look_motion(mplan, ROBOT_NAME, Qref, \n",
    "                                                 target_point=target_point,\n",
    "                                                 com_link = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][-3],\n",
    "                                                 view_dir = [0,0,1],timeout = 1)\n",
    "                    traj_rev = np.array(list(reversed(traj)))\n",
    "                    assert succ, \"looking motion failed\"\n",
    "\n",
    "                    Qref[6:] = traj[-1][6:]\n",
    "                    if CONNECT_INDY:\n",
    "                        with indy: # move to look\n",
    "                            crob.move_joint_traj(traj, one_by_one=True)\n",
    "\n",
    "                        # test code here\n",
    "                        if CONNECT_CAM:\n",
    "                            rdict = stream_capture_image(ImageType.CloseView, obj_type=\"closet\", host=CAM_HOST)\n",
    "\n",
    "                        if ENABLE_DETECT:\n",
    "                            closet_vis = gscene.NAME_DICT[\"closet_vis\"]\n",
    "                            Qdict_scan = list2dict(Qref, gscene.joint_names)\n",
    "                            T_bc = viewpoint.get_tf(Qdict_scan)\n",
    "                            T_bs = bed_vis.get_tf(Qdict_scan)\n",
    "                            T_sc = np.matmul(SE3_inv(T_bs), T_bc)\n",
    "                            T_bs_closet = closet_vis.get_tf(Qdict_scan)\n",
    "                            bed_dims = bed_mat.dims\n",
    "                            floor_margin = 0.1\n",
    "\n",
    "                            T_toff_closet = np.identity(4)\n",
    "                            T_toff_closet[:3,:3] = np.array([[1,0,0],[0,0,1],[0,-1,0]])\n",
    "                            T_toff_closet[:3,3] = np.array([0.3,0,0.2725])\n",
    "\n",
    "                            T_cs_closet = np.matmul(SE3_inv(T_bc), T_bs_closet)\n",
    "\n",
    "                            ICP_result_top_table_close, pcd = reprocess_top_table_detection(T_sc, T_cs_closet, bed_dims, T_toff_closet, visualize=False)\n",
    "\n",
    "                            T_toff_top_table = np.identity(4)\n",
    "                            T_toff_top_table[:3,:3] = np.array([[1,0,0],[0,0,1],[0,-1,0]])\n",
    "                            T_toff_top_table[:3,3] = np.array([0.3,0,0.2725])\n",
    "\n",
    "                            T_co_close = np.matmul(ICP_result_top_table_close, T_toff_top_table)\n",
    "                            T_bc = viewpoint.get_tf(Qdict_scan)\n",
    "                            T_bo_close = np.matmul(T_bc, T_co_close)\n",
    "\n",
    "                            T_bo_new = align_z(T_bo_close)\n",
    "\n",
    "                            # calculate transform based on obtained points\n",
    "                            pcd_center_prev = pcd.get_center()\n",
    "                            pcd_center_transformed_prev = np.matmul(T_bc[:3,:3], pcd_center_prev).transpose() + T_bc[:3,3]\n",
    "\n",
    "                            T_bo_p = np.identity(4)\n",
    "                            T_bo_p[:3,:3] = T_bo_close[:3,:3]\n",
    "                            T_bo_p[:3,3] = pcd_center_transformed_prev\n",
    "\n",
    "                            T_pooc = np.matmul(SE3_inv(T_bo_p), T_bo_close)\n",
    "                            T_bo_p[:3,:3] = Rot_axis(3, Rot2axis(T_bo_close[:3,:3], 3))\n",
    "                            T_bo_c_fix = np.matmul(T_bo_p, T_pooc)\n",
    "                            T_bo_c_fix[2,3] = 0\n",
    "\n",
    "                            # get Twoff from redetection\n",
    "                            Tbo0 = T_bs_closet\n",
    "                            Tbo1 = T_bo_c_fix\n",
    "\n",
    "                            Tbw0 = wayframer.get_tf_handle(list2dict(Qref, gscene.joint_names))\n",
    "                            Tow = np.matmul(SE3_inv(Tbo0), Tbw0)\n",
    "                            Tbw1 = np.matmul(Tbo1, Tow)\n",
    "\n",
    "                            Qtar = np.copy(Qref)\n",
    "                            Qtar[:2] = Tbw1[:2,3]\n",
    "                            Qtar[2] = Rot2axis(Tbw1[:3,:3], 3)\n",
    "\n",
    "                        if CONNECT_MOBILE:\n",
    "                            Qmoved = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, \n",
    "                                                              Qmoved, Qtar, D_APPROACH=0)\n",
    "                            gscene.show_pose(Qref)\n",
    "\n",
    "                        with indy: # retrieve motion\n",
    "                            crob.move_joint_traj(traj_rev, one_by_one=True)\n",
    "\n",
    "                    else:\n",
    "                        gscene.show_motion(traj)\n",
    "                        time.sleep(1)\n",
    "                        gscene.show_motion(traj_rev)\n",
    "                    ################ Look & adjust ######################\n",
    "#                 if UPDATE_MOTION: to_state.Q[:6] = Qmoved[:6]\n",
    "            else:\n",
    "                ppline.play_schedule([snode_pre, snode_nxt])\n",
    "        else:\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "    # leave highlight on cleared area\n",
    "    swp_fin = gscene.copy_from(gscene.NAME_DICT[\"sweep\"], new_name=\"sweep_fin_{}\".format(i_s), color=(0,0,1,0.5))\n",
    "    swp_fin.dims = (swp_fin.dims[0], swp_fin.dims[1], swp_fin.dims[2]+0.002)\n",
    "    gscene.update_marker(swp_fin)\n",
    "    swp_fin_list.append(swp_fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Clear highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fun_cl.clear()\n",
    "for swp_fin in swp_fin_list:\n",
    "    gscene.remove(swp_fin)\n",
    "swp_fin_list = []\n",
    "pscene.clear_subjects()\n",
    "for child in copy.copy(closet_leftup.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])\n",
    "for child in copy.copy(closet_rightup.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])\n",
    "for child in copy.copy(closet_down.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bed cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Make bed cleaning plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 get division-base pose combination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.constraint.constraint_common import *\n",
    "from pkg.planning.constraint.constraint_actor import *\n",
    "from pkg.planning.constraint.constraint_subject import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Height Reference: ', 0.6620000193119049)\n"
     ]
    }
   ],
   "source": [
    "wp_task, wp_hdl = add_waypoint_task(pscene, \"waypoint\", WP_DIMS, (0,0,0), (0,0,0), \n",
    "                                    parent=\"floor_ws\", color=(0, 0, 1, 0.5))\n",
    "BED_OFFSET = 0.10\n",
    "brush_face = pscene.create_binder(bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "                                  point=(0,0,-gscene.NAME_DICT['brush_face'].dims[2]/2-CLEARANCE-BED_OFFSET), \n",
    "                                  rpy=(0,0,0))\n",
    "\n",
    "T_e_brush = brush_face.get_tf_handle(crob.home_dict, from_link=TIP_LINK)\n",
    "T_brush_e = SE3_inv(T_e_brush)\n",
    "EE_HEIGHT = round(bed_mat.get_tf(HOME_DICT)[2,3] + bed_mat.dims[2]/2, 5) \\\n",
    "                + T_brush_e[2, 3] - INDY_BASE_OFFSET[2]\n",
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(bed_mat, brush_face, robot_config, \n",
    "                                          plane_val=EE_HEIGHT, tip_dir=SweepDirections.front.name, TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02, \n",
    "                                          sweep_margin=0.0, xout_cut=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 select base poses and generate motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250169/1635250166.84 s) ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250173/1635250169.98 s) ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: max iteration time reached (1635250178/1635250175.31 s) ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "\u001b[91mterminate_on_first is deprecated. Use max_solution_count=1\u001b[0m\n",
      "\u001b[91m==========================================================\u001b[0m\n",
      "Goal reached\n",
      "Goal reached\n",
      "=========================================================================================================\n",
      "======================= terminated 0: required answers acquired ===============================\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "HOME_POSE_MOVE = Q_CUR[6:]\n",
    "HOME_POSE_SWEEP = np.copy(Q_CUR)\n",
    "HOME_POSE_SWEEP[6:] = [0]*6\n",
    "crob.home_pose = HOME_POSE_SWEEP\n",
    "crob.home_dict = list2dict(crob.home_pose, gscene.joint_names)\n",
    "floor_ws = gscene.NAME_DICT[\"floor_ws\"]    \n",
    "test_fun = TestBaseDivFunc(ppline, floor_ws, bed_mat, WP_DIMS, TOOL_DIM, crob.home_dict, multiprocess=False)\n",
    "#                           , show_motion=True, timeout_loop=30, verbose=True)\n",
    "\n",
    "test_fun.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step,\n",
    "    test_fun=test_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 refine motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update 1th motion\n",
      "update 2th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "update 2th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "update 2th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "update 2th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "update 2th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "update 2th motion\n",
      "Goal reached\n",
      "update 1th motion\n",
      "update 2th motion\n",
      "Goal reached\n"
     ]
    }
   ],
   "source": [
    "HOME_POSE_SWEEP[6:] = HOME_POSE_MOVE\n",
    "gscene.show_pose(HOME_POSE_SWEEP)\n",
    "snode_schedule_list, idx_bases, idc_divs, scene_args_list, scene_kwargs_list = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, bed_mat, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Execute bed cleaning sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_APPROACH = 0.4\n",
    "UPDATE_MOTION = False\n",
    "LOOK_ADJUST = True\n",
    "VEL_LEVEL = 1\n",
    "\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        vel_level_bak = indy.get_joint_vel_level()\n",
    "        print(\"vel_level_bak: {}\".format(vel_level_bak))\n",
    "\n",
    "    with indy:\n",
    "        indy.set_joint_vel_level(VEL_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motions: 3\n",
      "['waypoints']\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n",
      "motions: 3\n",
      "['waypoints']\n",
      "['sweep']\n",
      "(0, 1)->(1, 1)\n",
      "['sweep']\n",
      "(1, 1)->(2, 1)\n",
      "[]\n",
      "(2, 1)->(2, 1)\n"
     ]
    }
   ],
   "source": [
    "swp_fin_list = []\n",
    "\n",
    "for i_s, (snode_schedule, sargs, skwargs) in enumerate(zip(snode_schedule_list, scene_args_list, scene_kwargs_list)):\n",
    "    print(\"motions: {}\".format(len(snode_schedule[:-1])-1))\n",
    "    set_base_sweep(*sargs, **skwargs)\n",
    "    for snode_pre, snode_nxt in zip(snode_schedule[:-1], snode_schedule[1:]):\n",
    "        snode_pre = snode_pre.copy(pscene)\n",
    "        snode_pre.traj = None\n",
    "        from_state = snode_pre.state\n",
    "        to_state = snode_nxt.state\n",
    "        subjects, ok = pscene.get_changing_subjects(from_state, to_state)\n",
    "        print(subjects)\n",
    "\n",
    "        if len(subjects) ==0 or subjects[0] == \"sweep\":\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "            if CONNECT_INDY:\n",
    "                if UPDATE_MOTION:\n",
    "                    print(\"try update trajectory\")\n",
    "                    traj, state_next, error, succ = \\\n",
    "                            ppline.test_connection(from_state=snode_pre.state, \n",
    "                                                   to_state=snode_nxt.state)\n",
    "                    if succ:\n",
    "                        snode_nxt.traj = traj\n",
    "                        snode_nxt.state = state_next\n",
    "            #         else:\n",
    "            #             raise(RuntimeError(\"Path update fail\"))\n",
    "                ppline.execute_schedule([snode_pre, snode_nxt], one_by_one=True)\n",
    "                with indy:\n",
    "                    time.sleep(0.5)\n",
    "                    indy.wait_for_move_finish()\n",
    "            else:\n",
    "                ppline.play_schedule([snode_pre, snode_nxt])\n",
    "\n",
    "        elif subjects[0] == \"waypoints\":\n",
    "            gscene.show_motion(snode_nxt.traj)\n",
    "            if CONNECT_MOBILE:\n",
    "                Qmoved = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, from_state.Q, to_state.Q, \n",
    "                                                  D_APPROACH=D_APPROACH)\n",
    "                \n",
    "                if LOOK_ADJUST:\n",
    "                    raise(RuntimeError(\"Look adjust here\"))\n",
    "                \n",
    "                if UPDATE_MOTION: to_state.Q = Qmoved\n",
    "        else:\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "    # leave highlight on cleared area\n",
    "    swp_fin = gscene.copy_from(gscene.NAME_DICT[\"sweep\"], new_name=\"sweep_fin_{}\".format(i_s), color=(0,0,1,0.5))\n",
    "    swp_fin.dims = (swp_fin.dims[0], swp_fin.dims[1], swp_fin.dims[2]+0.002)\n",
    "    gscene.update_marker(swp_fin)\n",
    "    swp_fin_list.append(swp_fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Clear highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fun.clear()\n",
    "for swp_fin in swp_fin_list:\n",
    "    gscene.remove(swp_fin)\n",
    "swp_fin_list = []\n",
    "pscene.clear_subjects()\n",
    "for child in copy.copy(bed_mat.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
