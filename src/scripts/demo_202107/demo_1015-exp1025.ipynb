{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Script for Milestone 10.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Prepare task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 prepare planning scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run camera server on the camera computer (192.168.0.10, use vnc viewer)\n",
    "```bash\n",
    "python stream_server.py --ip='192.168.0.10'\n",
    "```\n",
    "#### Run shared detector on bash\n",
    "```bash\n",
    "python3 /home/jhkim/Projects/rnb-planning/src/scripts/milestone_202110/utils/shared_detector.py\n",
    "```\n",
    "\n",
    "### Check IP request ip setting from mobile udp client (robot-side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/milestone_202110'))\n",
    "\n",
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from demo_utils.kiro_udp_send import start_mobile_udp_thread, send_pose_wait, get_xyzw_cur, get_reach_state\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "from demo_utils.streaming import *\n",
    "from demo_utils.detect_table import *\n",
    "from demo_utils.area_select import *\n",
    "from pkg.detector.aruco.marker_config import get_aruco_map\n",
    "aruco_map = get_aruco_map()\n",
    "\n",
    "\n",
    "CONNECT_CAM = False # True\n",
    "ENABLE_DETECT = False\n",
    "# DETECT_MARKER = True\n",
    "CONNECT_INDY = False # True\n",
    "CONNECT_MOBILE = False # True \n",
    "VISUALIZE = True\n",
    "\n",
    "# Tool dimensions\n",
    "TOOL_DIM = [0.32, 0.08]\n",
    "TOOL_OFFSET = 0.01\n",
    "MARGIN = 0\n",
    "TRACK_THICKNESS = 0.001\n",
    "\n",
    "INDY_BASE_OFFSET = (0.172,0,0.439)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "\n",
    "ip_cur = \"192.168.0.8\"# get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "INDY_IP = \"192.168.0.3\"\n",
    "CAM_HOST = '192.168.0.10'\n",
    "\n",
    "print(\"Current PC IP: {}\".format(ip_cur))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))\n",
    "print(\"CAM SERVER IP: {}\".format(CAM_HOST))\n",
    "\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from demo_utils.environment import *\n",
    "\n",
    "from utils.streaming import *\n",
    "from utils.detection_util import *\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                MOBILE_IP)\n",
    "robot_config = RobotConfig(1, RobotType.indy7, (INDY_BASE_OFFSET, (0,0,0)),\n",
    "                INDY_IP, root_on=\"kmb0_platform\", \n",
    "                           specs={\"no_sdk\":True})\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[False, CONNECT_INDY])\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "\n",
    "gtems = s_builder.add_robot_geometries(color=(0,1,0,0.5), display=True, collision=True)\n",
    "gscene.set_workspace_boundary(-3, 7, -5, 5, -CLEARANCE, 3, thickness=WALL_THICKNESS)\n",
    "\n",
    "\n",
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "ROBOT_BASE = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][0]\n",
    "TIP_LINK = pscene.robot_chain_dict[ROBOT_NAME][\"tip_link\"]\n",
    "MOBILE_BASE = pscene.robot_chain_dict[MOBILE_NAME][\"tip_link\"]\n",
    "HOLD_LINK = MOBILE_BASE\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=TIP_LINK)\n",
    "# add_indy_tool_kiro(gscene, tool_link=TIP_LINK, face_name=TOOL_NAME, zoff=TOOL_OFFSET)\n",
    "\n",
    "HOME_POSE = -crob.home_pose\n",
    "HOME_DICT = list2dict(HOME_POSE, gscene.joint_names)\n",
    "\n",
    "from pkg.planning.pipeline import PlanningPipeline\n",
    "ppline = PlanningPipeline(pscene)\n",
    "\n",
    "# Set planner\n",
    "from pkg.planning.motion.moveit.moveit_planner import MoveitPlanner\n",
    "from pkg.planning.filtering.grasp_filter import GraspChecker\n",
    "mplan = MoveitPlanner(pscene, enable_dual=False, incremental_constraint_motion=True)\n",
    "mplan.motion_filters = [GraspChecker(pscene)]\n",
    "mplan.update_gscene()\n",
    "gcheck = GraspChecker(pscene)\n",
    "mplan.motion_filters = [gcheck]\n",
    "\n",
    "from pkg.planning.task.rrt import TaskRRT\n",
    "tplan = TaskRRT(pscene)\n",
    "tplan.prepare()\n",
    "ppline.set_motion_planner(mplan)\n",
    "ppline.set_task_planner(tplan)\n",
    "\n",
    "from pkg.ui.ui_broker import *\n",
    "\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(ppline, s_builder)\n",
    "ui_broker.start_server()\n",
    "\n",
    "ui_broker.set_tables()\n",
    "\n",
    "add_kiro_indytool_down(gscene, zoff=TOOL_OFFSET, tool_link=TIP_LINK, face_name=TOOL_NAME)\n",
    "\n",
    "# Register binders\n",
    "from pkg.planning.constraint.constraint_actor import VacuumTool, Gripper2Tool, PlacePlane, SweepFramer, WayFramer\n",
    "brush_face = pscene.create_binder(bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "                                  point=(-gscene.NAME_DICT['brush_face'].dims[0]/2-CLEARANCE,0,0), \n",
    "                                  rpy=(0,np.pi/2*1,0))\n",
    "\n",
    "# waypoint\n",
    "WP_DIMS = (0.6,0.4,WALL_THICKNESS)\n",
    "gscene.create_safe(gtype=GEOTYPE.BOX, name=\"wayframer\", link_name=HOLD_LINK,\n",
    "                   dims=WP_DIMS, center=(0,0,WP_DIMS[2]/2), rpy=(0,0,0), color=(1, 0, 0, 0.5), display=True,\n",
    "                   collision=False, fixed=True)\n",
    "wayframer = pscene.create_binder(bname=\"wayframer\", gname=\"wayframer\", _type=WayFramer, \n",
    "                                 point=(0,0,-WP_DIMS[2]/2-CLEARANCE), rpy=(0,0,0))\n",
    "\n",
    "indy = crob.robot_dict[\"indy1\"]\n",
    "\n",
    "if CONNECT_MOBILE:\n",
    "    sock_mobile, server_thread = start_mobile_udp_thread(recv_ip=ip_cur)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Wait task start queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Detect bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Get environment map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.ros_utils import Listener\n",
    "from demo_utils.map_converter import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET MAP\n",
    "# map_listener = Listener(topic_name=\"/map\", topic_type=OccupancyGrid)\n",
    "# cost_listener = Listener(topic_name=\"/move_base/global_costmap/costmap\", topic_type=OccupancyGrid)\n",
    "# map_data = map_listener.get_data()\n",
    "# cost_data = cost_listener.get_data()\n",
    "map_data = load_pickle(os.path.join(os.environ[\"RNB_PLANNING_DIR\"],\"data/map_data.pkl\"))\n",
    "cost_data = load_pickle(os.path.join(os.environ[\"RNB_PLANNING_DIR\"],\"data/cost_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET LINES\n",
    "map_im, resolution = convert_map(map_data)\n",
    "ret, map_bin = cv2.threshold(map_im, 100, 255, cv2.THRESH_BINARY)\n",
    "lines = cv2.HoughLinesP(map_bin, 1, 1 * np.pi / 180, 30, minLineLength = 10, maxLineGap = 50)\n",
    "map_shape = map_im.shape\n",
    "bound_px = int(round(10 * 0.01 / resolution))\n",
    "line_im_accum = np.zeros(map_shape, np.uint8)\n",
    "lines_maj = []\n",
    "idc_exc = set()\n",
    "line_bounds = np.array([line2im(line[0], map_shape, bound_px) for line in lines])\n",
    "line_ims = np.array([line2im(line[0], map_shape) for line in lines])\n",
    "for i_l, (line0, line0bd) in enumerate(zip(lines, line_bounds)):\n",
    "    if i_l in idc_exc:\n",
    "        continue\n",
    "    line_im_accum = np.max([line_im_accum, line0bd], axis=0)\n",
    "    lines_maj.append(line0)\n",
    "    idc_inbound = np.where(np.sum(np.sum(line_ims[i_l:] > line_im_accum[np.newaxis, :, :], -1), -1) == 0)[0] + i_l\n",
    "    idc_exc = idc_exc.union(list(idc_inbound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.cvtColor(map_im, cv2.COLOR_GRAY2BGR)\n",
    "for i in lines_maj:\n",
    "    cv2.line(dst, (i[0][0], i[0][1]), (i[0][2], i[0][3]), (0, 0, 255), 2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_io_px = T_xyzquat(((lambda x: (x.x+map_shape[0]/2, x.y+map_shape[1]/2, x.z))(map_data.info.origin.position), \n",
    "                    (lambda x: (x.x, x.y, x.z, x.w))(map_data.info.origin.orientation)))\n",
    "T_io = T_io_px.copy()\n",
    "T_io[:3,3] *= resolution\n",
    "\n",
    "cur_xyzw = [ 0.8,   1.68, -0.15,  0.99]\n",
    "Q_CUR = np.copy(crob.home_pose)\n",
    "Q_CUR[:2] = cur_xyzw[:2]\n",
    "Q_CUR[2] = Rot2axis(Rotation.from_quat((0,0,cur_xyzw[2], cur_xyzw[3])).as_dcm(), 3)\n",
    "gscene.show_pose(Q_CUR)\n",
    "T_om = T_xyzquat(((tuple(cur_xyzw[:2])+(0,)), ((0,0)+tuple(cur_xyzw[2:]))))\n",
    "T_im = np.matmul(T_io, T_om)\n",
    "\n",
    "T_bm = wayframer.get_tf_handle(Q_CUR)\n",
    "\n",
    "T_bi = np.matmul(T_bm, SE3_inv(T_im))\n",
    "\n",
    "# for i_l, line in enumerate(lines_maj):\n",
    "#     ptx_px = line[0]\n",
    "#     pts = np.multiply(ptx_px, resolution)\n",
    "#     pt1, pt2 = map(lambda pt: np.matmul(T_bi[:2,:2], pt) + T_bi[:2,3], [pts[:2], pts[2:]])\n",
    "#     add_line_to_gscene(gscene, \"map_line_{}\".format(i_l), pt1, pt2, \n",
    "#                        thickness=bound_px*resolution*2, height=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Move to bed-seek pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_POSE = np.deg2rad([  0., 50.,  -70.,  -0.,  -90., 0])\n",
    "VIEW_LOC = [0,]*6\n",
    "VIEW_POSE_EXT = np.array(VIEW_LOC + list(VIEW_POSE))\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        indy.joint_move_to(np.rad2deg(VIEW_POSE))\n",
    "        time.sleep(0.5)\n",
    "        indy.wait_for_move_finish()\n",
    "        Qcur = np.deg2rad(indy.get_joint_pos())\n",
    "else:\n",
    "    Qcur = VIEW_POSE\n",
    "gscene.show_pose(VIEW_POSE_EXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **[TODO] rotate until bed is detected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_DETECT:\n",
    "    attacth_to_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAM_HOST = '192.168.0.40'\n",
    "if CONNECT_CAM:\n",
    "    # rdict = send_recv_demo_cam({1:1}, host=CAM_HOST)\n",
    "    rdict = stream_capture_image(ImageType.FirstView, obj_type=\"bed\", host=CAM_HOST)\n",
    "    cam_intrins, d_scale = [rdict[key] for key in [\"intrins\", \"depth_scale\"]]\n",
    "    set_cam_params(cam_intrins, d_scale)\n",
    "    cam_width, cam_height, cam_fx, cam_fy, cam_ppx, cam_ppy = cam_intrins\n",
    "    __d_scale = d_scale\n",
    "    bed_color_path = SAVE_DIR + '/bed.jpg'\n",
    "    bed_depth_path = SAVE_DIR + '/bed.png'\n",
    "else:\n",
    "#     cam_intrins = [1280, 720, 899.05322265625,  899.21044921875, 654.8836669921875, 352.9295654296875]\n",
    "#     d_scale = 0.0002500000118743628\n",
    "    cam_intrins = [1280, 720, 909.957763671875,  909.90283203125, 638.3824462890625, 380.0085144042969]\n",
    "    d_scale = 1 / 3999.999810010204\n",
    "    set_cam_params(cam_intrins, d_scale)\n",
    "    cam_width, cam_height, cam_fx, cam_fy, cam_ppx, cam_ppy = cam_intrins\n",
    "    __d_scale = d_scale\n",
    "    bed_color_path = SAVE_DIR + '/bed.jpg'\n",
    "    bed_depth_path = SAVE_DIR + '/bed.png'\n",
    "#     bed_color_path = EXP_IMG_DIR + '/bed.jpg'\n",
    "#     bed_depth_path = EXP_IMG_DIR + '/bed.png'\n",
    "#     bed_color_path = EXP_IMG_DIR + '/513.jpg'\n",
    "#     bed_depth_path = EXP_IMG_DIR + '/top_table_0024.png'\n",
    "\n",
    "# Read color, depth image file, keep 16bit information\n",
    "color_img_read = cv2.imread(bed_color_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "depth_img_read = cv2.imread(bed_depth_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Output of inference(mask for detected table)\n",
    "mask_out = detect_from_server(color_img_read)\n",
    "\n",
    "# If bed is not detected, then pass below detection part\n",
    "test = np.empty((720,1280), dtype=bool)\n",
    "test[:,:] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while np.array_equal(mask_out, test):\n",
    "    if CONNECT_INDY:\n",
    "        with indy:\n",
    "            Qnow = indy.get_joint_pos()\n",
    "            Qto = np.add(Qnow, [10,0,0,0,0,0])\n",
    "            Qto[0] = (Qto[0]+np.pi/2)%np.pi-np.pi/2\n",
    "            indy.joint_move_to(Qto)\n",
    "            indy.wait_motion()\n",
    "    \n",
    "    \n",
    "    # Take a picture again after rotate\n",
    "    time.sleep(1)\n",
    "    rdict = stream_capture_image(ImageType.FirstView, obj_type=\"bed\", host=CAM_HOST)\n",
    "    \n",
    "    # Read color, depth image file, keep 16bit information\n",
    "    color_img_read = cv2.imread(bed_color_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "    depth_img_read = cv2.imread(bed_depth_path, flags=cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # Output of inference(mask for detected table)\n",
    "    mask_out = detect_from_server(color_img_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2  detect bed and add to the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bc = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "if ENABLE_DETECT:\n",
    "    # Try ICP1\n",
    "    if not np.array_equal(mask_out, test):\n",
    "        plt.imshow(mask_out)\n",
    "\n",
    "        # Crop masking part\n",
    "        vis_mask = (mask_out * 255).astype('uint8')\n",
    "        color_instance = cv2.bitwise_and(color_img_read, color_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        depth_instance = cv2.bitwise_and(depth_img_read, depth_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.jpg', color_instance)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.png', depth_instance)\n",
    "\n",
    "        ICP_result_bed1, fitness1 = process_bed_detection_front(T_bc, visualize=False)\n",
    "\n",
    "        # Try ICP2\n",
    "    if not np.array_equal(mask_out, test):\n",
    "        plt.imshow(mask_out)\n",
    "\n",
    "        # Crop masking part\n",
    "        vis_mask = (mask_out * 255).astype('uint8')\n",
    "        color_instance = cv2.bitwise_and(color_img_read, color_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        depth_instance = cv2.bitwise_and(depth_img_read, depth_img_read, mask=vis_mask).astype(np.uint16)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.jpg', color_instance)\n",
    "        cv2.imwrite(CROP_DIR + '/bed_crop.png', depth_instance)\n",
    "\n",
    "        ICP_result_bed2, fitness2 = process_bed_detection(visualize=False)\n",
    "        \n",
    "    # Better result is adopted\n",
    "    if fitness1 > fitness2:\n",
    "        ICP_result_bed = ICP_result_bed1\n",
    "    else:\n",
    "        ICP_result_bed = ICP_result_bed2        \n",
    "\n",
    "\n",
    "    # Coorinate offeset\n",
    "    T_toff_bed = np.identity(4)\n",
    "    T_toff_bed[:3,:3] = np.array([[0,1,0],[0,0,1],[1,0,0]])\n",
    "    T_toff_bed[:3,3] = np.array([0.455,0,1.02])\n",
    "\n",
    "    T_co_bed = np.matmul(ICP_result_bed, T_toff_bed)\n",
    "    T_bc = viewpoint.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "    T_bo_bed = np.matmul(T_bc, T_co_bed)\n",
    "\n",
    "    bed_center = T_bo_bed[:3,3]\n",
    "    bed_rpy = Rot2rpy(T_bo_bed[:3,:3])\n",
    "    # bed_center = (2,0,0)\n",
    "    # bed_rpy = (0,0,np.pi/2)\n",
    "    COLOR_BED_COL = (0,1,0,0.3)\n",
    "    # T_revis = np.identity(4)\n",
    "    # T_revis[:3,:3] = Rot_axis(3, Rot2axis(bed_vis.get_tf(VIEW_POSE_EXT)[:3,:3],3))\n",
    "    # bed_rpy = Rot2rpy(Rot_axis(3, Rot2axis(bed_vis.get_tf(VIEW_POSE_EXT)[:3,:3],3)\n",
    "    T_bo_new = align_z(T_bo_bed)\n",
    "    bed_rpy = Rot2rpy(T_bo_new[:3,:3])\n",
    "\n",
    "    # adjust\n",
    "    bed_center[2]=0\n",
    "    if Rot_rpy(bed_rpy)[0,0] > 0:\n",
    "        bed_rpy[2] += np.pi\n",
    "\n",
    "    bed_mat = add_bed(gscene, bed_center, bed_rpy, COLOR_BED_COL)\n",
    "    \n",
    "else:\n",
    "    T_bc = viewpoint.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "    bed_center = (2,0,0)\n",
    "    bed_rpy = (0,0,np.pi/2)\n",
    "    COLOR_BED_COL = (0,1,0,0.3)\n",
    "    bed_mat = add_bed(gscene, bed_center, bed_rpy, COLOR_BED_COL)\n",
    "\n",
    "bed_vis = gscene.NAME_DICT[\"bed_vis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Detect Closet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.0 set checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_task, wp_hdl = add_waypoint_task(pscene, \"waypoint\", WP_DIMS, (0,0,0), (0,0,0), \n",
    "                                    parent=\"floor_ws\", color=(0, 0, 1, 0.5))\n",
    "ccheck = CachedCollisionCheck(gcheck, wp_task, wp_hdl, wayframer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1  move to full view position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.2.1.1  decide closet side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_vis = gscene.NAME_DICT[\"bed_vis\"]\n",
    "T_bo = bed_vis.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_CAM:\n",
    "    color_path = SAVE_DIR + '/bed.jpg'\n",
    "    depth_path = SAVE_DIR + '/bed.png'\n",
    "else:\n",
    "    color_path = EXP_IMG_DIR + '/bed.jpg'\n",
    "    depth_path = EXP_IMG_DIR + '/bed.png'\n",
    "\n",
    "if ENABLE_DETECT:\n",
    "    # Determine the location of closet\n",
    "    CLOSET_LOCATION = check_location_top_table(color_path, depth_path, T_bc, T_bo, bed_dims=bed_mat.dims, \n",
    "                                               visualize=False)\n",
    "    print(\"CLOSET on {}\".format(CLOSET_LOCATION))\n",
    "\n",
    "#     T_bm_from = wayframer.get_tf_handle(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "#     T_bs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "\n",
    "#     if CLOSET_LOCATION == \"LEFT\":\n",
    "#         T_sm = SE3(Rot_axis(3, np.pi), [1.5, -1.33, 0])\n",
    "#     elif CLOSET_LOCATION == \"RIGHT\":       \n",
    "#         T_sm = SE3(Rot_axis(3, np.pi), [1.5, 1.33, 0])\n",
    "\n",
    "#     T_bm = np.matmul(T_bs, T_sm)\n",
    "\n",
    "#     x,y = T_bm[:2,3]\n",
    "#     theta = Rot2axis(T_bm[:3,:3], 3)\n",
    "else:\n",
    "    CLOSET_LOCATION = \"LEFT\"\n",
    "#     T_bs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "#     T_sm = SE3(Rot_axis(3, np.pi), [1.5, -1.33, 0])\n",
    "#     T_bm = np.matmul(T_bs, T_sm)\n",
    "\n",
    "#     x,y = T_bm[:2,3]\n",
    "#     theta = Rot2axis(T_bm[:3,:3], 3)\n",
    "    \n",
    "# VIEW_MOVED_EXT = np.add(VIEW_POSE_EXT, [x,y,theta]+[0]*9) \n",
    "# gscene.show_pose(VIEW_MOVED_EXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1.2  decide full view position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLOSET_LOCATION == \"LEFT\":\n",
    "    angle_ref = 150\n",
    "elif CLOSET_LOCATION == \"RIGHT\":       \n",
    "    angle_ref = -150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_dim = np.linalg.norm(bed_mat.dims)\n",
    "h_fov_hf = np.arctan2(cam_intrins[0], 2*cam_intrins[2])\n",
    "x_z_ratio = np.tan(h_fov_hf)\n",
    "bed_dist = (bed_dim/2) / x_z_ratio * 3 \n",
    "while True:\n",
    "    angle_view = angle_ref + np.random.uniform(-10, 10)\n",
    "    dist_view = bed_dist + np.random.uniform(-0.5, 1)*bed_dist/4\n",
    "    Tbs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "    Tbs = np.matmul(Tbs, SE3(np.identity(3), (-bed_mat.dims[0]/2, 0,0)))\n",
    "    Tsc = np.matmul(SE3(Rot_axis(3, np.deg2rad(angle_view)), (0,)*3), \n",
    "                    SE3(np.identity(3), (-dist_view, 0,0)))\n",
    "    Tbc = np.matmul(Tbs, Tsc)\n",
    "    Tmc = viewpoint.get_tf(VIEW_POSE_EXT, from_link=MOBILE_BASE)\n",
    "    Tmc[:3,:3] = np.identity(3)\n",
    "    Tbm = np.matmul(Tbc, SE3_inv(Tmc))\n",
    "    full_view_ext = np.copy(VIEW_POSE_EXT)\n",
    "    full_view_ext[:2] = Tbm[:2,3]\n",
    "    full_view_ext[2] = Rot2axis(Tbm[:3, :3], 3)\n",
    "    gscene.show_pose(full_view_ext)\n",
    "    ccheck.clear()\n",
    "    res = ccheck(T_loal=Tbm, Q_dict=list2dict(full_view_ext, gscene.joint_names))\n",
    "    if res:\n",
    "        VIEW_MOVED_EXT = full_view_ext\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### move to full view position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_MOVED = np.deg2rad([  0., 50.,  -70.,  -0.,  -80., 0])\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        indy.joint_move_to(np.rad2deg(VIEW_MOVED))\n",
    "    \n",
    "VIEW_MOVED_EXT[crob.idx_dict[ROBOT_NAME]] = VIEW_MOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_MOBILE:\n",
    "    VIEW_MOVED_EXT = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, VIEW_POSE_EXT, VIEW_MOVED_EXT, \n",
    "                                              D_APPROACH=0)\n",
    "gscene.show_pose(VIEW_MOVED_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 redetect bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture image of full view\n",
    "if CONNECT_CAM:\n",
    "    rdict = stream_capture_image(ImageType.FullView, obj_type=\"full_view\", host=CAM_HOST)\n",
    "\n",
    "if ENABLE_DETECT:\n",
    "    bed_vis = gscene.NAME_DICT[\"bed_vis\"]\n",
    "    T_bc = viewpoint.get_tf(VIEW_MOVED_EXT)\n",
    "    T_bs = bed_vis.get_tf(VIEW_MOVED_EXT)\n",
    "    T_sc = np.matmul(SE3_inv(T_bs), T_bc)\n",
    "    bed_dims = bed_mat.dims\n",
    "    floor_margin = 0.1\n",
    "\n",
    "    T_toff_bed = np.identity(4)\n",
    "    T_toff_bed[:3,:3] = np.array([[0,1,0],[0,0,1],[1,0,0]])\n",
    "    T_toff_bed[:3,3] = np.array([0.455,0,1.05])\n",
    "\n",
    "\n",
    "    ICP_result_bed_full = reprocess_bed_detection(\n",
    "        T_sc, bed_dims, floor_margin, T_toff_bed, visualize=True)\n",
    "\n",
    "    T_co = np.matmul(ICP_result_bed_full, T_toff_bed)\n",
    "    T_bo_bed_full = np.matmul(T_bc, T_co)\n",
    "\n",
    "    bed_center = T_bo_bed_full[:3,3]\n",
    "    bed_rpy = Rot2rpy(T_bo_bed_full[:3,:3])\n",
    "\n",
    "    #adjust\n",
    "    bed_center[2]=0\n",
    "    T_bo_bed_full_new = align_z(T_bo_bed_full)\n",
    "    bed_rpy = Rot2rpy(T_bo_bed_full_new[:3,:3])\n",
    "    # if Rot_rpy(bed_rpy)[0,0] > 0:\n",
    "    #     bed_rpy[2] += np.pi\n",
    "\n",
    "    move_bed(gscene, bed_center, bed_rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3  detect and add closet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_DETECT:\n",
    "    if CONNECT_CAM:\n",
    "        rdict = stream_capture_image(ImageType.FirstView, obj_type=\"closet\", host=CAM_HOST)\n",
    "        closet_color_path = SAVE_DIR + '/top_table.jpg'\n",
    "        closet_depth_path = SAVE_DIR + '/top_table.png'\n",
    "    else:\n",
    "        closet_color_path = EXP_IMG_DIR + '/top_table_0024.jpg'\n",
    "        closet_depth_path = EXP_IMG_DIR + '/top_table_0024.png'\n",
    "\n",
    "    if CONNECT_CAM:\n",
    "        Qdict_scan = list2dict(VIEW_MOVED_EXT, gscene.joint_names)\n",
    "    else:\n",
    "        VIEW_POSE_MID = np.deg2rad([  0., 50.,  -70.,  -0.,  -75., 180])\n",
    "        VIEW_MOVED_EXT[6:] = VIEW_POSE_MID\n",
    "        Qdict_scan = list2dict(VIEW_MOVED_EXT, gscene.joint_names)\n",
    "    T_bc = viewpoint.get_tf(Qdict_scan)\n",
    "    T_bs = bed_vis.get_tf(Qdict_scan)\n",
    "    T_sc = np.matmul(SE3_inv(T_bs), T_bc)\n",
    "\n",
    "    ICP_result_top_table = process_top_table_detection(closet_color_path, closet_depth_path, T_sc=T_sc,\n",
    "                                                       bed_dims=bed_mat.dims, z_ceiling = 2.3,\n",
    "                                                       initial_offset=[0.3,1.1,0.6], floor_margin=0.1,\n",
    "                                                       visualize=False)\n",
    "\n",
    "    T_toff_top_table = np.identity(4)\n",
    "    T_toff_top_table[:3,:3] = np.array([[1,0,0],[0,0,1],[0,-1,0]])\n",
    "    T_toff_top_table[:3,3] = np.array([0.3,0,0.2725])\n",
    "\n",
    "    T_co = np.matmul(ICP_result_top_table, T_toff_top_table)\n",
    "    T_bc = viewpoint.get_tf(list2dict(VIEW_MOVED_EXT, gscene.joint_names))\n",
    "    T_bo = np.matmul(T_bc, T_co)\n",
    "    T_bo[:3,:3] = Rot_axis(3, Rot2axis(T_bo[:3,:3], 3))\n",
    "    T_bo[2,3] = 0\n",
    "else:\n",
    "    T_bo = T_xyzrpy((np.matmul(Rot_rpy(bed_rpy), (-0.75,-1.5,0))+bed_center, \n",
    "                     bed_rpy))\n",
    "\n",
    "closet_leftup, closet_rightup, closet_down = add_closet(\n",
    "    gscene, closet_center=T_bo[:3,3], closet_rpy=Rot2rpy(T_bo[:3,:3]), \n",
    "    COLOR_CLOSET_COL=(0,1,0,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Closet cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Make closet cleaning plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.constraint.constraint_common import *\n",
    "from pkg.planning.constraint.constraint_actor import *\n",
    "from pkg.planning.constraint.constraint_subject import *\n",
    "from pkg.utils.code_scraps import get_look_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_CUR = VIEW_MOVED_EXT\n",
    "HOME_POSE_SWEEP = np.copy(Q_CUR)\n",
    "# HOME_POSE_SWEEP[6:] = 0\n",
    "crob.home_pose = HOME_POSE_SWEEP\n",
    "crob.home_dict = list2dict(crob.home_pose, gscene.joint_names)\n",
    "floor_ws = gscene.NAME_DICT[\"floor_ws\"]    \n",
    "\n",
    "add_kiro_indytool_down(gscene, zoff=TOOL_OFFSET, tool_link=TIP_LINK, face_name=TOOL_NAME)\n",
    "brush_face = pscene.create_binder(bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "                                  point=(0,0,-gscene.NAME_DICT['brush_face'].dims[2]/2-CLEARANCE), \n",
    "                                  rpy=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(closet_leftup, brush_face, robot_config, \n",
    "                                          plane_val=None, tip_dir=\"up\", TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02)\n",
    "\n",
    "HOME_POSE_MOVE = np.copy(Q_CUR[6:])\n",
    "test_fun_cl = TestBaseDivFunc(ppline, floor_ws, closet_leftup, WP_DIMS, TOOL_DIM, crob.home_dict, tool_dir=1,\n",
    "                              multiprocess=False)\n",
    "test_fun_cl.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step, \n",
    "    test_fun=test_fun_cl, lazy_base_thresh=np.max(TOOL_DIM)/2)\n",
    "snode_schedule_list_leftup, idx_bases, idc_divs, scene_args_list_leftup, scene_kwargs_list_leftup = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, closet_leftup, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)\n",
    "test_fun_cl.clear()\n",
    "Q_CUR = snode_schedule_list_leftup[-1][-1].state.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(closet_rightup, brush_face, robot_config, \n",
    "                                          plane_val=None, tip_dir=\"up\", TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02)\n",
    "\n",
    "HOME_POSE_MOVE = np.copy(Q_CUR[6:])\n",
    "test_fun_cl = TestBaseDivFunc(ppline, floor_ws, closet_rightup, WP_DIMS, TOOL_DIM, crob.home_dict, tool_dir=1,\n",
    "                              multiprocess=False)\n",
    "test_fun_cl.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step, \n",
    "    test_fun=test_fun_cl, lazy_base_thresh=np.max(TOOL_DIM)/2)\n",
    "snode_schedule_list_rightup, idx_bases, idc_divs, scene_args_list_rightup, scene_kwargs_list_rightup = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, closet_rightup, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)\n",
    "test_fun_cl.clear()\n",
    "Q_CUR = snode_schedule_list_rightup[-1][-1].state.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(closet_down, brush_face, robot_config, \n",
    "                                          plane_val=None, tip_dir=\"down\", TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02)\n",
    "\n",
    "HOME_POSE_MOVE = np.copy(Q_CUR[6:])\n",
    "test_fun_cl = TestBaseDivFunc(ppline, floor_ws, closet_down, WP_DIMS, TOOL_DIM, crob.home_dict, tool_dir=-1,\n",
    "                              multiprocess=False)\n",
    "test_fun_cl.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step, \n",
    "    test_fun=test_fun_cl, lazy_base_thresh=np.max(TOOL_DIM)/2)\n",
    "snode_schedule_list_down, idx_bases, idc_divs, scene_args_list_down, scene_kwargs_list_down = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, closet_down, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)\n",
    "test_fun_cl.clear()\n",
    "Q_CUR = snode_schedule_list_rightup[-1][-1].state.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snode_schedule_list = snode_schedule_list_leftup + snode_schedule_list_rightup + snode_schedule_list_down\n",
    "scene_args_list = scene_args_list_leftup + scene_args_list_rightup + scene_args_list_down\n",
    "scene_kwargs_list = scene_kwargs_list_leftup + scene_kwargs_list_rightup + scene_kwargs_list_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Execute closet cleaning sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_APPROACH = 0.4\n",
    "UPDATE_MOTION = False\n",
    "LOOK_ADJUST = True\n",
    "VEL_LEVEL = 1\n",
    "\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        vel_level_bak = indy.get_joint_vel_level()\n",
    "        print(\"vel_level_bak: {}\".format(vel_level_bak))\n",
    "\n",
    "    with indy:\n",
    "        indy.set_joint_vel_level(VEL_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swp_fin_list = []\n",
    "first_approach = True\n",
    "\n",
    "for i_s, (snode_schedule, sargs, skwargs) in enumerate(zip(snode_schedule_list, scene_args_list, scene_kwargs_list)):\n",
    "    print(\"motions: {}\".format(len(snode_schedule[:-1])-1))\n",
    "    set_base_sweep(*sargs, **skwargs)\n",
    "    for snode_pre, snode_nxt in zip(snode_schedule[:-1], snode_schedule[1:]):\n",
    "        snode_pre = snode_pre.copy(pscene)\n",
    "        snode_pre.traj = None\n",
    "        from_state = snode_pre.state\n",
    "        to_state = snode_nxt.state\n",
    "        subjects, ok = pscene.get_changing_subjects(from_state, to_state)\n",
    "        print(subjects)\n",
    "\n",
    "        if len(subjects) ==0 or subjects[0] == \"sweep\":\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "            if CONNECT_INDY:\n",
    "                if UPDATE_MOTION:\n",
    "                    print(\"try update trajectory\")\n",
    "                    traj, state_next, error, succ = \\\n",
    "                            ppline.test_connection(from_state=snode_pre.state, \n",
    "                                                   to_state=snode_nxt.state)\n",
    "                    if succ:\n",
    "                        snode_nxt.traj = traj\n",
    "                        snode_nxt.state = state_next\n",
    "            #         else:\n",
    "            #             raise(RuntimeError(\"Path update fail\"))\n",
    "                ppline.execute_schedule([snode_pre, snode_nxt], one_by_one=True)\n",
    "                with indy:\n",
    "                    time.sleep(0.5)\n",
    "                    indy.wait_for_move_finish()\n",
    "            else:\n",
    "                ppline.play_schedule([snode_pre, snode_nxt])\n",
    "\n",
    "        elif subjects[0] == \"waypoints\":\n",
    "            if CONNECT_MOBILE:\n",
    "                Qmoved = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, from_state.Q, to_state.Q, \n",
    "                                                  D_APPROACH=0)\n",
    "                Qref = to_state.Q\n",
    "                if LOOK_ADJUST and first_approach:\n",
    "                    first_approach = False\n",
    "                    ################ Look & adjust ######################\n",
    "                    target_point=closet_leftup.get_tf(Qref)[:3,3]\n",
    "                    traj, succ = get_look_motion(mplan, ROBOT_NAME, Qref, \n",
    "                                                 target_point=target_point,\n",
    "                                                 com_link = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][-3],\n",
    "                                                 view_dir = [0,0,1],timeout = 1)\n",
    "                    traj_rev = np.array(list(reversed(traj)))\n",
    "                    assert succ, \"looking motion failed\"\n",
    "\n",
    "                    Qref[6:] = traj[-1][6:]\n",
    "                    if CONNECT_INDY:\n",
    "                        with indy: # move to look\n",
    "                            crob.move_joint_traj(traj, one_by_one=True)\n",
    "\n",
    "                        # test code here\n",
    "                        if CONNECT_CAM:\n",
    "                            rdict = stream_capture_image(ImageType.CloseView, obj_type=\"closet\", host=CAM_HOST)\n",
    "\n",
    "                        if ENABLE_DETECT:\n",
    "                            closet_vis = gscene.NAME_DICT[\"closet_vis\"]\n",
    "                            Qdict_scan = list2dict(Qref, gscene.joint_names)\n",
    "                            T_bc = viewpoint.get_tf(Qdict_scan)\n",
    "                            T_bs = bed_vis.get_tf(Qdict_scan)\n",
    "                            T_sc = np.matmul(SE3_inv(T_bs), T_bc)\n",
    "                            T_bs_closet = closet_vis.get_tf(Qdict_scan)\n",
    "                            bed_dims = bed_mat.dims\n",
    "                            floor_margin = 0.1\n",
    "\n",
    "                            T_toff_closet = np.identity(4)\n",
    "                            T_toff_closet[:3,:3] = np.array([[1,0,0],[0,0,1],[0,-1,0]])\n",
    "                            T_toff_closet[:3,3] = np.array([0.3,0,0.2725])\n",
    "\n",
    "                            T_cs_closet = np.matmul(SE3_inv(T_bc), T_bs_closet)\n",
    "\n",
    "                            ICP_result_top_table_close, pcd = reprocess_top_table_detection(T_sc, T_cs_closet, bed_dims, T_toff_closet, visualize=False)\n",
    "\n",
    "                            T_toff_top_table = np.identity(4)\n",
    "                            T_toff_top_table[:3,:3] = np.array([[1,0,0],[0,0,1],[0,-1,0]])\n",
    "                            T_toff_top_table[:3,3] = np.array([0.3,0,0.2725])\n",
    "\n",
    "                            T_co_close = np.matmul(ICP_result_top_table_close, T_toff_top_table)\n",
    "                            T_bc = viewpoint.get_tf(Qdict_scan)\n",
    "                            T_bo_close = np.matmul(T_bc, T_co_close)\n",
    "\n",
    "                            T_bo_new = align_z(T_bo_close)\n",
    "\n",
    "                            # calculate transform based on obtained points\n",
    "                            pcd_center_prev = pcd.get_center()\n",
    "                            pcd_center_transformed_prev = np.matmul(T_bc[:3,:3], pcd_center_prev).transpose() + T_bc[:3,3]\n",
    "\n",
    "                            T_bo_p = np.identity(4)\n",
    "                            T_bo_p[:3,:3] = T_bo_close[:3,:3]\n",
    "                            T_bo_p[:3,3] = pcd_center_transformed_prev\n",
    "\n",
    "                            T_pooc = np.matmul(SE3_inv(T_bo_p), T_bo_close)\n",
    "                            T_bo_p[:3,:3] = Rot_axis(3, Rot2axis(T_bo_close[:3,:3], 3))\n",
    "                            T_bo_c_fix = np.matmul(T_bo_p, T_pooc)\n",
    "                            T_bo_c_fix[2,3] = 0\n",
    "\n",
    "                            # get Twoff from redetection\n",
    "                            Tbo0 = T_bs_closet\n",
    "                            Tbo1 = T_bo_c_fix\n",
    "\n",
    "                            Tbw0 = wayframer.get_tf_handle(list2dict(Qref, gscene.joint_names))\n",
    "                            Tow = np.matmul(SE3_inv(Tbo0), Tbw0)\n",
    "                            Tbw1 = np.matmul(Tbo1, Tow)\n",
    "\n",
    "                            Qtar = np.copy(Qref)\n",
    "                            Qtar[:2] = Tbw1[:2,3]\n",
    "                            Qtar[2] = Rot2axis(Tbw1[:3,:3], 3)\n",
    "\n",
    "                        if CONNECT_MOBILE:\n",
    "                            Qmoved = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, \n",
    "                                                              Qmoved, Qtar, D_APPROACH=0)\n",
    "                            gscene.show_pose(Qref)\n",
    "\n",
    "                        with indy: # retrieve motion\n",
    "                            crob.move_joint_traj(traj_rev, one_by_one=True)\n",
    "\n",
    "                    else:\n",
    "                        gscene.show_motion(traj)\n",
    "                        time.sleep(1)\n",
    "                        gscene.show_motion(traj_rev)\n",
    "                    ################ Look & adjust ######################\n",
    "#                 if UPDATE_MOTION: to_state.Q[:6] = Qmoved[:6]\n",
    "            else:\n",
    "                ppline.play_schedule([snode_pre, snode_nxt])\n",
    "        else:\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "    # leave highlight on cleared area\n",
    "    swp_fin = gscene.copy_from(gscene.NAME_DICT[\"sweep\"], new_name=\"sweep_fin_{}\".format(i_s), color=(0,0,1,0.5))\n",
    "    swp_fin.dims = (swp_fin.dims[0], swp_fin.dims[1], swp_fin.dims[2]+0.002)\n",
    "    gscene.update_marker(swp_fin)\n",
    "    swp_fin_list.append(swp_fin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Clear highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fun_cl.clear()\n",
    "for swp_fin in swp_fin_list:\n",
    "    gscene.remove(swp_fin)\n",
    "swp_fin_list = []\n",
    "pscene.clear_subjects()\n",
    "for child in copy.copy(closet_leftup.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])\n",
    "for child in copy.copy(closet_rightup.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])\n",
    "for child in copy.copy(closet_down.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bed cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Make bed cleaning plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 get division-base pose combination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.constraint.constraint_common import *\n",
    "from pkg.planning.constraint.constraint_actor import *\n",
    "from pkg.planning.constraint.constraint_subject import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wp_task, wp_hdl = add_waypoint_task(pscene, \"waypoint\", WP_DIMS, (0,0,0), (0,0,0), \n",
    "                                    parent=\"floor_ws\", color=(0, 0, 1, 0.5))\n",
    "BED_OFFSET = 0.10\n",
    "brush_face = pscene.create_binder(bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "                                  point=(0,0,-gscene.NAME_DICT['brush_face'].dims[2]/2-CLEARANCE-BED_OFFSET), \n",
    "                                  rpy=(0,0,0))\n",
    "\n",
    "T_e_brush = brush_face.get_tf_handle(crob.home_dict, from_link=TIP_LINK)\n",
    "T_brush_e = SE3_inv(T_e_brush)\n",
    "EE_HEIGHT = round(bed_mat.get_tf(HOME_DICT)[2,3] + bed_mat.dims[2]/2, 5) \\\n",
    "                + T_brush_e[2, 3] - INDY_BASE_OFFSET[2]\n",
    "ccheck.clear()\n",
    "div_base_dict, Tsm_keys, surface_div_centers, div_num, (ax_step, ax_swp, ax_pln) = \\\n",
    "                        get_division_dict(bed_mat, brush_face, robot_config, \n",
    "                                          plane_val=EE_HEIGHT, tip_dir=SweepDirections.front.name, TOOL_DIM=TOOL_DIM, \n",
    "                                          ccheck=ccheck, resolution=0.02, \n",
    "                                          sweep_margin=0.0, xout_cut=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 select base poses and generate motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HOME_POSE_MOVE = Q_CUR[6:]\n",
    "HOME_POSE_SWEEP = np.copy(Q_CUR)\n",
    "HOME_POSE_SWEEP[6:] = [0]*6\n",
    "crob.home_pose = HOME_POSE_SWEEP\n",
    "crob.home_dict = list2dict(crob.home_pose, gscene.joint_names)\n",
    "floor_ws = gscene.NAME_DICT[\"floor_ws\"]    \n",
    "test_fun = TestBaseDivFunc(ppline, floor_ws, bed_mat, WP_DIMS, TOOL_DIM, crob.home_dict, multiprocess=False)\n",
    "#                           , show_motion=True, timeout_loop=30, verbose=True)\n",
    "\n",
    "test_fun.clear()\n",
    "\n",
    "idx_bases, idc_divs, covered_all, snode_schedule_list = select_max_cover_bases(\n",
    "    div_base_dict, Tsm_keys, surface_div_centers, div_num, ax_step,\n",
    "    test_fun=test_fun, lazy_base_thresh=np.max(TOOL_DIM)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 refine motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HOME_POSE_SWEEP[6:] = HOME_POSE_MOVE\n",
    "gscene.show_pose(HOME_POSE_SWEEP)\n",
    "snode_schedule_list, idx_bases, idc_divs, scene_args_list, scene_kwargs_list = refine_order_plan(\n",
    "    ppline, snode_schedule_list, idx_bases, idc_divs, Q_CUR, \n",
    "    floor_ws, wayframer, bed_mat, Tsm_keys, surface_div_centers,  \n",
    "    WP_DIMS, TOOL_DIM, ROBOT_NAME, MOBILE_NAME, HOME_POSE_MOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Execute bed cleaning sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_APPROACH = 0.4\n",
    "UPDATE_MOTION = False\n",
    "LOOK_ADJUST = True\n",
    "VEL_LEVEL = 1\n",
    "\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        vel_level_bak = indy.get_joint_vel_level()\n",
    "        print(\"vel_level_bak: {}\".format(vel_level_bak))\n",
    "\n",
    "    with indy:\n",
    "        indy.set_joint_vel_level(VEL_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "swp_fin_list = []\n",
    "\n",
    "for i_s, (snode_schedule, sargs, skwargs) in enumerate(zip(snode_schedule_list, scene_args_list, scene_kwargs_list)):\n",
    "    print(\"motions: {}\".format(len(snode_schedule[:-1])-1))\n",
    "    set_base_sweep(*sargs, **skwargs)\n",
    "    for snode_pre, snode_nxt in zip(snode_schedule[:-1], snode_schedule[1:]):\n",
    "        snode_pre = snode_pre.copy(pscene)\n",
    "        snode_pre.traj = None\n",
    "        from_state = snode_pre.state\n",
    "        to_state = snode_nxt.state\n",
    "        subjects, ok = pscene.get_changing_subjects(from_state, to_state)\n",
    "        print(subjects)\n",
    "\n",
    "        if len(subjects) ==0 or subjects[0] == \"sweep\":\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "            if CONNECT_INDY:\n",
    "                if UPDATE_MOTION:\n",
    "                    print(\"try update trajectory\")\n",
    "                    traj, state_next, error, succ = \\\n",
    "                            ppline.test_connection(from_state=snode_pre.state, \n",
    "                                                   to_state=snode_nxt.state)\n",
    "                    if succ:\n",
    "                        snode_nxt.traj = traj\n",
    "                        snode_nxt.state = state_next\n",
    "            #         else:\n",
    "            #             raise(RuntimeError(\"Path update fail\"))\n",
    "                ppline.execute_schedule([snode_pre, snode_nxt], one_by_one=True)\n",
    "                with indy:\n",
    "                    time.sleep(0.5)\n",
    "                    indy.wait_for_move_finish()\n",
    "            else:\n",
    "                ppline.play_schedule([snode_pre, snode_nxt])\n",
    "\n",
    "        elif subjects[0] == \"waypoints\":\n",
    "            gscene.show_motion(snode_nxt.traj)\n",
    "            if CONNECT_MOBILE:\n",
    "                Qmoved = move_mobile_update_state(sock_mobile, MOBILE_IP, wayframer, from_state.Q, to_state.Q, \n",
    "                                                  D_APPROACH=D_APPROACH)\n",
    "                \n",
    "                if LOOK_ADJUST:\n",
    "                    raise(RuntimeError(\"Look adjust here\"))\n",
    "                \n",
    "                if UPDATE_MOTION: to_state.Q = Qmoved\n",
    "        else:\n",
    "            to_state.Q[:6] = from_state.Q[:6]\n",
    "    # leave highlight on cleared area\n",
    "    swp_fin = gscene.copy_from(gscene.NAME_DICT[\"sweep\"], new_name=\"sweep_fin_{}\".format(i_s), color=(0,0,1,0.5))\n",
    "    swp_fin.dims = (swp_fin.dims[0], swp_fin.dims[1], swp_fin.dims[2]+0.002)\n",
    "    gscene.update_marker(swp_fin)\n",
    "    swp_fin_list.append(swp_fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Clear highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fun.clear()\n",
    "for swp_fin in swp_fin_list:\n",
    "    gscene.remove(swp_fin)\n",
    "swp_fin_list = []\n",
    "pscene.clear_subjects()\n",
    "for child in copy.copy(bed_mat.children):\n",
    "    gscene.remove(gscene.NAME_DICT[child])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
