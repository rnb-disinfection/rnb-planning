{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Script for testing new platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Prepare task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 prepare planning scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-collected sweep data\n",
    "* Get sweep data files from https://github.com/rnb-disinfection/arxiv-highcap/tree/rnb-planning/data and put them in *$RNB_PLANNING_DIR/data* folder.\n",
    "\n",
    "#### (Optional) To keep shared detector running, run shared detector on bash\n",
    "```bash\n",
    "python3 /home/kiro-ros/Projects/rnb-planning/src/scripts/demo_202107/demo_utils/shared_detector.py\n",
    "```\n",
    "\n",
    "#### Check and request ip setting from mobile udp client (robot-side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.1 Set parameters and create planning scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PC IP: 192.168.0.10\n",
      "Mobile ROB IP: 192.168.0.102\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "CONNECT_CAM = False\n",
    "CONNECT_INDY = False\n",
    "CONNECT_MOBILE = False\n",
    "\n",
    "CONNECT_TASK_PLANNER = False\n",
    "VISUALIZE = False\n",
    "VERBOSE = False\n",
    "PLANNING_MULTIPROC = True\n",
    "N_AGENTS = 10\n",
    "NODE_TRIAL_MAX = N_AGENTS * 2\n",
    "MAX_SOL_NUM = 5\n",
    "BASE_COST_CUT = 110\n",
    "\n",
    "TIMEOUT_MOTION = 0.5\n",
    "TIMEOUT_FULL = 5\n",
    "\n",
    "ROS_MASTER_ON_MOBILE = False\n",
    "# Tool dimensions\n",
    "TOOL_DIM = [0.15, 0.32]\n",
    "TOOL_THICKNESS = 0.05\n",
    "MARGIN = 0\n",
    "TRACK_THICKNESS = 0.001\n",
    "\n",
    "# INDY_BASE_OFFSET = (0.172,0,0.439)\n",
    "INDY_BASE_OFFSET = (0.216,0,0.496)\n",
    "INDY_BASE_RPY = (0,0,0)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "\n",
    "COL_COLOR = (1,1,1,0.2)\n",
    "\n",
    "IP_CUR = \"192.168.0.10\"# get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "INDY_IP = \"192.168.0.3\"\n",
    "\n",
    "print(\"Current PC IP: {}\".format(IP_CUR))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_TASK_PLANNER:\n",
    "    from demo_proto.DisinfectionOperationServicer import serve_on_thread\n",
    "    servicer = serve_on_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "kmb20: True\n",
      "indy1: False\n",
      "\u001b[91m[ERROR] Could not connect to /dev/ttyS10(115200)\u001b[0m\n",
      "\u001b[91m[ERROR] Keep running in OFFLINE MODE\u001b[0m\n",
      "==== Kiro Tool connected to /dev/ttyS10 (115200) ====\n",
      "[KTOOL] initialize\n",
      "[KTOOL] enable\n",
      "[KTOOL] op_init\n",
      "[KTOOL] led_off\n",
      "Unable to register with master node [http://localhost:11311]: master may not be running yet. Will keep trying.\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libmoveit_robot_model_loader.so.1.0.9: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8c0d34582aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Set planner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmotion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveit_planner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMoveitPlanner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiltering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrasp_filter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraspChecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m mplan = MoveitPlanner(pscene, enable_dual=False, \n",
      "\u001b[0;32m/home/jhkim/Projects/rnb-planning/src/pkg/planning/motion/moveit/moveit_planner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmoveit_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMoveitCompactPlanner_BP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObjectType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObjectMPC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mGeometry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeometryList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCartPose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVec3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_assign_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJointState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMotionInterface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist2dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotation_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSE3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSE3_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRot_rpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT2xyzquat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jhkim/Projects/rnb-planning/src/pkg/planning/motion/moveit/moveit_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RNB_PLANNING_DIR\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lib/moveit_interface_py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmoveit_interface_py\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libmoveit_robot_model_loader.so.1.0.9: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/demo_202107'))\n",
    "\n",
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from demo_utils.area_select import *\n",
    "from pkg.detector.aruco.marker_config import get_aruco_map\n",
    "aruco_map = get_aruco_map()\n",
    "\n",
    "from pkg.detector.multiICP.multiICP import *\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "from pkg.detector.multiICP.config import *\n",
    "\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from demo_utils.environment import *\n",
    "# from demo_utils.area_select import DATASET_DIR, SweepDirections\n",
    "from demo_utils.area_select import SweepDirections\n",
    "from demo_utils.demo_config import *\n",
    "from demo_utils.detection_util import *\n",
    "\n",
    "from pkg.utils.shared_function import *\n",
    "clear_channels_on(\"kiromobilemap\")\n",
    "\n",
    "if not CONNECT_INDY:\n",
    "    indy_7dof_client.kiro_tool.KIRO_TOOL_PORT = '/dev/ttyS10'\n",
    "kiro_udp_client.KIRO_UDP_OFFLINE_DEBUG = not CONNECT_MOBILE\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.kmb2, ((0,0,0), (0,0,0)),\n",
    "                \"{}/{}\".format(MOBILE_IP, IP_CUR))\n",
    "robot_config = RobotConfig(1, RobotType.indy7kiro, \n",
    "                           (INDY_BASE_OFFSET, INDY_BASE_RPY),\n",
    "                INDY_IP, root_on=\"kmb20_platform\")\n",
    "ROBOT_TYPE = robot_config.type\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[True, CONNECT_INDY])\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "SceneBuilder.autostart_roscore = not ROS_MASTER_ON_MOBILE\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "\n",
    "gtems = s_builder.add_robot_geometries(\n",
    "    color=COL_COLOR, display=True, collision=True)\n",
    "gscene.set_workspace_boundary(\n",
    "    -4, 12, -7, 5, -CLEARANCE, 3, thickness=WALL_THICKNESS)\n",
    "\n",
    "\n",
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "ROBOT_BASE = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][0]\n",
    "TIP_LINK = pscene.robot_chain_dict[ROBOT_NAME][\"tip_link\"]\n",
    "CAM_LINK = TIP_LINK.replace(\"tcp\", \"link6\")\n",
    "MOBILE_BASE = pscene.robot_chain_dict[MOBILE_NAME][\"tip_link\"]\n",
    "HOLD_LINK = MOBILE_BASE\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=CAM_LINK, center=(-0.0785, 0, 0.073))\n",
    "\n",
    "add_brush(gscene, face_name=TOOL_NAME, tool_link=TIP_LINK,\n",
    "          thickness=TOOL_THICKNESS, tool_dim=TOOL_DIM,\n",
    "          col_color=COL_COLOR)\n",
    "\n",
    "HOME_POSE = crob.home_pose\n",
    "HOME_DICT = list2dict(HOME_POSE, gscene.joint_names)\n",
    "\n",
    "from pkg.planning.pipeline import PlanningPipeline\n",
    "ppline = PlanningPipeline(pscene)\n",
    "\n",
    "# Set planner\n",
    "from pkg.planning.motion.moveit.moveit_planner import MoveitPlanner\n",
    "from pkg.planning.filtering.grasp_filter import GraspChecker\n",
    "mplan = MoveitPlanner(pscene, enable_dual=False, \n",
    "                      incremental_constraint_motion=True)\n",
    "mplan.motion_filters = [GraspChecker(pscene)]\n",
    "mplan.update_gscene()\n",
    "gcheck = GraspChecker(pscene)\n",
    "mplan.motion_filters = [gcheck]\n",
    "\n",
    "mplan.reset_PRQdict(enable_PRQ=0.5, radii=5e-2)\n",
    "for tip_dir, SWEEP_AXIS in [\n",
    "    (SweepDirections.front, \"X\"), (SweepDirections.up, \"Z\"), (SweepDirections.down, \"Z\")]:\n",
    "    filename = SweepDirections.get_file_name(ROBOT_TYPE, tip_dir.name+SWEEP_AXIS)+\"-PRQ.pkl\"\n",
    "    PRQ_PATH = os.path.join(SWEEP_DATA_DIR, filename)\n",
    "    try:\n",
    "        Pos_Rotvec_Qlist_dict = load_pickle(PRQ_PATH)\n",
    "        mplan.register_PRQ(ROBOT_NAME, Pos_Rotvec_Qlist_dict, decimal=2)\n",
    "        print(\"Loaded: {}\".format(filename))\n",
    "    except:\n",
    "        print(\"File not exist: {}\".format(filename))\n",
    "        continue\n",
    "\n",
    "from pkg.planning.task.rrt import TaskRRT\n",
    "tplan = TaskRRT(pscene, node_trial_max=NODE_TRIAL_MAX)\n",
    "tplan.prepare()\n",
    "ppline.set_motion_planner(mplan)\n",
    "ppline.set_task_planner(tplan)\n",
    "\n",
    "# Register binders\n",
    "from pkg.planning.constraint.constraint_actor import VacuumTool, \\\n",
    "    Gripper2Tool, PlacePlane, SweepFramer\n",
    "\n",
    "brush_face = pscene.create_binder(\n",
    "    bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "    point=(0,0, -gscene.NAME_DICT['brush_face'].dims[2]/2-CLEARANCE), \n",
    "    rpy=(0,0,0))\n",
    "\n",
    "gscene.create_safe(\n",
    "    gtype=GEOTYPE.BOX, name=\"floor_box\", link_name=\"base_link\",\n",
    "    dims=(15,15,0.4), center=(0,0,0), rpy=(0,0,0), \n",
    "    color=(1, 1, 1, 0.1), display=True, collision=False, fixed=True)\n",
    "\n",
    "gscene.add_highlight_axis(\"hl\", \"base_coord\", T=np.identity(4), dims=(0.5,0.1,0.1))\n",
    "\n",
    "kmb = crob.robot_dict[\"kmb0\"]\n",
    "indy = crob.robot_dict[\"indy1\"]\n",
    "mobile_box = gscene.NAME_DICT['kmb0_platform_Box_2']\n",
    "crob.simulator.set_gscene(gscene)\n",
    "\n",
    "if CONNECT_MOBILE:\n",
    "    assert np.sum(np.abs(get_xyzw_cur()))>1e-4, \"UDP Server not connected\"\n",
    "    \n",
    "if CONNECT_CAM:\n",
    "    realsense = RealSense()\n",
    "\n",
    "from demo_utils.data_reconstructed_camera import DataRecontructedCamera\n",
    "dcam = DataRecontructedCamera(crob, viewpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.ui.ui_broker import *\n",
    "\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(ppline, s_builder)\n",
    "ui_broker.start_server()\n",
    "\n",
    "ui_broker.set_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [DataRecon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_utils.data_reconstructed_camera import DataRecontructedCamera\n",
    "dcam = DataRecontructedCamera(crob, viewpoint)\n",
    "\n",
    "if not CONNECT_CAM:\n",
    "    dcam.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.2 Load environment map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_utils.ros_map_utils import KiroMobileMap\n",
    "kmm = KiroMobileMap(MOBILE_IP, IP_CUR, CONNECT_MOBILE)\n",
    "            \n",
    "VALID_BOX_SCALE = 0.8\n",
    "VALID_SCORE_CUT = 50\n",
    "kmb.coster = (lambda Q: \n",
    "                  np.max(\n",
    "                      kmm.get_box_costs(mobile_box, Q, kmm.T_bi, kmm.cost_im, kmm.resolution, \n",
    "                                        scale=VALID_BOX_SCALE)))\n",
    "kmb.cost_cut = VALID_SCORE_CUT\n",
    "kmb.gscene = gscene\n",
    "\n",
    "kmm.init_node(timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pole_pt_list, pole_res = kmm.update_map(gscene, crob, MOBILE_BASE, timeout=100)\n",
    "if not CONNECT_MOBILE:\n",
    "    crob.joint_move_make_sure(kmm.Q_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Wait task start queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Detect bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_CAM:\n",
    "    micp = MultiICP(realsense)\n",
    "    micp.initialize()\n",
    "    dcam.ready_saving(*realsense.get_config())\n",
    "    cam_pose = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "else:\n",
    "    micp = MultiICP(dcam)\n",
    "    micp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "# clear_channels_on(\"SharedDetector\")\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "sd.init()\n",
    "    \n",
    "obj_info_dict = get_obj_info()\n",
    "micp_bed = MultiICP_Obj(obj_info_dict[\"bed\"], None,\n",
    "                        OffsetOnModelCoord(\"bed\", R=Rot_axis(1, np.pi*5/8),\n",
    "                                          offset=(0, 0.5, 0.7)))\n",
    "\n",
    "mrule_closet = MaskBoxRule(\"closet\", \"bed\", merge_rule=np.all)\n",
    "mrule_closet.update_rule = ClosetRuleFun(mrule_closet)\n",
    "micp_closet = MultiICP_Obj(obj_info_dict[\"closet\"], \n",
    "                           mrule_closet,\n",
    "                           OffsetOnModelCoord(\"closet\", \n",
    "                                             offset=(0, 1, 0.3),\n",
    "                                             use_median=True\n",
    "                                     ))\n",
    "micp_dict = {\"bed\": micp_bed, \"closet\": micp_closet}\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_TASK_PLANNER:\n",
    "    while servicer.object_info_running.object_id < 0:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Move to bed-seek pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_CUR = crob.get_real_robot_pose()\n",
    "\n",
    "VIEW_POSE = crob.home_pose[6:]\n",
    "VIEW_LOC = list(Q_CUR[:6])\n",
    "VIEW_POSE_EXT = np.array(VIEW_LOC + list(VIEW_POSE))\n",
    "crob.joint_move_make_sure(VIEW_POSE_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_dir = 1\n",
    "Q0 = np.rad2deg(VIEW_POSE_EXT[6:])\n",
    "dQ = np.zeros(6)\n",
    "while True:\n",
    "    # Take a picture again after rotate\n",
    "    color_img, depth_img, VIEW_POSE_EXT = micp.get_image()\n",
    "    cam_mtx, discoeffs, d_scale = micp.get_camera_config()\n",
    "    if CONNECT_CAM:\n",
    "        dcam.save_scene(color, depth, \n",
    "                        viewpoint.get_tf(crob.get_real_robot_pose()))\n",
    "        \n",
    "\n",
    "    cdp = ColorDepthMap(color_img, depth_img, \n",
    "                        cammat2intrins(micp.config_list[0], micp.img_dim), \n",
    "                        micp.config_list[2])\n",
    "    \n",
    "    # Output of inference(mask for detected table)\n",
    "    mask_out = micp.inference(color_img=color_img)[class_dict[\"bed\"]]\n",
    "    mask_out = np.array(mask_out==1, dtype=np.int8)\n",
    "    cv2.imwrite(os.path.join(SAVE_DIR, \"mask_bed.png\"), mask_out)\n",
    "        \n",
    "    if np.any(mask_out):\n",
    "        cdp_masked = apply_mask(cdp, mask_out)\n",
    "        plt.imshow(cdp_masked.color[:,:,[2,1,0]])\n",
    "        break\n",
    "    turn_dir *= -1\n",
    "    dQ = np.add(dQ, [5,0,0,0,0,0])\n",
    "    Qto = Q0+turn_dir*dQ\n",
    "    Qto[0] = (Qto[0]+180/2)%180-180/2\n",
    "    indy.joint_move_make_sure(np.deg2rad(Qto))\n",
    "    VIEW_POSE_EXT[6:] = indy.get_qcur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2  detect bed and add to the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.utils import *\n",
    "gtimer = GlobalTimer.instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE = False\n",
    "T_bc = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "if np.any(mask_out):\n",
    "    if not CONNECT_CAM:\n",
    "        micp.cache_sensor(cdp.color, cdp.depth, VIEW_POSE_EXT)\n",
    "    pose_dict = micp.detect(name_mask = ['bed'], visualize=VISUALIZE)\n",
    "    if CONNECT_CAM:\n",
    "        save_last_input(micp, dcam, viewpoint)\n",
    "    T_bo_bed = pose_dict[\"bed\"]\n",
    "else:\n",
    "    raise(RuntimeError(\"BED NOT DETECTED\"))\n",
    "\n",
    "T_bo_new = fit_floor(align_z(T_bo_bed))\n",
    "bed_center = T_bo_new[:3,3]\n",
    "bed_rpy = Rot2rpy(T_bo_new[:3,:3])\n",
    "\n",
    "# match direction\n",
    "Tbm = gscene.get_tf(MOBILE_BASE, VIEW_POSE_EXT)\n",
    "Tmo = np.matmul(SE3_inv(Tbm), T_bo_new)\n",
    "if Tmo[0,0] > 0:\n",
    "    bed_rpy[2] += np.pi\n",
    "\n",
    "bed_mat = add_bed(gscene, bed_center, bed_rpy, (0,1,0,0.3))\n",
    "\n",
    "bed_vis = gscene.NAME_DICT[\"bed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Detect Closet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1  move to full view position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calc full view pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_MOVED = np.deg2rad([  0., 60.,  -60.,  -0.,  -100., 0, 0])\n",
    "VIEW_POSE_EXT[crob.idx_dict[ROBOT_NAME]] = VIEW_MOVED\n",
    "\n",
    "bed_vis = gscene.NAME_DICT[\"bed\"]\n",
    "T_bo = bed_vis.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "\n",
    "h_fov_hf = np.arctan2(cdp.intrins[0], 2*cdp.intrins[2])\n",
    "# Determine the location of closet\n",
    "CLOSET_LOCATION = check_location_top_table(\n",
    "    cdp2pcd(cdp), cdp2pcd(cdp_masked), T_bc, T_bo, \n",
    "    bed_dims=bed_mat.dims, visualize=False)\n",
    "print(\"CLOSET on {}\".format(CLOSET_LOCATION))\n",
    "    \n",
    "if CLOSET_LOCATION == \"LEFT\":\n",
    "    angle_refs = [150]\n",
    "elif CLOSET_LOCATION == \"RIGHT\":       \n",
    "    angle_refs = [-150]\n",
    "    \n",
    "bed_dim = np.linalg.norm(bed_mat.dims)\n",
    "x_z_ratio = np.tan(h_fov_hf)\n",
    "bed_dist = (bed_dim/2) / x_z_ratio * 1.5\n",
    "for angle_ref in angle_refs:\n",
    "    for _ in range(100):\n",
    "        angle_view = angle_ref + np.random.uniform(-10, 10)\n",
    "        dist_view = bed_dist + np.random.uniform(-1, 1)*bed_dist/4\n",
    "        Tbs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "        Tbs = np.matmul(Tbs, \n",
    "                        SE3(np.identity(3), (-bed_mat.dims[0]/2, 0,0)))\n",
    "        Tsc = np.matmul(SE3(Rot_axis(3, np.deg2rad(angle_view)), (0,)*3), \n",
    "                        SE3(np.identity(3), (-dist_view, 0,0)))\n",
    "        Tbc = np.matmul(Tbs, Tsc)\n",
    "        Tmc = viewpoint.get_tf(VIEW_POSE_EXT, from_link=MOBILE_BASE)\n",
    "        Tmc[:3,:3] = np.identity(3)\n",
    "        Tbm = np.matmul(Tbc, SE3_inv(Tmc))\n",
    "        full_view_ext = np.copy(VIEW_POSE_EXT)\n",
    "        full_view_ext[:2] = Tbm[:2,3]\n",
    "        full_view_ext[2] = Rot2axis(Tbm[:3, :3], 3)\n",
    "        gscene.show_pose(full_view_ext)\n",
    "        res = kmb.check_valid(full_view_ext[:6])\n",
    "        if res:\n",
    "            VIEW_MOVED_EXT = full_view_ext\n",
    "            print(\"Full view loc: {}\".format(np.round(VIEW_MOVED_EXT[:3], 2)))\n",
    "            break\n",
    "    if res:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### move to full view pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crob.joint_move_make_sure(VIEW_MOVED_EXT)\n",
    "print(\"VIEW_MOVED_EXT: {}\".format(\n",
    "    np.round(VIEW_MOVED_EXT, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 detect bed and closet together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "object_pose_dict = micp.detect(visualize=VISUALIZE)\n",
    "if CONNECT_CAM:\n",
    "    save_last_input(micp, dcam, viewpoint)\n",
    "    \n",
    "T_bc = viewpoint.get_tf(micp.last_input[2])\n",
    "T_bo_bed = fit_floor(align_z(object_pose_dict['bed']))\n",
    "move_bed(gscene, T_bo_bed[:3,3], Rot2rpy(T_bo_bed[:3,:3]))\n",
    "\n",
    "T_bo_cl = fit_vertical(T_bc, object_pose_dict['closet'], micp_closet.pcd)\n",
    "closet_leftup, closet_rightup, closet_down = add_closet(\n",
    "    gscene, closet_center=T_bo_cl[:3,3], closet_rpy=Rot2rpy(T_bo_cl[:3,:3]), \n",
    "    COLOR_CLOSET_COL=(0,1,0,0.3))\n",
    "\n",
    "add_backwall(gscene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set collision map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_pt_list = kmm.remove_poles_by_box(gscene, gscene.NAME_DICT[\"bed_box\"], \n",
    "                    pole_pt_list, VIEW_POSE_EXT)\n",
    "pole_pt_list = kmm.remove_poles_by_box(gscene, gscene.NAME_DICT[\"closet_box\"], \n",
    "                    pole_pt_list, VIEW_POSE_EXT)\n",
    "pole_pt_list = kmm.remove_poles_by_box(gscene, gscene.NAME_DICT[\"room_box\"], \n",
    "                    pole_pt_list, VIEW_POSE_EXT, inside=False)\n",
    "pole_list = kmm.add_pixel_poles(\"obs_pt\", gscene, pole_pt_list, pole_res)\n",
    "gcheck.ignore_always = pole_list\n",
    "\n",
    "gscene.update_markers_all() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Test/Remove mismatch in scene data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not CONNECT_CAM:\n",
    "    idc_mis = []\n",
    "    for idx in range(len(dcam.cam_pose_list)):\n",
    "        color, depth = dcam.color_depth_list[idx]\n",
    "        Tbc = dcam.cam_pose_list[idx]\n",
    "        pcd = cdp2pcd(\n",
    "            ColorDepthMap(color, depth, \n",
    "                          cammat2intrins(dcam.cameraMatrix, tuple(reversed(color.shape[:2]))),\n",
    "                          dcam.depth_scale), depth_trunc=10.0)\n",
    "        points_c = np.matmul(pcd.points, Tbc[:3,:3].transpose())+ Tbc[:3,3]\n",
    "        ptem = gscene.show_point_cloud(points_c, \"pcd{:03}\".format(idx), sample_to=1e5, point_size=0.01,\n",
    "                               color=(0,0,1,0.5))\n",
    "        gscene.add_highlight_axis(\"hl\", \"tbc\", T=Tbc, dims=(0.3,0.03,0.03))\n",
    "        cmd = raw_input()\n",
    "        if cmd == 'n':\n",
    "            gscene.remove(ptem)\n",
    "            idc_mis.append(idx)\n",
    "        elif cmd == 'x':\n",
    "            break\n",
    "        else:\n",
    "            print(\"ok\")\n",
    "            gscene.show_point_cloud(points_c, \"pcd{:03}\".format(idx), sample_to=1e5, point_size=0.01,\n",
    "                                   color=(0,1,0,0.5))\n",
    "    print(\"idc to remove: {}\".format(idc_mis))\n",
    "    gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CONNECT_CAM:\n",
    "    idc_remove = [0, 1, 6, 7]\n",
    "    dcam.cam_pose_list = list(dcam.cam_pose_list)\n",
    "    for idx in reversed(idc_remove):\n",
    "        dcam.cam_pose_list.pop(idx)\n",
    "        dcam.color_depth_list.pop(idx)\n",
    "    dcam.cam_pose_list = np.array(dcam.cam_pose_list)\n",
    "\n",
    "    for gname in deepcopy(gscene.NAME_DICT.keys()):\n",
    "        if \"pcd\" in gname:\n",
    "            gscene.remove(gscene.NAME_DICT[gname])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Prepare cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.constraint.constraint_common import *\n",
    "from pkg.planning.constraint.constraint_actor import *\n",
    "from pkg.planning.constraint.constraint_subject import *\n",
    "from pkg.utils.code_scraps import get_look_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mplan.reset_log(flag_log=True)\n",
    "Q_CUR = VIEW_MOVED_EXT\n",
    "HOME_POSE_SWEEP = np.copy(Q_CUR)\n",
    "# HOME_POSE_SWEEP[6:] = 0\n",
    "crob.home_pose = HOME_POSE_SWEEP\n",
    "crob.home_dict = list2dict(crob.home_pose, \n",
    "                           gscene.joint_names)\n",
    "floor_ws = gscene.NAME_DICT[\"floor_ws\"]    \n",
    "\n",
    "VEL_LIMS = 0.2\n",
    "ACC_LIMS = 0.2\n",
    "RADI_DEG = 1\n",
    "\n",
    "if CONNECT_INDY:\n",
    "    indy.QVEL_LEVEL = 3\n",
    "    indy.collision_policy = POLICY_NO_COLLISION_DETECTION\n",
    "    indy.reset()\n",
    "\n",
    "Qcur = VIEW_MOVED_EXT\n",
    "mode_switcher=ModeSwitcherKMB(pscene, push_dist=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_count_list = []\n",
    "THRESH = 0.05\n",
    "def look_closet_get_offset(gxter, crob, mplan, robot_name, Qref):\n",
    "    Qref_in = np.copy(Qref)\n",
    "    Qref = np.copy(Qref)\n",
    "    Qcur = crob.get_real_robot_pose()\n",
    "    for _ in range(5):\n",
    "        traj, succ = get_look_motion(mplan, robot_name, Qcur, \n",
    "                                     target_point=gscene.NAME_DICT[\"closet_leftup\"],\n",
    "                                     com_link=CAM_LINK,\n",
    "                                     cam_link=CAM_LINK,\n",
    "                                     view_dir=[0,0,1],timeout=1)\n",
    "        if succ:\n",
    "            traj = bspline_wps(1./DEFAULT_TRAJ_FREQUENCY, traj, \n",
    "                               VEL_LIMS, ACC_LIMS, radii_deg=RADI_DEG)\n",
    "            traj_rev = np.array(list(reversed(traj)))\n",
    "            break\n",
    "            \n",
    "    if not succ:\n",
    "        look_closet_get_offset.Qref_fail = Qref\n",
    "        raise(RuntimeError(\"Get Look Motion Fail\"))\n",
    "\n",
    "    crob.move_joint_traj(traj, one_by_one=True)\n",
    "    Qref[6:] = traj[-1][6:]\n",
    "\n",
    "    adjust_count_list.append(1)\n",
    "    \n",
    "    T_bo_close = micp.detect(name_mask=[\"closet\"], visualize=VISUALIZE)[\"closet\"]\n",
    "    if CONNECT_CAM:\n",
    "        save_last_input(micp, dcam, viewpoint)\n",
    "    Qview = micp.last_input[2]\n",
    "    T_bc = viewpoint.get_tf(Qview)\n",
    "    T_bs_closet = gscene.NAME_DICT[\"closet\"].get_tf(Qview)\n",
    "\n",
    "    crob.move_joint_traj(traj_rev, one_by_one=True)\n",
    "    Qcur = crob.get_real_robot_pose()\n",
    "    \n",
    "    if VISUALIZE:\n",
    "        ptem1 = gscene.show_point_cloud(\n",
    "            np.matmul(micp_closet.pcd.points, T_bc[:3,:3].T) + T_bc[:3,3],\n",
    "            \"pcd_sens\", color=(0,0,1,0.5))\n",
    "\n",
    "    # calculate transform based on obtained points\n",
    "    T_bo_c_fix = fit_vertical(T_bc, T_bo_close, micp_closet.pcd)\n",
    "\n",
    "    # get Twoff from redetection\n",
    "    Tbo0, Tbo1 = T_bs_closet, T_bo_c_fix\n",
    "    Tbw0 = gscene.get_tf(gxter.mobile_link, Qview)\n",
    "    Tow1 = np.matmul(SE3_inv(Tbo1), Tbw0) # mob from detected obj\n",
    "    Tbw1 = np.matmul(Tbo0, Tow1) # mob from base based on obj\n",
    "    \n",
    "    Qcur[:2] = Tbw1[:2,3]\n",
    "    Qcur[2] = Rot2axis(Tbw1[:3,:3], 3)\n",
    "\n",
    "    Tow0 = np.matmul(SE3_inv(Tbo0), Tbw0) # mob from obj ideal\n",
    "    Tbw1tar = np.matmul(Tbo1, Tow0) # mob target to fix error\n",
    "    Qtar = np.copy(Qcur)\n",
    "    Qtar[:2] = Tbw1tar[:2,3]\n",
    "    Qtar[2] = Rot2axis(Tbw1tar[:3,:3], 3)\n",
    "    \n",
    "    if VISUALIZE:\n",
    "        print(\"Tbo0: {}\".format(np.round(Tbo0, 2)))\n",
    "        print(\"Tbo1: {}\".format(np.round(Tbo1, 2)))\n",
    "        print(\"T_bo_close: {}\".format(np.round(T_bo_close, 2)))\n",
    "        Qview_adj = np.copy(Qview)\n",
    "        Qview_adj[:2] = Tbw1[:2,3]\n",
    "        Qview_adj[2] = Rot2axis(Tbw1[:3,:3], 3)\n",
    "        print(\"Qview: {}\".format(Qview))\n",
    "        print(\"Qview_adj: {}\".format(Qview_adj))\n",
    "        T_bc_adj = viewpoint.get_tf(Qview_adj)\n",
    "        ptem2 = gscene.show_point_cloud(\n",
    "            np.matmul(micp_closet.pcd.points, T_bc_adj[:3,:3].T) + T_bc_adj[:3,3], \n",
    "            \"pcd_adj\", color=(1,0,0,0.5))\n",
    "    \n",
    "#     if not (CONNECT_CAM and CONNECT_MOBILE):\n",
    "#         Qcur = np.copy(Qref_in)\n",
    "#         Qcur[:6] = Qref_in[:6] + np.random.uniform([-0.05, -0.05, -0.05, 0, 0, 0],\n",
    "#                                                      [0.05, 0.05, 0.05, 0, 0, 0])\n",
    "        \n",
    "#         Qtar = np.copy(Qref_in)\n",
    "#         Qtar[:6] = Qref_in[:6] + np.random.uniform([-0.05, -0.05, -0.05, 0, 0, 0],\n",
    "#                                                      [0.05, 0.05, 0.05, 0, 0, 0])\n",
    "    return Qcur, Qtar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bed cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_e_brush = brush_face.get_tf_handle(crob.home_dict, from_link=TIP_LINK)\n",
    "T_brush_e = SE3_inv(T_e_brush)\n",
    "EE_HEIGHT = round(bed_mat.get_tf(HOME_DICT)[2,3] + bed_mat.dims[2]/2, 5) \\\n",
    "                + T_brush_e[2, 3] - INDY_BASE_OFFSET[2]\n",
    "\n",
    "gscene.add_virtual_guardrail(closet_leftup, HEIGHT=0.02, margin=0.05)\n",
    "gscene.add_virtual_guardrail(closet_rightup, HEIGHT=0.02, margin=0.05)\n",
    "gscene.add_virtual_guardrail(closet_down, HEIGHT=0.02, margin=0.05, axis=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX\n",
    "\n",
    "gxter.set_test_kwargs(multiprocess=PLANNING_MULTIPROC, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "covereds_all = []\n",
    "for _ in range(1):\n",
    "    gxter.get_division_dict(bed_mat, \"front\", \"X\", EE_HEIGHT, xout_cut=True)\n",
    "    gxter.init_base_divs(Qcur)\n",
    "    # gxter.mark_tested(None, None, covereds_all, [])\n",
    "    snode_schedule_list_d, Qcur, covereds = gxter.greedy_execute(\n",
    "        Qcur, 1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT, covereds=covereds_all)\n",
    "    covereds_all = sorted(set(covereds_all+covereds))\n",
    "    gxter.test_clear()\n",
    "    len_covered, len_all = len(covereds_all), len(gxter.surface_div_centers)\n",
    "    print(\"########################### TRIAL ONCE DONE ( {} / {} )########################\".format(len_covered, len_all))\n",
    "    if len_covered >= len_all:\n",
    "        break\n",
    "    print(gtimer)\n",
    "gscene.clear_virtuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Closet cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gscene.add_virtual_guardrail(closet_rightup, HEIGHT=0.2, margin=0.15)\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX * 2\n",
    "\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "gxter.set_test_kwargs(multiprocess=PLANNING_MULTIPROC, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION*1.5, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "gxter.get_division_dict(closet_rightup, \"up\", \"Z\", None)\n",
    "gxter.init_base_divs(Qcur)\n",
    "snode_schedule_list_ru, Qcur, covereds = gxter.greedy_execute(\n",
    "    Qcur, 1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT, adjust_once=False)\n",
    "gxter.test_clear()\n",
    "gscene.clear_virtuals()\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gscene.add_virtual_guardrail(closet_leftup, HEIGHT=0.1, margin=0.1)\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX\n",
    "\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "gxter.set_test_kwargs(multiprocess=PLANNING_MULTIPROC, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "gxter.get_division_dict(closet_leftup, \"up\", \"Z\", None)\n",
    "gxter.init_base_divs(Qcur)\n",
    "snode_schedule_list_lu, Qcur, covereds = gxter.greedy_execute(\n",
    "    Qcur, 1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT)\n",
    "gxter.test_clear()\n",
    "gscene.clear_virtuals()\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gscene.add_virtual_guardrail(\n",
    "    closet_down, HEIGHT=0.05, margin=0.1, axis=\"xy\")\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX * 2\n",
    "\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "gxter.set_test_kwargs(multiprocess=PLANNING_MULTIPROC, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION*2, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "gxter.get_division_dict(closet_down, \"down\", \"Z\", None)\n",
    "gxter.init_base_divs(Qcur)\n",
    "snode_schedule_list_d, Qcur, covereds = gxter.greedy_execute(\n",
    "    Qcur, -1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT, \n",
    "    adjust_once=False)\n",
    "gxter.test_clear()\n",
    "gscene.clear_virtuals()\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_TASK_PLANNER:\n",
    "    servicer.mark_task_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MAX_SOL_NUM 적용 v\n",
    "* 위 오른쪽 안닦이는 문제 파악 - guardrail 마진 - v\n",
    "* 아래 닦을 때 위쪽 가운데 바운더리 추가 - v\n",
    "* 침대 닦을 때 옷장 바운더리 마진 추가 - v\n",
    "* 위치 보정, 드리프트 코드 검토 - ok - v\n",
    "* 인디 툴 무게 v\n",
    "* 툴 조인트 플래닝에 추가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjust에서 Qref와 Qcur 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
