{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Script for Milestone 10.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Prepare task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 prepare planning scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run shared detector on bash\n",
    "```bash\n",
    "python3 /home/kiro-ros/Projects/rnb-planning/src/scripts/demo_202107/demo_utils/shared_detector.py\n",
    "```\n",
    "\n",
    "#### Check and request ip setting from mobile udp client (robot-side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.1 Set parameters and create planning scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "CONNECT_CAM = False\n",
    "ENABLE_DETECT = True\n",
    "ENABLE_O3D = True\n",
    "\n",
    "CONNECT_INDY = False\n",
    "CONNECT_MOBILE = False\n",
    "\n",
    "CONNECT_TASK_PLANNER = False\n",
    "VISUALIZE = False\n",
    "VERBOSE = False\n",
    "PLANNING_MULTIPROC = True\n",
    "N_AGENTS = 10\n",
    "NODE_TRIAL_MAX = N_AGENTS * 2\n",
    "MAX_SOL_NUM = 5\n",
    "BASE_COST_CUT = 110\n",
    "\n",
    "TIMEOUT_MOTION = 0.5\n",
    "TIMEOUT_FULL = 5\n",
    "\n",
    "ROS_MASTER_ON_MOBILE = False\n",
    "# Tool dimensions\n",
    "TOOL_DIM = [0.15, 0.32]\n",
    "TOOL_THICKNESS = 0.05\n",
    "MARGIN = 0\n",
    "TRACK_THICKNESS = 0.001\n",
    "\n",
    "INDY_BASE_OFFSET = (0.172,0,0.439)\n",
    "INDY_BASE_RPY = (0,0,0)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "\n",
    "COL_COLOR = (1,1,1,0.2)\n",
    "\n",
    "IP_CUR = \"192.168.0.10\"# get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "INDY_IP = \"192.168.0.3\"\n",
    "\n",
    "print(\"Current PC IP: {}\".format(IP_CUR))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_TASK_PLANNER:\n",
    "    from demo_proto.TaskExecuteServer import serve_on_thread\n",
    "    servicer = serve_on_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.join(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/demo_202107'))\n",
    "\n",
    "from pkg.global_config import RNB_PLANNING_DIR\n",
    "from pkg.utils.utils import *    \n",
    "from pkg.utils.rotation_utils import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from demo_utils.area_select import *\n",
    "from pkg.detector.aruco.marker_config import get_aruco_map\n",
    "aruco_map = get_aruco_map()\n",
    "\n",
    "from pkg.detector.multiICP.multiICP import *\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "from pkg.detector.multiICP.config import *\n",
    "\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from demo_utils.environment import *\n",
    "from demo_utils.area_select import DATASET_DIR, SweepDirections\n",
    "from demo_utils.demo_config import *\n",
    "from demo_utils.detection_util import *\n",
    "\n",
    "from pkg.utils.shared_function import *\n",
    "clear_channels_on(\"kiromobilemap\")\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                \"{}/{}\".format(MOBILE_IP, IP_CUR), \n",
    "                            specs={\"dummy\":not CONNECT_MOBILE})\n",
    "robot_config = RobotConfig(1, RobotType.indy7kiro, \n",
    "                           (INDY_BASE_OFFSET, INDY_BASE_RPY),\n",
    "                INDY_IP, root_on=\"kmb0_platform\", \n",
    "                           specs={\"no_sdk\":True})\n",
    "ROBOT_TYPE = robot_config.type\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[CONNECT_MOBILE, CONNECT_INDY])\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "SceneBuilder.autostart_roscore = not ROS_MASTER_ON_MOBILE\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "\n",
    "gtems = s_builder.add_robot_geometries(\n",
    "    color=COL_COLOR, display=True, collision=True)\n",
    "gscene.set_workspace_boundary(\n",
    "    -4, 12, -7, 5, -CLEARANCE, 3, thickness=WALL_THICKNESS)\n",
    "\n",
    "\n",
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "ROBOT_BASE = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][0]\n",
    "TIP_LINK = pscene.robot_chain_dict[ROBOT_NAME][\"tip_link\"]\n",
    "CAM_LINK = TIP_LINK.replace(\"tcp\", \"link6\")\n",
    "MOBILE_BASE = pscene.robot_chain_dict[MOBILE_NAME][\"tip_link\"]\n",
    "HOLD_LINK = MOBILE_BASE\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=CAM_LINK, center=(-0.0785, 0, 0.073))\n",
    "\n",
    "add_brush(gscene, face_name=TOOL_NAME, tool_link=TIP_LINK,\n",
    "          thickness=TOOL_THICKNESS, tool_dim=TOOL_DIM,\n",
    "          col_color=COL_COLOR)\n",
    "\n",
    "HOME_POSE = crob.home_pose\n",
    "HOME_DICT = list2dict(HOME_POSE, gscene.joint_names)\n",
    "\n",
    "from pkg.planning.pipeline import PlanningPipeline\n",
    "ppline = PlanningPipeline(pscene)\n",
    "\n",
    "# Set planner\n",
    "from pkg.planning.motion.moveit.moveit_planner import MoveitPlanner\n",
    "from pkg.planning.filtering.grasp_filter import GraspChecker\n",
    "mplan = MoveitPlanner(pscene, enable_dual=False, \n",
    "                      incremental_constraint_motion=True)\n",
    "mplan.motion_filters = [GraspChecker(pscene)]\n",
    "mplan.update_gscene()\n",
    "gcheck = GraspChecker(pscene)\n",
    "mplan.motion_filters = [gcheck]\n",
    "\n",
    "mplan.reset_PRQdict(enable_PRQ=0.5, radii=5e-2)\n",
    "for tip_dir, SWEEP_AXIS in [\n",
    "    (SweepDirections.front, \"X\"), (SweepDirections.up, \"Z\"), (SweepDirections.down, \"Z\")]:\n",
    "    filename = SweepDirections.get_file_name(ROBOT_TYPE, tip_dir.name+SWEEP_AXIS)+\"-PRQ.pkl\"\n",
    "    PRQ_PATH = os.path.join(DATASET_DIR, filename)\n",
    "    try:\n",
    "        Pos_Rotvec_Qlist_dict = load_pickle(PRQ_PATH)\n",
    "        mplan.register_PRQ(ROBOT_NAME, Pos_Rotvec_Qlist_dict, decimal=2)\n",
    "        print(\"Loaded: {}\".format(filename))\n",
    "    except:\n",
    "        print(\"File not exist: {}\".format(filename))\n",
    "        continue\n",
    "\n",
    "from pkg.planning.task.rrt import TaskRRT\n",
    "tplan = TaskRRT(pscene, node_trial_max=NODE_TRIAL_MAX)\n",
    "tplan.prepare()\n",
    "ppline.set_motion_planner(mplan)\n",
    "ppline.set_task_planner(tplan)\n",
    "\n",
    "# Register binders\n",
    "from pkg.planning.constraint.constraint_actor import VacuumTool, \\\n",
    "    Gripper2Tool, PlacePlane, SweepFramer\n",
    "\n",
    "brush_face = pscene.create_binder(\n",
    "    bname=TOOL_NAME, gname=TOOL_NAME, _type=SweepFramer, \n",
    "    point=(0,0, -gscene.NAME_DICT['brush_face'].dims[2]/2-CLEARANCE), \n",
    "    rpy=(0,0,0))\n",
    "\n",
    "gscene.create_safe(\n",
    "    gtype=GEOTYPE.BOX, name=\"floor_box\", link_name=\"base_link\",\n",
    "    dims=(15,15,0.4), center=(0,0,0), rpy=(0,0,0), \n",
    "    color=(1, 1, 1, 0.1), display=True, collision=False, fixed=True)\n",
    "\n",
    "gscene.add_highlight_axis(\"hl\", \"base_coord\", T=np.identity(4), dims=(0.5,0.1,0.1))\n",
    "\n",
    "kmb = crob.robot_dict[\"kmb0\"]\n",
    "indy = crob.robot_dict[\"indy1\"]\n",
    "mobile_box = gscene.NAME_DICT['kmb0_platform_Box_2']\n",
    "\n",
    "if CONNECT_MOBILE:\n",
    "    assert np.sum(np.abs(get_xyzw_cur()))>1e-4, \"UDP Server not connected\"\n",
    "    \n",
    "if CONNECT_CAM:\n",
    "    realsense = RealSense()\n",
    "\n",
    "from demo_utils.data_reconstructed_camera import DataRecontructedCamera\n",
    "dcam = DataRecontructedCamera(crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1.2 Load environment map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_utils.ros_map_utils import KiroMobileMap\n",
    "kmm = KiroMobileMap(MOBILE_IP, IP_CUR, CONNECT_MOBILE)\n",
    "            \n",
    "VALID_BOX_SCALE = 0.8\n",
    "VALID_SCORE_CUT = 50\n",
    "kmb.coster = (lambda Q: \n",
    "                  np.max(\n",
    "                      kmm.get_box_costs(mobile_box, Q, kmm.T_bi, kmm.cost_im, kmm.resolution, \n",
    "                                        scale=VALID_BOX_SCALE)))\n",
    "kmb.cost_cut = VALID_SCORE_CUT\n",
    "kmb.gscene = gscene\n",
    "\n",
    "kmm.init_node(timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pole_pt_list, pole_res = kmm.update_map(gscene, crob, MOBILE_BASE, timeout=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detect scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Wait task start queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Detect bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_CAM:\n",
    "    micp = MultiICP(realsense)\n",
    "    micp.initialize()\n",
    "    dcam.ready_saving(*realsense.get_config())\n",
    "    cam_pose = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "else:\n",
    "    micp = MultiICP(dcam)\n",
    "    micp.initialize()\n",
    "    cameraMatrix = np.array([[909.957763671875, 0., 638.3824462890625],\n",
    "                             [0., 909.90283203125, 380.0085144042969],\n",
    "                             [0., 0., 1]])\n",
    "    distCoeffs = np.array([0.]*5)\n",
    "    depth_scale=1 / 3999.999810010204\n",
    "    config_list = [cameraMatrix, distCoeffs, depth_scale]\n",
    "    img_dim = (720, 1280)\n",
    "    micp.initialize(config_list, img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "if ENABLE_DETECT:\n",
    "    sd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_TASK_PLANNER:\n",
    "    while servicer.object_info_running.object_id < 0:\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Move to bed-seek pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_CUR = kmb.get_qcur()\n",
    "\n",
    "VIEW_POSE = crob.home_pose[6:]\n",
    "VIEW_LOC = list(Q_CUR[:6])\n",
    "VIEW_POSE_EXT = np.array(VIEW_LOC + list(VIEW_POSE))\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        indy.joint_move_to(np.rad2deg(VIEW_POSE))\n",
    "        time.sleep(0.5)\n",
    "        indy.wait_for_move_finish()\n",
    "        Qcur = np.deg2rad(indy.get_joint_pos())\n",
    "else:\n",
    "    Qcur = VIEW_POSE\n",
    "gscene.show_pose(VIEW_POSE_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_dir = 1\n",
    "Q0 = np.rad2deg(VIEW_POSE_EXT[6:])\n",
    "dQ = np.zeros(6)\n",
    "while True:\n",
    "    # Take a picture again after rotate\n",
    "    if CONNECT_CAM:\n",
    "#         rdict = camgen.stream_capture_image(obj_type=\"bed\", crob=crob)\n",
    "        color_img, depth_img, VIEW_POSE_EXT = micp.get_image()\n",
    "        cam_mtx, discoeffs, d_scale = micp.get_camera_config()\n",
    "        intrins = [micp.img_dim[1], micp.img_dim[0],\n",
    "                   cam_mtx[0, 0], cam_mtx[1, 1],cam_mtx[0, 2], cam_mtx[1, 2]]\n",
    "        rdict = {'color': color_img,\n",
    "                 'depth': depth_img,\n",
    "                 'intrins': intrins, 'depth_scale': d_scale}\n",
    "    else:\n",
    "        rdict, VIEW_POSE_EXT = load_rdict(\"bed\")\n",
    "        \n",
    "\n",
    "    cdp = rdict2cdp(rdict)\n",
    "        \n",
    "    \n",
    "    if ENABLE_DETECT:\n",
    "        # Output of inference(mask for detected bed)\n",
    "        mask_out_list = sd.inference(color_img=rdict['color'])\n",
    "        mask_out = mask_out_list[class_dict[\"bed\"]]\n",
    "        cv2.imwrite(os.path.join(SAVE_DIR, \"mask_bed.png\"), mask_out)\n",
    "    else:\n",
    "        mask_out = cv2.imread(os.path.join(SAVE_DIR, \"mask_bed.png\"))[:,:,0]\n",
    "        \n",
    "    if np.any(mask_out):\n",
    "        cdp_masked = apply_mask(cdp, mask_out)\n",
    "        plt.imshow(cdp_masked.color[:,:,[2,1,0]])\n",
    "        break\n",
    "    if CONNECT_INDY:\n",
    "        with indy:\n",
    "            turn_dir *= -1\n",
    "            dQ = np.add(dQ, [5,0,0,0,0,0])\n",
    "            Qto = Q0+turn_dir*dQ\n",
    "            Qto[0] = (Qto[0]+180/2)%180-180/2\n",
    "            indy.joint_move_to(Qto)\n",
    "            indy.wait_motion()\n",
    "            VIEW_POSE_EXT[6:] = np.deg2rad(indy.get_joint_pos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2  detect bed and add to the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.utils import *\n",
    "gtimer = GlobalTimer.instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bc = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "T_bc_bed_view = np.copy(T_bc)\n",
    "T_cb = SE3_inv(T_bc)\n",
    "gscene.show_pose(VIEW_POSE_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_info_dict = get_obj_info()\n",
    "micp_bed = MultiICP_Obj(obj_info_dict[\"bed\"], None,\n",
    "                        OffsetOnModelCoord(\"bed\", R=np.matmul(T_cb[:3, :3], Rot_axis(3, np.pi)),\n",
    "                                          offset=np.matmul(T_cb[:3, :3], (1.1 * 0.5, 0, -0.5))))\n",
    "\n",
    "mrule_closet = MaskBoxRule(\"closet\", \"bed\", merge_rule=np.all)\n",
    "mrule_closet.update_rule = ClosetRuleFun(mrule_closet)\n",
    "micp_closet = MultiICP_Obj(obj_info_dict[\"closet\"], \n",
    "                           mrule_closet,\n",
    "                           OffsetOnModelCoord(\"closet\", \n",
    "                                             offset=(0, 1, 0.3),\n",
    "                                             use_median=True\n",
    "                                     ))\n",
    "micp_dict = {\"bed\": micp_bed, \"closet\": micp_closet}\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VISUALIZE = True\n",
    "if ENABLE_O3D:\n",
    "    if np.any(mask_out):\n",
    "        if not CONNECT_CAM:\n",
    "            micp.cache_sensor(cdp.color, cdp.depth, VIEW_POSE_EXT)\n",
    "        pose_dict = micp.detect(name_mask = ['bed'], visualize=VISUALIZE)\n",
    "        T_bo_bed = pose_dict[\"bed\"]\n",
    "    \n",
    "    bed_center = T_bo_bed[:3,3]\n",
    "    T_bo_new = align_z(T_bo_bed)\n",
    "    bed_rpy = Rot2rpy(T_bo_new[:3,:3])\n",
    "\n",
    "    # adjust\n",
    "    bed_center[2]=0\n",
    "    Tbm = gscene.get_tf(MOBILE_BASE, VIEW_POSE_EXT)\n",
    "    Tmo = np.matmul(SE3_inv(Tbm), T_bo_new)\n",
    "    if Tmo[0,0] > 0:\n",
    "        bed_rpy[2] += np.pi\n",
    "\n",
    "    bed_mat = add_bed(gscene, bed_center, bed_rpy, (0,1,0,0.3))\n",
    "    \n",
    "else:\n",
    "    bed_center = (5.1,-0.1,0)\n",
    "    bed_rpy = (0,0,np.pi)\n",
    "    bed_mat = add_bed(gscene, bed_center, bed_rpy, (0,1,0,0.3))\n",
    "\n",
    "bed_vis = gscene.NAME_DICT[\"bed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Detect Closet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1  move to full view position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calc fule view pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_MOVED = np.deg2rad([  0., 60.,  -60.,  -0.,  -100., 0, 0])\n",
    "VIEW_POSE_EXT[crob.idx_dict[ROBOT_NAME]] = VIEW_MOVED\n",
    "\n",
    "bed_vis = gscene.NAME_DICT[\"bed\"]\n",
    "T_bo = bed_vis.get_tf(list2dict(VIEW_POSE_EXT, gscene.joint_names))\n",
    "\n",
    "if ENABLE_O3D:\n",
    "    h_fov_hf = np.arctan2(cdp.intrins[0], 2*cdp.intrins[2])\n",
    "    # Determine the location of closet\n",
    "    CLOSET_LOCATION = check_location_top_table(\n",
    "        cdp2pcd(cdp), cdp2pcd(cdp_masked), T_bc, T_bo, \n",
    "        bed_dims=bed_mat.dims, visualize=False)\n",
    "    print(\"CLOSET on {}\".format(CLOSET_LOCATION))\n",
    "else:\n",
    "    h_fov_hf = np.pi/4\n",
    "    CLOSET_LOCATION = \"LEFT\"\n",
    "    \n",
    "if CLOSET_LOCATION == \"LEFT\":\n",
    "    angle_refs = [150]\n",
    "elif CLOSET_LOCATION == \"RIGHT\":       \n",
    "    angle_refs = [-150]\n",
    "    \n",
    "bed_dim = np.linalg.norm(bed_mat.dims)\n",
    "x_z_ratio = np.tan(h_fov_hf)\n",
    "bed_dist = (bed_dim/2) / x_z_ratio * 3\n",
    "for angle_ref in angle_refs:\n",
    "    for _ in range(100):\n",
    "        angle_view = angle_ref + np.random.uniform(-10, 10)\n",
    "        dist_view = bed_dist + np.random.uniform(-1, 1)*bed_dist/4\n",
    "        Tbs = bed_mat.get_tf(VIEW_POSE_EXT)\n",
    "        Tbs = np.matmul(Tbs, \n",
    "                        SE3(np.identity(3), (-bed_mat.dims[0]/2, 0,0)))\n",
    "        Tsc = np.matmul(SE3(Rot_axis(3, np.deg2rad(angle_view)), (0,)*3), \n",
    "                        SE3(np.identity(3), (-dist_view, 0,0)))\n",
    "        Tbc = np.matmul(Tbs, Tsc)\n",
    "        Tmc = viewpoint.get_tf(VIEW_POSE_EXT, from_link=MOBILE_BASE)\n",
    "        Tmc[:3,:3] = np.identity(3)\n",
    "        Tbm = np.matmul(Tbc, SE3_inv(Tmc))\n",
    "        full_view_ext = np.copy(VIEW_POSE_EXT)\n",
    "        full_view_ext[:2] = Tbm[:2,3]\n",
    "        full_view_ext[2] = Rot2axis(Tbm[:3, :3], 3)\n",
    "        gscene.show_pose(full_view_ext)\n",
    "        res = kmb.check_valid(full_view_ext[:6])\n",
    "        if res:\n",
    "            VIEW_MOVED_EXT = full_view_ext\n",
    "            print(\"Full view loc: {}\".format(np.round(VIEW_MOVED_EXT[:3], 2)))\n",
    "            break\n",
    "    if res:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### move to full view pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_INDY and CONNECT_MOBILE:\n",
    "    gscene.show_pose(crob.get_real_robot_pose())\n",
    "    print(\"real_robot_pose: {}\".format(\n",
    "        np.round(crob.get_real_robot_pose(), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEW_MOVED = VIEW_POSE\n",
    "# VIEW_MOVED_EXT = VIEW_POSE_EXT\n",
    "# CLOSET_LOCATION = \"LEFT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.show_pose(VIEW_MOVED_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        indy.joint_move_to(np.rad2deg(VIEW_MOVED))\n",
    "    kmb.joint_move_make_sure(VIEW_MOVED_EXT[:6])\n",
    "    VIEW_MOVED_EXT = crob.get_real_robot_pose()\n",
    "if not CONNECT_INDY:\n",
    "    VIEW_MOVED_EXT[6:] = VIEW_MOVED.copy()\n",
    "gscene.show_pose(VIEW_MOVED_EXT)\n",
    "print(\"VIEW_MOVED_EXT: {}\".format(\n",
    "    np.round(VIEW_MOVED_EXT, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 detect bed and closet together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bc = viewpoint.get_tf(VIEW_MOVED_EXT)\n",
    "T_cb = SE3_inv(T_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_bed = MultiICP_Obj(obj_info_dict[\"bed\"], None,\n",
    "                        OffsetOnModelCoord(\"bed\", R=np.matmul(T_cb[:3, :3], Rot_axis(3, np.pi)),\n",
    "                                          offset=np.matmul(T_cb[:3, :3], (1.1 * 0.5, 0, -0.5))))\n",
    "\n",
    "mrule_closet = MaskBoxRule(\"closet\", \"bed\", merge_rule=np.all)\n",
    "mrule_closet.update_rule = ClosetRuleFun(mrule_closet)\n",
    "micp_closet = MultiICP_Obj(obj_info_dict[\"closet\"], \n",
    "                           mrule_closet,\n",
    "                           OffsetOnModelCoord(\"closet\", \n",
    "                                             offset=(0, 1, 0.3),\n",
    "                                             use_median=True\n",
    "                                     ))\n",
    "micp_dict = {\"bed\": micp_bed, \"closet\": micp_closet}\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VISUALIZE = True\n",
    "# capture image of full view\n",
    "if CONNECT_CAM:\n",
    "#     rdict = camgen.stream_capture_image(obj_type=\"full_view\", crob=crob)\n",
    "    color_img, depth_img, VIEW_MOVED_EXT = micp.get_image()\n",
    "    cam_mtx, discoeffs, d_scale = micp.get_camera_config()\n",
    "    intrins = [micp.img_dim[1], micp.img_dim[0],\n",
    "               cam_mtx[0, 0], cam_mtx[1, 1],\n",
    "               cam_mtx[0, 2], cam_mtx[1, 2]]\n",
    "    rdict = {'color': color_img,\n",
    "             'depth': depth_img,\n",
    "             'intrins': intrins, 'depth_scale': d_scale}\n",
    "else:\n",
    "    rdict, VIEW_MOVED_EXT = load_rdict(\"full_view\")\n",
    "    T_bc = viewpoint.get_tf(VIEW_MOVED_EXT)\n",
    "    gscene.show_pose(VIEW_MOVED_EXT)\n",
    "    \n",
    "cdp = rdict2cdp(rdict)\n",
    "\n",
    "if ENABLE_DETECT:\n",
    "    # Output of inference(mask for detected bed)\n",
    "    mask_out_list = sd.inference(color_img=cdp.color)\n",
    "    mask_out = mask_out_list[class_dict[\"bed\"]]\n",
    "    cv2.imwrite(os.path.join(SAVE_DIR, \"mask_bed_re.png\"), mask_out)\n",
    "else:\n",
    "    mask_out = cv2.imread(os.path.join(SAVE_DIR, \"mask_bed_re.png\"))[:,:,0]\n",
    "    \n",
    "if np.any(mask_out):\n",
    "    if not CONNECT_CAM:\n",
    "        micp.cache_sensor(cdp.color, cdp.depth, VIEW_MOVED_EXT)\n",
    "\n",
    "    micp_bed.clear()\n",
    "    pose_dict = micp.detect(visualize=VISUALIZE)\n",
    "    T_bo_bed = pose_dict[\"bed\"]\n",
    "    T_bo = pose_dict[\"closet\"]\n",
    "    \n",
    "    # adjust bed\n",
    "    T_bo_bed[2]=0\n",
    "    T_bo_bed[:3, :3]=Rot_axis(3, Rot2axis(T_bo_bed[:3, :3], 3))\n",
    "    move_bed(gscene, T_bo_bed[:3,3], Rot2rpy(T_bo_bed[:3,:3]))\n",
    "     \n",
    "    # adjust closet\n",
    "    T_bo[2]=0\n",
    "    T_bo[:3, :3]=Rot_axis(3, Rot2axis(T_bo[:3, :3], 3))\n",
    "\n",
    "    if not ENABLE_O3D:\n",
    "        T_bo = T_xyzrpy((np.matmul(Rot_rpy(bed_rpy), (-0.75,-1.5,0))+bed_center, \n",
    "                         bed_rpy))\n",
    "    \n",
    "    closet_leftup, closet_rightup, closet_down = add_closet(\n",
    "        gscene, closet_center=T_bo[:3,3], closet_rpy=Rot2rpy(T_bo[:3,:3]), \n",
    "        COLOR_CLOSET_COL=(0,1,0,0.3))\n",
    "\n",
    "    add_backwall(gscene)\n",
    "\n",
    "else:\n",
    "    raise(RuntimeError(\"bed not detected\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_pt_list = kmm.remove_poles_by_box(gscene, gscene.NAME_DICT[\"bed_box\"], \n",
    "                    pole_pt_list, VIEW_POSE_EXT)\n",
    "pole_pt_list = kmm.remove_poles_by_box(gscene, gscene.NAME_DICT[\"closet_box\"], \n",
    "                    pole_pt_list, VIEW_POSE_EXT)\n",
    "pole_pt_list = kmm.remove_poles_by_box(gscene, gscene.NAME_DICT[\"room_box\"], \n",
    "                    pole_pt_list, VIEW_POSE_EXT, inside=False)\n",
    "pole_list = kmm.add_pixel_poles(\"obs_pt\", gscene, pole_pt_list, pole_res)\n",
    "gcheck.ignore_always = pole_list\n",
    "\n",
    "gscene.update_markers_all() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.ui.ui_broker import *\n",
    "\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(ppline, s_builder)\n",
    "ui_broker.start_server()\n",
    "\n",
    "ui_broker.set_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Prepare cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.constraint.constraint_common import *\n",
    "from pkg.planning.constraint.constraint_actor import *\n",
    "from pkg.planning.constraint.constraint_subject import *\n",
    "from pkg.utils.code_scraps import get_look_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mplan.reset_log(flag_log=True)\n",
    "Q_CUR = VIEW_MOVED_EXT\n",
    "HOME_POSE_SWEEP = np.copy(Q_CUR)\n",
    "# HOME_POSE_SWEEP[6:] = 0\n",
    "crob.home_pose = HOME_POSE_SWEEP\n",
    "crob.home_dict = list2dict(crob.home_pose, \n",
    "                           gscene.joint_names)\n",
    "floor_ws = gscene.NAME_DICT[\"floor_ws\"]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_count_list = []\n",
    "THRESH = 0.05\n",
    "def look_closet_get_offset(gxter, crob, mplan, robot_name, Qref):\n",
    "    Qref_in = np.copy(Qref)\n",
    "    Qref = np.copy(Qref)\n",
    "    for _ in range(5):\n",
    "        traj, succ = get_look_motion(mplan, robot_name, Qref, \n",
    "                                     target_point=gscene.NAME_DICT[\"closet_leftup\"],\n",
    "                                     com_link=CAM_LINK,\n",
    "                                     cam_link=CAM_LINK,\n",
    "                                     view_dir=[0,0,1],timeout=1)\n",
    "        traj_rev = np.array(list(reversed(traj)))\n",
    "\n",
    "    if not succ:\n",
    "        look_closet_get_offset.Qref_fail = Qref\n",
    "        raise(RuntimeError(\"Get Look Motion Fail\"))\n",
    "\n",
    "    Qref[6:] = traj[-1][6:]\n",
    "    gscene.show_pose(Qref)\n",
    "    if CONNECT_INDY:\n",
    "        with indy: # move to look\n",
    "            crob.move_joint_traj(traj, one_by_one=True)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "#     icp_closet = MultiICP(model=MODEL_DIR + '/top_table/top_table.STL', \n",
    "#                        Toff=SE3([[1,0,0],[0,0,1],[0,-1,0]], [0.3,0,0.2725]))\n",
    "\n",
    "#     micp_closet.clear()\n",
    "    adjust_count_list.append(1)\n",
    "    if CONNECT_CAM:\n",
    "#         rdict = camgen.stream_capture_image( \n",
    "#                                      obj_type=\"closet_{}\".format(len(adjust_count_list)), \n",
    "#                                      crob=crob)\n",
    "        color_img, depth_img, Qref = micp.get_image()\n",
    "        cam_mtx, discoeffs, d_scale = micp.get_camera_config()\n",
    "        intrins = [micp.img_dim[1], micp.img_dim[0],\n",
    "                   cam_mtx[0, 0], cam_mtx[1, 1],\n",
    "                   cam_mtx[0, 2], cam_mtx[1, 2]]\n",
    "        rdict = {'color': color_img,\n",
    "                 'depth': depth_img,\n",
    "                 'intrins': intrins, 'depth_scale': d_scale}\n",
    "    else:\n",
    "        try:\n",
    "            rdict, Qref = load_rdict(\"closet_{}\".format(len(adjust_count_list)))\n",
    "            gscene.show_pose(Qref)\n",
    "        except Exception as e:\n",
    "            TextColors.YELLOW.println(\"[WARN] out of saved look refine data\")\n",
    "            print(e)\n",
    "            Qcur = np.copy(Qref_in)\n",
    "            Qcur[:6] = Qref_in[:6] + np.random.uniform([-0.05, -0.05, -0.05, 0, 0, 0],\n",
    "                                                         [0.05, 0.05, 0.05, 0, 0, 0])\n",
    "\n",
    "            Qtar = np.copy(Qref_in)\n",
    "            Qtar[:6] = Qref_in[:6] + np.random.uniform([-0.05, -0.05, -0.05, 0, 0, 0],\n",
    "                                                         [0.05, 0.05, 0.05, 0, 0, 0])\n",
    "            return Qcur, Qtar\n",
    "\n",
    "    T_bc, T_bs_closet = viewpoint.get_tf(Qref), gscene.NAME_DICT[\"closet\"].get_tf(Qref)\n",
    "\n",
    "    micp.cache_sensor(rdict['color'], rdict['depth'], Qref)\n",
    "    \n",
    "    pose_dict = micp.detect(name_mask=['closet'], visualize=True)\n",
    "    T_bo_close = pose_dict[\"closet\"]\n",
    "    pcd_closet = o3d.geometry.PointCloud()\n",
    "    points = np.asarray(micp_closet.pcd.points)\n",
    "    points_base = np.matmul(T_bc[:3,:3], points.T).T + T_bc[:3,3]\n",
    "    pcd_closet.points = o3d.utility.Vector3dVector(points_base)\n",
    "    pcd_masked = pcd_closet\n",
    "    \n",
    "#     cdp = rdict2cdp(rdict)\n",
    "#     pcd_closet = cdp2pcd(cdp, T_bc)\n",
    "\n",
    "#     with gtimer.block(\"masking\"):\n",
    "#         pcd_masked = mask_boxes(pcd_closet, \n",
    "#                             boxes=[gscene.NAME_DICT[\"closet_box\"]], \n",
    "#                             Q=Qref, inside=True, \n",
    "#                             merge_rule=np.all, link_ref=\"base_link\")\n",
    "#         pcd_masked = mask_boxes(pcd_masked, \n",
    "#                             boxes=[gscene.NAME_DICT[\"bed_box\"], \n",
    "#                                    gscene.NAME_DICT[\"bed_wall\"], \n",
    "#                                    gscene.NAME_DICT[\"floor_box\"],\n",
    "#                                    gscene.NAME_DICT[\"back_wall\"]], \n",
    "#                             Q=Qref, inside=False, \n",
    "#                             merge_rule=np.all, link_ref=\"base_link\")\n",
    "\n",
    "#     with gtimer.block(\"adding\"):\n",
    "#         icp_closet.add_pointcloud(pcd_masked, T_bc, ratio=0.2)\n",
    "\n",
    "#     initial_guess = gscene.NAME_DICT[\"closet\"].get_tf(Qref)\n",
    "#     with gtimer.block(\"compute_front_ICP\"):\n",
    "#         # front_ICP\n",
    "#         T_bo_close1, fitness1 = icp_closet.compute_front_ICP(\n",
    "#             T_bc, initial_guess, thres=THRESH, visualize=VISUALIZE)\n",
    "#         T_bo_close = T_bo_close1\n",
    "# #         T_bo_close2, fitness2 = icp_closet.compute_front_ICP(\n",
    "# #             T_bc, initial_guess, thres=THRESH*2, visualize=VISUALIZE)\n",
    "# #         T_bo_close = T_bo_close1 if fitness1 > fitness2 else T_bo_close2\n",
    "\n",
    "    # calculate transform based on obtained points\n",
    "    pcd_center_prev = pcd_masked.get_center()\n",
    "\n",
    "    T_bo_p = SE3(T_bo_close[:3,:3], pcd_center_prev)\n",
    "    T_pooc = np.matmul(SE3_inv(T_bo_p), T_bo_close)\n",
    "    T_bo_p[:3,:3] = Rot_axis(3, Rot2axis(T_bo_close[:3,:3], 3))\n",
    "    T_bo_c_fix = np.matmul(T_bo_p, T_pooc)\n",
    "    T_bo_c_fix[2,3] = 0\n",
    "\n",
    "    # get Twoff from redetection\n",
    "    Tbo0, Tbo1 = T_bs_closet, T_bo_c_fix\n",
    "    Tbw0 = gscene.get_tf(gxter.mobile_link, Qref)\n",
    "    Tow1 = np.matmul(SE3_inv(Tbo1), Tbw0)\n",
    "    Tbw1 = np.matmul(Tbo0, Tow1)\n",
    "\n",
    "    if CONNECT_CAM and CONNECT_MOBILE:\n",
    "        Qcur = np.copy(Qref)\n",
    "        Qcur[:2] = Tbw1[:2,3]\n",
    "        Qcur[2] = Rot2axis(Tbw1[:3,:3], 3)\n",
    "\n",
    "        Tow0 = np.matmul(SE3_inv(Tbo0), Tbw0)\n",
    "        Tbw1tar = np.matmul(Tbo1, Tow0)\n",
    "        Qtar = np.copy(Qref)\n",
    "        Qtar[:2] = Tbw1tar[:2,3]\n",
    "        Qtar[2] = Rot2axis(Tbw1tar[:3,:3], 3)\n",
    "    else:\n",
    "        Qcur = np.copy(Qref_in)\n",
    "        Qcur[:6] = Qref_in[:6] + np.random.uniform([-0.05, -0.05, -0.05, 0, 0, 0],\n",
    "                                                     [0.05, 0.05, 0.05, 0, 0, 0])\n",
    "        \n",
    "        Qtar = np.copy(Qref_in)\n",
    "        Qtar[:6] = Qref_in[:6] + np.random.uniform([-0.05, -0.05, -0.05, 0, 0, 0],\n",
    "                                                     [0.05, 0.05, 0.05, 0, 0, 0])\n",
    "    return Qcur, Qtar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEL_LEVEL = 3\n",
    "\n",
    "if CONNECT_INDY:\n",
    "    with indy:\n",
    "        vel_level_bak = indy.get_joint_vel_level()\n",
    "        print(\"vel_level_bak: {}\".format(vel_level_bak))\n",
    "\n",
    "    with indy:\n",
    "        indy.set_joint_vel_level(VEL_LEVEL)\n",
    "        \n",
    "    indy.collision_policy = POLICY_NO_COLLISION_DETECTION\n",
    "swp_fin_list = []\n",
    "\n",
    "Qcur = VIEW_MOVED_EXT\n",
    "mode_switcher=ModeSwitcherKMB(pscene, push_dist=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bed cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_e_brush = brush_face.get_tf_handle(crob.home_dict, from_link=TIP_LINK)\n",
    "T_brush_e = SE3_inv(T_e_brush)\n",
    "EE_HEIGHT = round(bed_mat.get_tf(HOME_DICT)[2,3] + bed_mat.dims[2]/2, 5) \\\n",
    "                + T_brush_e[2, 3] - INDY_BASE_OFFSET[2]\n",
    "\n",
    "gscene.add_virtual_guardrail(closet_leftup, HEIGHT=0.02, margin=0.05)\n",
    "gscene.add_virtual_guardrail(closet_rightup, HEIGHT=0.02, margin=0.05)\n",
    "gscene.add_virtual_guardrail(closet_down, HEIGHT=0.02, margin=0.05, axis=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX\n",
    "\n",
    "gxter.set_test_kwargs(multiprocess=False, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "covereds_all = []\n",
    "for _ in range(1):\n",
    "    gxter.get_division_dict(bed_mat, \"front\", \"X\", EE_HEIGHT, xout_cut=True)\n",
    "    gxter.init_base_divs(Qcur)\n",
    "    # gxter.mark_tested(None, None, covereds_all, [])\n",
    "    snode_schedule_list_d, Qcur, covereds = gxter.greedy_execute(\n",
    "        Qcur, 1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT, covereds=covereds_all)\n",
    "    covereds_all = sorted(set(covereds_all+covereds))\n",
    "    gxter.test_clear()\n",
    "    len_covered, len_all = len(covereds_all), len(gxter.surface_div_centers)\n",
    "    print(\"########################### TRIAL ONCE DONE ( {} / {} )########################\".format(len_covered, len_all))\n",
    "    if len_covered >= len_all:\n",
    "        break\n",
    "    print(gtimer)\n",
    "gscene.clear_virtuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Closet cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gscene.add_virtual_guardrail(closet_rightup, HEIGHT=0.2, margin=0.15)\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX * 2\n",
    "\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "gxter.set_test_kwargs(multiprocess=PLANNING_MULTIPROC, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION*1.5, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "gxter.get_division_dict(closet_rightup, \"up\", \"Z\", None)\n",
    "gxter.init_base_divs(Qcur)\n",
    "snode_schedule_list_ru, Qcur, covereds = gxter.greedy_execute(\n",
    "    Qcur, 1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT, adjust_once=False)\n",
    "gxter.test_clear()\n",
    "gscene.clear_virtuals()\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gscene.add_virtual_guardrail(closet_leftup, HEIGHT=0.1, margin=0.1)\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX\n",
    "\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "gxter.set_test_kwargs(multiprocess=PLANNING_MULTIPROC, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "gxter.get_division_dict(closet_leftup, \"up\", \"Z\", None)\n",
    "gxter.init_base_divs(Qcur)\n",
    "snode_schedule_list_lu, Qcur, covereds = gxter.greedy_execute(\n",
    "    Qcur, 1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT)\n",
    "gxter.test_clear()\n",
    "gscene.clear_virtuals()\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer.reset(scale=1, timeunit='s', stack=True)\n",
    "gscene.add_virtual_guardrail(\n",
    "    closet_down, HEIGHT=0.05, margin=0.1, axis=\"xy\")\n",
    "tplan.node_trial_max = NODE_TRIAL_MAX * 2\n",
    "\n",
    "gxter = GreedyExecuter(ppline, brush_face, TOOL_DIM, Qcur)\n",
    "gxter.set_test_kwargs(multiprocess=PLANNING_MULTIPROC, N_agents=N_AGENTS,\n",
    "                      timeout=TIMEOUT_MOTION*2, timeout_loop=TIMEOUT_FULL, \n",
    "                      verbose=VERBOSE, max_solution_count=MAX_SOL_NUM)\n",
    "\n",
    "gxter.get_division_dict(closet_down, \"down\", \"Z\", None)\n",
    "gxter.init_base_divs(Qcur)\n",
    "snode_schedule_list_d, Qcur, covereds = gxter.greedy_execute(\n",
    "    Qcur, -1, mode_switcher, look_closet_get_offset, cost_cut=BASE_COST_CUT, \n",
    "    adjust_once=False)\n",
    "gxter.test_clear()\n",
    "gscene.clear_virtuals()\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONNECT_TASK_PLANNER:\n",
    "    servicer.mark_task_finished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MAX_SOL_NUM 적용 v\n",
    "* 위 오른쪽 안닦이는 문제 파악 - guardrail 마진 - v\n",
    "* 아래 닦을 때 위쪽 가운데 바운더리 추가 - v\n",
    "* 침대 닦을 때 옷장 바운더리 마진 추가 - v\n",
    "* 위치 보정, 드리프트 코드 검토 - ok - v\n",
    "* 인디 툴 무게 v\n",
    "* 툴 조인트 플래닝에 추가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adjust에서 Qref와 Qcur 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
