{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = None\n",
    "rtype = \"panda\"\n",
    "PRECISION = \"FP16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SharedArray as sa\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "\n",
    "PROJ_DIR = os.environ[\"RNB_PLANNING_DIR\"]\n",
    "sys.path.append(os.path.join(PROJ_DIR, \"src\"))\n",
    "\n",
    "from pkg.utils.utils_python3 import *\n",
    "from pkg.controller.robot_config import RobotType\n",
    "from pkg.planning.filtering.lattice_model.data_utils import *\n",
    "import numpy as np\n",
    "int2rtypename = {v.value:v.name for v in RobotType}\n",
    "DATA_PATH = os.path.join(PROJ_DIR, \"data\")\n",
    "MODEL_PATH = os.path.join(PROJ_DIR, \"model\")\n",
    "LAT_MODEL_PATH = os.path.join(MODEL_PATH,\"latticized\")\n",
    "try_mkdir(MODEL_PATH)\n",
    "try_mkdir(LAT_MODEL_PATH)\n",
    "GRASP_FOLDER = \"grasp\"\n",
    "ARM10_FOLDER = \"arm_10\"\n",
    "ARM05_FOLDER = \"arm_05\"\n",
    "FULLS_FOLDER = \"full_scene\"\n",
    "\n",
    "ARM_FOLDER = ARM10_FOLDER\n",
    "GRASP_SHAPE = (20,20,20)\n",
    "ARM_SHAPE = (20,20,20)\n",
    "RH_MASK_SIZE = 512\n",
    "RH_MASK_STEP = 64\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "SERVER_PERIOD = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_TYPE_NAME = rtype\n",
    "ROBOT_MODEL_ROOT = os.path.join(LAT_MODEL_PATH, ROBOT_TYPE_NAME)\n",
    "last_model = sorted(os.listdir(ROBOT_MODEL_ROOT))[-1]\n",
    "last_save = sorted([item for item in os.listdir(os.path.join(ROBOT_MODEL_ROOT, last_model)) if item.startswith(\"model\")])[-1]\n",
    "model_path_rel = os.path.join(last_model, last_save)\n",
    "model_log_dir = os.path.join(ROBOT_MODEL_ROOT, model_path_rel)\n",
    "model_log_dir_trt = os.path.join(ROBOT_MODEL_ROOT, model_path_rel.replace(\"model\", \"trt\")+\"-\"+PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert and save frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(precision_mode=PRECISION)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=model_log_dir,\n",
    "                                    conversion_params=conversion_params)\n",
    "converter.convert()\n",
    "\n",
    "def my_input_fn():\n",
    "    grasp_img_t = tf.zeros((BATCH_SIZE,) + GRASP_SHAPE + (3,), dtype=tf.float32)\n",
    "    arm_img_t = tf.zeros((BATCH_SIZE,) + ARM_SHAPE + (1,), dtype=tf.float32)\n",
    "    rh_mask_t = tf.zeros((BATCH_SIZE, 54), dtype=tf.float32)\n",
    "    yield (grasp_img_t, arm_img_t, rh_mask_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.build(input_fn=my_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "converter.save(model_log_dir_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_img_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.grasp_img\", (BATCH_SIZE,) + GRASP_SHAPE + (3,))\n",
    "arm_img_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.arm_img\", (BATCH_SIZE,) + ARM_SHAPE + (1,))\n",
    "rh_vals_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.rh_vals\", (BATCH_SIZE, 2))\n",
    "result_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.result\", (BATCH_SIZE, 2))\n",
    "query_in = sa.create(f\"shm://{ROBOT_TYPE_NAME}.query_in\", (1,), dtype=np.bool)\n",
    "response_out = sa.create(f\"shm://{ROBOT_TYPE_NAME}.response_out\", (1,), dtype=np.bool)\n",
    "query_quit = sa.create(f\"shm://{ROBOT_TYPE_NAME}.query_quit\", (1,), dtype=np.bool)\n",
    "prepared_p = sa.create(f\"shm://{rtype}.prepared\", (1,), dtype=np.bool)\n",
    "\n",
    "grasp_img_p[:] = 0\n",
    "arm_img_p[:] = 0\n",
    "rh_vals_p[:] = 0\n",
    "result_p[:] = 0\n",
    "query_in[0] = False\n",
    "response_out[0] = False\n",
    "query_quit[0] = False\n",
    "rh_mask = np.zeros((BATCH_SIZE, 54))\n",
    "\n",
    "r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "prepared_p[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call checker once to get data example. run below cell to return response so the checker can stop waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load(\n",
    "    model_log_dir_trt, tags=[tag_constants.SERVING])\n",
    "graph_func = saved_model_loaded.signatures[\n",
    "    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "frozen_func = convert_variables_to_constants_v2(graph_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_in[0] = False\n",
    "grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "input_data = (grasp_img_t, arm_img_t, rh_mask_t)\n",
    "output = frozen_func(*input_data)[0].numpy()    \n",
    "for i_b in range(BATCH_SIZE):\n",
    "    result_p[i_b] = output[i_b]\n",
    "response_out[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "for _ in range(100):\n",
    "    while not query_in[0]:\n",
    "        time.sleep(SERVER_PERIOD)\n",
    "    query_in[0] = False\n",
    "    print(\"query in\")\n",
    "    with gtimer.block(\"frozen_func\"):\n",
    "        grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "        arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "        rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "        input_data = (grasp_img_t, arm_img_t, rh_mask_t)\n",
    "        output = frozen_func(*input_data)[0].numpy()    \n",
    "        for i_b in range(BATCH_SIZE):\n",
    "            result_p[i_b] = output[i_b]\n",
    "    response_out[0] = True\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.grasp_img\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.arm_img\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.rh_vals\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.result\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.query_in\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.response_out\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.query_quit\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
