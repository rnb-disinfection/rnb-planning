{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set running directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "os.chdir(os.path.join(os.environ[\"RNB_PLANNING_DIR\"], 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.controller.combined_robot import *\n",
    "from pkg.utils.utils import get_now, try_mkdir\n",
    "\n",
    "\n",
    "DATA_PATH = os.path.join(os.environ['RNB_PLANNING_DIR'], \"data\")\n",
    "try_mkdir(DATA_PATH)\n",
    "MODEL_PATH = os.path.join(os.environ['RNB_PLANNING_DIR'], \"model\")\n",
    "try_mkdir(MODEL_PATH)\n",
    "\n",
    "GF_DATA_PATH = os.path.join(DATA_PATH, \"gf3d\")\n",
    "try_mkdir(GF_DATA_PATH)\n",
    "GF_MODEL_PATH = os.path.join(MODEL_PATH, \"gf3d\")\n",
    "try_mkdir(GF_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALIZE = False\n",
    "\n",
    "ROBOT_TYPE = RobotType.indy7\n",
    "ROBOT_NAME = \"indy0\"\n",
    "TOOL_LINK = \"indy0_tcp\"\n",
    "TOOL_XYZ = (0,0,0.14)\n",
    "GRIP_DEPTH = 0.05\n",
    "HOME_POSE = (0,0,0,0,0,0)\n",
    "\n",
    "# ROBOT_TYPE = RobotType.panda\n",
    "# ROBOT_NAME = \"panda0\"\n",
    "# TOOL_LINK = \"panda0_hand\"\n",
    "# TOOL_XYZ = (0,0,0.112)\n",
    "# GRIP_DEPTH = 0.03\n",
    "# HOME_POSE = (0,-0.3,0,-0.5,0,2.5,0)\n",
    "\n",
    "\n",
    "TOOL_RPY = (-np.pi/2,0,0)\n",
    "CLEARANCE = 1e-3\n",
    "TIMEOUT_REACH = 1\n",
    "TIMEOUT_RETRIEVE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init combined robot config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "indy0: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pkg.project_config import *\n",
    "\n",
    "crob = CombinedRobot(robots_on_scene=[\n",
    "    RobotConfig(0, ROBOT_TYPE, None,\n",
    "                None)]\n",
    "              , connection_list=[False])\n",
    "ROBOT_NAME = crob.robot_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "s_builder = SceneBuilder(None, base_link=\"base_link\")\n",
    "# s_builder.reset_reference_coord(ref_name=\"floor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get ghnd with detected robot config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran0']/actuator[@name='indy0_motor0']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran1']/actuator[@name='indy0_motor1']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran2']/actuator[@name='indy0_motor2']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran3']/actuator[@name='indy0_motor3']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran4']/actuator[@name='indy0_motor4']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran5']/actuator[@name='indy0_motor5']\n"
     ]
    }
   ],
   "source": [
    "# xyz_rpy_robots = s_builder.detect_items(level_mask=[DetectionLevel.ROBOT])\n",
    "xyz_rpy_robots = {ROBOT_NAME: ((0,0,0), (0,0,0))}\n",
    "crob.update_robot_pos_dict(xyz_rpy_robots=xyz_rpy_robots)\n",
    "gscene = s_builder.create_gscene(crob, start_rviz=VISUALIZE)\n",
    "HOME_DICT = list2dict(HOME_POSE, gscene.joint_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.joint_utils import get_tf\n",
    "shoulder_link = gscene.urdf_content.joint_map[gscene.joint_names[1]].child\n",
    "shoulder_height = get_tf(shoulder_link, HOME_DICT, gscene.urdf_content)[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.geometry.geometry import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtems_robot = s_builder.add_robot_geometries(color=(0,1,0,0.5), display=True, collision=True, exclude_link=[\"panda1_link7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init planning scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.scene import PlanningScene\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)\n",
    "\n",
    "from pkg.planning.pipeline import PlanningPipeline\n",
    "ppline = PlanningPipeline(pscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register binders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.constraint.constraint_actor import Gripper2Tool, PlacePlane, SweepTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.create_safe(gtype=GEOTYPE.SPHERE, name=\"grip0\", link_name=TOOL_LINK, \n",
    "                 dims=(0.01,)*3, center=TOOL_XYZ, rpy=TOOL_RPY, color=(1,0,0,1), display=True, collision=False, fixed=True)\n",
    "gripper = pscene.create_binder(bname=\"grip0\", gname=\"grip0\", _type=Gripper2Tool, point=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.motion.moveit.moveit_planner import MoveitPlanner\n",
    "from pkg.planning.filtering.grasp_filter import GraspChecker\n",
    "from pkg.planning.filtering.reach_filter import ReachChecker\n",
    "from pkg.planning.filtering.latticized_filter import LatticedChecker\n",
    "mplan = MoveitPlanner(pscene)\n",
    "\n",
    "checkers=[]\n",
    "gcheck = GraspChecker(pscene)\n",
    "checkers.append(gcheck)\n",
    "rcheck = ReachChecker(pscene)\n",
    "checkers.append(rcheck)\n",
    "# lcheck = LatticedChecker(pscene, gcheck)\n",
    "# checkers.append(lcheck)\n",
    "mplan.motion_filters = [gcheck]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://0.0.0.0:8050/\n",
      "\n",
      " * Serving Flask app \"pkg.ui.dash_launcher\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from pkg.ui.ui_broker import *\n",
    "\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(ppline, s_builder)\n",
    "ui_broker.start_server()\n",
    "\n",
    "ui_broker.set_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pkg.utils.gjk",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-794e14981875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgjk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_point_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_gjk_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint_subject\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomObject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrasp2Point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlacePoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSweepPoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSweepTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiltering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpair_svm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_pairwise_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_step_dirYZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mPLANE_THICKNESS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pkg.utils.gjk"
     ]
    }
   ],
   "source": [
    "from pkg.utils.gjk import get_point_list, get_gjk_distance\n",
    "from pkg.planning.constraint.constraint_subject import CustomObject, Grasp2Point, PlacePoint, SweepPoint, SweepTask\n",
    "from pkg.planning.filtering.pair_svm import get_pairwise_feature, get_step_dirYZ\n",
    "\n",
    "PLANE_THICKNESS = 0.1\n",
    "\n",
    "##\n",
    "# @class ObstacleBase\n",
    "# @brief base class for obstacle generators\n",
    "class ObstacleBase:\n",
    "    RTH_MIN = None ## R: center ~ nearest point\n",
    "    RTH_MAX = None\n",
    "    RPY_MIN = None\n",
    "    RPY_MAX = None\n",
    "    DIM_MIN = None\n",
    "    DIM_MAX = None\n",
    "    GTYPE = None\n",
    "    COLOR = (0.7,0.7,0.7,1)\n",
    "    \n",
    "    def __init__(self, gscene, name, sampler=np.random.uniform, DIM=None, RTH=None, RPY=None):\n",
    "        self.name = name\n",
    "        self.DIM = sampler(self.DIM_MIN, self.DIM_MAX) if DIM is None else DIM\n",
    "        self.RTH = sampler(self.RTH_MIN, self.RTH_MAX) if RTH is None else RTH\n",
    "        self.RPY = sampler(self.RPY_MIN, self.RPY_MAX) if RPY is None else RPY\n",
    "        self.RPY[2] += self.RTH[1]\n",
    "        self.XYZ = np.array(cyl2cart(*self.RTH))\n",
    "        verts_rotated = np.matmul(Rot_rpy(self.RPY), (DEFAULT_VERT_DICT[self.GTYPE]*self.DIM).transpose())\n",
    "        xy_normed = self.XYZ[:2]/(np.linalg.norm(self.XYZ[:2])+1e-6)\n",
    "        verts_r_compo = np.dot(xy_normed, verts_rotated[:2,:])\n",
    "        self.XYZ[:2] -= xy_normed[:2]*np.min(verts_r_compo)\n",
    "        self.RTH[0] -= np.min(verts_r_compo)\n",
    "        self.geometry = gscene.create_safe(gtype=self.GTYPE, name=self.name, link_name=\"base_link\", \n",
    "                                  dims=self.DIM, center=tuple(self.XYZ), rpy=self.RPY,\n",
    "                                  color=self.COLOR, display=True, collision=True, fixed=True)\n",
    "        self.subgeo_list = []\n",
    "        \n",
    "    def is_overlapped_with(self, gtem):\n",
    "        verts, radii = gtem.get_vertice_radius()\n",
    "        verts_global = np.add(np.matmul(verts, gtem.orientation_mat.transpose()), gtem.center)\n",
    "        verts_me, raddii_me = self.geometry.get_vertice_radius()\n",
    "        verts_me_global = np.add(np.matmul(verts_me, self.geometry.orientation_mat.transpose()), \n",
    "                                 self.geometry.center)\n",
    "        return get_gjk_distance(get_point_list(verts_global), get_point_list(verts_me_global))-radii-raddii_me < 1e-4\n",
    "        \n",
    "##\n",
    "# @class WorkPlane\n",
    "# @brief working plane. target and obstacle objects are generated on this plane\n",
    "class WorkPlane(ObstacleBase):\n",
    "    RTH_MIN = (0.3, -np.pi/2, -0.2)\n",
    "    RTH_MAX = (0.3, +np.pi/2, 0.5)\n",
    "    RPY_MIN = (0, 0, -np.pi/6)\n",
    "    RPY_MAX = (0, 0, +np.pi/6)\n",
    "    DIM_MIN = (0.6, 0.6, PLANE_THICKNESS)\n",
    "    DIM_MAX = (0.6, 0.6, PLANE_THICKNESS)\n",
    "    GTYPE = GEOTYPE.BOX\n",
    "    COLOR=  (0.8,0.8,0.2,0.5)\n",
    "    \n",
    "    def __init__(self, gscene, name, *args, **kwargs):\n",
    "        ObstacleBase.__init__(self, gscene, name, *args, **kwargs)\n",
    "        \n",
    "    def is_overlapped_with(self, gtem):\n",
    "        verts, radii = gtem.get_vertice_radius()\n",
    "        verts_global = np.add(np.matmul(verts, gtem.orientation_mat.transpose()), gtem.center)\n",
    "        verts_wp = np.multiply(DEFAULT_VERT_DICT[self.GTYPE], tuple(self.DIM[:2])+(self.H,))\n",
    "        verts_wp_global = np.add(np.matmul(verts_wp, self.geometry.orientation_mat.transpose()), \n",
    "                                 np.add(self.geometry.center, (0,0,self.H/2)))\n",
    "        return get_gjk_distance(get_point_list(verts_global), get_point_list(verts_wp_global))-radii < 1e-4\n",
    "    \n",
    "##\n",
    "# @class PlaneObstacle\n",
    "# @brief Obstacles on the workplane\n",
    "class PlaneObject(ObstacleBase):\n",
    "    RTH_MIN = (0.2, -np.pi/2, -0.2)\n",
    "    RTH_MAX = (0.8, +np.pi/2, +0.5)\n",
    "    RPY_MIN = (0, 0, 0)\n",
    "    RPY_MAX = (0, 0, 0)\n",
    "    DIM_MIN = (0.02, GRIP_DEPTH, GRIP_DEPTH)\n",
    "    DIM_MAX = (0.055, 0.3, 0.3)\n",
    "    GTYPE = GEOTYPE.BOX\n",
    "    COLOR =  (0.2,0.2,0.8,0.5)\n",
    "    def __init__(self, gscene, name, workplane, XYZ_LOC=None, **kwargs):\n",
    "        ObstacleBase.__init__(self, gscene=gscene, name=name, **kwargs)\n",
    "        verts, radii = self.geometry.get_vertice_radius()\n",
    "        verts_rot = np.matmul(self.geometry.orientation_mat, verts.transpose()) ## verices with global orientaion\n",
    "        verts_rot_loc = np.matmul(workplane.geometry.Toff[:3,:3].transpose(), verts_rot) ## verices with local orientaion\n",
    "        max_verts = np.max(verts_rot_loc, axis=-1)\n",
    "        min_verts = np.min(verts_rot_loc, axis=-1)\n",
    "        if XYZ_LOC is None:\n",
    "            self.XYZ_LOC = np.random.uniform(np.negative(workplane.DIM)/2-min_verts+radii,np.array(workplane.DIM)/2-max_verts-radii)\n",
    "            self.XYZ_LOC[2] = workplane.DIM[2]/2 + self.DIM[2]/2 + CLEARANCE\n",
    "        else:\n",
    "            self.XYZ_LOC = self.XYZ_LOC\n",
    "        self.XYZ = np.matmul(workplane.geometry.Toff[:3,:3], self.XYZ_LOC) + workplane.geometry.Toff[:3,3]\n",
    "        self.RPY = (0,0,0)\n",
    "        self.geometry.set_offset_tf(center = self.XYZ, orientation_mat=Rot_rpy(self.RPY))\n",
    "        self.RTH = cart2cyl(*self.XYZ)\n",
    "        gscene.update_marker(self.geometry)\n",
    "        \n",
    "        \n",
    "def clear_class(gscene, key, Nmax):\n",
    "    for iw in range(Nmax):\n",
    "        gname = \"{}_{}\".format(key, iw)\n",
    "        if gname in gscene.NAME_DICT:\n",
    "            gscene.remove(gscene.NAME_DICT[gname])\n",
    "\n",
    "            \n",
    "def disperse_objects(gscene, object_class, key, Nobj, workplane_on):\n",
    "    clear_class(gscene, key, Nobj)\n",
    "        \n",
    "    obs_list = []\n",
    "    for iw in range(Nobj):\n",
    "        while len(obs_list) != iw+1:\n",
    "            obs = object_class(gscene, \"{}_{}\".format(key, iw), workplane_on)\n",
    "            remove_this = False\n",
    "            for obs_pre in obs_list:\n",
    "                if obs_pre.is_overlapped_with(obs.geometry):\n",
    "                    remove_this = True\n",
    "                    break\n",
    "            if remove_this:\n",
    "                gscene.remove(obs.geometry)\n",
    "            else:\n",
    "                obs_list.append(obs)\n",
    "    return obs_list\n",
    "\n",
    "\n",
    "def add_object(pscene, obj, HANDLE_THICKNESS=1e-6, HANDLE_COLOR = (1,0,0,0.3)):\n",
    "    gscene = pscene.gscene\n",
    "    handles = []\n",
    "    handles.append(\n",
    "        gscene.create_safe(gtype=GEOTYPE.BOX, name=\"hdl_tp_a\", link_name=\"base_link\", \n",
    "                       dims=(obj.DIM[1], GRIP_DEPTH, HANDLE_THICKNESS), center=(0,0,obj.DIM[2]/2-GRIP_DEPTH/2), rpy=(np.pi/2,0,np.pi/2), \n",
    "                           color=HANDLE_COLOR, display=True, collision=False, fixed=False,\n",
    "                       parent=obj.name)\n",
    "    )\n",
    "\n",
    "    handles.append(\n",
    "        gscene.create_safe(gtype=GEOTYPE.BOX, name=\"hdl_tp_b\", link_name=\"base_link\", \n",
    "                       dims=(obj.DIM[1], GRIP_DEPTH, HANDLE_THICKNESS), center=(0,0,obj.DIM[2]/2-GRIP_DEPTH/2), rpy=(np.pi/2,0,-np.pi/2), \n",
    "                           color=HANDLE_COLOR, display=True, collision=False, fixed=False,\n",
    "                       parent=obj.name)\n",
    "    )\n",
    "\n",
    "    handles.append(\n",
    "        gscene.create_safe(gtype=GEOTYPE.BOX, name=\"hdl_ft_a\", link_name=\"base_link\", \n",
    "                       dims=(obj.DIM[2], GRIP_DEPTH,HANDLE_THICKNESS), center=(0,obj.DIM[1]/2-GRIP_DEPTH/2,0), rpy=(0,np.pi/2,0), \n",
    "                           color=HANDLE_COLOR, display=True, collision=False, fixed=False,\n",
    "                       parent=obj.name)\n",
    "    )\n",
    "\n",
    "    handles.append(\n",
    "        gscene.create_safe(gtype=GEOTYPE.BOX, name=\"hdl_ft_b\", link_name=\"base_link\", \n",
    "                       dims=(obj.DIM[2], GRIP_DEPTH,HANDLE_THICKNESS), center=(0,obj.DIM[1]/2-GRIP_DEPTH/2,0), rpy=(0,-np.pi/2,0), \n",
    "                           color=HANDLE_COLOR, display=True, collision=False, fixed=False,\n",
    "                       parent=obj.name)\n",
    "    )\n",
    "\n",
    "    handles.append(\n",
    "        gscene.create_safe(gtype=GEOTYPE.BOX, name=\"hdl_bk_a\", link_name=\"base_link\", \n",
    "                       dims=(obj.DIM[2], GRIP_DEPTH,HANDLE_THICKNESS), center=(0,-obj.DIM[1]/2+GRIP_DEPTH/2,0), rpy=(-np.pi,-np.pi/2,0), \n",
    "                       color=HANDLE_COLOR, display=True, collision=False, fixed=False,\n",
    "                   parent=obj.name)\n",
    "    )\n",
    "\n",
    "    handles.append(\n",
    "        gscene.create_safe(gtype=GEOTYPE.BOX, name=\"hdl_bk_b\", link_name=\"base_link\", \n",
    "                       dims=(obj.DIM[2], GRIP_DEPTH,HANDLE_THICKNESS), center=(0,-obj.DIM[1]/2+GRIP_DEPTH/2,0), rpy=(-np.pi,+np.pi/2,0), \n",
    "                           color=HANDLE_COLOR, display=True, collision=False, fixed=False,\n",
    "                       parent=obj.name)\n",
    "    )\n",
    "\n",
    "    action_points_dict = {\"placement\": PlacePoint(\"placement\", obj.geometry, [0,0,-obj.DIM[2]/2], [0,0,0])}\n",
    "    action_points_dict.update({handle.name: Grasp2Point(handle.name, handle, None, (0,0,0)) for handle in handles})\n",
    "    obj_pscene = pscene.create_subject(oname=obj.name, gname=obj.name, _type=CustomObject, \n",
    "                                 action_points_dict=action_points_dict)\n",
    "    return obj_pscene, handles\n",
    "\n",
    "ROBOT_DATA_ROOT = os.path.join(GF_DATA_PATH, ROBOT_TYPE.name)\n",
    "try_mkdir(ROBOT_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for checking\n",
    "# from pkg.planning.filtering.pair_svm import PairSVM\n",
    "# pcheck = PairSVM(pscene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_max_sample = 1000\n",
    "N_print = 10\n",
    "\n",
    "for _ in range(5):\n",
    "    i_s = 0\n",
    "    i_print = 0\n",
    "    features_dat_dict = defaultdict(list)\n",
    "    reach_list_dict = defaultdict(list)\n",
    "    retrieve_list_dict = defaultdict(list)\n",
    "    reach_list = []\n",
    "    retrieve_list = []\n",
    "    feature_time_list = []\n",
    "    gtimer = GlobalTimer.instance()\n",
    "    gtimer.reset(stack=True)\n",
    "\n",
    "    filter_results_dict = defaultdict(lambda:defaultdict(list))\n",
    "    filter_time_dict = defaultdict(list)\n",
    "\n",
    "    gtimer.tic(\"full_loop\")\n",
    "    while i_s < N_max_sample:\n",
    "        ## set workplane\n",
    "        wp = WorkPlane(gscene, \"wp\")\n",
    "        pscene.create_binder(bname=\"wp\", gname=\"wp\", _type=PlacePlane, point=None)\n",
    "\n",
    "        ## add object\n",
    "        obj_list = disperse_objects(gscene, PlaneObject, \"obj\", 2, workplane_on=wp)\n",
    "\n",
    "        obj = obj_list[0]\n",
    "        SHOW_PERIOD = 0.05\n",
    "        obj_pscene, handles = add_object(pscene, obj)\n",
    "        mplan.update_gscene()\n",
    "\n",
    "        for rotate_obj in [False, True]:\n",
    "            if rotate_obj:\n",
    "                obj_pscene.geometry.set_offset_tf(orientation_mat=Rot_axis(3,np.pi/2))\n",
    "            else:\n",
    "                obj_pscene.geometry.set_offset_tf(orientation_mat=Rot_axis(3,0))\n",
    "            obj_pscene.geometry.set_offset_tf(orientation_mat=np.matmul(obj_pscene.geometry.orientation_mat, \n",
    "                                                                        Rot_axis(3,np.random.uniform(-np.pi/4, np.pi/4-1e-6))))\n",
    "\n",
    "            for obj_tmp in obj_list[1:]:\n",
    "                Rot_candis = [Rot_axis(3,np.pi/2), Rot_axis(3,0)]\n",
    "                i_rot = random.choice([0,1])\n",
    "                obj_tmp.geometry.set_offset_tf(orientation_mat=Rot_candis[i_rot])\n",
    "                obj_tmp.geometry.set_offset_tf(orientation_mat=np.matmul(obj_tmp.geometry.orientation_mat, \n",
    "                                                                         Rot_axis(3,np.random.uniform(-np.pi/4, np.pi/4-1e-6))))\n",
    "                if obj_tmp.is_overlapped_with(obj_pscene.geometry):\n",
    "                    obj_tmp.geometry.set_offset_tf(orientation_mat=Rot_candis[(i_rot+1)%2])\n",
    "                    obj_tmp.geometry.set_offset_tf(orientation_mat=np.matmul(obj_tmp.geometry.orientation_mat, \n",
    "                                                                             Rot_axis(3,np.random.uniform(-np.pi/4, np.pi/4-1e-6))))\n",
    "                while obj_tmp.is_overlapped_with(obj_pscene.geometry):\n",
    "                    obs = obj_tmp.__init__(gscene, obj_tmp.name, wp)\n",
    "\n",
    "            initial_state = pscene.initialize_state(HOME_POSE)\n",
    "            pscene.set_object_state(initial_state)\n",
    "            from_state = initial_state.copy(pscene)\n",
    "            to_node = (\"grip0\",)\n",
    "            for bp in sorted(obj_pscene.action_points_dict.keys()):\n",
    "                pscene.set_object_state(initial_state)\n",
    "                gscene.update_markers_all()\n",
    "                handle = obj_pscene.action_points_dict[bp]\n",
    "                if not gripper.check_type(handle):\n",
    "                    continue\n",
    "                to_state, redundancy_dict = pscene.sample_leaf_state(from_state, {'obj_0': [(bp, 'grip0', 'grip0')]}, to_node)\n",
    "                redundancy_dict['obj_0']['grip0']['w'] = 0\n",
    "                redundancy_dict['obj_0'][bp]['w'] = 0\n",
    "                redundancy_dict['obj_0'][bp]['x'] = 0\n",
    "                redundancy_dict['obj_0'][bp]['y'] = 0\n",
    "\n",
    "                redundancy = redundancy_dict['obj_0']\n",
    "                redundancy_values = {}\n",
    "                redundancy_values[('obj_0', 'grip0')] = calc_redundancy(redundancy['grip0'], gripper)\n",
    "                redundancy_values[('obj_0', bp)] = calc_redundancy(redundancy[bp], handle)\n",
    "\n",
    "                point_add_handle, rpy_add_handle = redundancy_values[(obj_pscene.oname, bp)]\n",
    "                point_add_actor, rpy_add_actor = redundancy_values[(obj_pscene.oname, gripper.name)]\n",
    "                T_handle_gh = np.matmul(handle.Toff_gh, SE3(Rot_rpy(rpy_add_handle), point_add_handle))\n",
    "                T_ah = T_xyzrpy((point_add_actor, rpy_add_actor))\n",
    "                T_ahg = np.matmul(T_ah, SE3_inv(T_handle_gh))\n",
    "                if obj_pscene.geometry == handle.geometry:\n",
    "                    T_ao = T_ahg\n",
    "                else:\n",
    "                    T_hgo = np.matmul(SE3_inv(handle.geometry.Toff), obj_pscene.geometry.Toff)\n",
    "                    T_ao = np.matmul(T_ahg, T_hgo)\n",
    "                T_bo = obj_pscene.geometry.get_tf(crob.home_dict)\n",
    "                T_ba = np.matmul(T_bo, SE3_inv(T_ao))\n",
    "                dirkey = get_step_dirYZ(T_ba)\n",
    "\n",
    "                assert to_state.binding_state[0][1] == bp, \"bp is not to_state.binding_state[0][1]\"\n",
    "\n",
    "                for checker in checkers:\n",
    "                    fname = checker.__class__.__name__\n",
    "                    gtimer.tic(fname)\n",
    "                    res = checker.check(gripper, obj_pscene, \n",
    "                                        handle, \n",
    "                                        redundancy_values, HOME_DICT)\n",
    "                    etime = gtimer.toc(fname)\n",
    "                    filter_time_dict[fname].append(etime)\n",
    "                    filter_results_dict[fname][dirkey].append(res)\n",
    "\n",
    "                success_reach, success_retrieve = False, False\n",
    "                with gtimer.block(\"reach\"):\n",
    "                    Traj_reach, LastQ, error, success_reach, binding_list = mplan.plan_transition(\n",
    "                        from_state=from_state, to_state=to_state, redundancy_dict=redundancy_dict, timeout=TIMEOUT_REACH)\n",
    "                #             print(\"reach: {}\".format(success_reach))\n",
    "                Traj_retrieve = []\n",
    "                if success_reach:\n",
    "                    if VISUALIZE:\n",
    "                        gscene.show_motion(Traj_reach, period=SHOW_PERIOD)\n",
    "                    for bd in binding_list:\n",
    "                        pscene.rebind(bd, list2dict(LastQ, pscene.gscene.joint_names))\n",
    "                    binding_state, state_param = pscene.get_object_state()\n",
    "                    new_state = State(binding_state, state_param, list(LastQ), pscene)\n",
    "                    end_state = new_state.copy(pscene)\n",
    "                    end_state.Q = np.array(HOME_POSE)\n",
    "                    with gtimer.block(\"retrieve\"):\n",
    "                        Traj_retrieve, LastQ, error, success_retrieve, binding_list = mplan.plan_transition(\n",
    "                            from_state=new_state, to_state=end_state, timeout=TIMEOUT_RETRIEVE)\n",
    "                #                 print(\"retrieve: {}\".format(success_retrieve))\n",
    "                    if success_retrieve and VISUALIZE:\n",
    "                        gscene.show_motion(Traj_retrieve, period=SHOW_PERIOD)\n",
    "                pscene.set_object_state(from_state)\n",
    "                obs_count = 0\n",
    "                for obj_obs in obj_list:\n",
    "                    if obj_obs.geometry == obj_pscene.geometry:\n",
    "                        continue\n",
    "                    obs_count += 1 \n",
    "                    gtimer.tic(\"get_pairwise_feature\")\n",
    "                    featurevec = get_pairwise_feature(\n",
    "                        obj_pscene.geometry.Toff, obj_pscene.geometry.dims,\n",
    "                        obj_obs.geometry, wp.geometry.Toff[2,3]+wp.geometry.dims[2]/2)\n",
    "                feature_time_list.append(gtimer.toc(\"get_pairwise_feature\"))\n",
    "                assert obs_count == 1, \"obstacle count should be 1: this is pair-wise trainning data collection\"\n",
    "                features_dat_dict[dirkey].append(featurevec)\n",
    "    #             ## for checking\n",
    "    #             print(\"--------------------------------------------------\")\n",
    "    #             print(\"REACH: {}\".format(success_retrieve))\n",
    "    #             print(\"--------------------------------------------------\")\n",
    "    #             print(\"ORIGINAL DIR: {}\".format(dirkey))\n",
    "    #             print(\"ORIGINAL FEA: {}\".format(np.round(featurevec, 2)))\n",
    "    #             res = pcheck.check(gripper, obj_pscene, \n",
    "    #                                 handle, \n",
    "    #                                 redundancy_values, HOME_DICT)\n",
    "    #             print(\"--------------------------------------------------\")\n",
    "                reach_list_dict[dirkey].append(success_reach)\n",
    "                retrieve_list_dict[dirkey].append(success_retrieve)\n",
    "                reach_list.append(success_reach)\n",
    "                retrieve_list.append(success_retrieve)\n",
    "            pscene.set_object_state(initial_state)\n",
    "            gscene.update_markers_all()\n",
    "        i_s += 1\n",
    "        gscene.update_markers_all()\n",
    "        if i_s > 0 :\n",
    "            if i_s > i_print*N_print:\n",
    "                i_print +=  1\n",
    "                print_end = \"\\n\"\n",
    "            else:\n",
    "                print_end = \"\\r\"\n",
    "            time_elapsed = gtimer.toc(\"full_loop\")/1000\n",
    "            print(\"{} / {} in {} / {} s -- reach,retrieve = ({} %, {} %)                     \".format(\n",
    "                i_s, N_max_sample, round(time_elapsed, 2), round(time_elapsed/i_s*N_max_sample, 2), \n",
    "                round(np.mean(reach_list)*100, 1), round(np.mean(retrieve_list)*100, 1)), end=print_end)\n",
    "\n",
    "    time_elapsed = gtimer.toc(\"full_loop\")/1000\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"============= Finished {} in {} s -- reach,retrieve = ({} %, {} %) =================\".format(\n",
    "        i_s, round(time_elapsed, 2), round(np.mean(reach_list)*100, 1), round(np.mean(retrieve_list)*100, 1)))\n",
    "\n",
    "\n",
    "    ## save data\n",
    "    DATASET_PATH = os.path.join(ROBOT_DATA_ROOT, get_now())\n",
    "    try_mkdir(DATASET_PATH)\n",
    "\n",
    "    save_pickle(os.path.join(DATASET_PATH, \"train_dat.pkl\"), \n",
    "                {\"features_dat_dict\": dict(**features_dat_dict), \n",
    "                 \"retrieve_list_dict\": dict(**retrieve_list_dict), \n",
    "                 \"feature_time_list\": feature_time_list, \n",
    "                 \"filter_results_dict\": dict(**filter_results_dict),\n",
    "                 \"filter_time_dict\": dict(**filter_time_dict)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sorted(retrieve_list_dict.keys()):\n",
    "    v = retrieve_list_dict[k]\n",
    "    print(\"{} - {} %\".format(k, np.round(np.mean(v)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sorted(gtimer.timelist_dict[\"reach\"]), '.')\n",
    "plt.plot(sorted(gtimer.timelist_dict[\"retrieve\"]), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_max_sample = 1000\n",
    "N_print = 10\n",
    "\n",
    "i_s = 0\n",
    "i_print = 0\n",
    "features_dat_dict = defaultdict(list)\n",
    "reach_list_dict = defaultdict(list)\n",
    "retrieve_list_dict = defaultdict(list)\n",
    "reach_list = []\n",
    "retrieve_list = []\n",
    "feature_time_list = []\n",
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset(stack=True)\n",
    "\n",
    "filter_results_dict = defaultdict(lambda:defaultdict(list))\n",
    "filter_time_dict = defaultdict(list)\n",
    "\n",
    "gtimer.tic(\"full_loop\")\n",
    "while i_s < N_max_sample:\n",
    "    ## set workplane\n",
    "    wp = WorkPlane(gscene, \"wp\")\n",
    "    pscene.create_binder(bname=\"wp\", gname=\"wp\", _type=PlacePlane)\n",
    "\n",
    "    ## add object\n",
    "    obj_list = disperse_objects(gscene, PlaneObject, \"obj\", 2, workplane_on=wp)\n",
    "\n",
    "    obj = obj_list[0]\n",
    "    SHOW_PERIOD = 0.05\n",
    "    obj_pscene, handles = add_object(pscene, obj)\n",
    "    mplan.update_gscene()\n",
    "    \n",
    "    for rotate_obj in [False, True]:\n",
    "        if rotate_obj:\n",
    "            obj_pscene.geometry.set_offset_tf(orientation_mat=Rot_axis(3,np.pi/2))\n",
    "        else:\n",
    "            obj_pscene.geometry.set_offset_tf(orientation_mat=Rot_axis(3,0))\n",
    "        obj_pscene.geometry.set_offset_tf(orientation_mat=np.matmul(obj_pscene.geometry.orientation_mat, \n",
    "                                                                    Rot_axis(3,np.random.uniform(-np.pi/4, np.pi/4-1e-6))))\n",
    "            \n",
    "        for obj_tmp in obj_list[1:]:\n",
    "            Rot_candis = [Rot_axis(3,np.pi/2), Rot_axis(3,0)]\n",
    "            i_rot = random.choice([0,1])\n",
    "            obj_tmp.geometry.set_offset_tf(orientation_mat=Rot_candis[i_rot])\n",
    "            obj_tmp.geometry.set_offset_tf(orientation_mat=np.matmul(obj_tmp.geometry.orientation_mat, \n",
    "                                                                     Rot_axis(3,np.random.uniform(-np.pi/4, np.pi/4-1e-6))))\n",
    "            if obj_tmp.is_overlapped_with(obj_pscene.geometry):\n",
    "                obj_tmp.geometry.set_offset_tf(orientation_mat=Rot_candis[(i_rot+1)%2])\n",
    "                obj_tmp.geometry.set_offset_tf(orientation_mat=np.matmul(obj_tmp.geometry.orientation_mat, \n",
    "                                                                         Rot_axis(3,np.random.uniform(-np.pi/4, np.pi/4-1e-6))))\n",
    "            while obj_tmp.is_overlapped_with(obj_pscene.geometry):\n",
    "                obs = obj_tmp.__init__(gscene, obj_tmp.name, wp)\n",
    "\n",
    "        initial_state = pscene.initialize_state(HOME_POSE)\n",
    "        pscene.set_object_state(initial_state)\n",
    "        from_state = initial_state.copy(pscene)\n",
    "        to_node = (\"grip0\",)\n",
    "        for bp in sorted(obj_pscene.action_points_dict.keys()):\n",
    "            pscene.set_object_state(initial_state)\n",
    "            gscene.update_markers_all()\n",
    "            handle = obj_pscene.action_points_dict[bp]\n",
    "            if not gripper.check_type(handle):\n",
    "                continue\n",
    "            to_state, redundancy_dict = pscene.sample_leaf_state(from_state, {'obj_0': [(bp, 'grip0', 'grip0')]}, to_node)\n",
    "            redundancy_dict['obj_0']['grip0']['w'] = 0\n",
    "            redundancy_dict['obj_0'][bp]['w'] = 0\n",
    "            redundancy_dict['obj_0'][bp]['x'] = 0\n",
    "            redundancy_dict['obj_0'][bp]['y'] = 0\n",
    "            \n",
    "            redundancy = redundancy_dict['obj_0']\n",
    "            redundancy_values = {}\n",
    "            redundancy_values[('obj_0', 'grip0')] = calc_redundancy(redundancy['grip0'], gripper)\n",
    "            redundancy_values[('obj_0', bp)] = calc_redundancy(redundancy[bp], handle)\n",
    "                                \n",
    "            point_add_handle, rpy_add_handle = redundancy_values[(obj_pscene.oname, bp)]\n",
    "            point_add_actor, rpy_add_actor = redundancy_values[(obj_pscene.oname, gripper.name)]\n",
    "            T_handle_gh = np.matmul(handle.Toff_gh, SE3(Rot_rpy(rpy_add_handle), point_add_handle))\n",
    "            T_ah = T_xyzrpy((point_add_actor, rpy_add_actor))\n",
    "            T_ahg = np.matmul(T_ah, SE3_inv(T_handle_gh))\n",
    "            if obj_pscene.geometry == handle.geometry:\n",
    "                T_ao = T_ahg\n",
    "            else:\n",
    "                T_hgo = np.matmul(SE3_inv(handle.geometry.Toff), obj_pscene.geometry.Toff)\n",
    "                T_ao = np.matmul(T_ahg, T_hgo)\n",
    "            T_bo = obj_pscene.geometry.get_tf(crob.home_dict)\n",
    "            T_ba = np.matmul(T_bo, SE3_inv(T_ao))\n",
    "            dirkey = get_step_dirYZ(T_ba)\n",
    "            \n",
    "            assert to_state.binding_state[0][1] == bp, \"bp is not to_state.binding_state[0][1]\"\n",
    "            \n",
    "            for checker in checkers:\n",
    "                fname = checker.__class__.__name__\n",
    "                gtimer.tic(fname)\n",
    "                res = checker.check(gripper, obj_pscene, \n",
    "                                    handle, \n",
    "                                    redundancy_values, HOME_DICT)\n",
    "                etime = gtimer.toc(fname)\n",
    "                filter_time_dict[fname].append(etime)\n",
    "                filter_results_dict[fname][dirkey].append(res)\n",
    "            \n",
    "            success_reach, success_retrieve = False, False\n",
    "            with gtimer.block(\"reach\"):\n",
    "                Traj_reach, LastQ, error, success_reach, binding_list = mplan.plan_transition(\n",
    "                    from_state=from_state, to_state=to_state, redundancy_dict=redundancy_dict, timeout=TIMEOUT_REACH)\n",
    "            #             print(\"reach: {}\".format(success_reach))\n",
    "            Traj_retrieve = []\n",
    "            if success_reach:\n",
    "                if VISUALIZE:\n",
    "                    gscene.show_motion(Traj_reach, period=SHOW_PERIOD)\n",
    "                for bd in binding_list:\n",
    "                    pscene.rebind(bd, list2dict(LastQ, pscene.gscene.joint_names))\n",
    "                binding_state, state_param = pscene.get_object_state()\n",
    "                new_state = State(binding_state, state_param, list(LastQ), pscene)\n",
    "                end_state = new_state.copy(pscene)\n",
    "                end_state.Q = np.array(HOME_POSE)\n",
    "                with gtimer.block(\"retrieve\"):\n",
    "                    Traj_retrieve, LastQ, error, success_retrieve, binding_list = mplan.plan_transition(\n",
    "                        from_state=new_state, to_state=end_state, timeout=TIMEOUT_RETRIEVE)\n",
    "            #                 print(\"retrieve: {}\".format(success_retrieve))\n",
    "                if success_retrieve and VISUALIZE:\n",
    "                    gscene.show_motion(Traj_retrieve, period=SHOW_PERIOD)\n",
    "            pscene.set_object_state(from_state)\n",
    "            obs_count = 0\n",
    "            for obj_obs in obj_list:\n",
    "                if obj_obs.geometry == obj_pscene.geometry:\n",
    "                    continue\n",
    "                obs_count += 1 \n",
    "                gtimer.tic(\"get_pairwise_feature\")\n",
    "                featurevec = get_pairwise_feature(\n",
    "                    obj_pscene.geometry.Toff, obj_pscene.geometry.dims,\n",
    "                    obj_obs.geometry, wp.geometry.Toff[2,3]+wp.geometry.dims[2]/2)\n",
    "            feature_time_list.append(gtimer.toc(\"get_pairwise_feature\"))\n",
    "            assert obs_count == 1, \"obstacle count should be 1: this is pair-wise trainning data collection\"\n",
    "            features_dat_dict[dirkey].append(featurevec)\n",
    "#             ## for checking\n",
    "#             print(\"--------------------------------------------------\")\n",
    "#             print(\"REACH: {}\".format(success_retrieve))\n",
    "#             print(\"--------------------------------------------------\")\n",
    "#             print(\"ORIGINAL DIR: {}\".format(dirkey))\n",
    "#             print(\"ORIGINAL FEA: {}\".format(np.round(featurevec, 2)))\n",
    "#             res = pcheck.check(gripper, obj_pscene, \n",
    "#                                 handle, \n",
    "#                                 redundancy_values, HOME_DICT)\n",
    "#             print(\"--------------------------------------------------\")\n",
    "            reach_list_dict[dirkey].append(success_reach)\n",
    "            retrieve_list_dict[dirkey].append(success_retrieve)\n",
    "            reach_list.append(success_reach)\n",
    "            retrieve_list.append(success_retrieve)\n",
    "        pscene.set_object_state(initial_state)\n",
    "        gscene.update_markers_all()\n",
    "    i_s += 1\n",
    "    gscene.update_markers_all()\n",
    "    if i_s > 0 :\n",
    "        if i_s > i_print*N_print:\n",
    "            i_print +=  1\n",
    "            print_end = \"\\n\"\n",
    "        else:\n",
    "            print_end = \"\\r\"\n",
    "        time_elapsed = gtimer.toc(\"full_loop\")/1000\n",
    "        print(\"{} / {} in {} / {} s -- reach,retrieve = ({} %, {} %)                     \".format(\n",
    "            i_s, N_max_sample, round(time_elapsed, 2), round(time_elapsed/i_s*N_max_sample, 2), \n",
    "            round(np.mean(reach_list)*100, 1), round(np.mean(retrieve_list)*100, 1)), end=print_end)\n",
    "\n",
    "time_elapsed = gtimer.toc(\"full_loop\")/1000\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"============= Finished {} in {} s -- reach,retrieve = ({} %, {} %) =================\".format(\n",
    "    i_s, round(time_elapsed, 2), round(np.mean(reach_list)*100, 1), round(np.mean(retrieve_list)*100, 1)))\n",
    "\n",
    "\n",
    "## save data\n",
    "DATASET_PATH = os.path.join(ROBOT_DATA_ROOT, sorted(os.listdir(ROBOT_DATA_ROOT))[-1])\n",
    "\n",
    "save_pickle(os.path.join(DATASET_PATH, \"test_dat.pkl\"), \n",
    "            {\"features_dat_dict\": dict(**features_dat_dict), \n",
    "             \"retrieve_list_dict\": dict(**retrieve_list_dict), \n",
    "             \"feature_time_list\": feature_time_list, \n",
    "             \"filter_results_dict\": dict(**filter_results_dict),\n",
    "             \"filter_time_dict\": dict(**filter_time_dict)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dat_dict_train = defaultdict(list)\n",
    "retrieve_list_dict_train = defaultdict(list)\n",
    "feature_time_list_train = []\n",
    "filter_results_dict_train = defaultdict(lambda:defaultdict(list))\n",
    "filter_time_dict_train = defaultdict(list)\n",
    "for folder in sorted(os.listdir(ROBOT_DATA_ROOT)):\n",
    "    DATASET_PATH = os.path.join(ROBOT_DATA_ROOT, folder)\n",
    "    try: train_dat = load_pickle(os.path.join(DATASET_PATH, \"train_dat.pkl\"))\n",
    "    except: continue\n",
    "    for k, v in train_dat[\"features_dat_dict\"].items():\n",
    "        features_dat_dict_train[k] += v\n",
    "    for k, v in train_dat[\"retrieve_list_dict\"].items():\n",
    "        retrieve_list_dict_train[k] += v\n",
    "    feature_time_list_train += train_dat[\"feature_time_list\"]\n",
    "    for k, v in train_dat[\"filter_results_dict\"].items():\n",
    "        for vk, vv in v.items():\n",
    "            filter_results_dict_train[k][vk] += vv\n",
    "    for k, v in train_dat[\"filter_time_dict\"].items():\n",
    "        filter_time_dict_train[k] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dat_dict_test = defaultdict(list)\n",
    "retrieve_list_dict_test = defaultdict(list)\n",
    "feature_time_list_test = []\n",
    "filter_results_dict_test = defaultdict(lambda:defaultdict(list))\n",
    "filter_time_dict_test = defaultdict(list)\n",
    "for folder in sorted(os.listdir(ROBOT_DATA_ROOT)):\n",
    "    DATASET_PATH = os.path.join(ROBOT_DATA_ROOT, folder)\n",
    "    try: test_dat = load_pickle(os.path.join(DATASET_PATH, \"test_dat.pkl\"))\n",
    "    except: continue\n",
    "    for k, v in test_dat[\"features_dat_dict\"].items():\n",
    "        features_dat_dict_test[k] += v\n",
    "    for k, v in test_dat[\"retrieve_list_dict\"].items():\n",
    "        retrieve_list_dict_test[k] += v\n",
    "    feature_time_list_test += test_dat[\"feature_time_list\"]\n",
    "    for k, v in test_dat[\"filter_results_dict\"].items():\n",
    "        for vk, vv in v.items():\n",
    "            filter_results_dict_test[k][vk] += vv\n",
    "    for k, v in test_dat[\"filter_time_dict\"].items():\n",
    "        filter_time_dict_test[k] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "gtimer = GlobalTimer.instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "C_svm_list = [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
    "clf_dict_list = []\n",
    "\n",
    "for C_svm in C_svm_list:\n",
    "    train_res_all = []\n",
    "    success_list_all = []\n",
    "    clf_dict = {}\n",
    "    fail_bds = []\n",
    "    for rotbd in sorted(retrieve_list_dict_train.keys()):\n",
    "        feature_mat_train = np.array(features_dat_dict_train[rotbd])\n",
    "        feature_mat_train[:,:6] = np.abs(feature_mat_train[:,:6])\n",
    "        label_array = np.array(retrieve_list_dict_train[rotbd])\n",
    "        clf_dict[rotbd] = svm.SVC(kernel='rbf', C=C_svm, gamma='scale')\n",
    "        if np.all(label_array) or not np.any(label_array):\n",
    "            print(\"no good data - {}\".format(rotbd))\n",
    "            fail_bds.append(rotbd)\n",
    "            continue\n",
    "        clf_dict[rotbd].fit(feature_mat_train, label_array)\n",
    "        train_res_all = train_res_all + list(np.equal(clf_dict[rotbd].predict(feature_mat_train), label_array))\n",
    "        success_list_all = success_list_all + list(label_array)\n",
    "    train_res_all = np.array(train_res_all)\n",
    "\n",
    "    test_res_all = []\n",
    "    success_list_all_test = []\n",
    "    test_time_all = []\n",
    "    for rotbd in sorted(retrieve_list_dict_train.keys()):\n",
    "        if rotbd in fail_bds:\n",
    "            continue\n",
    "        feature_mat_test = np.array(features_dat_dict_test[rotbd])\n",
    "        feature_mat_test[:,:6] = np.abs(feature_mat_test[:,:6])\n",
    "        label_array_test = np.array(retrieve_list_dict_test[rotbd])\n",
    "        for features, label in zip(feature_mat_test, label_array_test):\n",
    "            clf = clf_dict[rotbd]\n",
    "            gtimer.tic(\"predict\")\n",
    "            res = clf.predict(np.array([features]))\n",
    "            test_time_all.append(gtimer.toc(\"predict\"))\n",
    "            test_res_all.append(np.equal(res[0], label))\n",
    "        success_list_all_test = success_list_all_test + list(label_array_test)\n",
    "    test_res_all = np.array(test_res_all)\n",
    "\n",
    "\n",
    "    print(\"=\" * 35 + \" C={} \".format(C_svm) + \"=\" * 35)\n",
    "    print(\"trainning accuracy ({}) = {} %\".format(len(train_res_all), round(np.mean(train_res_all) * 100, 2)))\n",
    "    print(\"trainning success accuracy ({}) = {} %\".format(int(np.sum(success_list_all)), \n",
    "        round(np.mean(train_res_all[np.where(success_list_all)]) * 100, 2)))\n",
    "    print(\"trainning failure accuracy ({}) = {} %\".format(int(np.sum(np.logical_not(success_list_all))), \n",
    "        round(np.mean(train_res_all[np.where(np.logical_not(success_list_all))]) * 100, 2)))\n",
    "    print(\"=\" * 80)\n",
    "    print(\"test accuracy ({}) = {} %\".format(len(test_res_all), round(np.mean(test_res_all) * 100, 2)))\n",
    "    print(\"test success accuracy ({}) = {} %\".format(int(np.sum(success_list_all_test)), \n",
    "        round(np.mean(test_res_all[np.where(success_list_all_test)]) * 100, 2)))\n",
    "    print(\"test failure accuracy ({}) = {} %\".format(int(np.sum(np.logical_not(success_list_all_test))), \n",
    "        round(np.mean(test_res_all[np.where(np.logical_not(success_list_all_test))]) * 100, 2)))\n",
    "    print(\"-\" * 80)\n",
    "    print(\"feature time = {} ({}/{})ms\".format(round(np.mean(feature_time_list_test), 3), \n",
    "                                          round(np.min(feature_time_list_test), 3), round(np.max(feature_time_list_test), 3)))\n",
    "    print(\"inference time = {} ({}/{})ms\".format(round(np.mean(test_time_all), 3), \n",
    "                                          round(np.min(test_time_all), 3), round(np.max(test_time_all), 3)))\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    train_acc_list.append(round(np.mean(train_res_all) * 100, 2))\n",
    "    test_acc_list.append(round(np.mean(test_res_all) * 100, 2))\n",
    "    clf_dict_list.append(clf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(C_svm_list, train_acc_list)\n",
    "plt.xscale('log')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(C_svm_list, test_acc_list)\n",
    "plt.xscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### log\n",
    "* 1000 x 12 max test accuracy / C_svm: 81.4 / 32\n",
    "* 2000 x 12 max test accuracy / C_svm: 83.4 / 256\n",
    "* 3000 x 12 max test accuracy / C_svm: 84.5 / 512\n",
    "* 3000 x 12 max test accuracy / C_svm: 84.9 / 1024 + scale gamma below\n",
    "* 4000 x 12 max test accuracy / C_svm: 85.0 / 1024\n",
    "* **5000 x 12 max test accuracy / C_svm: 85.7 / 1024**\n",
    "* 6000 x 12 max test accuracy / C_svm: 85.9 / 4096\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imax = np.argmax(test_acc_list)\n",
    "C_svm = C_svm_list[imax]\n",
    "clf_dict = clf_dict_list[imax]\n",
    "\n",
    "save_pickle(os.path.join(GF_MODEL_PATH, \"{}.pkl\".format(ROBOT_TYPE.name)), \n",
    "            {\"clf_dict\": clf_dict,\n",
    "             \"tool_link\": TOOL_LINK, \n",
    "             \"tool_T\": T_xyzrpy((TOOL_XYZ, TOOL_RPY))\n",
    "             }\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_pickle(os.path.join(GF_MODEL_PATH, \"{}.pkl\".format(ROBOT_TYPE.name)))\n",
    "clf_dict = model[\"clf_dict\"]\n",
    "\n",
    "test_res_all = []\n",
    "success_list_all_test = []\n",
    "test_time_all = []\n",
    "for rotbd in sorted(retrieve_list_dict_train.keys()):\n",
    "    if rotbd in fail_bds:\n",
    "        continue\n",
    "    feature_mat_test = np.array(features_dat_dict_test[rotbd])\n",
    "    feature_mat_test[:,:6] = np.abs(feature_mat_test[:,:6])\n",
    "    label_array_test = np.array(retrieve_list_dict_test[rotbd])\n",
    "    for features, label in zip(feature_mat_test, label_array_test):\n",
    "        clf = clf_dict[rotbd]\n",
    "        gtimer.tic(\"predict\")\n",
    "        res = clf.predict(np.array([features]))\n",
    "        test_time_all.append(gtimer.toc(\"predict\"))\n",
    "        test_res_all.append(np.equal(res[0], label))\n",
    "    success_list_all_test = success_list_all_test + list(label_array_test)\n",
    "test_res_all = np.array(test_res_all)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"test accuracy ({}) = {} %\".format(len(test_res_all), round(np.mean(test_res_all) * 100, 2)))\n",
    "print(\"test success accuracy ({}) = {} %\".format(int(np.sum(success_list_all_test)), \n",
    "    round(np.mean(test_res_all[np.where(success_list_all_test)]) * 100, 2)))\n",
    "print(\"test failure accuracy ({}) = {} %\".format(int(np.sum(np.logical_not(success_list_all_test))), \n",
    "    round(np.mean(test_res_all[np.where(np.logical_not(success_list_all_test))]) * 100, 2)))\n",
    "print(\"-\" * 80)\n",
    "print(\"feature time = {} ({}/{})ms\".format(round(np.mean(feature_time_list_test), 3), \n",
    "                                      round(np.min(feature_time_list_test), 3), round(np.max(feature_time_list_test), 3)))\n",
    "print(\"inference time = {} ({}/{})ms\".format(round(np.mean(test_time_all), 3), \n",
    "                                      round(np.min(test_time_all), 3), round(np.max(test_time_all), 3)))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test filter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname_accumm = []\n",
    "for checker in checkers:\n",
    "    fname_cur = checker.__class__.__name__\n",
    "    fname_accumm.append(fname_cur)\n",
    "    test_res_all = []\n",
    "    success_list_all_test = []\n",
    "    for rotbd in sorted(retrieve_list_dict_train.keys()):\n",
    "        filter_results = np.all([filter_results_dict_test[fname][rotbd] for fname in fname_accumm], axis=0)\n",
    "        label_array_test = np.array(retrieve_list_dict_test[rotbd])\n",
    "        test_res_all = test_res_all + list(np.equal(filter_results, label_array_test))\n",
    "        success_list_all_test = success_list_all_test + list(label_array_test)\n",
    "    test_res_all = np.array(test_res_all)\n",
    "    filter_times = np.sum([filter_time_dict_test[fname] for fname in fname_accumm], axis=0)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"{} accuracy = {} %\".format(fname_cur, round(np.mean(test_res_all) * 100, 2)))\n",
    "    print(\"{} success accuracy = {} %\".format(fname_cur,\n",
    "        round(np.mean(test_res_all[np.where(success_list_all_test)]) * 100, 2)))\n",
    "    print(\"{} failure accuracy = {} %\".format(fname_cur,\n",
    "        round(np.mean(test_res_all[np.where(np.logical_not(success_list_all_test))]) * 100, 2)))\n",
    "    print(\"-\" * 80)\n",
    "    print(\"{} time = {} ({}/{})ms\".format(fname_cur, round(np.mean(filter_times), 3), \n",
    "                                          round(np.min(filter_times), 3), round(np.max(filter_times), 3)))\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize grasp directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_dict = load_pickle(\"data/T_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in T_dict.keys():\n",
    "    T_dict[k] = np.array(T_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klist = sorted(T_dict.keys())\n",
    "for k in klist:\n",
    "    Tlist = T_dict[k]\n",
    "    print(k, np.mean(Tlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "for ik, k in enumerate(klist):\n",
    "    plt.subplot(2,6,ik+1)\n",
    "    plt.plot(T_dict[k][:,:3,0],'.')\n",
    "    plt.legend(\"xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "for ik, k in enumerate(klist):\n",
    "    plt.subplot(2,6,ik+1)\n",
    "    plt.plot(T_dict[k][:,:3,1],'.')\n",
    "    plt.legend(\"xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,5))\n",
    "for ik, k in enumerate(klist):\n",
    "    plt.subplot(2,6,ik+1)\n",
    "    plt.plot(T_dict[k][:,:3,2],'.')\n",
    "    plt.legend(\"xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2dir = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik = 0\n",
    "\n",
    "k = klist[ik+0]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3])\n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])\n",
    "\n",
    "k = klist[ik+1]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3], dims=(0.20, 0.005, 0.005))        \n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ik = 2\n",
    "\n",
    "k = klist[ik+0]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3])\n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])\n",
    "\n",
    "k = klist[ik+1]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3], dims=(0.20, 0.005, 0.005))        \n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ik = 4\n",
    "\n",
    "k = klist[ik+0]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3])\n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])\n",
    "\n",
    "k = klist[ik+1]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3], dims=(0.20, 0.005, 0.005))        \n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik = 6\n",
    "\n",
    "k = klist[ik+0]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3])\n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])\n",
    "\n",
    "k = klist[ik+1]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3], dims=(0.20, 0.005, 0.005))        \n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik = 8\n",
    "\n",
    "k = klist[ik+0]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3])\n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])\n",
    "\n",
    "k = klist[ik+1]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3], dims=(0.20, 0.005, 0.005))        \n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ik = 10\n",
    "\n",
    "k = klist[ik+0]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3])\n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])\n",
    "\n",
    "k = klist[ik+1]\n",
    "print(k)\n",
    "for ig, T in enumerate(T_dict[k]):\n",
    "    gscene.add_highlight_axis(\"ax\", \"{}_{}_{}\".format(k[0], k[1], ig),\n",
    "                              \"base_link\",  center=T[:3,3], orientation_mat=T[:3,:3], dims=(0.20, 0.005, 0.005))        \n",
    "meanY, meanZ = np.mean(T_dict[k][:, :3,1], axis=0), np.mean(T_dict[k][:, :3,2], axis=0)\n",
    "idxY, idxZ = np.argmax(np.abs(meanY)), np.argmax(np.abs(meanZ))\n",
    "sgnY, sgnZ = np.sign(meanY[idxY]), np.sign(meanZ[idxZ])\n",
    "\n",
    "dirY, dirZ = np.zeros(3,dtype=np.int), np.zeros(3,dtype=np.int)\n",
    "dirY[idxY], dirZ[idxZ] = sgnY, sgnZ\n",
    "key2dir[k] = (dirY, dirZ)\n",
    "print(key2dir[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"key2dir = {\")\n",
    "for k in sorted(key2dir.keys()):\n",
    "    print(\"\\t {} : ({}, {}),\".format(k, tuple(key2dir[k][0]), tuple(key2dir[k][1])))\n",
    "print(\"}\")\n",
    "\n",
    "for k in klist:\n",
    "    checkY, checkZ = all(np.matmul(T_dict[k][:, :3,1], key2dir[k][0])>0), all(np.matmul(T_dict[k][:, :3,2], key2dir[k][1])>0)\n",
    "    print(\"{} \\t - {} / {}\".format(k, checkY, checkZ))\n",
    "    gscene.clear_highlight()\n",
    "    assert checkY and checkZ, \"wrong assignment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2dir = {\n",
    "\t (False, 'hdl_bk_a') : ((0, -1, 0), (1, 0, 0)),\n",
    "\t (False, 'hdl_bk_b') : ((0, -1, 0), (-1, 0, 0)),\n",
    "\t (False, 'hdl_ft_a') : ((0, 1, 0), (1, 0, 0)),\n",
    "\t (False, 'hdl_ft_b') : ((0, 1, 0), (-1, 0, 0)),\n",
    "\t (False, 'hdl_tp_a') : ((0, 0, 1), (1, 0, 0)),\n",
    "\t (False, 'hdl_tp_b') : ((0, 0, 1), (-1, 0, 0)),\n",
    "\t (True, 'hdl_bk_a') : ((1, 0, 0), (0, 1, 0)),\n",
    "\t (True, 'hdl_bk_b') : ((1, 0, 0), (0, -1, 0)),\n",
    "\t (True, 'hdl_ft_a') : ((-1, 0, 0), (0, 1, 0)),\n",
    "\t (True, 'hdl_ft_b') : ((-1, 0, 0), (0, -1, 0)),\n",
    "\t (True, 'hdl_tp_a') : ((0, 0, 1), (0, 1, 0)),\n",
    "\t (True, 'hdl_tp_b') : ((0, 0, 1), (0, -1, 0)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
