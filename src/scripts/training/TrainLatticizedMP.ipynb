{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수정사항\n",
    "#### 2021.06.06\n",
    "* T_ej는 마지막 조인트 각도에 영향을 받음, 하지만 Q는 unkown이므로 특정하는게 불가능, T_ee로 학습할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "PROJ_DIR = os.environ[\"RNB_PLANNING_DIR\"]\n",
    "os.chdir(os.path.join(PROJ_DIR, \"src\"))\n",
    "\n",
    "from pkg.utils.utils_python3 import *\n",
    "DATA_PATH = os.path.join(PROJ_DIR, \"data\")\n",
    "LAT_DATA_PATH = os.path.join(DATA_PATH, \"latticized\")\n",
    "MODEL_PATH = os.path.join(PROJ_DIR, \"model\")\n",
    "LAT_MODEL_PATH = os.path.join(MODEL_PATH,\"latticized\")\n",
    "try_mkdir(MODEL_PATH)\n",
    "try_mkdir(LAT_MODEL_PATH)\n",
    "GRASP_FOLDER = \"grasp\"\n",
    "ARM10_FOLDER = \"arm_10\"\n",
    "ARM05_FOLDER = \"arm_05\"\n",
    "FULLS_FOLDER = \"full_scene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_TYPE_NAME=\"panda\"\n",
    "ROBOT_DATA_ROOT = os.path.join(LAT_DATA_PATH, ROBOT_TYPE_NAME)\n",
    "# ROBOT_DATA_ROOT = LAT_DATA_PATH\n",
    "ROBOT_MODEL_ROOT =  os.path.join(LAT_MODEL_PATH, ROBOT_TYPE_NAME)\n",
    "ARM_FOLDER = ARM10_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = sorted(os.listdir(ROBOT_DATA_ROOT))\n",
    "DATASET_TRAIN = dataset_list[:10]\n",
    "DATASET_TEST = dataset_list[10:15]\n",
    "print(DATASET_TRAIN)\n",
    "print(DATASET_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_TRAIN = ['20210214-232708', '20210215-041031', '20210215-085110', '20210215-133753', '20210215-184319', \n",
    "#                  '20210216-005455', '20210216-054418', '20210216-104554', '20210216-152114', '20210216-201729']\n",
    "# DATASET_TEST = ['20210217-010926', '20210217-063641', '20210217-113319', '20210217-162106', '20210217-205606']\n",
    "# DATASET_TRAIN = ['20210219-091338', '20210219-124428', '20210219-234147', '20210220-035639', '20210220-080119', \n",
    "#                  '20210220-122304', '20210220-160737', '20210220-194129', '20210220-234400', '20210221-043209']\n",
    "# DATASET_TEST = ['20210221-082144', '20210221-123619', '20210221-160542', '20210221-195509', '20210221-234239']\n",
    "GRASP_SHAPE = (20,20,20)\n",
    "ARM_SHAPE = (20,20,20)\n",
    "RH_MASK_SIZE = 512\n",
    "RH_MASK_STEP = 64\n",
    "\n",
    "data_pairs_train = []\n",
    "for dataset in DATASET_TRAIN:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_train.append((os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT, dataset, ARM_FOLDER, file)))\n",
    "print(\"train set: {}\".format(len(data_pairs_train)))        \n",
    "        \n",
    "        \n",
    "data_pairs_test = []\n",
    "for dataset in DATASET_TEST:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_test.append((os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT, dataset, ARM_FOLDER, file)))\n",
    "print(\"test set: {}\".format(len(data_pairs_test)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "def div_r_gaussian(r_val):\n",
    "    return gaussian(r_val, np.arange(0.1,1.2, 0.05),0.1)\n",
    "\n",
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.1)\n",
    "\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "#     r_ej, th_ej, h_ej = cart2cyl(*Tej[:3,3])  # not exact value, no use\n",
    "    r_mask = div_r_gaussian(r)\n",
    "    h_mask = div_h_gaussian(h)\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "#     rh_mask = np.array([r, h, r_ej, h_ej])\n",
    "    # r_ej_list.append(r_ej)\n",
    "    # h_ej_list.append(h_ej)\n",
    "    # reach_lb_list.append(reach_lb)\n",
    "#     Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "#     grasp_img = np.stack([grasp_tool_img, np.logical_or(grasp_obj_img, grasp_tar_img)], axis=-1)\n",
    "#     grasp_img = np.stack([grasp_tool_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.filtering.lattice_model.lattice_model import *\n",
    "\n",
    "# Create an instance of the model\n",
    "model = ResNetModelTP()\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = get_now()\n",
    "logpath = os.path.join(ROBOT_MODEL_ROOT, current_time)\n",
    "try_mkdir(logpath)\n",
    "train_log_dir = os.path.join(logpath, 'train')\n",
    "test_log_dir = os.path.join(logpath, 'test')\n",
    "model_log_dir = os.path.join(logpath, 'model_{}/')\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "shutil.copy(os.path.join(PROJ_DIR,'src', 'pkg','planning','filtering','lattice_model','lattice_model.py' ), logpath)\n",
    "print(f'Log path: {logpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_S = 0\n",
    "EPOCHS_E = 15\n",
    "BATCH_SIZE = 16\n",
    "LOG_STEP = 100\n",
    "N_train = len(data_pairs_train)\n",
    "N_test = len(data_pairs_test)\n",
    "\n",
    "for epoch in range(EPOCHS_S, EPOCHS_E):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    random.shuffle(data_pairs_train)\n",
    "    i_step = 0\n",
    "    data_batch, label_batch = [], []\n",
    "    for data_pair in data_pairs_train:\n",
    "        i_step += 1\n",
    "        grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "        data_batch.append([grasp_img, arm_img, rh_mask])\n",
    "        label_batch.append(label)\n",
    "        if i_step%BATCH_SIZE==0:\n",
    "            grasp_img_batch = np.array([grasp_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            arm_img_batch = np.array([arm_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            rh_mask_batch = np.array([rh_mask for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            label_batch = np.array(label_batch, dtype=np.int)\n",
    "            train_step([grasp_img_batch, arm_img_batch, rh_mask_batch], label_batch)\n",
    "            data_batch, label_batch = [], []\n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"train step - {}/{}        \".format(i_step, N_train), end = '\\r')\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    i_step = 0\n",
    "    data_batch, label_batch = [], []\n",
    "    for data_pair in data_pairs_test:\n",
    "        i_step += 1\n",
    "        grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "        data_batch.append([grasp_img, arm_img, rh_mask])\n",
    "        label_batch.append(label)\n",
    "        if i_step%BATCH_SIZE==0:\n",
    "            grasp_img_batch = np.array([grasp_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            arm_img_batch = np.array([arm_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            rh_mask_batch = np.array([rh_mask for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            label_batch = np.array(label_batch, dtype=np.int)\n",
    "            test_step([grasp_img_batch, arm_img_batch, rh_mask_batch], label_batch)\n",
    "            data_batch, label_batch = [], []\n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "            \n",
    "    model.save(model_log_dir.format(epoch + 1))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=================================================================\")\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Loss: {test_loss.result()}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )\n",
    "    print(\"=================================================================\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20210219-221604 : FC 적용 - 대충 86% 초반대\n",
    "* 20210219-230156 : Mask 적용 - 87 근접\n",
    "* 20210222-103707 : gaussian - 87.12\n",
    "* 20210222-110433 : gaussian 10 - 87.33\n",
    "* 20210222-113816 : feature half - 87.58\n",
    "* 20210222-120009 : feature half - 86.*\n",
    "* 20210222-134724 : feature 복구 - 87.32\n",
    "* 20210222-140832 : dropout 0.5 - 87.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20210219-221604\n",
    "```python\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    rh_mask = np.array([r, h, r_ej, h_ej])\n",
    "    # r_ej_list.append(r_ej)\n",
    "    # h_ej_list.append(h_ej)\n",
    "    # reach_lb_list.append(reach_lb)\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```\n",
    "\n",
    "* 20210219-230156 : Mask 적용 - 87 근접\n",
    "```python\n",
    "def div_r(r):\n",
    "    return floor(sigmoid((r)/0.1-7)*8)\n",
    "def div_h(h):\n",
    "    return floor(sigmoid((h+0.6)/0.2-4.5)*8)\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_class = div_r(r_ej)\n",
    "    h_class = div_h(h_ej)\n",
    "    r_mask = np.zeros(RH_MASK_SIZE)\n",
    "    r_mask[r_class*RH_MASK_STEP:r_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "    h_mask = np.zeros(RH_MASK_SIZE)\n",
    "    h_mask[h_class*RH_MASK_STEP:h_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```\n",
    "\n",
    "* 20210222-103707\n",
    "```python\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "def div_r_gaussian(r_val):\n",
    "    return gaussian(r_val, np.arange(0.1,1.2, 0.05),0.05)\n",
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.05)\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_mask = div_r_gaussian(r_ej)\n",
    "    h_mask = div_h_gaussian(h_ej)\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```\n",
    "\n",
    "* 20210222-110433\n",
    "```python\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "def div_r_gaussian(r_val):\n",
    "    return gaussian(r_val, np.arange(0.1,1.2, 0.05),0.1)\n",
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.1)\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_mask = div_r_gaussian(r_ej)\n",
    "    h_mask = div_h_gaussian(h_ej)\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_json(\"grasp_img.json\", np.where(grasp_img))\n",
    "# save_json(\"arm_img.json\", np.where(arm_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model = sorted(os.listdir(ROBOT_MODEL_ROOT))[-1]\n",
    "logpath = os.path.join(ROBOT_MODEL_ROOT, last_model)\n",
    "\n",
    "model_epoch_list = []\n",
    "acc_epoch_list = []\n",
    "loss_epoch_list = []\n",
    "last_save = sorted([item for item in os.listdir(logpath) if item.startswith(\"model\")], key=lambda x: int(x[6:]))[-1]\n",
    "# last_save = 'model_1'\n",
    "model_log_dir = os.path.join(logpath, last_save)\n",
    "\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(model_log_dir)\n",
    "\n",
    "@tf.function\n",
    "def inference(images):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    return predictions\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "@tf.function\n",
    "def calc_loss(labels, predictions):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    return loss_object(labels, predictions)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LOG_STEP = 100\n",
    "N_test = len(data_pairs_test)\n",
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "\n",
    "grasp_img, arm_img, rh_mask, label = load_data(data_pairs_test[0])\n",
    "res = inference([np.array([grasp_img]), np.array([arm_img]), np.array([rh_mask])])\n",
    "\n",
    "\n",
    "i_step = 0\n",
    "res_list = []\n",
    "label_list = []\n",
    "loss_list= []\n",
    "grasp_img_batch = []\n",
    "arm_img_batch = []\n",
    "rh_mask_batch = []\n",
    "label_batch = [] \n",
    "for data_pair in data_pairs_test:\n",
    "    i_step += 1\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "    grasp_img_batch.append(grasp_img)\n",
    "    arm_img_batch.append(arm_img)\n",
    "    rh_mask_batch.append(rh_mask)\n",
    "    label_batch.append(label)\n",
    "    if len(grasp_img_batch)==BATCH_SIZE:\n",
    "        grasp_img_batch, arm_img_batch, rh_mask_batch = np.array(grasp_img_batch), np.array(arm_img_batch), np.array(rh_mask_batch)\n",
    "        with gtimer.block(\"inference\"):\n",
    "            res = inference([grasp_img_batch, arm_img_batch, rh_mask_batch])\n",
    "        loss = calc_loss(label_batch, res)\n",
    "        res_list = res_list + list(res.numpy()>0.5)\n",
    "        label_list = label_list + label_batch\n",
    "        loss_list.append(loss.numpy())\n",
    "        grasp_img_batch = []\n",
    "        arm_img_batch = []\n",
    "        rh_mask_batch = []\n",
    "        label_batch = [] \n",
    "    if i_step%LOG_STEP==0:\n",
    "        print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')\n",
    "\n",
    "res_list = np.array(res_list)[:5000,1]\n",
    "label_list = np.array(label_list)[:5000,1]\n",
    "loss_list = np.array(loss_list)[:5000]\n",
    "\n",
    "acc = np.mean(np.equal(res_list, label_list)) * 100\n",
    "mean_loss = np.mean(loss_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"=================================================================\")\n",
    "print(\n",
    "    f'Test Loss: {mean_loss} \\n'\n",
    "    f'Test Accuracy: {acc} \\n'\n",
    "    f'TP / FN / ACC: {np.sum(np.logical_and(res_list, label_list))}, ' \n",
    "    f'{np.sum(np.logical_and(np.logical_not(res_list), label_list))}, ' \n",
    "    f'{round(np.mean(res_list[np.where(label_list)])*100,2)}\\n'\n",
    "    f'FP / TN / ACC: {np.sum(np.logical_and(res_list, np.logical_not(label_list)))}, '\n",
    "    f'{np.sum(np.logical_and(np.logical_not(res_list), np.logical_not(label_list)))}, '\n",
    "    f'{round(np.mean(np.logical_not(res_list[np.where(np.logical_not(label_list))]))*100,2)}\\n'\n",
    "    f'PACC / NACC / TACC: {round(np.mean(label_list[np.where(res_list)])*100,2)}, '\n",
    "    f'{round(np.mean(np.logical_not(label_list[np.where(np.logical_not(res_list))]))*100,2)}, '\n",
    "    f'{round(np.mean(res_list==label_list)*100,2)}\\n'\n",
    ")\n",
    "print(\"=================================================================\")\n",
    "print(\"\")\n",
    "print(gtimer)\n",
    "model_epoch_list.append(last_save)\n",
    "acc_epoch_list.append(acc)\n",
    "loss_epoch_list.append(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model = sorted(os.listdir(ROBOT_MODEL_ROOT))[-1]\n",
    "logpath = os.path.join(ROBOT_MODEL_ROOT, last_model)\n",
    "\n",
    "model_epoch_list = []\n",
    "acc_epoch_list = []\n",
    "loss_epoch_list = []\n",
    "# last_save = sorted([item for item in os.listdir(logpath) if item.startswith(\"model\")])[-1]\n",
    "# last_save = 'model_1'\n",
    "for last_save in sorted([item for item in os.listdir(logpath) if item.startswith(\"model\")], key=lambda x: int(x[6:])):\n",
    "    model_log_dir = os.path.join(logpath, last_save)\n",
    "\n",
    "    import tensorflow as tf\n",
    "    model = tf.keras.models.load_model(model_log_dir)\n",
    "\n",
    "    @tf.function\n",
    "    def inference(images):\n",
    "        # training=False is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=False)\n",
    "        return predictions\n",
    "\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    @tf.function\n",
    "    def calc_loss(labels, predictions):\n",
    "        # training=False is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        return loss_object(labels, predictions)\n",
    "    \n",
    "    BATCH_SIZE = 50\n",
    "    LOG_STEP = 100\n",
    "    N_test = len(data_pairs_test)\n",
    "    gtimer = GlobalTimer.instance()\n",
    "    gtimer.reset()\n",
    "\n",
    "    i_step = 0\n",
    "    res_list = []\n",
    "    label_list = []\n",
    "    loss_list= []\n",
    "    grasp_img_batch = []\n",
    "    arm_img_batch = []\n",
    "    rh_mask_batch = []\n",
    "    label_batch = [] \n",
    "    for data_pair in data_pairs_test:\n",
    "        i_step += 1\n",
    "        grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "        grasp_img_batch.append(grasp_img)\n",
    "        arm_img_batch.append(arm_img)\n",
    "        rh_mask_batch.append(rh_mask)\n",
    "        label_batch.append(label)\n",
    "        if len(grasp_img_batch)==BATCH_SIZE:\n",
    "            grasp_img_batch, arm_img_batch, rh_mask_batch = np.array(grasp_img_batch), np.array(arm_img_batch), np.array(rh_mask_batch)\n",
    "            with gtimer.block(\"inference\"):\n",
    "                res = inference([grasp_img_batch, arm_img_batch, rh_mask_batch])\n",
    "            loss = calc_loss(label_batch, res)\n",
    "            res_list = res_list + list(res.numpy()>0.5)\n",
    "            label_list = label_list + label_batch\n",
    "            loss_list.append(loss.numpy())\n",
    "            grasp_img_batch = []\n",
    "            arm_img_batch = []\n",
    "            rh_mask_batch = []\n",
    "            label_batch = [] \n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')\n",
    "\n",
    "    res_list = np.array(res_list)[:5000,1]\n",
    "    label_list = np.array(label_list)[:5000,1]\n",
    "    loss_list = np.array(loss_list)[:5000]\n",
    "    \n",
    "    acc = np.mean(np.equal(res_list, label_list)) * 100\n",
    "    mean_loss = np.mean(loss_list)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=================================================================\")\n",
    "    print(\n",
    "        f'Test Loss: {mean_loss} \\n'\n",
    "        f'Test Accuracy: {acc} \\n'\n",
    "        f'TP / FN / ACC: {np.sum(np.logical_and(res_list, label_list))}, ' \n",
    "        f'{np.sum(np.logical_and(np.logical_not(res_list), label_list))}, ' \n",
    "        f'{round(np.mean(res_list[np.where(label_list)])*100,2)}\\n'\n",
    "        f'FP / TN / ACC: {np.sum(np.logical_and(res_list, np.logical_not(label_list)))}, '\n",
    "        f'{np.sum(np.logical_and(np.logical_not(res_list), np.logical_not(label_list)))}, '\n",
    "        f'{round(np.mean(np.logical_not(res_list[np.where(np.logical_not(label_list))]))*100,2)}\\n'\n",
    "        f'PACC / NACC / TACC: {round(np.mean(label_list[np.where(res_list)])*100,2)}, '\n",
    "        f'{round(np.mean(np.logical_not(label_list[np.where(np.logical_not(res_list))]))*100,2)}, '\n",
    "        f'{round(np.mean(res_list==label_list)*100,2)}\\n'\n",
    "    )\n",
    "    print(\"=================================================================\")\n",
    "    print(\"\")\n",
    "    print(gtimer)\n",
    "    model_epoch_list.append(last_save)\n",
    "    acc_epoch_list.append(acc)\n",
    "    loss_epoch_list.append(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(model_epoch_list)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc_epoch_list)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(ROBOT_TYPE_NAME+\".json\", {\"epoch\": np.array(model_epoch_list), \"acc\": np.array(acc_epoch_list), \"loss\": np.array(loss_epoch_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on shared array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SharedArray as sa\n",
    "BATCH_SIZE = 1\n",
    "SERVER_PERIOD = 1e-2\n",
    "# Create an array in shared memory.\n",
    "robot_type_p = sa.attach(\"shm://robot_type\")\n",
    "grasp_img_p = sa.attach(\"shm://grasp_img\")\n",
    "arm_img_p = sa.attach(\"shm://arm_img\")\n",
    "rh_mask_p = sa.attach(\"shm://rh_mask\")\n",
    "result_p = sa.attach(\"shm://result\")\n",
    "query_in = sa.attach(\"shm://query_in\")\n",
    "response_out = sa.attach(\"shm://response_out\")\n",
    "query_quit = sa.attach(\"shm://query_quit\")\n",
    "\n",
    "def query_wait_response(grasp_img_batch, arm_img_batch, rh_mask_batch):\n",
    "    grasp_img_p[:] = grasp_img_batch[:]\n",
    "    arm_img_p[:] = arm_img_batch[:]\n",
    "    rh_mask_p[:] = rh_mask_batch[:]\n",
    "    query_in[0] = True\n",
    "    while not response_out[0]:\n",
    "        time.sleep(SERVER_PERIOD)\n",
    "    response_out[0] = False\n",
    "    return np.copy(result_p)\n",
    "\n",
    "def quit_shared_server():\n",
    "    query_quit[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_STEP = 100\n",
    "N_test = len(data_pairs_test)\n",
    "\n",
    "i_step = 0\n",
    "data_batch, label_batch = [], []\n",
    "result_list = []\n",
    "label_list = []\n",
    "for data_pair in data_pairs_test:\n",
    "    i_step += 1\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "    data_batch.append([grasp_img, arm_img, rh_mask])\n",
    "    label_batch.append(label)\n",
    "    if i_step%BATCH_SIZE==0:\n",
    "        grasp_img_batch = np.array([grasp_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "        arm_img_batch = np.array([arm_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "        rh_mask_batch = np.array([rh_mask for grasp_img, arm_img, rh_mask in data_batch])\n",
    "        label_batch = np.array(label_batch, dtype=np.int)\n",
    "        result = query_wait_response(grasp_img_batch, arm_img_batch, rh_mask_batch)\n",
    "        result_list.append(result)\n",
    "        label_list.append(label_batch)\n",
    "        data_batch, label_batch = [], []\n",
    "    if i_step%LOG_STEP==0:\n",
    "        print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all = np.array(result_list)\n",
    "label_all = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.round(result_all).astype(np.int) == label_all.astype(np.int), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_shared_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save gridded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pair = data_pairs_test[0]\n",
    "grasp_data = load_pickle(data_pair[0])\n",
    "arm_data = load_pickle(data_pair[1])\n",
    "grasp_tar_idx = grasp_data[b'tar']\n",
    "grasp_tool_idx = grasp_data[b'tool']\n",
    "arm_tar_idx = arm_data[b'tar']\n",
    "Tee = grasp_data[b'T_end_effector']\n",
    "Tej = grasp_data[b'T_end_joint']\n",
    "Tref_base = grasp_data[b'Tref_base']\n",
    "reach_lb = grasp_data[b'reach']\n",
    "retrieve_lb = grasp_data[b'retrieve']\n",
    "r, th, h = cart2cyl(*Tee[:3,3])\n",
    "r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "r_class = div_r(r_ej)\n",
    "h_class = div_h(h_ej)\n",
    "r_mask = np.zeros(RH_MASK_SIZE)\n",
    "r_mask[r_class*RH_MASK_STEP:r_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "h_mask = np.zeros(RH_MASK_SIZE)\n",
    "h_mask[h_class*RH_MASK_STEP:h_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "rh_mask = np.concatenate([r_mask, h_mask])\n",
    "# r_ej_list.append(r_ej)\n",
    "# h_ej_list.append(h_ej)\n",
    "# reach_lb_list.append(reach_lb)\n",
    "Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "grasp_img = np.stack([grasp_tool_img, grasp_tar_img], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_json(\"tar_arm.json\", np.array(np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_json(\"tool_effector.json\", np.array(np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)).transpose())\n",
    "# save_json(\"tar_effector.json\", np.array(np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize r, h class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "r_ej_list = []\n",
    "h_ej_list = []\n",
    "for data_pair in data_pairs_train:\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_ej_list.append(r_ej)\n",
    "    h_ej_list.append(h_ej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_r(r):\n",
    "    return floor(sigmoid((r)/0.1-7)*8)\n",
    "\n",
    "def div_h(h):\n",
    "    return floor(sigmoid((h+0.6)/0.2-5)*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(sorted([div_r(r_ej_) for r_ej_ in r_ej_list]), '.')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sorted([div_h(h_ej_) for h_ej_ in h_ej_list]), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(sorted([div_r(r_ej_) for r_ej_ in r_ej_list]), '.')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sorted([div_h(h_ej_) for h_ej_ in h_ej_list]), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(sorted(np.floor(np.divide(r_ej_list,0.1))), '.')\n",
    "plt.plot(sorted(np.floor(np.divide(h_ej_list,0.1))), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(sorted(r_ej_list), '.')\n",
    "plt.plot(sorted(h_ej_list), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(r_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 - 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min((np.array(r_ej_list)-0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.floor((np.array(r_ej_list)-0.2)/0.05).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = div_r_gaussian(sorted(r_ej_list)[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = div_h_gaussian(sorted(h_ej_list)[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,5))\n",
    "plt.imshow(x[np.newaxis, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.imshow(y[np.newaxis, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def div_h(h):\n",
    "    return floor(sigmoid((h+0.6)/0.2-4.5)*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.repeat(np.transpose([div_r_gaussian(r_val) for r_val in sorted(r_ej_list)]), 100, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.repeat(np.transpose([div_h_gaussian(h_val) for h_val in sorted(h_ej_list)]), 100, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(r_ej_list), max(r_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(h_ej_list), max(h_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(np.clip(np.floor((np.array(r_ej_list)-0.2)/0.05).astype(np.int), 0, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndat = len(data_pairs_train)\n",
    "sorted(r_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
