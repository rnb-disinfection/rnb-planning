{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수정사항\n",
    "#### 2021.06.06\n",
    "* T_ej는 마지막 조인트 각도에 영향을 받음, 하지만 Q는 unkown이므로 특정하는게 불가능, T_ee로 전부 새로 학습할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "PROJ_DIR = os.environ[\"RNB_PLANNING_DIR\"]\n",
    "os.chdir(os.path.join(PROJ_DIR, \"src\"))\n",
    "\n",
    "from pkg.utils.utils_python3 import *\n",
    "DATA_PATH = os.path.join(PROJ_DIR, \"data\")\n",
    "LAT_DATA_PATH = os.path.join(DATA_PATH, \"latticized\")\n",
    "MODEL_PATH = os.path.join(PROJ_DIR, \"model\")\n",
    "LAT_MODEL_PATH = os.path.join(MODEL_PATH,\"latticized\")\n",
    "try_mkdir(MODEL_PATH)\n",
    "try_mkdir(LAT_MODEL_PATH)\n",
    "GRASP_FOLDER = \"grasp\"\n",
    "ARM10_FOLDER = \"arm_10\"\n",
    "ARM05_FOLDER = \"arm_05\"\n",
    "FULLS_FOLDER = \"full_scene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_TYPE_NAME=\"panda\"\n",
    "ROBOT_DATA_ROOT = os.path.join(LAT_DATA_PATH, ROBOT_TYPE_NAME)\n",
    "ROBOT_DATA_ROOT_FAILS = ROBOT_DATA_ROOT+\"-failmore\"\n",
    "# ROBOT_DATA_ROOT = LAT_DATA_PATH\n",
    "ROBOT_MODEL_ROOT =  os.path.join(LAT_MODEL_PATH, ROBOT_TYPE_NAME+\"-balanced\")\n",
    "ARM_FOLDER = ARM10_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20210219-091338', '20210219-124428', '20210219-234147', '20210220-035639', '20210220-080119', '20210220-122304', '20210220-160737', '20210220-194129', '20210220-234400', '20210221-043209']\n",
      "['20210221-082144', '20210221-123619', '20210221-160542', '20210221-195509', '20210221-234239']\n",
      "['20210606-043936', '20210606-045859', '20210606-052131', '20210606-054248', '20210606-060031', '20210606-061942']\n",
      "['20210606-063854', '20210606-065755', '20210606-072108']\n"
     ]
    }
   ],
   "source": [
    "dataset_list = sorted(os.listdir(ROBOT_DATA_ROOT))\n",
    "DATASET_TRAIN = dataset_list[:10]\n",
    "DATASET_TEST = dataset_list[10:15]\n",
    "print(DATASET_TRAIN)\n",
    "print(DATASET_TEST)\n",
    "\n",
    "dataset_list_fails = sorted([folder for folder in os.listdir(ROBOT_DATA_ROOT_FAILS) if not folder.startswith(\".\")])\n",
    "DATASET_TRAIN_FAILS = dataset_list_fails[:6]\n",
    "DATASET_TEST_FAILS = dataset_list_fails[6:9]\n",
    "print(DATASET_TRAIN_FAILS)\n",
    "print(DATASET_TEST_FAILS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 10047\n",
      "test set: 5014\n",
      "train fail set: 6021\n",
      "test fail set: 3006\n"
     ]
    }
   ],
   "source": [
    "GRASP_SHAPE = (20,20,20)\n",
    "ARM_SHAPE = (20,20,20)\n",
    "RH_MASK_SIZE = 512\n",
    "RH_MASK_STEP = 64\n",
    "\n",
    "data_pairs_train_succ = []\n",
    "for dataset in DATASET_TRAIN:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_train_succ.append((os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT, dataset, ARM_FOLDER, file)))\n",
    "print(\"train set: {}\".format(len(data_pairs_train_succ)))        \n",
    "        \n",
    "        \n",
    "data_pairs_test_succ = []\n",
    "for dataset in DATASET_TEST:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_test_succ.append((os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT, dataset, ARM_FOLDER, file)))\n",
    "print(\"test set: {}\".format(len(data_pairs_test_succ)))        \n",
    "\n",
    "data_pairs_train_fails = []\n",
    "for dataset in DATASET_TRAIN_FAILS:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT_FAILS, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_train_fails.append((os.path.join(ROBOT_DATA_ROOT_FAILS, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT_FAILS, dataset, ARM_FOLDER, file)))\n",
    "print(\"train fail set: {}\".format(len(data_pairs_train_fails)))        \n",
    "        \n",
    "        \n",
    "data_pairs_test_fails = []\n",
    "for dataset in DATASET_TEST_FAILS:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT_FAILS, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_test_fails.append((os.path.join(ROBOT_DATA_ROOT_FAILS, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT_FAILS, dataset, ARM_FOLDER, file)))\n",
    "print(\"test fail set: {}\".format(len(data_pairs_test_fails)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "def div_r_gaussian(r_val):\n",
    "    return gaussian(r_val, np.arange(0.1,1.2, 0.05),0.1)\n",
    "\n",
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.1)\n",
    "\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "#     r_ej, th_ej, h_ej = cart2cyl(*Tej[:3,3])  # not exact value, no use\n",
    "    r_mask = div_r_gaussian(r)\n",
    "    h_mask = div_h_gaussian(h)\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "#     rh_mask = np.array([r, h, r_ej, h_ej])\n",
    "    # r_ej_list.append(r_ej)\n",
    "    # h_ej_list.append(h_ej)\n",
    "    # reach_lb_list.append(reach_lb)\n",
    "#     Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "#     grasp_img = np.stack([grasp_tool_img, np.logical_or(grasp_obj_img, grasp_tar_img)], axis=-1)\n",
    "#     grasp_img = np.stack([grasp_tool_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set succ: 10047\n",
      "train set fail: 6021\n",
      "train set all: 16068\n",
      "test set succ: 5014\n",
      "test set fail: 3006\n",
      "test set all: 8020\n"
     ]
    }
   ],
   "source": [
    "data_pairs_train = []\n",
    "for data_pairs in data_pairs_train_succ:\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pairs)\n",
    "    if True: #all(label):\n",
    "        data_pairs_train.append(data_pairs)\n",
    "N_succ = len(data_pairs_train)\n",
    "print(\"train set succ: {}\".format(N_succ))        \n",
    "\n",
    "\n",
    "for data_pairs in data_pairs_train_fails:\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pairs)\n",
    "    if True: #not all(label):\n",
    "        data_pairs_train.append(data_pairs)\n",
    "N_train = len(data_pairs_train)\n",
    "N_fail = N_train - N_succ\n",
    "print(\"train set fail: {}\".format(N_fail))\n",
    "print(\"train set all: {}\".format(N_train))\n",
    "\n",
    "data_pairs_test = []\n",
    "for data_pairs in data_pairs_test_succ:\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pairs)\n",
    "    if True: #all(label):\n",
    "        data_pairs_test.append(data_pairs)\n",
    "N_succ = len(data_pairs_test)\n",
    "print(\"test set succ: {}\".format(N_succ))        \n",
    "\n",
    "\n",
    "for data_pairs in data_pairs_test_fails:\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pairs)\n",
    "    if True: #not all(label):\n",
    "        data_pairs_test.append(data_pairs)\n",
    "N_test = len(data_pairs_test)\n",
    "N_fail = N_test - N_succ\n",
    "print(\"test set fail: {}\".format(N_fail))\n",
    "print(\"test set all: {}\".format(N_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.planning.filtering.lattice_model.lattice_model import *\n",
    "\n",
    "# Create an instance of the model\n",
    "model = ResNetModelTP()\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302\n"
     ]
    }
   ],
   "source": [
    "current_time = get_now()\n",
    "logpath = os.path.join(ROBOT_MODEL_ROOT, current_time)\n",
    "try_mkdir(logpath)\n",
    "train_log_dir = os.path.join(logpath, 'train')\n",
    "test_log_dir = os.path.join(logpath, 'test')\n",
    "model_log_dir = os.path.join(logpath, 'model_{}/')\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "shutil.copy(os.path.join(PROJ_DIR,'src', 'pkg','planning','filtering','lattice_model','lattice_model.py' ), logpath)\n",
    "print(f'Log path: {logpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step - 8000/8020           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Epoch 1, Loss: 0.38853707909584045, Accuracy: 82.59150695800781, Test Loss: 0.3111308813095093, Test Accuracy: 86.3647689819336\n",
      "=================================================================\n",
      "\n",
      "test step - 8000/8020           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Epoch 2, Loss: 0.300649493932724, Accuracy: 87.5435791015625, Test Loss: 0.2918878197669983, Test Accuracy: 87.7557373046875\n",
      "=================================================================\n",
      "\n",
      "test step - 8000/8020           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Epoch 3, Loss: 0.2728971242904663, Accuracy: 88.57071685791016, Test Loss: 0.33040252327919006, Test Accuracy: 87.20059967041016\n",
      "=================================================================\n",
      "\n",
      "test step - 8000/8020           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Epoch 4, Loss: 0.2625500559806824, Accuracy: 89.09984588623047, Test Loss: 0.3339874744415283, Test Accuracy: 86.82634735107422\n",
      "=================================================================\n",
      "\n",
      "test step - 8000/8020           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Epoch 5, Loss: 0.2456774115562439, Accuracy: 89.71613311767578, Test Loss: 0.39058542251586914, Test Accuracy: 86.4895248413086\n",
      "=================================================================\n",
      "\n",
      "test step - 8000/8020           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Epoch 6, Loss: 0.241510272026062, Accuracy: 89.97447204589844, Test Loss: 0.281714528799057, Test Accuracy: 87.98028564453125\n",
      "=================================================================\n",
      "\n",
      "test step - 8000/8020           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as conv1_layer_call_and_return_conditional_losses, conv1_layer_call_fn, activation_layer_call_and_return_conditional_losses, activation_layer_call_fn, conv_block3d_layer_call_and_return_conditional_losses while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda-balanced/20210606-082302/model_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Epoch 7, Loss: 0.2238096445798874, Accuracy: 90.80241394042969, Test Loss: 0.2958923876285553, Test Accuracy: 86.71407318115234\n",
      "=================================================================\n",
      "\n",
      "train step - 5100/16068        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e1cebfa4b4c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_pairs_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mi_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mgrasp_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marm_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrh_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrasp_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marm_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrh_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ca5e73a99e27>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_pair)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgrasp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0marm_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mgrasp_obj_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrasp_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'obj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rnb/Projects/rnb-planning/src/pkg/utils/utils_python3.py\u001b[0m in \u001b[0;36mload_pickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS_S = 0\n",
    "EPOCHS_E = 15\n",
    "BATCH_SIZE = 16\n",
    "LOG_STEP = 100\n",
    "N_train = len(data_pairs_train)\n",
    "N_test = len(data_pairs_test)\n",
    "random.shuffle(data_pairs_test)\n",
    "\n",
    "for epoch in range(EPOCHS_S, EPOCHS_E):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    random.shuffle(data_pairs_train)\n",
    "    i_step = 0\n",
    "    data_batch, label_batch = [], []\n",
    "    for data_pair in data_pairs_train:\n",
    "        i_step += 1\n",
    "        grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "        data_batch.append([grasp_img, arm_img, rh_mask])\n",
    "        label_batch.append(label)\n",
    "        if i_step%BATCH_SIZE==0:\n",
    "            grasp_img_batch = np.array([grasp_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            arm_img_batch = np.array([arm_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            rh_mask_batch = np.array([rh_mask for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            label_batch = np.array(label_batch, dtype=np.int)\n",
    "            train_step([grasp_img_batch, arm_img_batch, rh_mask_batch], label_batch)\n",
    "            data_batch, label_batch = [], []\n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"train step - {}/{}        \".format(i_step, N_train), end = '\\r')\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    i_step = 0\n",
    "    data_batch, label_batch = [], []\n",
    "    for data_pair in data_pairs_test:\n",
    "        i_step += 1\n",
    "        grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "        data_batch.append([grasp_img, arm_img, rh_mask])\n",
    "        label_batch.append(label)\n",
    "        if i_step%BATCH_SIZE==0:\n",
    "            grasp_img_batch = np.array([grasp_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            arm_img_batch = np.array([arm_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            rh_mask_batch = np.array([rh_mask for grasp_img, arm_img, rh_mask in data_batch])\n",
    "            label_batch = np.array(label_batch, dtype=np.int)\n",
    "            test_step([grasp_img_batch, arm_img_batch, rh_mask_batch], label_batch)\n",
    "            data_batch, label_batch = [], []\n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "            \n",
    "    model.save(model_log_dir.format(epoch + 1))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=================================================================\")\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Loss: {test_loss.result()}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )\n",
    "    print(\"=================================================================\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New train 2021-06\n",
    "* **[IMPORTANT] 이전에 Tej 사용 틀린 점 보완 했음** \n",
    "* 20210606-080139 : first balanced train trial, 96.6% 달성 / 이전 데이터와 collision boundary shape 차이일 수 있음\n",
    "* 20210606-082302 : 이전 데이터와 전부 섞어서 collision boundary shape 차이 영향 확인 - 87% 가량, 영향 확실, 재수집 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20210219-221604 : FC 적용 - 대충 86% 초반대\n",
    "* 20210219-230156 : Mask 적용 - 87 근접\n",
    "* 20210222-103707 : gaussian - 87.12\n",
    "* 20210222-110433 : gaussian 10 - 87.33\n",
    "* 20210222-113816 : feature half - 87.58\n",
    "* 20210222-120009 : feature half - 86.*\n",
    "* 20210222-134724 : feature 복구 - 87.32\n",
    "* 20210222-140832 : dropout 0.5 - 87.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20210219-221604\n",
    "```python\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    rh_mask = np.array([r, h, r_ej, h_ej])\n",
    "    # r_ej_list.append(r_ej)\n",
    "    # h_ej_list.append(h_ej)\n",
    "    # reach_lb_list.append(reach_lb)\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```\n",
    "\n",
    "* 20210219-230156 : Mask 적용 - 87 근접\n",
    "```python\n",
    "def div_r(r):\n",
    "    return floor(sigmoid((r)/0.1-7)*8)\n",
    "def div_h(h):\n",
    "    return floor(sigmoid((h+0.6)/0.2-4.5)*8)\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_class = div_r(r_ej)\n",
    "    h_class = div_h(h_ej)\n",
    "    r_mask = np.zeros(RH_MASK_SIZE)\n",
    "    r_mask[r_class*RH_MASK_STEP:r_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "    h_mask = np.zeros(RH_MASK_SIZE)\n",
    "    h_mask[h_class*RH_MASK_STEP:h_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```\n",
    "\n",
    "* 20210222-103707\n",
    "```python\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "def div_r_gaussian(r_val):\n",
    "    return gaussian(r_val, np.arange(0.1,1.2, 0.05),0.05)\n",
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.05)\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_mask = div_r_gaussian(r_ej)\n",
    "    h_mask = div_h_gaussian(h_ej)\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```\n",
    "\n",
    "* 20210222-110433\n",
    "```python\n",
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "def div_r_gaussian(r_val):\n",
    "    return gaussian(r_val, np.arange(0.1,1.2, 0.05),0.1)\n",
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.1)\n",
    "def load_data(data_pair):\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_mask = div_r_gaussian(r_ej)\n",
    "    h_mask = div_h_gaussian(h_ej)\n",
    "    rh_mask = np.concatenate([r_mask, h_mask])\n",
    "    Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "    grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_obj_img = np.zeros(GRASP_SHAPE)\n",
    "    grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "    grasp_obj_img[np.unravel_index(grasp_obj_idx, shape=GRASP_SHAPE)] = 1\n",
    "    arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "    arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "    grasp_img = np.stack([grasp_tool_img, grasp_obj_img, grasp_tar_img], axis=-1)\n",
    "    label = np.array([reach_lb, retrieve_lb])\n",
    "    return grasp_img, arm_img, rh_mask, label\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_json(\"grasp_img.json\", np.where(grasp_img))\n",
    "# save_json(\"arm_img.json\", np.where(arm_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model = sorted(os.listdir(ROBOT_MODEL_ROOT))[-1]\n",
    "logpath = os.path.join(ROBOT_MODEL_ROOT, last_model)\n",
    "\n",
    "model_epoch_list = []\n",
    "acc_epoch_list = []\n",
    "loss_epoch_list = []\n",
    "last_save = sorted([item for item in os.listdir(logpath) if item.startswith(\"model\")], key=lambda x: int(x[6:]))[-1]\n",
    "# last_save = 'model_1'\n",
    "model_log_dir = os.path.join(logpath, last_save)\n",
    "\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(model_log_dir)\n",
    "\n",
    "@tf.function\n",
    "def inference(images):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    return predictions\n",
    "\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "@tf.function\n",
    "def calc_loss(labels, predictions):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    return loss_object(labels, predictions)\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LOG_STEP = 100\n",
    "N_test = len(data_pairs_test)\n",
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "\n",
    "grasp_img, arm_img, rh_mask, label = load_data(data_pairs_test[0])\n",
    "res = inference([np.array([grasp_img]), np.array([arm_img]), np.array([rh_mask])])\n",
    "\n",
    "\n",
    "i_step = 0\n",
    "res_list = []\n",
    "label_list = []\n",
    "loss_list= []\n",
    "grasp_img_batch = []\n",
    "arm_img_batch = []\n",
    "rh_mask_batch = []\n",
    "label_batch = [] \n",
    "for data_pair in data_pairs_test:\n",
    "    i_step += 1\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "    grasp_img_batch.append(grasp_img)\n",
    "    arm_img_batch.append(arm_img)\n",
    "    rh_mask_batch.append(rh_mask)\n",
    "    label_batch.append(label)\n",
    "    if len(grasp_img_batch)==BATCH_SIZE:\n",
    "        grasp_img_batch, arm_img_batch, rh_mask_batch = np.array(grasp_img_batch), np.array(arm_img_batch), np.array(rh_mask_batch)\n",
    "        with gtimer.block(\"inference\"):\n",
    "            res = inference([grasp_img_batch, arm_img_batch, rh_mask_batch])\n",
    "        loss = calc_loss(label_batch, res)\n",
    "        res_list = res_list + list(res.numpy()>0.5)\n",
    "        label_list = label_list + label_batch\n",
    "        loss_list.append(loss.numpy())\n",
    "        grasp_img_batch = []\n",
    "        arm_img_batch = []\n",
    "        rh_mask_batch = []\n",
    "        label_batch = [] \n",
    "    if i_step%LOG_STEP==0:\n",
    "        print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')\n",
    "\n",
    "res_list = np.array(res_list)[:5000,1]\n",
    "label_list = np.array(label_list)[:5000,1]\n",
    "loss_list = np.array(loss_list)[:5000]\n",
    "\n",
    "acc = np.mean(np.equal(res_list, label_list)) * 100\n",
    "mean_loss = np.mean(loss_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"=================================================================\")\n",
    "print(\n",
    "    f'Test Loss: {mean_loss} \\n'\n",
    "    f'Test Accuracy: {acc} \\n'\n",
    "    f'TP / FN / ACC: {np.sum(np.logical_and(res_list, label_list))}, ' \n",
    "    f'{np.sum(np.logical_and(np.logical_not(res_list), label_list))}, ' \n",
    "    f'{round(np.mean(res_list[np.where(label_list)])*100,2)}\\n'\n",
    "    f'FP / TN / ACC: {np.sum(np.logical_and(res_list, np.logical_not(label_list)))}, '\n",
    "    f'{np.sum(np.logical_and(np.logical_not(res_list), np.logical_not(label_list)))}, '\n",
    "    f'{round(np.mean(np.logical_not(res_list[np.where(np.logical_not(label_list))]))*100,2)}\\n'\n",
    "    f'PACC / NACC / TACC: {round(np.mean(label_list[np.where(res_list)])*100,2)}, '\n",
    "    f'{round(np.mean(np.logical_not(label_list[np.where(np.logical_not(res_list))]))*100,2)}, '\n",
    "    f'{round(np.mean(res_list==label_list)*100,2)}\\n'\n",
    ")\n",
    "print(\"=================================================================\")\n",
    "print(\"\")\n",
    "print(gtimer)\n",
    "model_epoch_list.append(last_save)\n",
    "acc_epoch_list.append(acc)\n",
    "loss_epoch_list.append(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_model = sorted(os.listdir(ROBOT_MODEL_ROOT))[-1]\n",
    "logpath = os.path.join(ROBOT_MODEL_ROOT, last_model)\n",
    "\n",
    "model_epoch_list = []\n",
    "acc_epoch_list = []\n",
    "loss_epoch_list = []\n",
    "# last_save = sorted([item for item in os.listdir(logpath) if item.startswith(\"model\")])[-1]\n",
    "# last_save = 'model_1'\n",
    "for last_save in sorted([item for item in os.listdir(logpath) if item.startswith(\"model\")], key=lambda x: int(x[6:])):\n",
    "    model_log_dir = os.path.join(logpath, last_save)\n",
    "\n",
    "    import tensorflow as tf\n",
    "    model = tf.keras.models.load_model(model_log_dir)\n",
    "\n",
    "    @tf.function\n",
    "    def inference(images):\n",
    "        # training=False is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=False)\n",
    "        return predictions\n",
    "\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    @tf.function\n",
    "    def calc_loss(labels, predictions):\n",
    "        # training=False is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        return loss_object(labels, predictions)\n",
    "    \n",
    "    BATCH_SIZE = 50\n",
    "    LOG_STEP = 100\n",
    "    N_test = len(data_pairs_test)\n",
    "    gtimer = GlobalTimer.instance()\n",
    "    gtimer.reset()\n",
    "\n",
    "    i_step = 0\n",
    "    res_list = []\n",
    "    label_list = []\n",
    "    loss_list= []\n",
    "    grasp_img_batch = []\n",
    "    arm_img_batch = []\n",
    "    rh_mask_batch = []\n",
    "    label_batch = [] \n",
    "    for data_pair in data_pairs_test:\n",
    "        i_step += 1\n",
    "        grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "        grasp_img_batch.append(grasp_img)\n",
    "        arm_img_batch.append(arm_img)\n",
    "        rh_mask_batch.append(rh_mask)\n",
    "        label_batch.append(label)\n",
    "        if len(grasp_img_batch)==BATCH_SIZE:\n",
    "            grasp_img_batch, arm_img_batch, rh_mask_batch = np.array(grasp_img_batch), np.array(arm_img_batch), np.array(rh_mask_batch)\n",
    "            with gtimer.block(\"inference\"):\n",
    "                res = inference([grasp_img_batch, arm_img_batch, rh_mask_batch])\n",
    "            loss = calc_loss(label_batch, res)\n",
    "            res_list = res_list + list(res.numpy()>0.5)\n",
    "            label_list = label_list + label_batch\n",
    "            loss_list.append(loss.numpy())\n",
    "            grasp_img_batch = []\n",
    "            arm_img_batch = []\n",
    "            rh_mask_batch = []\n",
    "            label_batch = [] \n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')\n",
    "\n",
    "    res_list = np.array(res_list)[:5000,1]\n",
    "    label_list = np.array(label_list)[:5000,1]\n",
    "    loss_list = np.array(loss_list)[:5000]\n",
    "    \n",
    "    acc = np.mean(np.equal(res_list, label_list)) * 100\n",
    "    mean_loss = np.mean(loss_list)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"=================================================================\")\n",
    "    print(\n",
    "        f'Test Loss: {mean_loss} \\n'\n",
    "        f'Test Accuracy: {acc} \\n'\n",
    "        f'TP / FN / ACC: {np.sum(np.logical_and(res_list, label_list))}, ' \n",
    "        f'{np.sum(np.logical_and(np.logical_not(res_list), label_list))}, ' \n",
    "        f'{round(np.mean(res_list[np.where(label_list)])*100,2)}\\n'\n",
    "        f'FP / TN / ACC: {np.sum(np.logical_and(res_list, np.logical_not(label_list)))}, '\n",
    "        f'{np.sum(np.logical_and(np.logical_not(res_list), np.logical_not(label_list)))}, '\n",
    "        f'{round(np.mean(np.logical_not(res_list[np.where(np.logical_not(label_list))]))*100,2)}\\n'\n",
    "        f'PACC / NACC / TACC: {round(np.mean(label_list[np.where(res_list)])*100,2)}, '\n",
    "        f'{round(np.mean(np.logical_not(label_list[np.where(np.logical_not(res_list))]))*100,2)}, '\n",
    "        f'{round(np.mean(res_list==label_list)*100,2)}\\n'\n",
    "    )\n",
    "    print(\"=================================================================\")\n",
    "    print(\"\")\n",
    "    print(gtimer)\n",
    "    model_epoch_list.append(last_save)\n",
    "    acc_epoch_list.append(acc)\n",
    "    loss_epoch_list.append(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(model_epoch_list)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc_epoch_list)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss_epoch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(ROBOT_TYPE_NAME+\".json\", {\"epoch\": np.array(model_epoch_list), \"acc\": np.array(acc_epoch_list), \"loss\": np.array(loss_epoch_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on shared array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SharedArray as sa\n",
    "BATCH_SIZE = 1\n",
    "SERVER_PERIOD = 1e-2\n",
    "# Create an array in shared memory.\n",
    "robot_type_p = sa.attach(\"shm://robot_type\")\n",
    "grasp_img_p = sa.attach(\"shm://grasp_img\")\n",
    "arm_img_p = sa.attach(\"shm://arm_img\")\n",
    "rh_mask_p = sa.attach(\"shm://rh_mask\")\n",
    "result_p = sa.attach(\"shm://result\")\n",
    "query_in = sa.attach(\"shm://query_in\")\n",
    "response_out = sa.attach(\"shm://response_out\")\n",
    "query_quit = sa.attach(\"shm://query_quit\")\n",
    "\n",
    "def query_wait_response(grasp_img_batch, arm_img_batch, rh_mask_batch):\n",
    "    grasp_img_p[:] = grasp_img_batch[:]\n",
    "    arm_img_p[:] = arm_img_batch[:]\n",
    "    rh_mask_p[:] = rh_mask_batch[:]\n",
    "    query_in[0] = True\n",
    "    while not response_out[0]:\n",
    "        time.sleep(SERVER_PERIOD)\n",
    "    response_out[0] = False\n",
    "    return np.copy(result_p)\n",
    "\n",
    "def quit_shared_server():\n",
    "    query_quit[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_STEP = 100\n",
    "N_test = len(data_pairs_test)\n",
    "\n",
    "i_step = 0\n",
    "data_batch, label_batch = [], []\n",
    "result_list = []\n",
    "label_list = []\n",
    "for data_pair in data_pairs_test:\n",
    "    i_step += 1\n",
    "    grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "    data_batch.append([grasp_img, arm_img, rh_mask])\n",
    "    label_batch.append(label)\n",
    "    if i_step%BATCH_SIZE==0:\n",
    "        grasp_img_batch = np.array([grasp_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "        arm_img_batch = np.array([arm_img for grasp_img, arm_img, rh_mask in data_batch])\n",
    "        rh_mask_batch = np.array([rh_mask for grasp_img, arm_img, rh_mask in data_batch])\n",
    "        label_batch = np.array(label_batch, dtype=np.int)\n",
    "        result = query_wait_response(grasp_img_batch, arm_img_batch, rh_mask_batch)\n",
    "        result_list.append(result)\n",
    "        label_list.append(label_batch)\n",
    "        data_batch, label_batch = [], []\n",
    "    if i_step%LOG_STEP==0:\n",
    "        print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_all = np.array(result_list)\n",
    "label_all = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.round(result_all).astype(np.int) == label_all.astype(np.int), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quit_shared_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save gridded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pair = data_pairs_test[0]\n",
    "grasp_data = load_pickle(data_pair[0])\n",
    "arm_data = load_pickle(data_pair[1])\n",
    "grasp_tar_idx = grasp_data[b'tar']\n",
    "grasp_tool_idx = grasp_data[b'tool']\n",
    "arm_tar_idx = arm_data[b'tar']\n",
    "Tee = grasp_data[b'T_end_effector']\n",
    "Tej = grasp_data[b'T_end_joint']\n",
    "Tref_base = grasp_data[b'Tref_base']\n",
    "reach_lb = grasp_data[b'reach']\n",
    "retrieve_lb = grasp_data[b'retrieve']\n",
    "r, th, h = cart2cyl(*Tee[:3,3])\n",
    "r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "r_class = div_r(r_ej)\n",
    "h_class = div_h(h_ej)\n",
    "r_mask = np.zeros(RH_MASK_SIZE)\n",
    "r_mask[r_class*RH_MASK_STEP:r_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "h_mask = np.zeros(RH_MASK_SIZE)\n",
    "h_mask[h_class*RH_MASK_STEP:h_class*RH_MASK_STEP+RH_MASK_STEP] = 1\n",
    "rh_mask = np.concatenate([r_mask, h_mask])\n",
    "# r_ej_list.append(r_ej)\n",
    "# h_ej_list.append(h_ej)\n",
    "# reach_lb_list.append(reach_lb)\n",
    "Tref = SE3(Rot_axis(3, th), Tee[:3,3])\n",
    "grasp_tool_img = np.zeros(GRASP_SHAPE)\n",
    "grasp_tar_img = np.zeros(GRASP_SHAPE)\n",
    "grasp_tool_img[np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)] = 1\n",
    "grasp_tar_img[np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)] = 1\n",
    "arm_img = np.zeros(ARM_SHAPE+(1,))\n",
    "arm_img[np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)] = 1\n",
    "grasp_img = np.stack([grasp_tool_img, grasp_tar_img], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_json(\"tar_arm.json\", np.array(np.unravel_index(arm_tar_idx, shape=ARM_SHAPE)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_json(\"tool_effector.json\", np.array(np.unravel_index(grasp_tool_idx, shape=GRASP_SHAPE)).transpose())\n",
    "# save_json(\"tar_effector.json\", np.array(np.unravel_index(grasp_tar_idx, shape=GRASP_SHAPE)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize r, h class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "r_ej_list = []\n",
    "h_ej_list = []\n",
    "for data_pair in data_pairs_train:\n",
    "    grasp_data = load_pickle(data_pair[0])\n",
    "    arm_data = load_pickle(data_pair[1])\n",
    "    grasp_obj_idx = grasp_data[b'obj']\n",
    "    grasp_tar_idx = grasp_data[b'tar']\n",
    "    grasp_tool_idx = grasp_data[b'tool']\n",
    "    arm_tar_idx = arm_data[b'tar']\n",
    "    Tee = grasp_data[b'T_end_effector']\n",
    "    Tej = grasp_data[b'T_end_joint']\n",
    "    Tref_base = grasp_data[b'Tref_base']\n",
    "    reach_lb = grasp_data[b'reach']\n",
    "    retrieve_lb = grasp_data[b'retrieve']\n",
    "    r, th, h = cart2cyl(*Tee[:3,3])\n",
    "    r_ej, th, h_ej = cart2cyl(*Tej[:3,3])\n",
    "    r_ej_list.append(r_ej)\n",
    "    h_ej_list.append(h_ej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_r(r):\n",
    "    return floor(sigmoid((r)/0.1-7)*8)\n",
    "\n",
    "def div_h(h):\n",
    "    return floor(sigmoid((h+0.6)/0.2-5)*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(sorted([div_r(r_ej_) for r_ej_ in r_ej_list]), '.')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sorted([div_h(h_ej_) for h_ej_ in h_ej_list]), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(sorted([div_r(r_ej_) for r_ej_ in r_ej_list]), '.')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sorted([div_h(h_ej_) for h_ej_ in h_ej_list]), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(sorted(np.floor(np.divide(r_ej_list,0.1))), '.')\n",
    "plt.plot(sorted(np.floor(np.divide(h_ej_list,0.1))), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(sorted(r_ej_list), '.')\n",
    "plt.plot(sorted(h_ej_list), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(r_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 - 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min((np.array(r_ej_list)-0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.floor((np.array(r_ej_list)-0.2)/0.05).astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = div_r_gaussian(sorted(r_ej_list)[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = div_h_gaussian(sorted(h_ej_list)[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,5))\n",
    "plt.imshow(x[np.newaxis, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.imshow(y[np.newaxis, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_h_gaussian(h_val):\n",
    "    return gaussian(h_val, np.arange(-0.5,1.1, 0.05),0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def div_h(h):\n",
    "    return floor(sigmoid((h+0.6)/0.2-4.5)*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.repeat(np.transpose([div_r_gaussian(r_val) for r_val in sorted(r_ej_list)]), 100, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.repeat(np.transpose([div_h_gaussian(h_val) for h_val in sorted(h_ej_list)]), 100, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(r_ej_list), max(r_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(h_ej_list), max(h_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(np.clip(np.floor((np.array(r_ej_list)-0.2)/0.05).astype(np.int), 0, 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndat = len(data_pairs_train)\n",
    "sorted(r_ej_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
