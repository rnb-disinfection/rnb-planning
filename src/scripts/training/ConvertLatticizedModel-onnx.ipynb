{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt.trt_convert import TrtPrecisionMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = None\n",
    "rtype = \"panda\"\n",
    "PRECISION = TrtPrecisionMode.FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SharedArray as sa\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "\n",
    "PROJ_DIR = os.environ[\"RNB_PLANNING_DIR\"]\n",
    "sys.path.append(os.path.join(PROJ_DIR, \"src\"))\n",
    "\n",
    "from pkg.utils.utils_python3 import *\n",
    "from pkg.controller.robot_config import RobotType\n",
    "from pkg.planning.filtering.lattice_model.data_utils import *\n",
    "import numpy as np\n",
    "int2rtypename = {v.value:v.name for v in RobotType}\n",
    "DATA_PATH = os.path.join(PROJ_DIR, \"data\")\n",
    "MODEL_PATH = os.path.join(PROJ_DIR, \"model\")\n",
    "LAT_MODEL_PATH = os.path.join(MODEL_PATH,\"latticized\")\n",
    "try_mkdir(MODEL_PATH)\n",
    "try_mkdir(LAT_MODEL_PATH)\n",
    "GRASP_FOLDER = \"grasp\"\n",
    "ARM10_FOLDER = \"arm_10\"\n",
    "ARM05_FOLDER = \"arm_05\"\n",
    "FULLS_FOLDER = \"full_scene\"\n",
    "\n",
    "ARM_FOLDER = ARM10_FOLDER\n",
    "GRASP_SHAPE = (20,20,20)\n",
    "ARM_SHAPE = (20,20,20)\n",
    "RH_MASK_SIZE = 512\n",
    "RH_MASK_STEP = 64\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "SERVER_PERIOD = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_TYPE_NAME = rtype\n",
    "ROBOT_MODEL_ROOT = os.path.join(LAT_MODEL_PATH, ROBOT_TYPE_NAME)\n",
    "last_model = sorted(os.listdir(ROBOT_MODEL_ROOT))[-1]\n",
    "last_save = sorted([item for item in os.listdir(os.path.join(ROBOT_MODEL_ROOT, last_model)) if item.startswith(\"model\")])[-1]\n",
    "model_path_rel = os.path.join(last_model, last_save)\n",
    "model_log_dir = os.path.join(ROBOT_MODEL_ROOT, model_path_rel)\n",
    "model_log_dir_trt = os.path.join(ROBOT_MODEL_ROOT, model_path_rel.replace(\"model\", \"trt\")+\"-\"+PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20210920-194311', '20210920-233941', '20210921-032259', '20210921-072543', '20210921-111615', '20210921-150638', '20210921-192001', '20210921-232015', '20210922-033134', '20210922-074138']\n",
      "['20210922-113744', '20210922-153855', '20210922-193840', '20210922-233844', '20210923-040005']\n",
      "train set: 10003\n",
      "test set: 5000\n",
      "====================\n",
      "filtered data: 10000 / 5000\n"
     ]
    }
   ],
   "source": [
    "LAT_DATA_PATH = os.path.join(DATA_PATH, \"latticized\")\n",
    "\n",
    "ROBOT_DATA_ROOT = os.path.join(LAT_DATA_PATH, ROBOT_TYPE_NAME)\n",
    "\n",
    "dataset_list = sorted(os.listdir(ROBOT_DATA_ROOT))\n",
    "DATASET_TRAIN_FILTERED = dataset_list[:10]\n",
    "DATASET_TEST_FILTERED = dataset_list[10:15]\n",
    "print(DATASET_TRAIN_FILTERED)\n",
    "print(DATASET_TEST_FILTERED)\n",
    "\n",
    "data_pairs_train_filtered = []\n",
    "for dataset in DATASET_TRAIN_FILTERED:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_train_filtered.append((os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT, dataset, ARM_FOLDER, file)))\n",
    "print(\"train set: {}\".format(len(data_pairs_train_filtered)))        \n",
    "        \n",
    "        \n",
    "data_pairs_test_filtered = []\n",
    "for dataset in DATASET_TEST_FILTERED:\n",
    "    file_list = sorted(os.listdir(os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER)))\n",
    "    for file in file_list:\n",
    "        data_pairs_test_filtered.append((os.path.join(ROBOT_DATA_ROOT, dataset, GRASP_FOLDER, file), \n",
    "                                 os.path.join(ROBOT_DATA_ROOT, dataset, ARM_FOLDER, file)))\n",
    "print(\"test set: {}\".format(len(data_pairs_test_filtered)))        \n",
    "\n",
    "N_max_train = 10000\n",
    "N_max_test = 5000\n",
    "\n",
    "data_pairs_train_filtered = data_pairs_train_filtered[:N_max_train]\n",
    "data_pairs_test_filtered = data_pairs_test_filtered[:N_max_test]\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"filtered data: {} / {}\".format(\n",
    "    len(data_pairs_train_filtered), \n",
    "    len(data_pairs_test_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert and save frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1238642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1226173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1231329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_1238516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1185256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1203942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_1238358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1238685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1223560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1204039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_1202564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1234831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1202660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1237117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1233615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1202708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1238814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1201955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1205964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1208251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_1202609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_1238491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_1202503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1200207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1238771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1228716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1238333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "temp_onnx_dir = os.path.join(ROBOT_MODEL_ROOT, \n",
    "                                  model_path_rel.split(\"/\")[0], \"temp.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!python3 -m tf2onnx.convert --saved-model /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/model_17 --output /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/temp.onnx\n"
     ]
    }
   ],
   "source": [
    "    print(\"!python3 -m tf2onnx.convert --saved-model {} --output {}\".format(model_log_dir, temp_onnx_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert tf2onnx - copy and run result of above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2021-10-04 19:51:19,094 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2021-10-04 19:51:19,412 - WARNING - Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1238642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:19,458 - WARNING - Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1226173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:19,825 - WARNING - Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1231329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:20,068 - WARNING - Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_1238516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:20,274 - WARNING - Importing a function (__inference__wrapped_model_1185256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:20,588 - WARNING - Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1203942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:20,807 - WARNING - Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_1238358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:20,948 - WARNING - Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1238685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:21,012 - WARNING - Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1223560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:21,263 - WARNING - Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1204039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:21,337 - WARNING - Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_1202564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:21,405 - WARNING - Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1234831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:21,572 - WARNING - Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1202660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:21,591 - WARNING - Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1237117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:21,732 - WARNING - Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1233615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,020 - WARNING - Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1202708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,045 - WARNING - Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1238814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,064 - WARNING - Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1201955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,248 - WARNING - Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1205964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,404 - WARNING - Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1208251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,569 - WARNING - Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_1202609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,860 - WARNING - Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_1238491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,862 - WARNING - Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_1202503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:22,886 - WARNING - Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1200207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:23,157 - WARNING - Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1238771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:23,942 - WARNING - Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1228716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:24,248 - WARNING - Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1238333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "2021-10-04 19:51:25,980 - INFO - Signatures found in model: [serving_default].\n",
      "2021-10-04 19:51:25,980 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2021-10-04 19:51:25,981 - INFO - Output names: ['output_1']\n",
      "WARNING:tensorflow:From /home/rnb/.local/lib/python3.6/site-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-04 19:51:28,260 - WARNING - From /home/rnb/.local/lib/python3.6/site-packages/tf2onnx/tf_loader.py:703: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2021-10-04 19:51:29,374 - INFO - Using tensorflow=2.6.0, onnx=1.9.0, tf2onnx=1.9.2/0f28b7\n",
      "2021-10-04 19:51:29,374 - INFO - Using opset <onnx, 9>\n",
      "2021-10-04 19:51:32,677 - INFO - Computed 0 values for constant folding\n",
      "2021-10-04 19:51:36,010 - INFO - Optimizing ONNX model\n",
      "2021-10-04 19:51:37,034 - WARNING - Failed to apply optimize_transpose\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py\", line 62, in optimize_graph\n",
      "    graph = opt.optimize(current, iteration) or graph\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py\", line 41, in optimize\n",
      "    graph = self._optimize(graph)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 157, in _optimize\n",
      "    return self._apply_optimization(graph, self._optimize_at_current_graph_level)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py\", line 62, in _apply_optimization\n",
      "    graph = optimize_func(graph)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 191, in _optimize_at_current_graph_level\n",
      "    self.post_optimize_action()\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 123, in post_optimize_action\n",
      "    new_shape = _calculate_new_shape(self._g, op)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in _calculate_new_shape\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in <listcomp>\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-04 19:51:39,068 - WARNING - Failed to apply optimize_transpose\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/__init__.py\", line 62, in optimize_graph\n",
      "    graph = opt.optimize(current, iteration) or graph\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py\", line 41, in optimize\n",
      "    graph = self._optimize(graph)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 157, in _optimize\n",
      "    return self._apply_optimization(graph, self._optimize_at_current_graph_level)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/optimizer_base.py\", line 62, in _apply_optimization\n",
      "    graph = optimize_func(graph)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 191, in _optimize_at_current_graph_level\n",
      "    self.post_optimize_action()\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 123, in post_optimize_action\n",
      "    new_shape = _calculate_new_shape(self._g, op)\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in _calculate_new_shape\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "  File \"/home/rnb/.local/lib/python3.6/site-packages/tf2onnx/optimizer/transpose_optimizer.py\", line 98, in <listcomp>\n",
      "    perm_shape = [tagged_shape[p] for p in perm]\n",
      "IndexError: list index out of range\n",
      "2021-10-04 19:51:40,250 - INFO - After optimization: Cast -2 (2->0), Const -10 (549->539), Identity -13 (13->0), Transpose -118 (428->310)\n",
      "2021-10-04 19:51:40,417 - INFO - \n",
      "2021-10-04 19:51:40,417 - INFO - Successfully converted TensorFlow model /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/model_17 to ONNX\n",
      "2021-10-04 19:51:40,418 - INFO - Model inputs: ['input_1', 'input_2', 'input_3']\n",
      "2021-10-04 19:51:40,418 - INFO - Model outputs: ['output_1']\n",
      "2021-10-04 19:51:40,418 - INFO - ONNX model is saved at /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/temp.onnx\n"
     ]
    }
   ],
   "source": [
    "!python3 -m tf2onnx.convert --saved-model /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/model_17 --output /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/temp.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onnx_model  = onnx.load_model(temp_onnx_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "inputs = onnx_model.graph.input\n",
    "for input in inputs:\n",
    "    dim1 = input.type.tensor_type.shape.dim[0]\n",
    "    dim1.dim_value = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = model_log_dir.replace(\"model_\", \"onnx_\")+\".onnx\"\n",
    "trt_model_path = model_log_dir.replace(\"model_\", \"trt_engine_\")+\".trt\"\n",
    "onnx.save_model(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!trtexec --onnx=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/onnx_17.onnx --saveEngine=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/trt_engine_17.trt  --explicitBatch\n"
     ]
    }
   ],
   "source": [
    "print(\"!trtexec --onnx={} --saveEngine={}  --explicitBatch\".format(onnx_model_path, trt_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert onnx2trt - copy and run result of above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8003] # trtexec --onnx=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/onnx_17.onnx --saveEngine=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/trt_engine_17.trt --explicitBatch\n",
      "[10/04/2021-19:52:28] [I] === Model Options ===\n",
      "[10/04/2021-19:52:28] [I] Format: ONNX\n",
      "[10/04/2021-19:52:28] [I] Model: /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/onnx_17.onnx\n",
      "[10/04/2021-19:52:28] [I] Output:\n",
      "[10/04/2021-19:52:28] [I] === Build Options ===\n",
      "[10/04/2021-19:52:28] [I] Max batch: explicit\n",
      "[10/04/2021-19:52:28] [I] Workspace: 16 MiB\n",
      "[10/04/2021-19:52:28] [I] minTiming: 1\n",
      "[10/04/2021-19:52:28] [I] avgTiming: 8\n",
      "[10/04/2021-19:52:28] [I] Precision: FP32\n",
      "[10/04/2021-19:52:28] [I] Calibration: \n",
      "[10/04/2021-19:52:28] [I] Refit: Disabled\n",
      "[10/04/2021-19:52:28] [I] Sparsity: Disabled\n",
      "[10/04/2021-19:52:28] [I] Safe mode: Disabled\n",
      "[10/04/2021-19:52:28] [I] Restricted mode: Disabled\n",
      "[10/04/2021-19:52:28] [I] Save engine: /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/trt_engine_17.trt\n",
      "[10/04/2021-19:52:28] [I] Load engine: \n",
      "[10/04/2021-19:52:28] [I] NVTX verbosity: 0\n",
      "[10/04/2021-19:52:28] [I] Tactic sources: Using default tactic sources\n",
      "[10/04/2021-19:52:28] [I] timingCacheMode: local\n",
      "[10/04/2021-19:52:28] [I] timingCacheFile: \n",
      "[10/04/2021-19:52:28] [I] Input(s)s format: fp32:CHW\n",
      "[10/04/2021-19:52:28] [I] Output(s)s format: fp32:CHW\n",
      "[10/04/2021-19:52:28] [I] Input build shapes: model\n",
      "[10/04/2021-19:52:28] [I] Input calibration shapes: model\n",
      "[10/04/2021-19:52:28] [I] === System Options ===\n",
      "[10/04/2021-19:52:28] [I] Device: 0\n",
      "[10/04/2021-19:52:28] [I] DLACore: \n",
      "[10/04/2021-19:52:28] [I] Plugins:\n",
      "[10/04/2021-19:52:28] [I] === Inference Options ===\n",
      "[10/04/2021-19:52:28] [I] Batch: Explicit\n",
      "[10/04/2021-19:52:28] [I] Input inference shapes: model\n",
      "[10/04/2021-19:52:28] [I] Iterations: 10\n",
      "[10/04/2021-19:52:28] [I] Duration: 3s (+ 200ms warm up)\n",
      "[10/04/2021-19:52:28] [I] Sleep time: 0ms\n",
      "[10/04/2021-19:52:28] [I] Streams: 1\n",
      "[10/04/2021-19:52:28] [I] ExposeDMA: Disabled\n",
      "[10/04/2021-19:52:28] [I] Data transfers: Enabled\n",
      "[10/04/2021-19:52:28] [I] Spin-wait: Disabled\n",
      "[10/04/2021-19:52:28] [I] Multithreading: Disabled\n",
      "[10/04/2021-19:52:28] [I] CUDA Graph: Disabled\n",
      "[10/04/2021-19:52:28] [I] Separate profiling: Disabled\n",
      "[10/04/2021-19:52:28] [I] Time Deserialize: Disabled\n",
      "[10/04/2021-19:52:28] [I] Time Refit: Disabled\n",
      "[10/04/2021-19:52:28] [I] Skip inference: Disabled\n",
      "[10/04/2021-19:52:28] [I] Inputs:\n",
      "[10/04/2021-19:52:28] [I] === Reporting Options ===\n",
      "[10/04/2021-19:52:28] [I] Verbose: Disabled\n",
      "[10/04/2021-19:52:28] [I] Averages: 10 inferences\n",
      "[10/04/2021-19:52:28] [I] Percentile: 99\n",
      "[10/04/2021-19:52:28] [I] Dump refittable layers:Disabled\n",
      "[10/04/2021-19:52:28] [I] Dump output: Disabled\n",
      "[10/04/2021-19:52:28] [I] Profile: Disabled\n",
      "[10/04/2021-19:52:28] [I] Export timing to JSON file: \n",
      "[10/04/2021-19:52:28] [I] Export output to JSON file: \n",
      "[10/04/2021-19:52:28] [I] Export profile to JSON file: \n",
      "[10/04/2021-19:52:28] [I] \n",
      "[10/04/2021-19:52:28] [I] === Device Information ===\n",
      "[10/04/2021-19:52:28] [I] Selected Device: GeForce RTX 3090\n",
      "[10/04/2021-19:52:28] [I] Compute Capability: 8.6\n",
      "[10/04/2021-19:52:28] [I] SMs: 82\n",
      "[10/04/2021-19:52:28] [I] Compute Clock Rate: 1.86 GHz\n",
      "[10/04/2021-19:52:28] [I] Device Global Memory: 24265 MiB\n",
      "[10/04/2021-19:52:28] [I] Shared Memory per SM: 100 KiB\n",
      "[10/04/2021-19:52:28] [I] Memory Bus Width: 384 bits (ECC disabled)\n",
      "[10/04/2021-19:52:28] [I] Memory Clock Rate: 9.751 GHz\n",
      "[10/04/2021-19:52:28] [I] \n",
      "[10/04/2021-19:52:28] [I] TensorRT version: 8003\n",
      "[10/04/2021-19:52:28] [I] [TRT] [MemUsageChange] Init CUDA: CPU +539, GPU +0, now: CPU 546, GPU 1354 (MiB)\n",
      "[10/04/2021-19:52:28] [I] Start parsing network model\n",
      "[10/04/2021-19:52:28] [I] [TRT] ----------------------------------------------------------------\n",
      "[10/04/2021-19:52:28] [I] [TRT] Input filename:   /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/onnx_17.onnx\n",
      "[10/04/2021-19:52:28] [I] [TRT] ONNX IR version:  0.0.4\n",
      "[10/04/2021-19:52:28] [I] [TRT] Opset version:    9\n",
      "[10/04/2021-19:52:28] [I] [TRT] Producer name:    tf2onnx\n",
      "[10/04/2021-19:52:28] [I] [TRT] Producer version: 1.9.2\n",
      "[10/04/2021-19:52:28] [I] [TRT] Domain:           \n",
      "[10/04/2021-19:52:28] [I] [TRT] Model version:    0\n",
      "[10/04/2021-19:52:28] [I] [TRT] Doc string:       \n",
      "[10/04/2021-19:52:28] [I] [TRT] ----------------------------------------------------------------\n",
      "[10/04/2021-19:52:28] [W] [TRT] onnx2trt_utils.cpp:364: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[10/04/2021-19:52:28] [E] Error[4]: StatefulPartitionedCall/res_net_model_tp/res_net_1/bn_conv1/FusedBatchNormV3__10: first transpose is not valid.\n",
      "[10/04/2021-19:52:28] [E] [TRT] ModelImporter.cpp:720: While parsing node number 2 [Transpose -> \"StatefulPartitionedCall/res_net_model_tp/res_net_1/bn_conv1/FusedBatchNormV3__10:0\"]:\n",
      "[10/04/2021-19:52:28] [E] [TRT] ModelImporter.cpp:721: --- Begin node ---\n",
      "[10/04/2021-19:52:28] [E] [TRT] ModelImporter.cpp:722: input: \"StatefulPartitionedCall/res_net_model_tp/res_net_1/conv1/Conv3D:0\"\n",
      "output: \"StatefulPartitionedCall/res_net_model_tp/res_net_1/bn_conv1/FusedBatchNormV3__10:0\"\n",
      "name: \"StatefulPartitionedCall/res_net_model_tp/res_net_1/bn_conv1/FusedBatchNormV3__10\"\n",
      "op_type: \"Transpose\"\n",
      "attribute {\n",
      "  name: \"perm\"\n",
      "  ints: 0\n",
      "  ints: 4\n",
      "  ints: 2\n",
      "  ints: 3\n",
      "  type: INTS\n",
      "}\n",
      "\n",
      "[10/04/2021-19:52:28] [E] [TRT] ModelImporter.cpp:723: --- End node ---\n",
      "[10/04/2021-19:52:28] [E] [TRT] ModelImporter.cpp:726: ERROR: ModelImporter.cpp:179 In function parseGraph:\n",
      "[6] Invalid Node - StatefulPartitionedCall/res_net_model_tp/res_net_1/bn_conv1/FusedBatchNormV3__10\n",
      "StatefulPartitionedCall/res_net_model_tp/res_net_1/bn_conv1/FusedBatchNormV3__10: first transpose is not valid.\n",
      "[10/04/2021-19:52:28] [E] Failed to parse onnx file\n",
      "[10/04/2021-19:52:28] [I] Finish parsing network model\n",
      "[10/04/2021-19:52:28] [E] Parsing model failed\n",
      "[10/04/2021-19:52:28] [E] Engine creation failed\n",
      "[10/04/2021-19:52:28] [E] Engine set up failed\n",
      "&&&& FAILED TensorRT.trtexec [TensorRT v8003] # trtexec --onnx=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/onnx_17.onnx --saveEngine=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/trt_engine_17.trt --explicitBatch\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/onnx_17.onnx --saveEngine=/home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/trt_engine_17.trt  --explicitBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn():\n",
    "    data_pairs_train = data_pairs_train_filtered\n",
    "    data_batch = []\n",
    "    i_step = 0\n",
    "    for data_pair in data_pairs_train:\n",
    "        i_step += 1\n",
    "        grasp_img, arm_img, rh_mask, label = load_data(data_pair)\n",
    "        data_batch.append([grasp_img, arm_img, rh_mask])\n",
    "        if i_step%BATCH_SIZE==0:\n",
    "            grasp_img_batch = tf.constant([grasp_img for grasp_img, arm_img, rh_mask in data_batch], tf.float32)\n",
    "            arm_img_batch = tf.constant([arm_img for grasp_img, arm_img, rh_mask in data_batch], tf.float32)\n",
    "            rh_mask_batch = tf.constant([rh_mask for grasp_img, arm_img, rh_mask in data_batch], tf.float32)\n",
    "            data_batch = []\n",
    "            yield grasp_img_batch, arm_img_batch, rh_mask_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 2, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1238642) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1226173) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1231329) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_1238516) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_1185256) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1203942) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_1238358) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1238685) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1223560) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1204039) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_1202564) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1234831) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1202660) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1237117) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1233615) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1202708) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1238814) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1201955) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1205964) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1208251) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_1202609) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_1238491) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_1202503) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_1200207) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_1238771) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_1228716) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_1238333) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(precision_mode=PRECISION)\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=model_log_dir,\n",
    "                                    conversion_params=conversion_params)\n",
    "if PRECISION == \"INT8\":\n",
    "    converter.convert(calibration_input_fn=my_input_fn)\n",
    "else:\n",
    "    converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.build(input_fn=my_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/trt_17-FP32/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/rnb/Projects/rnb-planning/model/latticized/panda/20211003-081015/trt_17-FP32/assets\n"
     ]
    }
   ],
   "source": [
    "converter.save(model_log_dir_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_img_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.grasp_img\", (BATCH_SIZE,) + GRASP_SHAPE + (3,))\n",
    "arm_img_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.arm_img\", (BATCH_SIZE,) + ARM_SHAPE + (1,))\n",
    "rh_vals_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.rh_vals\", (BATCH_SIZE, 2))\n",
    "result_p = sa.create(f\"shm://{ROBOT_TYPE_NAME}.result\", (BATCH_SIZE, 2))\n",
    "query_in = sa.create(f\"shm://{ROBOT_TYPE_NAME}.query_in\", (1,), dtype=np.bool)\n",
    "response_out = sa.create(f\"shm://{ROBOT_TYPE_NAME}.response_out\", (1,), dtype=np.bool)\n",
    "query_quit = sa.create(f\"shm://{ROBOT_TYPE_NAME}.query_quit\", (1,), dtype=np.bool)\n",
    "prepared_p = sa.create(f\"shm://{rtype}.prepared\", (1,), dtype=np.bool)\n",
    "\n",
    "grasp_img_p[:] = 0\n",
    "arm_img_p[:] = 0\n",
    "rh_vals_p[:] = 0\n",
    "result_p[:] = 0\n",
    "query_in[0] = False\n",
    "response_out[0] = False\n",
    "query_quit[0] = False\n",
    "rh_mask = np.zeros((BATCH_SIZE, 54))\n",
    "\n",
    "r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "prepared_p[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call checker once to get data example. run below cell to return response so the checker can stop waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load(\n",
    "    model_log_dir_trt, tags=[tag_constants.SERVING])\n",
    "graph_func = saved_model_loaded.signatures[\n",
    "    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "frozen_func = convert_variables_to_constants_v2(graph_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_in[0] = False\n",
    "grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "input_data = (grasp_img_t, arm_img_t, rh_mask_t)\n",
    "output = frozen_func(*input_data)[0].numpy()    \n",
    "for i_b in range(BATCH_SIZE):\n",
    "    result_p[i_b] = output[i_b]\n",
    "response_out[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "while not query_quit[0]:\n",
    "    while not query_in[0]:\n",
    "        time.sleep(SERVER_PERIOD)\n",
    "    query_in[0] = False\n",
    "    with gtimer.block(\"frozen_func\"):\n",
    "        grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "        arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "        rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "        input_data = (grasp_img_t, arm_img_t, rh_mask_t)\n",
    "        output = frozen_func(*input_data)[0].numpy()    \n",
    "        for i_b in range(BATCH_SIZE):\n",
    "            result_p[i_b] = output[i_b]\n",
    "    response_out[0] = True\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.grasp_img\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.arm_img\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.rh_vals\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.result\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.query_in\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.response_out\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.query_quit\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
