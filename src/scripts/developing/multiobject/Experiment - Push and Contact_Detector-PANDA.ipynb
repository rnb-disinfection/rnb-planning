{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PC IP: 192.168.17.4\n",
      "Mobile ROB IP: 192.168.0.102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/demo_202107'))\n",
    "\n",
    "CONNECT_PANDA = True\n",
    "CONNECT_MOBILE = False\n",
    "\n",
    "IP_CUR = \"192.168.17.4\"# get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "PANDA_HOST_IP = \"192.168.17.2\"\n",
    "PANDA_ROBOT_IP = \"192.168.17.3\"\n",
    "\n",
    "print(\"Current PC IP: {}\".format(IP_CUR))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))\n",
    "\n",
    "from concurrent import futures\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import grpc\n",
    "import RemoteCam_pb2\n",
    "import RemoteCam_pb2_grpc\n",
    "\n",
    "MAX_MESSAGE_LENGTH = 10000000\n",
    "PORT_CAM = 10509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "kmb0: False\n",
      "panda1: True\n"
     ]
    }
   ],
   "source": [
    "PANDA_BASE_OFFSET = (0.172,0,0.439)\n",
    "PANDA_BASE_RPY = (0,0,0)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "WS_HEIGHT = 1.6\n",
    "COL_COLOR = (1,1,1,0.2)\n",
    "CARRIER_DIM = (0.4, 0.29, 0.635)\n",
    "CLOCK_DIM = (0.138, 0.05, 0.078)\n",
    "TABLE_DIM = (1.6, 0.8, 0.725)\n",
    "    \n",
    "# if EXP_SCENARIO == ExpType.REMOVE_OBS: ## Obstacle removing\n",
    "#     BAG_COUNT = 5\n",
    "#     CLOCK_COUNT = 0\n",
    "#     TARGET_COUNT = 5\n",
    "#     LOG_FORCE = False\n",
    "# else: ## Contact \n",
    "#     BAG_COUNT = 3\n",
    "#     CLOCK_COUNT = 3\n",
    "#     TARGET_COUNT = 5\n",
    "#     LOG_FORCE = True\n",
    "\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "\n",
    "\n",
    "if not CONNECT_PANDA:\n",
    "    indy_7dof_client.kiro_tool.OFFLINE_MODE = True\n",
    "kiro_udp_client.KIRO_UDP_OFFLINE_DEBUG = not CONNECT_MOBILE\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                \"{}/{}\".format(MOBILE_IP, IP_CUR))\n",
    "robot_config = RobotConfig(1, RobotType.panda, \n",
    "                           (PANDA_BASE_OFFSET, PANDA_BASE_RPY),\n",
    "                           \"{}/{}\".format(PANDA_HOST_IP, PANDA_ROBOT_IP), root_on=\"kmb0_platform\")\n",
    "\n",
    "ROBOT_TYPE = robot_config.type\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[CONNECT_MOBILE, CONNECT_PANDA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mros_node already initialized somewhere else\u001b[0m\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from pkg.planning.scene import PlanningScene\n",
    "from pkg.geometry.geometry import GeometryItem\n",
    "from pkg.geometry.geotype import GEOTYPE\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "gtems = s_builder.add_robot_geometries(\n",
    "    color=COL_COLOR, display=True, collision=True)\n",
    "\n",
    "gscene.set_workspace_boundary(\n",
    "    -1, 4, -2.5, 2.5, -CLEARANCE, WS_HEIGHT, thickness=WALL_THICKNESS)\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=\"panda1_link8\")\n",
    "gscene.show_pose(crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_CUR = crob.get_real_robot_pose()[6:] + [0.1] *7\n",
    "# Q_LOC = list(Q_CUR[:6])\n",
    "# Q_NEW = np.array(Q_LOC + list(Q_CUR))\n",
    "# crob.joint_move_make_sure(Q_NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiICP detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.multiICP import MultiICP, MultiICP_Obj\n",
    "from pkg.detector.multiICP.config import *\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "CONNECT_CAM = False\n",
    "REMOTE_CAM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is not set - skip initialization, use remote camera\n",
      "request 0 -> response 0\n",
      "==== Received camera config from remote camera ====\n"
     ]
    }
   ],
   "source": [
    "# realsense = RealSense()\n",
    "\n",
    "# from demo_utils.data_reconstructed_camera import DataRecontructedCamera\n",
    "# dcam = DataRecontructedCamera(crob, viewpoint)\n",
    "# if not CONNECT_CAM:\n",
    "#     dcam.initialize()\n",
    "    \n",
    "if CONNECT_CAM:\n",
    "    realsense = RealSense()\n",
    "    micp = MultiICP(realsense)\n",
    "    micp.initialize()\n",
    "#     dcam.ready_saving(*realsense.get_config())\n",
    "#     cam_pose = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "else:\n",
    "    if REMOTE_CAM:\n",
    "        # use remote camera\n",
    "        micp = MultiICP(None)\n",
    "        micp.initialize(remote_cam=REMOTE_CAM)\n",
    "    else:\n",
    "        # use manually given camera configs\n",
    "        micp = MultiICP(None)\n",
    "        cam_mtx = np.array([[639.782, 0, 635.894],\n",
    "                                        [0, 638.492, 359.51],\n",
    "                                        [0, 0, 1]])\n",
    "        distcoeffs = np.array([-0.0534753, -0.0592427, 2.97771e-5, -0.000914619, -0.0184789])\n",
    "        depth_scale = 0.001\n",
    "        config_list = [cam_mtx, distcoeffs, depth_scale]\n",
    "        img_dim = (720, 1280)\n",
    "#         config_list, img_dim = load_pickle(RNB_PLANNING_DIR+\"release/multiICP_data/cam_configs.pkl\")\n",
    "        micp.initialize(config_list, img_dim)#\n",
    "#         micp = MultiICP(dcam)\n",
    "#         micp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "\n",
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "sd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set ICP config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file of object information\n",
    "obj_info_dict = get_obj_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess는 실험하는거 보면서 수정?\n",
    "micp_suitcase = MultiICP_Obj(obj_info_dict[\"suitcase\"], None,\n",
    "                        OffsetOnModelCoord(\"suitcase\", R=Rot_axis(1, np.pi/2), offset=(0.,0.,0.)))\n",
    "\n",
    "\n",
    "micp_clock = MultiICP_Obj(obj_info_dict[\"clock\"], None,\n",
    "                        OffsetOnModelCoord(\"clock\", R=Rot_axis(1, np.pi/2), offset=(-0.07,0.03,0.)))\n",
    "\n",
    "\n",
    "micp_table = MultiICP_Obj(obj_info_dict[\"dining table\"], None,\n",
    "                        OffsetOnModelCoord(\"dining table\", R=Rot_axis(1, np.pi/2), offset=(0.,0.,0.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_dict = {\"suitcase\": micp_suitcase, \"clock\": micp_clock, \"dining table\": micp_table}\n",
    "# micp_dict = {\"clock\": micp_clock}\n",
    "# micp_dict = {\"dining table\": micp_table}\n",
    "# micp_dict = {\"suitcase\": micp_suitcase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config information for micp\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(\"./test_img/color/0001.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "mask_out_list = micp.inference(color_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f995bd79550>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_zero = np.empty((720, 1280), dtype=bool)\n",
    "mask_zero[:,:] = False\n",
    "mask_zero[np.where(mask_out_list[60] == 1)] = True\n",
    "plt.imshow(mask_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['clock']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "===== Detected : clock, 2 object(s) =====\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.302832e-02, and correspondence_set size of 927\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.96033754 -0.26991409 -0.06998714 -0.1371841 ]\n",
      " [-0.13239211 -0.22046956 -0.96636717  0.2290702 ]\n",
      " [ 0.24540609  0.93730441 -0.24745969  0.99280253]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.96033754 -0.26991409 -0.06998714 -0.1371841 ]\n",
      " [-0.13239211 -0.22046956 -0.96636717  0.2290702 ]\n",
      " [ 0.24540609  0.93730441 -0.24745969  0.99280253]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.96 -0.27 -0.07 -0.14]\n",
      " [-0.13 -0.22 -0.97  0.23]\n",
      " [ 0.25  0.94 -0.25  0.99]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=7.761244e-03, and correspondence_set size of 452\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.94108456 -0.3357376   0.04049843 -0.13858116]\n",
      " [-0.1689467  -0.57051305 -0.80372375  0.21994794]\n",
      " [ 0.29294517  0.74952993 -0.59362278  1.00962686]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.94108456 -0.3357376   0.04049843 -0.13858116]\n",
      " [-0.1689467  -0.57051305 -0.80372375  0.21994794]\n",
      " [ 0.29294517  0.74952993 -0.59362278  1.00962686]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.94 -0.34  0.04 -0.14]\n",
      " [-0.17 -0.57 -0.8   0.22]\n",
      " [ 0.29  0.75 -0.59  1.01]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_1\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.122167e-02, and correspondence_set size of 777\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.93617727 -0.3219279  -0.14118973  0.12400631]\n",
      " [-0.17013113 -0.06346243 -0.98337578  0.18320609]\n",
      " [ 0.30761586  0.94463482 -0.11418204  1.10558217]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.93617727 -0.3219279  -0.14118973  0.12400631]\n",
      " [-0.17013113 -0.06346243 -0.98337578  0.18320609]\n",
      " [ 0.30761586  0.94463482 -0.11418204  1.10558217]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.94 -0.32 -0.14  0.12]\n",
      " [-0.17 -0.06 -0.98  0.18]\n",
      " [ 0.31  0.94 -0.11  1.11]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=4.679106e-03, and correspondence_set size of 376\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.91722422 -0.38544788 -0.10064622  0.12690752]\n",
      " [-0.15426654 -0.11073381 -0.98180439  0.18733255]\n",
      " [ 0.36728948  0.91606111 -0.16102945  1.120678  ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.91722422 -0.38544788 -0.10064622  0.12690752]\n",
      " [-0.15426654 -0.11073381 -0.98180439  0.18733255]\n",
      " [ 0.36728948  0.91606111 -0.16102945  1.120678  ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.92 -0.39 -0.1   0.13]\n",
      " [-0.15 -0.11 -0.98  0.19]\n",
      " [ 0.37  0.92 -0.16  1.12]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_2\n"
     ]
    }
   ],
   "source": [
    "# for clock\n",
    "micp.set_ICP_thres(thres_ICP=0.09, thres_front_ICP=0.03)\n",
    "micp.set_multiobject_num(num=3)\n",
    "pose_dict = micp.detect(name_mask=[\"clock\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['suitcase']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "===== Detected : suitcase, 2 object(s) =====\n",
      "\n",
      "'suitcase' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=7.847797e-02, and correspondence_set size of 3222\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.8524701  -0.51167659 -0.10715314 -0.36871257]\n",
      " [-0.16670342 -0.0717961  -0.98338969  0.50735839]\n",
      " [ 0.49548431  0.85617311 -0.14650227  2.1761255 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.8524701  -0.51167659 -0.10715314 -0.36871257]\n",
      " [-0.16670342 -0.0717961  -0.98338969  0.50735839]\n",
      " [ 0.49548431  0.85617311 -0.14650227  2.1761255 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.85 -0.51 -0.11 -0.37]\n",
      " [-0.17 -0.07 -0.98  0.51]\n",
      " [ 0.5   0.86 -0.15  2.18]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.567463e-01, inlier_rmse=1.880045e-02, and correspondence_set size of 1482\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.13955913 -0.98516063 -0.0999089  -0.38877878]\n",
      " [-0.24546628  0.063328   -0.96733442  0.5133495 ]\n",
      " [ 0.95930681  0.15952462 -0.23298571  2.27964034]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.13955913 -0.98516063 -0.0999089  -0.38877878]\n",
      " [-0.24546628  0.063328   -0.96733442  0.5133495 ]\n",
      " [ 0.95930681  0.15952462 -0.23298571  2.27964034]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.14 -0.99 -0.1  -0.39]\n",
      " [-0.25  0.06 -0.97  0.51]\n",
      " [ 0.96  0.16 -0.23  2.28]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of suitcase_1\n",
      "\n",
      "'suitcase' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.100544e-01, and correspondence_set size of 728\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.90468101 -0.42037727 -0.06953573  0.36947768]\n",
      " [-0.19556551 -0.26467127 -0.9443004   0.49260545]\n",
      " [ 0.37855832  0.86788943 -0.32165437  1.97843932]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.90468101 -0.42037727 -0.06953573  0.36947768]\n",
      " [-0.19556551 -0.26467127 -0.9443004   0.49260545]\n",
      " [ 0.37855832  0.86788943 -0.32165437  1.97843932]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.9  -0.42 -0.07  0.37]\n",
      " [-0.2  -0.26 -0.94  0.49]\n",
      " [ 0.38  0.87 -0.32  1.98]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=6.916168e-01, inlier_rmse=3.666850e-02, and correspondence_set size of 231\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82183772 -0.56965894  0.00845286  0.38717499]\n",
      " [-0.21317895 -0.32124112 -0.92269111  0.4847653 ]\n",
      " [ 0.52833465  0.75650038 -0.38544737  2.11365948]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.82183772 -0.56965894  0.00845286  0.38717499]\n",
      " [-0.21317895 -0.32124112 -0.92269111  0.4847653 ]\n",
      " [ 0.52833465  0.75650038 -0.38544737  2.11365948]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.82 -0.57  0.01  0.39]\n",
      " [-0.21 -0.32 -0.92  0.48]\n",
      " [ 0.53  0.76 -0.39  2.11]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of suitcase_2\n"
     ]
    }
   ],
   "source": [
    "# for suitcase\n",
    "micp.set_ICP_thres(thres_ICP=0.2, thres_front_ICP=0.06)\n",
    "micp.set_multiobject_num(num=5)\n",
    "pose_dict = micp.detect(name_mask=[\"suitcase\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['dining table']\n",
      "===== Detected : dining table, 4 object(s) =====\n",
      "\n",
      "'dining table' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=2.429649e-01, and correspondence_set size of 4461\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.12475526 -0.94020075 -0.31695217  0.42278522]\n",
      " [-0.45983325  0.22828058 -0.85816161  0.95578992]\n",
      " [ 0.87919822  0.25280532 -0.40385637  1.32865771]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.12475526 -0.94020075 -0.31695217  0.42278522]\n",
      " [-0.45983325  0.22828058 -0.85816161  0.95578992]\n",
      " [ 0.87919822  0.25280532 -0.40385637  1.32865771]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.12 -0.94 -0.32  0.42]\n",
      " [-0.46  0.23 -0.86  0.96]\n",
      " [ 0.88  0.25 -0.4   1.33]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.813615e-01, and correspondence_set size of 2021\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.13666545 -0.91368375 -0.38275915  0.44135759]\n",
      " [-0.52231722  0.26184881 -0.81155401  1.03669812]\n",
      " [ 0.84172874  0.31083309 -0.44144707  1.42346696]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.13666545 -0.91368375 -0.38275915  0.44135759]\n",
      " [-0.52231722  0.26184881 -0.81155401  1.03669812]\n",
      " [ 0.84172874  0.31083309 -0.44144707  1.42346696]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.14 -0.91 -0.38  0.44]\n",
      " [-0.52  0.26 -0.81  1.04]\n",
      " [ 0.84  0.31 -0.44  1.42]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of dining table_1\n"
     ]
    }
   ],
   "source": [
    "# for dining table\n",
    "micp.set_ICP_thres(thres_ICP=2, thres_front_ICP=0.8)\n",
    "micp.set_multiobject_num(num = 1)\n",
    "color_img = cv2.imread(\"./test_img/color/0001.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "depth_img = cv2.imread(\"./test_img/depth/0001.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "Q = crob.get_real_robot_pose()\n",
    "micp.cache_sensor(color_img, depth_img, Q)\n",
    "pose_dict = micp.detect(name_mask=[\"dining table\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pose_dict = micp.detect(name_mask=[\"suitcase\", \"clock\", \"dining table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Object to scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add table\n",
    "center, rpy = pose_refine(\"dining table\", pose_dict[\"dining table_1\"])\n",
    "table_vis = add_table(gscene, \"table\", center, rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2 suitcase in the scene\n",
      "Update existing suitcase in the scene\n",
      "Add new suitcase in the scene\n"
     ]
    }
   ],
   "source": [
    "# add or update suitcase\n",
    "add_update_object(gscene, crob, \"suitcase\", pose_dict, height = CARRIER_DIM[2]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 3 clock in the scene\n",
      "Update existing clock in the scene\n",
      "Update existing clock in the scene\n",
      "Update existing clock in the scene\n"
     ]
    }
   ],
   "source": [
    "# add or update clock\n",
    "add_update_object(gscene, crob, \"clock\", pose_dict, separate_dist=0.2, height = TABLE_DIM[2]+CLOCK_DIM[2]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code for multiple instance detection\n",
    "* MultiICP Detector 이전까지 실행시키고 아래의 코드 실행\n",
    "* Separte distance는 수동으로 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origianlly, 4 suitcases are existed in scene\n",
    "c10 = add_carrier(gscene, \"suitcase_0\", (1.,1.,0), (0,0,0))\n",
    "c11 = add_carrier(gscene, \"suitcase_1\", (1.,2.,0), (0,0,0))\n",
    "c12 = add_carrier(gscene, \"suitcase_2\", (2.,1.,0), (0,0,0))\n",
    "c13 = add_carrier(gscene, \"suitcase_3\", (2.,2.,0), (0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection result, but T1, T2 are already detected objects so, these are in the scene\n",
    "# T3 is newly detected object so this is not in the scene\n",
    "# Therefore, 1 and 2 should be updated, but 3 should be added\n",
    "\n",
    "T1 = SE3(Rot_axis(3, np.pi/10), (1.1,1.18,0.3))\n",
    "T2 = SE3(np.identity(3), (2.1,1.88,-0.1))\n",
    "T3 = SE3(Rot_axis(1, -np.pi/5) , (3.1,1.9,-0.2))\n",
    "pose_dict = {\"suitcase_0\":T1, \"suitcase_1\":T2, \"suitcase_2\":T3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4 suitcase in the scene\n",
      "Update existing suitcase in the scene\n",
      "Update existing suitcase in the scene\n",
      "Add new suitcase in the scene\n"
     ]
    }
   ],
   "source": [
    "add_update_object(gscene, crob, \"suitcase\", pose_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
