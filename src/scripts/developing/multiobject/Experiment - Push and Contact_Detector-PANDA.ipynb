{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PC IP: 192.168.17.4\n",
      "Mobile ROB IP: 192.168.0.102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/demo_202107'))\n",
    "\n",
    "CONNECT_PANDA = False\n",
    "CONNECT_MOBILE = False\n",
    "\n",
    "IP_CUR = \"192.168.17.4\"# get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "PANDA_HOST_IP = \"192.168.17.2\"\n",
    "PANDA_ROBOT_IP = \"192.168.17.3\"\n",
    "\n",
    "print(\"Current PC IP: {}\".format(IP_CUR))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))\n",
    "\n",
    "from concurrent import futures\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import grpc\n",
    "import RemoteCam_pb2\n",
    "import RemoteCam_pb2_grpc\n",
    "\n",
    "MAX_MESSAGE_LENGTH = 10000000\n",
    "PORT_CAM = 10509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "kmb0: False\n",
      "panda1: False\n"
     ]
    }
   ],
   "source": [
    "PANDA_BASE_OFFSET = (0.172,0,0.439)\n",
    "PANDA_BASE_RPY = (0,0,0)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "WS_HEIGHT = 1.6\n",
    "COL_COLOR = (1,1,1,0.2)\n",
    "CARRIER_DIM = (0.4, 0.29, 0.635)\n",
    "CLOCK_DIM = (0.138, 0.05, 0.078)\n",
    "TABLE_DIM = (1.6, 0.8, 0.725)\n",
    "    \n",
    "# if EXP_SCENARIO == ExpType.REMOVE_OBS: ## Obstacle removing\n",
    "#     BAG_COUNT = 5\n",
    "#     CLOCK_COUNT = 0\n",
    "#     TARGET_COUNT = 5\n",
    "#     LOG_FORCE = False\n",
    "# else: ## Contact \n",
    "#     BAG_COUNT = 3\n",
    "#     CLOCK_COUNT = 3\n",
    "#     TARGET_COUNT = 5\n",
    "#     LOG_FORCE = True\n",
    "\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "\n",
    "\n",
    "if not CONNECT_PANDA:\n",
    "    indy_7dof_client.kiro_tool.OFFLINE_MODE = True\n",
    "kiro_udp_client.KIRO_UDP_OFFLINE_DEBUG = not CONNECT_MOBILE\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                \"{}/{}\".format(MOBILE_IP, IP_CUR))\n",
    "robot_config = RobotConfig(1, RobotType.panda, \n",
    "                           (PANDA_BASE_OFFSET, PANDA_BASE_RPY),\n",
    "                           \"{}/{}\".format(PANDA_HOST_IP, PANDA_ROBOT_IP), root_on=\"kmb0_platform\")\n",
    "\n",
    "ROBOT_TYPE = robot_config.type\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[CONNECT_MOBILE, CONNECT_PANDA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to register with master node [http://localhost:11311]: master may not be running yet. Will keep trying.\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from pkg.planning.scene import PlanningScene\n",
    "from pkg.geometry.geometry import GeometryItem\n",
    "from pkg.geometry.geotype import GEOTYPE\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "gtems = s_builder.add_robot_geometries(\n",
    "    color=COL_COLOR, display=True, collision=True)\n",
    "\n",
    "gscene.set_workspace_boundary(\n",
    "    -1, 4, -2.5, 2.5, -CLEARANCE, WS_HEIGHT, thickness=WALL_THICKNESS)\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=\"panda1_link8\")\n",
    "gscene.show_pose(crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_CUR = crob.get_real_robot_pose()[6:] + [0.1] *7\n",
    "# Q_LOC = list(Q_CUR[:6])\n",
    "# Q_NEW = np.array(Q_LOC + list(Q_CUR))\n",
    "# crob.joint_move_make_sure(Q_NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiICP detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.multiICP import MultiICP, MultiICP_Obj\n",
    "from pkg.detector.multiICP.config import *\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "CONNECT_CAM = False\n",
    "REMOTE_CAM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is not set - skip initialization, use manually given camera configs\n"
     ]
    }
   ],
   "source": [
    "# realsense = RealSense()\n",
    "\n",
    "# from demo_utils.data_reconstructed_camera import DataRecontructedCamera\n",
    "# dcam = DataRecontructedCamera(crob, viewpoint)\n",
    "# if not CONNECT_CAM:\n",
    "#     dcam.initialize()\n",
    "    \n",
    "if CONNECT_CAM:\n",
    "    realsense = RealSense()\n",
    "    micp = MultiICP(realsense)\n",
    "    micp.initialize()\n",
    "#     dcam.ready_saving(*realsense.get_config())\n",
    "#     cam_pose = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "else:\n",
    "    if REMOTE_CAM:\n",
    "        # use remote camera\n",
    "        micp = MultiICP(None)\n",
    "        micp.initialize(remote_cam=REMOTE_CAM)\n",
    "    else:\n",
    "        # use manually given camera configs\n",
    "        micp = MultiICP(None)\n",
    "#         cam_mtx = np.array([[639.782, 0, 635.894],\n",
    "#                                         [0, 638.492, 359.51],\n",
    "#                                         [0, 0, 1]])\n",
    "#         distcoeffs = np.array([-0.0534753, -0.0592427, 2.97771e-5, -0.000914619, -0.0184789])\n",
    "#         depth_scale = 0.001\n",
    "#         config_list = [cam_mtx, distcoeffs, depth_scale]\n",
    "#         img_dim = (720, 1280)\n",
    "        config_list, img_dim = load_pickle(RNB_PLANNING_DIR+\"release/multiICP_data/cam_configs.pkl\")\n",
    "        micp.initialize(config_list, img_dim)\n",
    "#         micp = MultiICP(dcam)\n",
    "#         micp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "\n",
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "sd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set ICP config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file of object information\n",
    "obj_info_dict = get_obj_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess는 실험하는거 보면서 수정?\n",
    "micp_suitcase = MultiICP_Obj(obj_info_dict[\"suitcase\"], None,\n",
    "                        OffsetOnModelCoord(\"suitcase\", R=np.matmul(Rot_axis(1, np.pi/2), Rot_axis(3, np.pi/2)), offset=(0.,0.,0.14)))\n",
    "\n",
    "\n",
    "micp_clock = MultiICP_Obj(obj_info_dict[\"clock\"], None,\n",
    "                        OffsetOnModelCoord(\"clock\", R=Rot_axis(1, np.pi/2), offset=(-0.07,0.03,0.)))\n",
    "\n",
    "\n",
    "micp_table = MultiICP_Obj(obj_info_dict[\"dining table\"], None,\n",
    "                        OffsetOnModelCoord(\"dining table\", R=Rot_axis(1, 3*np.pi/4), offset=(0.,0.35,0.6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_dict = {\"suitcase\": micp_suitcase, \"clock\": micp_clock, \"dining table\": micp_table}\n",
    "# micp_dict = {\"clock\": micp_clock}\n",
    "# micp_dict = {\"dining table\": micp_table}\n",
    "# micp_dict = {\"suitcase\": micp_suitcase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config information for micp\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_img = cv2.imread(\"./test_img/color/0021.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "mask_out_list = micp.inference(color_img)\n",
    "np.max(mask_out_list[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f49d411a950>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_zero = np.empty((720, 1280), dtype=bool)\n",
    "mask_zero[:,:] = False\n",
    "mask_zero[np.where(mask_out_list[60] == 3)] = True\n",
    "plt.imshow(mask_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['clock']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "Maximun num of object for detection : 3\n",
      "===== Detected : clock, 4 object(s) =====\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.195425e-02, and correspondence_set size of 693\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.98064841 -0.14244078 -0.13431051 -0.14558757]\n",
      " [-0.17044213 -0.28362229 -0.94366725  0.01912652]\n",
      " [ 0.09632325  0.94829796 -0.30241166  1.15243266]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.98064841 -0.14244078 -0.13431051 -0.14558757]\n",
      " [-0.17044213 -0.28362229 -0.94366725  0.01912652]\n",
      " [ 0.09632325  0.94829796 -0.30241166  1.15243266]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.98 -0.14 -0.13 -0.15]\n",
      " [-0.17 -0.28 -0.94  0.02]\n",
      " [ 0.1   0.95 -0.3   1.15]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=5.537653e-03, and correspondence_set size of 282\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.98018302 -0.17432102 -0.09409268 -0.14324927]\n",
      " [-0.15258855 -0.36150794 -0.91979821  0.02116462]\n",
      " [ 0.12632491  0.91592805 -0.38094333  1.16961206]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.98018302 -0.17432102 -0.09409268 -0.14324927]\n",
      " [-0.15258855 -0.36150794 -0.91979821  0.02116462]\n",
      " [ 0.12632491  0.91592805 -0.38094333  1.16961206]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.98 -0.17 -0.09 -0.14]\n",
      " [-0.15 -0.36 -0.92  0.02]\n",
      " [ 0.13  0.92 -0.38  1.17]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_1\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.441969e-02, and correspondence_set size of 416\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.82424184  0.5640119   0.05015944  0.14778473]\n",
      " [ 0.14398997 -0.12310269 -0.98189236  0.01959637]\n",
      " [-0.54762421  0.81653923 -0.18267845  1.1413238 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.82424184  0.5640119   0.05015944  0.14778473]\n",
      " [ 0.14398997 -0.12310269 -0.98189236  0.01959637]\n",
      " [-0.54762421  0.81653923 -0.18267845  1.1413238 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.82  0.56  0.05  0.15]\n",
      " [ 0.14 -0.12 -0.98  0.02]\n",
      " [-0.55  0.82 -0.18  1.14]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=7.308183e-03, and correspondence_set size of 209\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.73844342  0.67398051 -0.02125062  0.1517351 ]\n",
      " [ 0.19181013 -0.24015962 -0.95159457  0.02059454]\n",
      " [-0.64645974  0.69862266 -0.30662058  1.15157476]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.73844342  0.67398051 -0.02125062  0.1517351 ]\n",
      " [ 0.19181013 -0.24015962 -0.95159457  0.02059454]\n",
      " [-0.64645974  0.69862266 -0.30662058  1.15157476]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.74  0.67 -0.02  0.15]\n",
      " [ 0.19 -0.24 -0.95  0.02]\n",
      " [-0.65  0.7  -0.31  1.15]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_2\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.472876e-02, and correspondence_set size of 926\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.71426286  0.69609773  0.07263963 -0.42324353]\n",
      " [-0.0232794   0.12736121 -0.99158317  0.09311785]\n",
      " [-0.69949026  0.70656003  0.10717412  0.99474741]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.71426286  0.69609773  0.07263963 -0.42324353]\n",
      " [-0.0232794   0.12736121 -0.99158317  0.09311785]\n",
      " [-0.69949026  0.70656003  0.10717412  0.99474741]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.71  0.7   0.07 -0.42]\n",
      " [-0.02  0.13 -0.99  0.09]\n",
      " [-0.7   0.71  0.11  0.99]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=7.540650e-03, and correspondence_set size of 368\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.53455494  0.84127646 -0.08065314 -0.42243806]\n",
      " [-0.05487508 -0.06068043 -0.99664769  0.09880745]\n",
      " [-0.84335031  0.53718879  0.01372809  1.00502855]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.53455494  0.84127646 -0.08065314 -0.42243806]\n",
      " [-0.05487508 -0.06068043 -0.99664769  0.09880745]\n",
      " [-0.84335031  0.53718879  0.01372809  1.00502855]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.53  0.84 -0.08 -0.42]\n",
      " [-0.05 -0.06 -1.    0.1 ]\n",
      " [-0.84  0.54  0.01  1.01]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_3\n"
     ]
    }
   ],
   "source": [
    "# for clock\n",
    "micp.set_ICP_thres(thres_ICP=0.09, thres_front_ICP=0.03)\n",
    "micp.set_multiobject_num(num=3)\n",
    "pose_dict = micp.detect(name_mask=[\"clock\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['suitcase']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "Maximun num of object for detection : 2\n",
      "===== Detected : suitcase, 2 object(s) =====\n",
      "\n",
      "'suitcase' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.756227e-01, inlier_rmse=7.673662e-02, and correspondence_set size of 3682\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[-0.93474121 -0.29554393 -0.19726289  0.32464131]\n",
      " [ 0.07717803  0.37303473 -0.92460188  0.25438519]\n",
      " [ 0.34684639 -0.87948785 -0.32588144  2.22035377]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[-0.93474121 -0.29554393 -0.19726289  0.32464131]\n",
      " [ 0.07717803  0.37303473 -0.92460188  0.25438519]\n",
      " [ 0.34684639 -0.87948785 -0.32588144  2.22035377]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[-0.93 -0.3  -0.2   0.32]\n",
      " [ 0.08  0.37 -0.92  0.25]\n",
      " [ 0.35 -0.88 -0.33  2.22]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.175705e-01, inlier_rmse=1.437391e-02, and correspondence_set size of 1692\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[-0.66002326 -0.72219991 -0.20687333  0.32216571]\n",
      " [-0.16414     0.40735399 -0.89839901  0.23229081]\n",
      " [ 0.73309437 -0.55900806 -0.38740501  2.31507948]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[-0.66002326 -0.72219991 -0.20687333  0.32216571]\n",
      " [-0.16414     0.40735399 -0.89839901  0.23229081]\n",
      " [ 0.73309437 -0.55900806 -0.38740501  2.31507948]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[-0.66 -0.72 -0.21  0.32]\n",
      " [-0.16  0.41 -0.9   0.23]\n",
      " [ 0.73 -0.56 -0.39  2.32]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of suitcase_1\n",
      "\n",
      "'suitcase' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=9.965454e-02, and correspondence_set size of 1381\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99719137  0.03494824 -0.06624186 -0.10771041]\n",
      " [-0.05251631 -0.30431594 -0.95112241 -0.02012806]\n",
      " [-0.05339851  0.95192985 -0.30162588  3.31063234]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.99719137  0.03494824 -0.06624186 -0.10771041]\n",
      " [-0.05251631 -0.30431594 -0.95112241 -0.02012806]\n",
      " [-0.05339851  0.95192985 -0.30162588  3.31063234]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 1.    0.03 -0.07 -0.11]\n",
      " [-0.05 -0.3  -0.95 -0.02]\n",
      " [-0.05  0.95 -0.3   3.31]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=6.701183e-01, inlier_rmse=2.008628e-02, and correspondence_set size of 453\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.97756107  0.17412331 -0.11855556 -0.10482571]\n",
      " [-0.04482696 -0.37795942 -0.9247363  -0.04131982]\n",
      " [-0.20582733  0.90930069 -0.361673    3.44026003]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.97756107  0.17412331 -0.11855556 -0.10482571]\n",
      " [-0.04482696 -0.37795942 -0.9247363  -0.04131982]\n",
      " [-0.20582733  0.90930069 -0.361673    3.44026003]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.98  0.17 -0.12 -0.1 ]\n",
      " [-0.04 -0.38 -0.92 -0.04]\n",
      " [-0.21  0.91 -0.36  3.44]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of suitcase_2\n"
     ]
    }
   ],
   "source": [
    "# for suitcase\n",
    "micp.set_ICP_thres(thres_ICP=0.17, thres_front_ICP=0.05)\n",
    "micp.set_multiobject_num(num=2)\n",
    "pose_dict = micp.detect(name_mask=[\"suitcase\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['dining table']\n",
      "Maximun num of object for detection : 1\n",
      "===== Detected : dining table, 3 object(s) =====\n",
      "[NOTICE] You choose merge option for mask. Detected masks would be merged.\n",
      "\n",
      "'dining table' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.277007e-01, and correspondence_set size of 7427\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99207964 -0.10943726 -0.06165603 -0.11160695]\n",
      " [-0.12321966 -0.7525802  -0.64686933  0.0846871 ]\n",
      " [ 0.0243905   0.64934313 -0.76010432  2.43868537]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.99207964 -0.10943726 -0.06165603 -0.11160695]\n",
      " [-0.12321966 -0.7525802  -0.64686933  0.0846871 ]\n",
      " [ 0.0243905   0.64934313 -0.76010432  2.43868537]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.99 -0.11 -0.06 -0.11]\n",
      " [-0.12 -0.75 -0.65  0.08]\n",
      " [ 0.02  0.65 -0.76  2.44]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.471380e-01, inlier_rmse=3.174787e-02, and correspondence_set size of 2516\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99486383 -0.04242311 -0.09190345 -0.09599049]\n",
      " [-0.10047071 -0.52429979 -0.84558579  0.22784915]\n",
      " [-0.01231258  0.85047632 -0.52586918  2.36020352]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.99486383 -0.04242311 -0.09190345 -0.09599049]\n",
      " [-0.10047071 -0.52429979 -0.84558579  0.22784915]\n",
      " [-0.01231258  0.85047632 -0.52586918  2.36020352]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.99 -0.04 -0.09 -0.1 ]\n",
      " [-0.1  -0.52 -0.85  0.23]\n",
      " [-0.01  0.85 -0.53  2.36]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of dining table_1\n"
     ]
    }
   ],
   "source": [
    "# for dining table\n",
    "micp.set_ICP_thres(thres_ICP=0.8, thres_front_ICP=0.15)\n",
    "# micp.set_multiobject_num(num = 1)\n",
    "micp.set_merge_mask(merge=True)\n",
    "color_img = cv2.imread(\"./test_img/color/0022.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "depth_img = cv2.imread(\"./test_img/depth/0022.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "Q = crob.get_real_robot_pose()\n",
    "micp.cache_sensor(color_img, depth_img, Q)\n",
    "pose_dict = micp.detect(name_mask=[\"dining table\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pose_dict = micp.detect(name_mask=[\"suitcase\", \"clock\", \"dining table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Object to scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = (.8,0,0)\n",
    "rpy = (0,0,-np.pi/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add table\n",
    "# center, rpy = pose_refine(\"dining table\", pose_dict[\"dining table_1\"])\n",
    "table_vis = add_table(gscene, \"table\", center, rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 suitcase in the scene\n",
      "Add new suitcase in the scene\n",
      "Add new suitcase in the scene\n"
     ]
    }
   ],
   "source": [
    "# add or update suitcase\n",
    "add_update_object(gscene, crob, \"suitcase\", pose_dict, height = CARRIER_DIM[2]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 clock in the scene\n",
      "Add new clock in the scene\n",
      "Add new clock in the scene\n",
      "Add new clock in the scene\n"
     ]
    }
   ],
   "source": [
    "# add or update clock\n",
    "add_update_object(gscene, crob, \"clock\", pose_dict, separate_dist=0.2, height = TABLE_DIM[2]+CLOCK_DIM[2]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_CUR = crob.get_real_robot_pose()\n",
    "\n",
    "Tbc = viewpoint.get_tf(VIEW_CUR)\n",
    "\n",
    "Tbt = gscene.NAME_DICT[\"table\"].get_tf(VIEW_CUR)\n",
    "\n",
    "table_dim = np.linalg.norm(TABLE_DIM)\n",
    "\n",
    "x_z_ratio = np.tan(micp.h_fov_hf)\n",
    "dist = (table_dim/2) / x_z_ratio * 1\n",
    "\n",
    "angle_ref = 20\n",
    "\n",
    "angle_view = angle_ref #+ np.random.uniform(-10, 10)\n",
    "dist_view = dist #+ np.random.uniform(-1, 1)*bed_dist/4\n",
    "Tbs = gscene.NAME_DICT[\"table\"].get_tf(VIEW_CUR)\n",
    "Tbs = np.matmul(Tbs, \n",
    "                SE3(np.identity(3), (-TABLE_DIM[0]/2, 0,0)))\n",
    "Tsc = np.matmul(SE3(Rot_axis(3, np.deg2rad(angle_view)), (0,)*3), \n",
    "                SE3(np.identity(3), (-dist_view, 0,0)))\n",
    "Tbc = np.matmul(Tbs, Tsc)\n",
    "Tmc = viewpoint.get_tf(VIEW_CUR, from_link=MOBILE_BASE)\n",
    "Tmc[:3,:3] = np.identity(3)\n",
    "Tbm = np.matmul(Tbc, SE3_inv(Tmc))\n",
    "full_view_ext = np.copy(VIEW_POSE_EXT)\n",
    "full_view_ext[:2] = Tbm[:2,3]\n",
    "full_view_ext[2] = Rot2axis(Tbm[:3, :3], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code for multiple instance detection\n",
    "* MultiICP Detector 이전까지 실행시키고 아래의 코드 실행\n",
    "* Separte distance는 수동으로 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origianlly, 4 suitcases are existed in scene\n",
    "c10 = add_carrier(gscene, \"suitcase_0\", (1.,1.,0), (0,0,0))\n",
    "c11 = add_carrier(gscene, \"suitcase_1\", (1.,2.,0), (0,0,0))\n",
    "c12 = add_carrier(gscene, \"suitcase_2\", (2.,1.,0), (0,0,0))\n",
    "c13 = add_carrier(gscene, \"suitcase_3\", (2.,2.,0), (0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection result, but T1, T2 are already detected objects so, these are in the scene\n",
    "# T3 is newly detected object so this is not in the scene\n",
    "# Therefore, 1 and 2 should be updated, but 3 should be added\n",
    "\n",
    "T1 = SE3(Rot_axis(3, np.pi/10), (1.1,1.18,0.3))\n",
    "T2 = SE3(np.identity(3), (2.1,1.88,-0.1))\n",
    "T3 = SE3(Rot_axis(1, -np.pi/5) , (3.1,1.9,-0.2))\n",
    "pose_dict = {\"suitcase_0\":T1, \"suitcase_1\":T2, \"suitcase_2\":T3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4 suitcase in the scene\n",
      "Update existing suitcase in the scene\n",
      "Update existing suitcase in the scene\n",
      "Add new suitcase in the scene\n"
     ]
    }
   ],
   "source": [
    "add_update_object(gscene, crob, \"suitcase\", pose_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
