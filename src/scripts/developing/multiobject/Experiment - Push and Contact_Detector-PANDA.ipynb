{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PC IP: 192.168.17.4\n",
      "Mobile ROB IP: 192.168.0.102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/demo_202107'))\n",
    "\n",
    "CONNECT_PANDA = False\n",
    "CONNECT_MOBILE = False\n",
    "\n",
    "IP_CUR = \"192.168.17.4\"# get_ip_address()\n",
    "MOBILE_IP = \"192.168.0.102\"\n",
    "PANDA_HOST_IP = \"192.168.17.2\"\n",
    "PANDA_ROBOT_IP = \"192.168.17.3\"\n",
    "\n",
    "print(\"Current PC IP: {}\".format(IP_CUR))\n",
    "print(\"Mobile ROB IP: {}\".format(MOBILE_IP))\n",
    "\n",
    "from concurrent import futures\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import grpc\n",
    "import RemoteCam_pb2\n",
    "import RemoteCam_pb2_grpc\n",
    "\n",
    "MAX_MESSAGE_LENGTH = 10000000\n",
    "PORT_CAM = 10509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "kmb0: False\n",
      "panda1: False\n"
     ]
    }
   ],
   "source": [
    "PANDA_BASE_OFFSET = (0.172,0,0.439)\n",
    "PANDA_BASE_RPY = (0,0,0)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "WS_HEIGHT = 1.6\n",
    "COL_COLOR = (1,1,1,0.2)\n",
    "    \n",
    "# if EXP_SCENARIO == ExpType.REMOVE_OBS: ## Obstacle removing\n",
    "#     BAG_COUNT = 5\n",
    "#     CLOCK_COUNT = 0\n",
    "#     TARGET_COUNT = 5\n",
    "#     LOG_FORCE = False\n",
    "# else: ## Contact \n",
    "#     BAG_COUNT = 3\n",
    "#     CLOCK_COUNT = 3\n",
    "#     TARGET_COUNT = 5\n",
    "#     LOG_FORCE = True\n",
    "\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "\n",
    "\n",
    "if not CONNECT_PANDA:\n",
    "    indy_7dof_client.kiro_tool.OFFLINE_MODE = True\n",
    "kiro_udp_client.KIRO_UDP_OFFLINE_DEBUG = not CONNECT_MOBILE\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.kmb, ((0,0,0), (0,0,0)),\n",
    "                \"{}/{}\".format(MOBILE_IP, IP_CUR))\n",
    "robot_config = RobotConfig(1, RobotType.panda, \n",
    "                           (PANDA_BASE_OFFSET, PANDA_BASE_RPY),\n",
    "                           \"{}/{}\".format(PANDA_HOST_IP, PANDA_ROBOT_IP), root_on=\"kmb0_platform\")\n",
    "\n",
    "ROBOT_TYPE = robot_config.type\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config]\n",
    "              , connection_list=[CONNECT_MOBILE, CONNECT_PANDA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from pkg.planning.scene import PlanningScene\n",
    "from pkg.geometry.geometry import GeometryItem\n",
    "from pkg.geometry.geotype import GEOTYPE\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "gtems = s_builder.add_robot_geometries(\n",
    "    color=COL_COLOR, display=True, collision=True)\n",
    "\n",
    "gscene.set_workspace_boundary(\n",
    "    -1, 4, -2.5, 2.5, -CLEARANCE, WS_HEIGHT, thickness=WALL_THICKNESS)\n",
    "\n",
    "viewpoint = add_cam(gscene, tool_link=\"panda1_link8\")\n",
    "gscene.show_pose(crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_CUR = crob.get_real_robot_pose()[6:] + [0.1] *7\n",
    "# Q_LOC = list(Q_CUR[:6])\n",
    "# Q_NEW = np.array(Q_LOC + list(Q_CUR))\n",
    "# crob.joint_move_make_sure(Q_NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiICP detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.multiICP import MultiICP, MultiICP_Obj\n",
    "from pkg.detector.multiICP.config import *\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "CONNECT_CAM = False\n",
    "REMOTE_CAM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is not set - skip initialization, use manually given camera configs\n"
     ]
    }
   ],
   "source": [
    "# realsense = RealSense()\n",
    "\n",
    "# from demo_utils.data_reconstructed_camera import DataRecontructedCamera\n",
    "# dcam = DataRecontructedCamera(crob, viewpoint)\n",
    "# if not CONNECT_CAM:\n",
    "#     dcam.initialize()\n",
    "    \n",
    "if CONNECT_CAM:\n",
    "    realsense = RealSense()\n",
    "    micp = MultiICP(realsense)\n",
    "    micp.initialize()\n",
    "#     dcam.ready_saving(*realsense.get_config())\n",
    "#     cam_pose = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "else:\n",
    "    if REMOTE_CAM:\n",
    "        # use remote camera\n",
    "        micp = MultiICP(None)\n",
    "        micp.initialize(remote_cam=REMOTE_CAM)\n",
    "    else:\n",
    "        # use manually given camera configs\n",
    "        micp = MultiICP(None)\n",
    "        cam_mtx = np.array([[639.782, 0, 635.894],\n",
    "                                        [0, 638.492, 359.51],\n",
    "                                        [0, 0, 1]])\n",
    "        distcoeffs = np.array([-0.0534753, -0.0592427, 2.97771e-5, -0.000914619, -0.0184789])\n",
    "        depth_scale = 0.001\n",
    "        config_list = [cam_mtx, distcoeffs, depth_scale]\n",
    "        img_dim = (720, 1280)\n",
    "#         config_list, img_dim = load_pickle(RNB_PLANNING_DIR+\"release/multiICP_data/cam_configs.pkl\")\n",
    "        micp.initialize(config_list, img_dim)#\n",
    "#         micp = MultiICP(dcam)\n",
    "#         micp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "\n",
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "sd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set ICP config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file of object information\n",
    "obj_info_dict = get_obj_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess는 실험하는거 보면서 수정?\n",
    "micp_suitcase = MultiICP_Obj(obj_info_dict[\"suitcase\"], None,\n",
    "                        OffsetOnModelCoord(\"suitcase\", R=Rot_axis(1, np.pi/2), offset=(0.,0.,0.)))\n",
    "\n",
    "\n",
    "micp_clock = MultiICP_Obj(obj_info_dict[\"clock\"], None,\n",
    "                        OffsetOnModelCoord(\"clock\", R=Rot_axis(1, np.pi/2), offset=(-0.07,0.03,0.)))\n",
    "\n",
    "\n",
    "micp_table = MultiICP_Obj(obj_info_dict[\"dining table\"], None,\n",
    "                        OffsetOnModelCoord(\"dining table\", R=Rot_axis(1, np.pi/2), offset=(0.,0.,0.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_dict = {\"suitcase\": micp_suitcase, \"clock\": micp_clock, \"dining table\": micp_table}\n",
    "# micp_dict = {\"clock\": micp_clock}\n",
    "# micp_dict = {\"dining table\": micp_table}\n",
    "# micp_dict = {\"suitcase\": micp_suitcase}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config information for micp\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread(\"./test_img/color/0001.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "mask_out_list = micp.inference(color_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f995bd79550>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_zero = np.empty((720, 1280), dtype=bool)\n",
    "mask_zero[:,:] = False\n",
    "mask_zero[np.where(mask_out_list[60] == 1)] = True\n",
    "plt.imshow(mask_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['clock']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "===== Detected : clock, 3 object(s) =====\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.132418e-02, and correspondence_set size of 833\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.9791202  -0.14746238 -0.13992314 -0.02925557]\n",
      " [-0.17838306 -0.29318058 -0.93926814  0.10750502]\n",
      " [ 0.09748397  0.94461632 -0.31336381  1.03556314]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.9791202  -0.14746238 -0.13992314 -0.02925557]\n",
      " [-0.17838306 -0.29318058 -0.93926814  0.10750502]\n",
      " [ 0.09748397  0.94461632 -0.31336381  1.03556314]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.98 -0.15 -0.14 -0.03]\n",
      " [-0.18 -0.29 -0.94  0.11]\n",
      " [ 0.1   0.94 -0.31  1.04]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=5.017268e-03, and correspondence_set size of 401\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.96017771 -0.23694672 -0.1480372  -0.02198184]\n",
      " [-0.23183634 -0.38001536 -0.89545532  0.11147473]\n",
      " [ 0.15591879  0.89411665 -0.41981514  1.05130063]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.96017771 -0.23694672 -0.1480372  -0.02198184]\n",
      " [-0.23183634 -0.38001536 -0.89545532  0.11147473]\n",
      " [ 0.15591879  0.89411665 -0.41981514  1.05130063]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.96 -0.24 -0.15 -0.02]\n",
      " [-0.23 -0.38 -0.9   0.11]\n",
      " [ 0.16  0.89 -0.42  1.05]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_1\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.217046e-02, and correspondence_set size of 953\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.9641602  -0.22416723 -0.14193011 -0.25866505]\n",
      " [-0.21940077 -0.37282226 -0.9015913   0.17171064]\n",
      " [ 0.14919252  0.90041802 -0.40864285  0.97757479]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.9641602  -0.22416723 -0.14193011 -0.25866505]\n",
      " [-0.21940077 -0.37282226 -0.9015913   0.17171064]\n",
      " [ 0.14919252  0.90041802 -0.40864285  0.97757479]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.96 -0.22 -0.14 -0.26]\n",
      " [-0.22 -0.37 -0.9   0.17]\n",
      " [ 0.15  0.9  -0.41  0.98]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=7.462868e-03, and correspondence_set size of 437\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.96123055 -0.22659198 -0.15713659 -0.26125109]\n",
      " [-0.2518585  -0.48945145 -0.834868    0.17304168]\n",
      " [ 0.11226366  0.84207681 -0.5275448   0.99973094]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.96123055 -0.22659198 -0.15713659 -0.26125109]\n",
      " [-0.2518585  -0.48945145 -0.834868    0.17304168]\n",
      " [ 0.11226366  0.84207681 -0.5275448   0.99973094]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.96 -0.23 -0.16 -0.26]\n",
      " [-0.25 -0.49 -0.83  0.17]\n",
      " [ 0.11  0.84 -0.53  1.  ]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_2\n",
      "\n",
      "'clock' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.170500e-02, and correspondence_set size of 897\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.98797162  0.10811669 -0.11055708  0.21557119]\n",
      " [-0.07297719 -0.30433654 -0.94976502  0.06897861]\n",
      " [-0.13633201  0.94640903 -0.29278582  1.03500815]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.98797162  0.10811669 -0.11055708  0.21557119]\n",
      " [-0.07297719 -0.30433654 -0.94976502  0.06897861]\n",
      " [-0.13633201  0.94640903 -0.29278582  1.03500815]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.99  0.11 -0.11  0.22]\n",
      " [-0.07 -0.3  -0.95  0.07]\n",
      " [-0.14  0.95 -0.29  1.04]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=6.376759e-03, and correspondence_set size of 429\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99408572  0.07089596 -0.08226382  0.21630959]\n",
      " [-0.0512572  -0.3615152  -0.93095621  0.07162568]\n",
      " [-0.09574066  0.92966689 -0.35574317  1.04860914]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.99408572  0.07089596 -0.08226382  0.21630959]\n",
      " [-0.0512572  -0.3615152  -0.93095621  0.07162568]\n",
      " [-0.09574066  0.92966689 -0.35574317  1.04860914]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.99  0.07 -0.08  0.22]\n",
      " [-0.05 -0.36 -0.93  0.07]\n",
      " [-0.1   0.93 -0.36  1.05]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of clock_3\n"
     ]
    }
   ],
   "source": [
    "# for clock\n",
    "micp.set_ICP_thres(thres_ICP=0.09, thres_front_ICP=0.03)\n",
    "micp.set_multiobject_num(num=3)\n",
    "pose_dict = micp.detect(name_mask=[\"clock\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['suitcase']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "===== Detected : suitcase, 1 object(s) =====\n",
      "\n",
      "'suitcase' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.998064e-01, inlier_rmse=7.842064e-02, and correspondence_set size of 5165\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.93354582  0.33892048 -0.11672662 -0.17278852]\n",
      " [ 0.07232877 -0.49703907 -0.86470846  0.15783211]\n",
      " [-0.35108509  0.79880228 -0.48852245  2.02548466]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.93354582  0.33892048 -0.11672662 -0.17278852]\n",
      " [ 0.07232877 -0.49703907 -0.86470846  0.15783211]\n",
      " [-0.35108509  0.79880228 -0.48852245  2.02548466]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.93  0.34 -0.12 -0.17]\n",
      " [ 0.07 -0.5  -0.86  0.16]\n",
      " [-0.35  0.8  -0.49  2.03]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.996024e-01, inlier_rmse=1.338865e-02, and correspondence_set size of 2514\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.71464867  0.68873721 -0.12214061 -0.17754158]\n",
      " [ 0.36071961 -0.51248389 -0.7792571   0.05207773]\n",
      " [-0.59929846  0.51283653 -0.61468695  2.25109229]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.71464867  0.68873721 -0.12214061 -0.17754158]\n",
      " [ 0.36071961 -0.51248389 -0.7792571   0.05207773]\n",
      " [-0.59929846  0.51283653 -0.61468695  2.25109229]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.71  0.69 -0.12 -0.18]\n",
      " [ 0.36 -0.51 -0.78  0.05]\n",
      " [-0.6   0.51 -0.61  2.25]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of suitcase_1\n"
     ]
    }
   ],
   "source": [
    "# for suitcase\n",
    "micp.set_ICP_thres(thres_ICP=0.2, thres_front_ICP=0.08)\n",
    "micp.set_multiobject_num(num=5)\n",
    "pose_dict = micp.detect(name_mask=[\"suitcase\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['dining table']\n",
      "===== Detected : dining table, 4 object(s) =====\n",
      "\n",
      "'dining table' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=2.429649e-01, and correspondence_set size of 4461\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.12475526 -0.94020075 -0.31695217  0.42278522]\n",
      " [-0.45983325  0.22828058 -0.85816161  0.95578992]\n",
      " [ 0.87919822  0.25280532 -0.40385637  1.32865771]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.12475526 -0.94020075 -0.31695217  0.42278522]\n",
      " [-0.45983325  0.22828058 -0.85816161  0.95578992]\n",
      " [ 0.87919822  0.25280532 -0.40385637  1.32865771]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "initial: \n",
      "[[ 0.12 -0.94 -0.32  0.42]\n",
      " [-0.46  0.23 -0.86  0.96]\n",
      " [ 0.88  0.25 -0.4   1.33]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.813615e-01, and correspondence_set size of 2021\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.13666545 -0.91368375 -0.38275915  0.44135759]\n",
      " [-0.52231722  0.26184881 -0.81155401  1.03669812]\n",
      " [ 0.84172874  0.31083309 -0.44144707  1.42346696]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.13666545 -0.91368375 -0.38275915  0.44135759]\n",
      " [-0.52231722  0.26184881 -0.81155401  1.03669812]\n",
      " [ 0.84172874  0.31083309 -0.44144707  1.42346696]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.14 -0.91 -0.38  0.44]\n",
      " [-0.52  0.26 -0.81  1.04]\n",
      " [ 0.84  0.31 -0.44  1.42]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Found 6DoF pose of dining table_1\n"
     ]
    }
   ],
   "source": [
    "# for dining table\n",
    "micp.set_ICP_thres(thres_ICP=2, thres_front_ICP=0.8)\n",
    "micp.set_multiobject_num(num = 1)\n",
    "color_img = cv2.imread(\"./test_img/color/0001.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "depth_img = cv2.imread(\"./test_img/depth/0001.png\", flags=cv2.IMREAD_UNCHANGED)\n",
    "Q = crob.get_real_robot_pose()\n",
    "micp.cache_sensor(color_img, depth_img, Q)\n",
    "pose_dict = micp.detect(name_mask=[\"dining table\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pose_dict = micp.detect(name_mask=[\"suitcase\", \"clock\", \"dining table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Object to scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add table\n",
    "center, rpy = pose_refine(\"dining table\", pose_dict[\"dining table_1\"])\n",
    "table_vis = add_table(gscene, \"table\", center, rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 suitcase in the scene\n",
      "Add new suitcase in the scene\n"
     ]
    }
   ],
   "source": [
    "# add or update suitcase\n",
    "add_update_object(gscene, crob, \"suitcase\", pose_dict, height = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 clock in the scene\n",
      "Add new clock in the scene\n",
      "Add new clock in the scene\n",
      "Add new clock in the scene\n"
     ]
    }
   ],
   "source": [
    "# add or update clock\n",
    "add_update_object(gscene, crob, \"clock\", pose_dict, separate_dist=0.2, height = 0.725)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test code for multiple instance detection\n",
    "* MultiICP Detector 이전까지 실행시키고 아래의 코드 실행\n",
    "* Separte distance는 수동으로 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origianlly, 4 suitcases are existed in scene\n",
    "c10 = add_carrier(gscene, \"suitcase_0\", (1.,1.,0), (0,0,0))\n",
    "c11 = add_carrier(gscene, \"suitcase_1\", (1.,2.,0), (0,0,0))\n",
    "c12 = add_carrier(gscene, \"suitcase_2\", (2.,1.,0), (0,0,0))\n",
    "c13 = add_carrier(gscene, \"suitcase_3\", (2.,2.,0), (0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection result, but T1, T2 are already detected objects so, these are in the scene\n",
    "# T3 is newly detected object so this is not in the scene\n",
    "# Therefore, 1 and 2 should be updated, but 3 should be added\n",
    "\n",
    "T1 = SE3(Rot_axis(3, np.pi/10), (1.1,1.18,0.3))\n",
    "T2 = SE3(np.identity(3), (2.1,1.88,-0.1))\n",
    "T3 = SE3(Rot_axis(1, -np.pi/5) , (3.1,1.9,-0.2))\n",
    "pose_dict = {\"suitcase_0\":T1, \"suitcase_1\":T2, \"suitcase_2\":T3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4 suitcase in the scene\n",
      "Update existing suitcase in the scene\n",
      "Update existing suitcase in the scene\n",
      "Add new suitcase in the scene\n"
     ]
    }
   ],
   "source": [
    "add_update_object(gscene, crob, \"suitcase\", pose_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
