{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Process\n",
    "## Prepare HW\n",
    "1. Switch supply power to mobile robot system\n",
    "2. Turn on panda controller and mobile computer on the mobile system\n",
    "3. Connect to Mobile WiFi (RNB-MOBILE, PW: robot!!!1)\n",
    "4. Connect to Franka Desk (192.168.17.3) and unlock panda joints, make sure blue LED is on.\n",
    "\n",
    "## Prepare Mobile Panda\n",
    "1. Connect to mobile computer with AnyDesk (349 336 873)\n",
    "    - Proceed this section in connected mobile computer.\n",
    "2. Prepare SteamVR\n",
    "    - Make sure Each Vive Base Station have unique ID (should be set in advance in Windows SteamVR)\n",
    "    - Make sure Vive Base Stations are placed properly (facing each other)\n",
    "    - Turn on vrmonitor\n",
    "    - Connect Vive Tracker (Menu-Devices-Pair Controller)\n",
    "    - Make sure All Base Station and Tracker icons are active\n",
    "3. Start camera server\n",
    "```bash\n",
    "cd ~/Projects/grpc_cam/\n",
    "python3 cam_grpc_server.py\n",
    "```\n",
    "    - If any error is raised, disconnect and reconnect camera \n",
    "4. Start panda control program\n",
    "```bash\n",
    "roslaunch panda_control joint_control_rnb.launch robot_ip:=192.168.17.3 load_gripper:=false\n",
    "```\n",
    "5. Start mobile robot server\n",
    "```bash\n",
    "~/run_mobile_server.sh\n",
    "```\n",
    "\n",
    "\n",
    "## Proceed Experiment\n",
    "* Place table, chair, clocks and target markers and run scripts below\n",
    "\n",
    "\n",
    "## Trouble shooting\n",
    "* Panda stop: panda controller can stop due to excessive  torque or network loss\n",
    "    - push and turn panda activation button to reset state, and restart panda control program\n",
    "    \n",
    "## NOTE\n",
    "* Panda joint offset value backup:\n",
    " - [-0.01, -0.009, -0.022, 0.0, 0.007, -0.012, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "QOFF_PANDA = [-0.01, -0.009, -0.022, 0.0, 0.007, -0.012, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile IP: 192.168.17.2\n",
      "ROBOT  IP: 192.168.17.2\n",
      "PANDA  IP: 192.168.17.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src')))\n",
    "sys.path.append(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/demo_202107'))\n",
    "\n",
    "CONNECT_MOBILE = True\n",
    "CONNECT_ROBOT = True\n",
    "SAVE_DATA = False\n",
    "\n",
    "MOBILE_IP = \"192.168.17.2\"\n",
    "ROBOT_IP = \"192.168.17.2\"\n",
    "PANDA_IP = \"192.168.17.3\"\n",
    "\n",
    "print(\"Mobile IP: {}\".format(MOBILE_IP))\n",
    "print(\"ROBOT  IP: {}\".format(ROBOT_IP))\n",
    "print(\"PANDA  IP: {}\".format(PANDA_IP))\n",
    "\n",
    "sys.path.append(os.path.join(\n",
    "    os.environ[\"RNB_PLANNING_DIR\"], 'src/scripts/developing/multiobject'))\n",
    "\n",
    "from concurrent import futures\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import grpc\n",
    "import RemoteCam_pb2\n",
    "import RemoteCam_pb2_grpc\n",
    "\n",
    "MAX_MESSAGE_LENGTH = 10000000\n",
    "PORT_CAM = 10509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection command:\n",
      "pmb0: True\n",
      "panda_arm1: True\n"
     ]
    }
   ],
   "source": [
    "ROBOT_BASE_OFFSET = (+0.02-0.035-0.15+0.008,0,0.592)\n",
    "ROBOT_BASE_RPY = (0,0,0)\n",
    "TOOL_NAME = \"brush_face\"\n",
    "WALL_THICKNESS = 0.01\n",
    "CLEARANCE = 0.001\n",
    "WS_HEIGHT = 1.7\n",
    "COL_COLOR = (1,1,1,0.2)\n",
    "    \n",
    "LOG_FORCE = False\n",
    "\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.project_config import *\n",
    "\n",
    "kiro_udp_client.KIRO_UDP_OFFLINE_DEBUG = not CONNECT_MOBILE\n",
    "\n",
    "mobile_config = RobotConfig(0, RobotType.pmb, ((0,0,0), (0,0,0)), MOBILE_IP)\n",
    "robot_config = RobotConfig(1, RobotType.panda_arm, \n",
    "                           (ROBOT_BASE_OFFSET, ROBOT_BASE_RPY),\n",
    "                           \"{}/{}\".format(ROBOT_IP, PANDA_IP), root_on=\"pmb0_platform\")\n",
    "\n",
    "ROBOT_TYPE = robot_config.type\n",
    "MOBILE_NAME = mobile_config.get_indexed_name()\n",
    "ROBOT_NAME = robot_config.get_indexed_name()\n",
    "crob = CombinedRobot(robots_on_scene=[mobile_config, robot_config],\n",
    "                     connection_list=[CONNECT_MOBILE, CONNECT_ROBOT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to register with master node [http://localhost:11311]: master may not be running yet. Will keep trying.\n",
      "Please create a subscriber to the marker\n",
      "publication OK\n",
      "published: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Please create a subscriber to the marker\n"
     ]
    }
   ],
   "source": [
    "from pkg.geometry.builder.scene_builder import SceneBuilder\n",
    "from pkg.planning.scene import PlanningScene\n",
    "\n",
    "s_builder = SceneBuilder(None)\n",
    "gscene = s_builder.create_gscene(crob)\n",
    "gtems = s_builder.add_robot_geometries(\n",
    "    color=COL_COLOR, display=True, collision=True)\n",
    "\n",
    "gscene.set_workspace_boundary(\n",
    "    -1, 4, -2.5, 2.5, -CLEARANCE, WS_HEIGHT, thickness=WALL_THICKNESS)\n",
    "\n",
    "HOME_POSE_DEFAULT = np.copy(crob.home_pose)\n",
    "gscene.show_pose(crob.home_pose)\n",
    "crob.simulator.gscene=gscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.geometry.geometry import *\n",
    "from pkg.utils.code_scraps import *\n",
    "from pkg.planning.constraint.constraint_subject import *\n",
    "from pkg.planning.constraint.constraint_actor import *\n",
    "from exp_config import *\n",
    "\n",
    "pscene = PlanningScene(gscene, combined_robot=crob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_BASE = pscene.robot_chain_dict[ROBOT_NAME]['link_names'][0]\n",
    "TIP_LINK = pscene.robot_chain_dict[ROBOT_NAME][\"tip_link\"]\n",
    "MOBILE_BASE = pscene.robot_chain_dict[MOBILE_NAME][\"tip_link\"]\n",
    "HOLD_LINK = MOBILE_BASE\n",
    "BRUSH_NAME = \"brush_face\"\n",
    "theta = -np.pi*3/4\n",
    "viewpoint  = add_panda_cam(gscene, tool_link=TIP_LINK, theta=theta)\n",
    "brush_face = add_panda_brush(gscene, tool_link=TIP_LINK, theta=theta, brush_name=BRUSH_NAME)\n",
    "\n",
    "point_brush, rpy_brush = (0,0,-brush_face.dims[2]/2), (0,0,0)\n",
    "brush_b = pscene.create_binder(BRUSH_NAME, BRUSH_NAME, WayFramer, point=point_brush, rpy=rpy_brush)\n",
    "gscene.show_pose(HOME_POSE_DEFAULT)\n",
    "\n",
    "MOBILE_PUSH_NAME = \"mpush\"\n",
    "MOBILE_PUSH_HEIGHT = 0.4\n",
    "MOBILE_PUSH_KEY = 1\n",
    "MOBILE_SLIDE_KEY = 2\n",
    "front_dist = 0.03\n",
    "mpush_g = gscene.create_safe(GEOTYPE.SPHERE, MOBILE_PUSH_NAME, link_name=HOLD_LINK,dims=(0.01,0.01,0.01),\n",
    "                           center=(front_dist, 0, MOBILE_PUSH_HEIGHT), rpy=(0,np.pi/2,0),\n",
    "                           fixed=True, collision=False, color=(1,0,0,0.5))\n",
    "mpush_b = pscene.create_binder(MOBILE_PUSH_NAME, MOBILE_PUSH_NAME, FramedTool, point=(0,0,0), rpy=(0,0,0), key=MOBILE_PUSH_KEY)\n",
    "\n",
    "floor_b = pscene.create_binder(\"floor_ws\", \"floor_ws\", PlaceFrame, point=(0,0,WALL_THICKNESS/2), key=MOBILE_SLIDE_KEY)\n",
    "\n",
    "TOOL_PUSH_NAME = \"tpush\"\n",
    "TOOL_PUSH_KEY = 10\n",
    "TOOL_SLIDE_KEY = 11\n",
    "brush_col = gscene.NAME_DICT[BRUSH_NAME+\"_col\"]\n",
    "TOOL_DIM = brush_col.dims\n",
    "\n",
    "center_push, rpy_push = (TOOL_DIM[0]/2+CLEARANCE, 0, 0), (0,np.pi/2,0)    \n",
    "tpush_g = gscene.create_safe(GEOTYPE.SPHERE, TOOL_PUSH_NAME, link_name=TIP_LINK,dims=(0.01,0.01,0.01),\n",
    "                           center=center_push, rpy=rpy_push,\n",
    "                           fixed=True, collision=False, color=(1,0,0,0.5), parent=BRUSH_NAME)\n",
    "tpush_b = pscene.create_binder(TOOL_PUSH_NAME, TOOL_PUSH_NAME, FramedTool, point=(0,0,0), rpy=(0,0,0), key=TOOL_PUSH_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start detecting - set joint offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.controller.trajectory_client.web_client import *\n",
    "wc = WebClient(ip='192.168.17.2', port=9990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI sent: http://192.168.17.2:9990/param_setting?q_off6=0.0&q_off5=-0.012&q_off4=0.007&q_off3=0.0&q_off2=-0.022&q_off1=-0.009&q_off0=-0.01\n"
     ]
    }
   ],
   "source": [
    "wc.change_gain(**{\"q_off{}\".format(i_q): q_off_val for i_q, q_off_val in enumerate(QOFF_PANDA)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiICP Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.multiICP.multiICP import MultiICP, MultiICP_Obj\n",
    "from pkg.detector.multiICP.config import *\n",
    "from pkg.detector.camera.realsense import RealSense\n",
    "from pkg.detector.detector_interface import DetectionLevel\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "CONNECT_CAM = False\n",
    "REMOTE_CAM = True\n",
    "\n",
    "CARRIER_DIM = (0.4, 0.29, 0.635)\n",
    "CLOCK_DIM = (0.138, 0.05, 0.078)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera is not set - skip initialization, use remote camera\n",
      "request 0 -> response 0\n",
      "==== Received camera config from remote camera ====\n"
     ]
    }
   ],
   "source": [
    "from demo_utils.data_reconstructed_camera import DataRecontructedCamera\n",
    "dcam = DataRecontructedCamera(crob, viewpoint)\n",
    "# if not CONNECT_CAM and not REMOTE_CAM:\n",
    "#     dcam.initialize()\n",
    "\n",
    "if CONNECT_CAM:\n",
    "    realsense = RealSense()\n",
    "    micp = MultiICP(realsense)\n",
    "    micp.initialize()\n",
    "else:\n",
    "    if REMOTE_CAM:\n",
    "        # use remote camera\n",
    "        micp = MultiICP(None)\n",
    "        micp.initialize(remote_cam=REMOTE_CAM)\n",
    "#         dcam.ready_saving(*micp.get_camera_config())\n",
    "#         cam_pose = viewpoint.get_tf(VIEW_POSE_EXT)\n",
    "    else:\n",
    "        # use manually given camera configs\n",
    "        micp = MultiICP(None)\n",
    "        config_list, img_dim = load_pickle(RNB_PLANNING_DIR+\"release/multiICP_data/cam_configs.pkl\")\n",
    "        micp.initialize(config_list, img_dim)\n",
    "#         micp = MultiICP(dcam)\n",
    "#         micp.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.utils.shared_function import clear_channels_on, sa\n",
    "clear_channels_on(\"SharedDetector\")\n",
    "\n",
    "from pkg.detector.multiICP.shared_detector import SharedDetectorGen\n",
    "sd = SharedDetectorGen(tuple(reversed(micp.dsize))+(3,))()\n",
    "sd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set ICP Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config file of object information\n",
    "obj_info_dict = get_obj_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_suitcase = MultiICP_Obj(obj_info_dict[\"suitcase\"], None,\n",
    "                        OffsetOnModelCoord(\"suitcase\", R=np.matmul(Rot_axis(1, 2*np.pi/3), Rot_axis(3, np.pi/2)), offset=(0.,0.,0.2)))\n",
    "\n",
    "\n",
    "micp_clock = MultiICP_Obj(obj_info_dict[\"clock\"], None,\n",
    "                        OffsetOnModelCoord(\"clock\", R=Rot_axis(1, np.pi/4), offset=(-0.04,-0.03,0.04)))\n",
    "\n",
    "\n",
    "micp_table = MultiICP_Obj(obj_info_dict[\"dining table\"], None,\n",
    "                        OffsetOnModelCoord(\"dining table\", R=Rot_axis(1, 3*np.pi/4), offset=(0.,0.35,0.6)))\n",
    "\n",
    "micp_chair = MultiICP_Obj(obj_info_dict[\"chair\"], None,\n",
    "                        OffsetOnModelCoord(\"chair\", R=Rot_axis(1, 3*np.pi/4), offset=(0.1, 0.1,0.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "micp_dict = {\"suitcase\": micp_suitcase, \"clock\": micp_clock,\n",
    "             \"dining table\": micp_table, \"chair\": micp_chair}\n",
    "micp.set_config(micp_dict, sd, crob, viewpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW_LOC = crob.get_real_robot_pose()[:6]\n",
    "VIEW_ARM = HOME_POSE_DEFAULT[6:] + np.deg2rad([0,0,0,0,0,45,-45])\n",
    "VIEW_TABLE = list(VIEW_LOC) + list(VIEW_ARM)\n",
    "crob.joint_move_make_sure(np.array(VIEW_TABLE), ref_speed=np.pi/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLE_NAME = \"table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['dining table']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "Maximun num of object for detection : 1\n",
      "===== Detected : dining table, 1 object(s) =====\n",
      "[NOTICE] You choose merge option for mask. Detected masks would be merged.\n",
      "\n",
      "'dining table' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.876977e-01, inlier_rmse=2.396227e-01, and correspondence_set size of 562\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.95550638  0.2849378   0.07627588 -0.18591386]\n",
      " [ 0.21914704 -0.51265794 -0.83015443  0.34029197]\n",
      " [-0.19743895  0.80993349 -0.5522912   3.52891823]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.95550638  0.2849378   0.07627588 -0.18591386]\n",
      " [ 0.21914704 -0.51265794 -0.83015443  0.34029197]\n",
      " [-0.19743895  0.80993349 -0.5522912   3.52891823]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Inlier ratio: 0.13282247765\n",
      "initial: \n",
      "[[ 0.96  0.28  0.08 -0.19]\n",
      " [ 0.22 -0.51 -0.83  0.34]\n",
      " [-0.2   0.81 -0.55  3.53]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=6.438356e-01, inlier_rmse=1.023125e-01, and correspondence_set size of 141\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.97535185  0.21905103  0.02655947 -0.16489854]\n",
      " [ 0.11390545 -0.39674121 -0.91083584  0.43650051]\n",
      " [-0.1889823   0.8914107  -0.41191338  3.48107938]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.97535185  0.21905103  0.02655947 -0.16489854]\n",
      " [ 0.11390545 -0.39674121 -0.91083584  0.43650051]\n",
      " [-0.1889823   0.8914107  -0.41191338  3.48107938]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.98  0.22  0.03 -0.16]\n",
      " [ 0.11 -0.4  -0.91  0.44]\n",
      " [-0.19  0.89 -0.41  3.48]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Inlier ratio: 0.072934973638\n",
      "Found 6DoF pose of dining table_1\n"
     ]
    }
   ],
   "source": [
    "# for dining table\n",
    "micp.set_ICP_thres(thres_ICP=0.6, thres_front_ICP=0.18)\n",
    "micp.set_pcd_ratio(ratio=0.5)\n",
    "micp.set_inlier_ratio(ratio=0.02)\n",
    "# micp.set_multiobject_num(num = 1)\n",
    "micp.set_merge_mask(merge=True)\n",
    "pose_dict = micp.detect(name_mask=[\"dining table\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add table\n",
    "center, rpy = pose_refine(\"dining table\", pose_dict[\"dining table_1\"])\n",
    "table_vis, table_g = add_table(gscene, TABLE_NAME, center, rpy)\n",
    "TABLE_HEIGHT = table_g.center[2] + table_g.dims[2]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_b = pscene.create_binder(TABLE_NAME, TABLE_NAME, PlaceFrame, point=(0,0,table_g.dims[2]/2), key=TOOL_SLIDE_KEY)\n",
    "# gscene.add_virtual_guardrail(table_g, HEIGHT=0.01, axis=\"xy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tbt = table_g.get_tf(HOME_POSE_DEFAULT)\n",
    "Tbm = gscene.get_tf(MOBILE_BASE, VIEW_TABLE)\n",
    "Ttm = np.matmul(np.linalg.inv(Tbt), Tbm)\n",
    "\n",
    "Ymax = table_g.dims[1]/2\n",
    "Ymin = Ttm[1,3]-0.9\n",
    "Xmax = Ttm[0,3]+0.8\n",
    "Xmin = -table_g.dims[0]/2-0.3\n",
    "Xtc = np.mean([Xmax, Xmin])\n",
    "Ytc = np.mean([Ymax, Ymin])\n",
    "dX = Xmax - Xmin\n",
    "dY = Ymax - Ymin\n",
    "Xbc, Ybc, _, _ = np.matmul(Tbt, [Xtc, Ytc, 0, 1])\n",
    "Xmax, Xmin = Xbc + dX/2, Xbc - dX/2\n",
    "Ymax, Ymin = Ybc + dY/2, Ybc - dY/2\n",
    "\n",
    "gscene.set_workspace_boundary(\n",
    "    Xmin, Xmax, Ymin, Ymax, -CLEARANCE, WS_HEIGHT, thickness=WALL_THICKNESS, \n",
    "    RPY=Rot2rpy(Tbt[:3,:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pkg.geometry.geometry.GeometryItem at 0x7fbc440d6690>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floor_ws = gscene.NAME_DICT[\"floor_ws\"]\n",
    "gscene.create_safe(GEOTYPE.BOX, \"obstacle_corner\", link_name=\"base_link\",\n",
    "                   dims = (0.5,0.5,1), \n",
    "                   center=(floor_ws.dims[0]/2-0.3, floor_ws.dims[1]/2-0.3, 0.5), \n",
    "                  display=True, collision=True, parent=\"floor_ws\",\n",
    "                  color=(1,1,0,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [SAVE DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DATA:\n",
    "    color, depth, Qcur = micp.get_image()\n",
    "    cam_pose = viewpoint.get_tf(Qcur)\n",
    "    dcam.ready_saving(*micp.get_camera_config())\n",
    "    dcam.save_scene(color, depth, cam_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    try:\n",
    "        gscene.remove(gscene.NAME_DICT[\"chair_{}\".format(i)])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_mask is ['chair']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "Maximun num of object for detection : 5\n",
      "===== Detected : chair, 1 object(s) =====\n",
      "\n",
      "'chair' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=6.743235e-02, and correspondence_set size of 12936\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.93816025 -0.34198204  0.05388536 -0.44804352]\n",
      " [-0.14941331 -0.54036167 -0.82806093  0.44853513]\n",
      " [ 0.31229956  0.76880266 -0.5580425   2.03317537]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.93816025 -0.34198204  0.05388536 -0.44804352]\n",
      " [-0.14941331 -0.54036167 -0.82806093  0.44853513]\n",
      " [ 0.31229956  0.76880266 -0.5580425   2.03317537]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Inlier ratio: 0.105095788412\n",
      "initial: \n",
      "[[ 0.94 -0.34  0.05 -0.45]\n",
      " [-0.15 -0.54 -0.83  0.45]\n",
      " [ 0.31  0.77 -0.56  2.03]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.914453e-01, inlier_rmse=2.576220e-02, and correspondence_set size of 4262\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99470425 -0.08765497 -0.05366616 -0.38355206]\n",
      " [-0.09469445 -0.57862179 -0.81008009  0.41162376]\n",
      " [ 0.03995514  0.810872   -0.58385799  2.03891215]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.99470425 -0.08765497 -0.05366616 -0.38355206]\n",
      " [-0.09469445 -0.57862179 -0.81008009  0.41162376]\n",
      " [ 0.03995514  0.810872   -0.58385799  2.03891215]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.99 -0.09 -0.05 -0.38]\n",
      " [-0.09 -0.58 -0.81  0.41]\n",
      " [ 0.04  0.81 -0.58  2.04]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Inlier ratio: 0.0950061842919\n",
      "Found 6DoF pose of chair_1\n",
      "Total 0 chair in the scene\n",
      "Add new chair in the scene\n",
      "name_mask is ['chair']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "Maximun num of object for detection : 5\n",
      "===== Detected : chair, 2 object(s) =====\n",
      "\n",
      "'chair' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=6.671509e-02, and correspondence_set size of 11095\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99684641 -0.07789495  0.01515295  0.49712799]\n",
      " [-0.0259385  -0.50030206 -0.86546231  0.45254463]\n",
      " [ 0.0749962   0.86233995 -0.50074479  1.94050101]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.99684641 -0.07789495  0.01515295  0.49712799]\n",
      " [-0.0259385  -0.50030206 -0.86546231  0.45254463]\n",
      " [ 0.0749962   0.86233995 -0.50074479  1.94050101]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Inlier ratio: 0.0995850622407\n",
      "initial: \n",
      "[[ 1.   -0.08  0.02  0.5 ]\n",
      " [-0.03 -0.5  -0.87  0.45]\n",
      " [ 0.07  0.86 -0.5   1.94]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.345768e-01, inlier_rmse=2.915834e-02, and correspondence_set size of 3915\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99205191  0.12474467 -0.01648578  0.51372762]\n",
      " [ 0.06504081 -0.62052542 -0.7814844   0.4042583 ]\n",
      " [-0.10771586  0.77420084 -0.62370692  2.01158853]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.99205191  0.12474467 -0.01648578  0.51372762]\n",
      " [ 0.06504081 -0.62052542 -0.7814844   0.4042583 ]\n",
      " [-0.10771586  0.77420084 -0.62370692  2.01158853]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.99  0.12 -0.02  0.51]\n",
      " [ 0.07 -0.62 -0.78  0.4 ]\n",
      " [-0.11  0.77 -0.62  2.01]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Inlier ratio: 0.0930148715638\n",
      "Found 6DoF pose of chair_1\n",
      "\n",
      "'chair' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=5.267000e-02, and correspondence_set size of 11185\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.92821782 -0.36760146  0.05727866 -0.57193333]\n",
      " [-0.18237531 -0.58378594 -0.7911594   0.12273584]\n",
      " [ 0.32426984  0.72392203 -0.60892194  2.49098328]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.92821782 -0.36760146  0.05727866 -0.57193333]\n",
      " [-0.18237531 -0.58378594 -0.7911594   0.12273584]\n",
      " [ 0.32426984  0.72392203 -0.60892194  2.49098328]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Inlier ratio: 0.160540202129\n",
      "initial: \n",
      "[[ 0.93 -0.37  0.06 -0.57]\n",
      " [-0.18 -0.58 -0.79  0.12]\n",
      " [ 0.32  0.72 -0.61  2.49]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.113953e-01, inlier_rmse=2.646984e-02, and correspondence_set size of 3919\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.9227875  -0.38478162  0.0201579  -0.56353935]\n",
      " [-0.19706084 -0.51625637 -0.83345447  0.14697463]\n",
      " [ 0.33110461  0.76512903 -0.55222031  2.48821252]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.9227875  -0.38478162  0.0201579  -0.56353935]\n",
      " [-0.19706084 -0.51625637 -0.83345447  0.14697463]\n",
      " [ 0.33110461  0.76512903 -0.55222031  2.48821252]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.92 -0.38  0.02 -0.56]\n",
      " [-0.2  -0.52 -0.83  0.15]\n",
      " [ 0.33  0.77 -0.55  2.49]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Inlier ratio: 0.11113097899\n",
      "Found 6DoF pose of chair_2\n",
      "Total 1 chair in the scene\n",
      "Update existing chair in the scene\n",
      "Add new chair in the scene\n",
      "name_mask is ['chair']\n",
      "request 0 -> response 0\n",
      "==== Received color, depth image from remote camera ====\n",
      "Maximun num of object for detection : 5\n",
      "===== Detected : chair, 3 object(s) =====\n",
      "\n",
      "'chair' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=5.081226e-02, and correspondence_set size of 9441\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.94599535  0.32402939  0.00988651 -0.49903959]\n",
      " [ 0.17735537 -0.49177456 -0.85246866  0.1110362 ]\n",
      " [-0.27136298  0.80818482 -0.5226848   2.52785178]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.94599535  0.32402939  0.00988651 -0.49903959]\n",
      " [ 0.17735537 -0.49177456 -0.85246866  0.1110362 ]\n",
      " [-0.27136298  0.80818482 -0.5226848   2.52785178]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Inlier ratio: 0.13418394471\n",
      "initial: \n",
      "[[ 0.95  0.32  0.01 -0.5 ]\n",
      " [ 0.18 -0.49 -0.85  0.11]\n",
      " [-0.27  0.81 -0.52  2.53]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=9.479371e-01, inlier_rmse=2.929551e-02, and correspondence_set size of 3860\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.98134685  0.19181837  0.01280935 -0.49919458]\n",
      " [ 0.12341219 -0.57748794 -0.80701739  0.09546223]\n",
      " [-0.14740353  0.7935448  -0.59038869  2.58302967]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.98134685  0.19181837  0.01280935 -0.49919458]\n",
      " [ 0.12341219 -0.57748794 -0.80701739  0.09546223]\n",
      " [-0.14740353  0.7935448  -0.59038869  2.58302967]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.98  0.19  0.01 -0.5 ]\n",
      " [ 0.12 -0.58 -0.81  0.1 ]\n",
      " [-0.15  0.79 -0.59  2.58]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Inlier ratio: 0.135367016206\n",
      "Found 6DoF pose of chair_1\n",
      "\n",
      "'chair' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=8.924761e-02, and correspondence_set size of 28066\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.69833613  0.66218871 -0.27172182 -1.10204137]\n",
      " [ 0.25350626 -0.58383149 -0.77128162 -0.17693428]\n",
      " [-0.66937376  0.46973063 -0.57557961  2.73897868]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.69833613  0.66218871 -0.27172182 -1.10204137]\n",
      " [ 0.25350626 -0.58383149 -0.77128162 -0.17693428]\n",
      " [-0.66937376  0.46973063 -0.57557961  2.73897868]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Inlier ratio: 0.0352034811142\n",
      "\n",
      "'chair' is not in gscene. Use manual input for initial guess\n",
      "\n",
      "Apply point-to-point ICP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registration::RegistrationResult with fitness=1.000000e+00, inlier_rmse=6.251138e-02, and correspondence_set size of 10631\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.9725274   0.22948728 -0.03906467  0.67370124]\n",
      " [ 0.1423839  -0.71916753 -0.68009179  0.1190211 ]\n",
      " [-0.18416646  0.65584572 -0.73208543  2.48057075]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.9725274   0.22948728 -0.03906467  0.67370124]\n",
      " [ 0.1423839  -0.71916753 -0.68009179  0.1190211 ]\n",
      " [-0.18416646  0.65584572 -0.73208543  2.48057075]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Inlier ratio: 0.122199209188\n",
      "initial: \n",
      "[[ 0.97  0.23 -0.04  0.67]\n",
      " [ 0.14 -0.72 -0.68  0.12]\n",
      " [-0.18  0.66 -0.73  2.48]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Apply point-to-point ICP\n",
      "registration::RegistrationResult with fitness=8.887750e-01, inlier_rmse=3.224442e-02, and correspondence_set size of 3468\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.96570829  0.25221121 -0.06161982  0.69908203]\n",
      " [ 0.12274195 -0.65264151 -0.74765864  0.11567866]\n",
      " [-0.22878355  0.71445681 -0.66121821  2.46904927]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Total ICP Transformation is:\n",
      "[[ 0.96570829  0.25221121 -0.06161982  0.69908203]\n",
      " [ 0.12274195 -0.65264151 -0.74765864  0.11567866]\n",
      " [-0.22878355  0.71445681 -0.66121821  2.46904927]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "result: \n",
      "[[ 0.97  0.25 -0.06  0.7 ]\n",
      " [ 0.12 -0.65 -0.75  0.12]\n",
      " [-0.23  0.71 -0.66  2.47]\n",
      " [ 0.    0.    0.    1.  ]]\n",
      "Inlier ratio: 0.0927476248707\n",
      "Found 6DoF pose of chair_2\n",
      "Total 2 chair in the scene\n",
      "Update existing chair in the scene\n",
      "Add new chair in the scene\n"
     ]
    }
   ],
   "source": [
    "panda_arm1 = crob.robot_dict[\"panda_arm1\"]\n",
    "img_list = []\n",
    "for theta0 in [-30, 0, 30]:\n",
    "    VIEW_LOC = crob.get_real_robot_pose()[:6]\n",
    "#     VIEW_ARM = HOME_POSE_DEFAULT[6:] + np.deg2rad([theta0,-45,0,-70,0,70,-45])\n",
    "    VIEW_ARM = HOME_POSE_DEFAULT[6:] + np.deg2rad([theta0,-55,0,-65,0,45,-45])\n",
    "    VIEW_CHAIR = list(VIEW_LOC) + list(VIEW_ARM)\n",
    "    \n",
    "    crob.joint_move_make_sure(np.array(VIEW_CHAIR), ref_speed=np.pi/8)\n",
    "    \n",
    "    # for chair\n",
    "    micp.set_ICP_thres(thres_ICP=0.3, thres_front_ICP=0.08)\n",
    "    micp.set_pcd_ratio(ratio=1)\n",
    "    micp.set_inlier_ratio(ratio=0.05)\n",
    "    micp.set_multiobject_num(num = 5)\n",
    "    micp.set_outlier_removal(nb_points=18, radius=0.05)\n",
    "    # micp.set_merge_mask(merge=True)\n",
    "    pose_dict = micp.detect(name_mask=[\"chair\"], visualize=True)\n",
    "    \n",
    "    # add or update suitcase\n",
    "    add_update_object(gscene, crob, \"chair\", pose_dict, separate_dist=0.28, height = 0)\n",
    "    \n",
    "    color, depth = micp.last_input[:2]\n",
    "    Qcur = crob.get_real_robot_pose()\n",
    "    \n",
    "    img_list.append((color, depth))\n",
    "    \n",
    "    # save data\n",
    "    if SAVE_DATA:\n",
    "        cam_pose = viewpoint.get_tf(Qcur)\n",
    "        dcam.ready_saving(*micp.get_camera_config())\n",
    "        dcam.save_scene(color, depth, cam_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcol_names = sorted([gname for gname in gscene.NAME_DICT.keys() \n",
    "                 if \"chair\" in gname and \"col\" in gname])\n",
    "chair_names = []\n",
    "\n",
    "for gcol_name in gcol_names:\n",
    "    chair_col_g = gscene.NAME_DICT[gcol_name]\n",
    "    chair_g = gscene.NAME_DICT[chair_col_g.parent]\n",
    "    chair_dim = chair_col_g.dims\n",
    "    chair_name = chair_g.name\n",
    "    chair_names.append(chair_name)\n",
    "    push_point_list = []\n",
    "    for i in range(4):\n",
    "        R = Rot_axis_series([3, 2], [np.pi/2*i, np.pi/2])\n",
    "        point = np.round(np.multiply(chair_dim, -R[:,2])/2, 4)\n",
    "        point[2] = MOBILE_PUSH_HEIGHT\n",
    "        ap_name = \"side{}\".format(i)\n",
    "        push_point_list.append(FramePoint(ap_name, chair_g, point=point, rpy=Rot2rpy(R), key=MOBILE_PUSH_KEY))\n",
    "\n",
    "    slide_point = SlidePoint(\"bottom_p\", chair_g, point=(0,0,-CLEARANCE), rpy=(0,0,0), \n",
    "                                               binded_on=floor_b, dist_push_min=0.1, dist_push_max=1.0, key=MOBILE_SLIDE_KEY)\n",
    "\n",
    "    chair_s = pscene.create_subject(oname=chair_name, gname=chair_name, _type=PushObject, \n",
    "                                  push_point_list=push_point_list, slide_point=slide_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add  ref waypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_body = gscene.NAME_DICT[TABLE_NAME]\n",
    "\n",
    "WP_NAME = \"wp_0\"\n",
    "WP_DIM = (0.1,0.1,0.01)\n",
    "WP_LOC = (0, -0.2, table_body.dims[2]/2+WP_DIM[2]/2)\n",
    "WP_RPY = (0,0,np.pi/2)\n",
    "\n",
    "wp_g = gscene.create_safe(GEOTYPE.BOX, WP_NAME, link_name=\"base_link\", \n",
    "                          dims=WP_DIM,\n",
    "                          center=(WP_LOC[0], WP_LOC[1], WP_LOC[2]), rpy=WP_RPY,\n",
    "                          fixed=True, collision=True, color=(0.0,0.0,0.8,1), parent=TABLE_NAME)\n",
    "\n",
    "waypoint_s = pscene.create_subject(oname=\"waypoints\", gname=TABLE_NAME, _type=WaypointTask,\n",
    "                                 action_points_dict={\n",
    "                                     wp_g.name: WayFrame(\n",
    "                                         wp_g.name, wp_g, [0, 0, wp_g.dims[2] / 2], [0, 0, 0])\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[WARN] reach data is not ready for pmb. Ignoring this robot...\u001b[0m\n",
      "Dash is running on http://0.0.0.0:8050/\n",
      "\n",
      " * Serving Flask app \"pkg.ui.dash_launcher\" (lazy loading)\n",
      " * Environment: production\n"
     ]
    }
   ],
   "source": [
    "from pkg.planning.filtering.grasp_filter import GraspChecker\n",
    "from pkg.planning.filtering.reach_filter import ReachChecker\n",
    "gcheck = GraspChecker(pscene)\n",
    "rcheck = ReachChecker(pscene)\n",
    "\n",
    "from pkg.planning.motion.moveit.moveit_planner import MoveitPlanner\n",
    "mplan = MoveitPlanner(pscene, enable_dual=False)\n",
    "mplan.update_gscene()\n",
    "mplan.incremental_constraint_motion = True\n",
    "\n",
    "from pkg.planning.incremental_search import *\n",
    "# joint motion is not allowed when pusing object with holder\n",
    "idc_push = np.where([stype == PushObject for stype in pscene.subject_type_list])[0]\n",
    "inc = IncrementalSearch(pscene, gcheck, rcheck, \n",
    "                        explicit_rule= lambda pscene, node, leaf: not any([node[idx]==leaf[idx] and \"push\" in node[idx] for idx in idc_push]))\n",
    "inc.prepare()\n",
    "inc.set_motion_planner(mplan)\n",
    "\n",
    "cresv = CollisionResolver(inc, gcheck)\n",
    "rresv = ReachResolver(inc, rcheck, mplan, floor=floor_b.geometry, N_try_max=100)\n",
    "mresv = MotionResolver(inc, mplan)\n",
    "inc.resolver_stack = [cresv, rresv, mresv]\n",
    "\n",
    "from pkg.ui.ui_broker import *\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(inc, s_builder)\n",
    "ui_broker.start_server()\n",
    "\n",
    "ui_broker.set_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n",
      "['chair_0', 'chair_1', 'chair_2', 'waypoints']\n",
      "('floor_ws', 'floor_ws', 'floor_ws', 0)\n"
     ]
    }
   ],
   "source": [
    "gscene.show_pose(VIEW_TABLE)\n",
    "chain_list = \\\n",
    "    [BindingChain(chair_name, \"bottom_p\", \"floor_ws\", \"floor_ws\") for chair_name in chair_names] \\\n",
    "    + [BindingChain(\"waypoints\", None, None, None)]\n",
    "# chain_list = \\\n",
    "#     [BindingChain(bag_name, \"bottom_p\", \"floor_ws\", \"floor_ws\") for chair_name in chair_names] \\\n",
    "#     + [BindingChain(clock_name, \"bottom_p\", \"table\", \"table\") for clock_name in clock_names] \\\n",
    "#     + [BindingChain(\"waypoints\", None, None, None)]\n",
    "initial_state = pscene.initialize_state(VIEW_TABLE, chain_list=chain_list)\n",
    "gscene.update_markers_all()\n",
    "print(pscene.subject_name_list)\n",
    "print(initial_state.node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonholonomic_planner import *\n",
    "\n",
    "nhp = NonHolonomicPlanner(mplan, MOBILE_NAME, min_radi=MIN_RADI_DEFAULT)\n",
    "def custom_planner(group_name, tool_link, goal_pose, target_link, from_Q,\n",
    "                   timeout=1, **kwargs):\n",
    "    if group_name == MOBILE_NAME:\n",
    "        Tbm = np.matmul(gscene.get_tf(target_link, from_Q), \n",
    "                        T_xyzquat((goal_pose[:3], goal_pose[3:])))\n",
    "        to_Q = Tbm[:2, 3].tolist()+[Rot2axis(Tbm[:3,:3], 3)]\n",
    "        traj = nhp.search(from_Q, to_Q, timeout=timeout, update_gscene=False)\n",
    "        return traj, traj is not None\n",
    "    else:\n",
    "        return mplan.planner.plan_py(group_name, tool_link, goal_pose, target_link, from_Q,\n",
    "                       timeout=1, **kwargs)\n",
    "    \n",
    "def custom_planner_joint(group_name, goal_state, Q_init, timeout=1, **kwargs):\n",
    "    if group_name == MOBILE_NAME:\n",
    "        custom_planner_joint.args = (group_name, goal_state, Q_init, timeout)\n",
    "        custom_planner_joint.kwargs = kwargs\n",
    "        traj = nhp.search(Q_init, goal_state[:3], timeout=timeout, update_gscene=False)\n",
    "#         if traj is None:\n",
    "#             raise(RuntimeError(\"fail\"))\n",
    "        return traj, traj is not None\n",
    "    else:\n",
    "        return mplan.planner.plan_joint_motion_py(group_name, goal_state, Q_init, timeout=1, **kwargs)\n",
    "    \n",
    "mplan.custom_planner = custom_planner\n",
    "mplan.custom_planner_joint = custom_planner_joint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start moving - set joint offset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI sent: http://192.168.17.2:9990/param_setting?q_off6=0&q_off5=0&q_off4=0&q_off3=0&q_off2=0&q_off1=0&q_off0=0\n"
     ]
    }
   ],
   "source": [
    "wc.change_gain(**{\"q_off{}\".format(i_q): 0 for i_q, q_off_val in enumerate(QOFF_PANDA)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "crob.joint_move_make_sure(initial_state.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "crob.home_pose = initial_state.Q\n",
    "crob.home_dict = list2dict(crob.home_pose, crob.joint_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 10/20 agents\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "\u001b[91m[WARN] Transition Queue Empty\u001b[0m\n",
      "=========================================================================================================\n",
      "======================= terminated 2: required answers acquired  (12.9/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 8: Stop called from other agent  (13.0/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 9: Stop called from other agent  (13.1/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 6: Stop called from other agent  (13.2/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 4: Stop called from other agent  (13.3/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 5: Stop called from other agent  (13.3/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 1: Stop called from other agent  (13.3/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 7: Stop called from other agent  (13.4/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 3: Stop called from other agent  (13.6/100.0) ===============================\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "======================= terminated 0: Stop called from other agent  (13.8/100.0) ===============================\n",
      "=========================================================================================================\n",
      "========================== FINISHED (13.9 / 100.0 s) ==============================]\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "DEBUG = False\n",
    "inc.prepare()\n",
    "from_state = initial_state.copy(pscene)\n",
    "goal_nodes = [initial_state.node[:-1]+(1,)]\n",
    "\n",
    "inc.search(from_state, goal_nodes, max_solution_count=1,\n",
    "           verbose=DEBUG, display=DEBUG, dt_vis=0.001, \n",
    "           timeout=1.0, timeout_loop=100, \n",
    "           multiprocess=not DEBUG, add_homing=False)\n",
    "time_approach_planning = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get snode schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snode_schedule = inc.get_best_schedule(at_home=False)\n",
    "snode_schedule_move = []\n",
    "for snode in snode_schedule:\n",
    "    if snode.state.node[-1] != 0:\n",
    "        break\n",
    "    snode_schedule_move.append(snode)\n",
    "len(snode_schedule_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### play schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscene.set_object_state(initial_state)\n",
    "gscene.show_pose(initial_state.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('floor_ws', 'floor_ws', 'floor_ws', 0)->('mpush', 'floor_ws', 'floor_ws', 0)\n",
      "('mpush', 'floor_ws', 'floor_ws', 0)->('floor_ws', 'floor_ws', 'floor_ws', 0)\n",
      "('floor_ws', 'floor_ws', 'floor_ws', 0)->('mpush', 'floor_ws', 'floor_ws', 0)\n",
      "('mpush', 'floor_ws', 'floor_ws', 0)->('floor_ws', 'floor_ws', 'floor_ws', 0)\n",
      "('floor_ws', 'floor_ws', 'floor_ws', 0)->('mpush', 'floor_ws', 'floor_ws', 0)\n",
      "('mpush', 'floor_ws', 'floor_ws', 0)->('floor_ws', 'floor_ws', 'floor_ws', 0)\n",
      "('floor_ws', 'floor_ws', 'floor_ws', 0)->('floor_ws', 'mpush', 'floor_ws', 0)\n",
      "('floor_ws', 'mpush', 'floor_ws', 0)->('floor_ws', 'floor_ws', 'floor_ws', 0)\n",
      "('floor_ws', 'floor_ws', 'floor_ws', 0)->('floor_ws', 'floor_ws', 'floor_ws', 0)\n"
     ]
    }
   ],
   "source": [
    "snode_schedule_cvt = snode_schedule_move\n",
    "inc.play_schedule(snode_schedule_cvt, period=0.002)\n",
    "pscene.set_object_state(snode_schedule_cvt[-1].state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make trajectory safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_lims, acc_lims, dt_step = 0.5, 0.5, 0.02\n",
    "snode_schedule_safe = [snode_schedule_cvt[0].copy(pscene)]\n",
    "for snode, snode_pre in zip(snode_schedule_cvt[1:], snode_schedule_cvt[:-1]):\n",
    "    snames, _ = pscene.get_changing_subjects(snode.state, snode_pre.state)\n",
    "    if len(snames) > 1:\n",
    "        raise(RuntimeError(\"More than 1 subject change - {}\".format(snames)))\n",
    "    if len(snames) == 1:\n",
    "        subject = pscene.subject_dict[snames[0]]\n",
    "    else:\n",
    "        subject = None\n",
    "        \n",
    "    snode_cp = snode.copy(pscene)\n",
    "    rpairs = crob.get_robots_in_act(snode_cp.traj)\n",
    "    for rname, robot in rpairs:\n",
    "        if rname == ROBOT_NAME:\n",
    "            traj_simp = simplify_traj(snode.traj)\n",
    "            snode_cp.set_traj(calc_safe_trajectory(\n",
    "                dt_step, traj_simp, vel_lims=vel_lims, acc_lims=acc_lims)[1])\n",
    "            break\n",
    "    snode_cp.traj[:,6:] -= QOFF_PANDA\n",
    "    snode_cp.state.Q[6:] -= QOFF_PANDA\n",
    "    snode_schedule_safe.append(snode_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForceModeSwitcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_custom_log(ip_addr, JOINT_DOF, UI_PORT=9990, DT=1.0 / 2e3):\n",
    "    uri = \"http://{ip_addr}:{UI_PORT}/download_log\".format(ip_addr=ip_addr, UI_PORT=UI_PORT)\n",
    "    print(uri)\n",
    "    log_dat = requests.get(uri)\n",
    "    dat = log_dat.text\n",
    "    lines = dat.split(\"\\n\")\n",
    "    heads = lines[0].split(\",\")[:-1]\n",
    "    data_mat = []\n",
    "    for line in lines[1:]:\n",
    "        data_line = list(map(float, line.split(\",\")[:-1]))\n",
    "        if len(data_line) > 0:\n",
    "            data_mat.append(data_line)\n",
    "    data_mat = np.array(data_mat)\n",
    "    Fext = data_mat[:, JOINT_DOF * 6+6:JOINT_DOF * 7+6]\n",
    "    Fext = Fext[-int(10.0 / DT):]\n",
    "    # idx_peak = np.argmax(Fext[:, 2])\n",
    "    # print(\"peak: {}\".format(np.round(Fext[idx_peak, 2], 1)))\n",
    "    # Fext = Fext[idx_peak + int(1.0 / DT):idx_peak + int(4.0 / DT), 2]\n",
    "    # print(\"force min/max: {} / {} in {}\".format(np.round(np.min(Fext), 1), np.round(np.max(Fext), 1), len(Fext)))\n",
    "    return Fext\n",
    "\n",
    "class SimpleForceModeSwitcher(ModeSwitcherTemplate):\n",
    "    def __init__(self, pscene, rname, crob, web_client, force_delay=5, switch_delay=0.5, log_force=False, DT=1.0 / 1e3):\n",
    "        ModeSwitcherTemplate.__init__(self, pscene, switch_delay=switch_delay)\n",
    "        self.crob = crob\n",
    "        self.web_client = web_client\n",
    "        self.DT = DT\n",
    "        self.log_force = log_force\n",
    "        self.force_log = []\n",
    "        self.rname =rname\n",
    "        self.robot = self.crob.robot_dict[rname]\n",
    "        self.force_delay = force_delay\n",
    "\n",
    "    def switch_in(self, snode_pre, snode_new):\n",
    "        switch_state = False\n",
    "        for stype, n1, n2 in zip(\n",
    "                pscene.subject_type_list, snode_pre.state.node, snode_new.state.node):\n",
    "            if stype==WaypointTask and n2>n1:\n",
    "                switch_state = True\n",
    "                break\n",
    "        return switch_state\n",
    "\n",
    "    def switch_out(self, switch_state, snode_new):\n",
    "        if switch_state:\n",
    "            self.web_client.change_controller(\"Hybrid_Null\")\n",
    "            sleep(self.switch_delay)\n",
    "            self.web_client.change_gain(switch_control0=1)\n",
    "            \n",
    "            sleep(self.force_delay)\n",
    "\n",
    "            self.robot.reset()\n",
    "            sleep(self.switch_delay)\n",
    "            self.web_client.change_gain(switch_control0=0)\n",
    "            sleep(self.switch_delay)\n",
    "            self.web_client.change_controller(\"NRIC_PD\")\n",
    "            \n",
    "            Qrobot = snode_new.state.Q[self.crob.idx_dict[self.rname]]\n",
    "            self.robot.joint_move_make_sure(Qrobot, ref_speed=np.pi / 36)  # return planned trajectory\n",
    "\n",
    "            if self.log_force:\n",
    "                sleep(self.switch_delay)\n",
    "                Fext = down_custom_log(self.robot.server_ip, len(self.crob.idx_dict[self.rname]), DT=self.DT)\n",
    "                self.force_log.append(Fext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_switcher = SimpleForceModeSwitcher(pscene, ROBOT_NAME, crob, wc, \n",
    "                                        force_delay=5, switch_delay=1, \n",
    "                                        log_force=False, DT=1.0/1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "crob.joint_move_make_sure(crob.home_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'qcount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-27c8b6e48e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnode_schedule_safe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_by_one\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_switcher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode_switcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rnb/Projects/rnb-planning/src/pkg/planning/pipeline.pyc\u001b[0m in \u001b[0;36mexecute_schedule\u001b[0;34m(self, snode_schedule, auto_stop, mode_switcher, one_by_one, multiproc, error_stop_deg, auto_sync_robot_pose)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 \u001b[0mt_exe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpscene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_robot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_joint_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_by_one\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_by_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpscene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_robot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_robots_in_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No motion for connected robot - playing motion in RVIZ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rnb/Projects/rnb-planning/src/pkg/controller/combined_robot.pyc\u001b[0m in \u001b[0;36mmove_joint_traj\u001b[0;34m(self, trajectory, auto_stop, wait_motion, one_by_one, error_stop)\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_move_make_sure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"joint_move_make_sure done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_joint_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_motion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_motion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merror_stop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qcur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rnb/Projects/rnb-planning/src/pkg/controller/trajectory_client/trajectory_client.pyc\u001b[0m in \u001b[0;36mmove_joint_traj\u001b[0;34m(self, trajectory, auto_stop, wait_motion)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_motion\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_queue_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mauto_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rnb/Projects/rnb-planning/src/pkg/controller/trajectory_client/trajectory_client.pyc\u001b[0m in \u001b[0;36mwait_queue_empty\u001b[0;34m(self, max_dur)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait_queue_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dur\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiodic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_dur\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rnb/Projects/rnb-planning/src/pkg/controller/combined_robot.pyc\u001b[0m in \u001b[0;36mget_qcount\u001b[0;34m()\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_qcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0mqcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0mqcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqstack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimul_speed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rnb/Projects/rnb-planning/src/pkg/controller/trajectory_client/trajectory_client.pyc\u001b[0m in \u001b[0;36mget_qcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_qcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msend_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'qcount'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_ip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qcount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_qcur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'qcount'"
     ]
    }
   ],
   "source": [
    "inc.execute_schedule(snode_schedule_safe, one_by_one=True, mode_switcher=mode_switcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.show_pose(crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove default waypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pscene.remove_subject(waypoint_s)\n",
    "    for wname, wp in waypoint_s.action_points_dict.items():\n",
    "        gscene.remove(wp.geometry)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock and Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.aruco.marker_config import *\n",
    "aruco_map = get_aruco_map()\n",
    "cameraMatrix, distCoeffs, _ = micp.get_camera_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    try:           gscene.remove(gscene.NAME_DICT[\"clock_{}\".format(i)])\n",
    "    except:     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start detecting - set joint offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.change_gain(**{\"q_off{}\".format(i_q): q_off_val for i_q, q_off_val in enumerate(QOFF_PANDA)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get initial pose toward table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qcur = crob.get_real_robot_pose()\n",
    "Tbt = table_body.get_tf(Qcur)\n",
    "Tbr = gscene.get_tf(ROBOT_BASE, Qcur)\n",
    "Trt = np.matmul(np.linalg.inv(Tbr), Tbt)\n",
    "Qcur[6] = np.arctan2(Trt[1,3], Trt[0,3])\n",
    "gscene.show_pose(Qcur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get look motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewpoint = gscene.NAME_DICT[\"viewpoint\"]\n",
    "\n",
    "Qview_init =np.copy(Qcur)\n",
    "Qview_init[6:] = Qview_init[6:] + [0,0,0,0,0,np.deg2rad(-30),0]\n",
    "gscene.show_pose(Qview_init)\n",
    "traj_list = get_scan_motions(mplan, viewpoint, table_g, Qview_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qview_list = []\n",
    "for traj in traj_list:\n",
    "    gscene.show_pose(traj[-1])\n",
    "    Qview_list.append(np.copy(traj[-1]))\n",
    "    time.sleep(1)\n",
    "crob.joint_move_make_sure(Qview_init)\n",
    "len(Qview_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaze and detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_dict = {}\n",
    "for Qview in Qview_list:\n",
    "    t, traj = calc_safe_trajectory(0.02, [crob.get_real_robot_pose(), Qview], 0.5, 0.5)\n",
    "    # gscene.show_motion(traj)\n",
    "    crob.joint_move_make_sure(np.array(Qview), ref_speed = np.pi/10)\n",
    "\n",
    "    #### Detect clocks\n",
    "    # for clock\n",
    "    micp.set_ICP_thres(thres_ICP=0.09, thres_front_ICP=0.03)\n",
    "    micp.set_outlier_removal(nb_points=20, radius=0.03)\n",
    "    micp.set_inlier_ratio(0.1)\n",
    "    micp.set_multiobject_num(num=3)\n",
    "    pose_dict = micp.detect(name_mask=[\"clock\"], visualize=True)\n",
    "\n",
    "    # add or update clock\n",
    "    add_update_object(gscene, crob, \"clock\", pose_dict, separate_dist=0.2, height = TABLE_HEIGHT+CLOCK_DIM[1]/2+CLEARANCE)\n",
    "\n",
    "    #### Detect markers\n",
    "    color_img = micp.last_input[0].astype(np.uint8)\n",
    "    obj_dict, corner_dict = aruco_map.get_object_pose_dict(color_img, cameraMatrix, distCoeffs)\n",
    "    img_out = aruco_map.draw_objects(color_img, obj_dict, corner_dict, cameraMatrix, distCoeffs)\n",
    "\n",
    "    Tbc = viewpoint.get_tf(crob.get_real_robot_pose())\n",
    "    Tbt = table_g.get_tf(crob.home_pose)\n",
    "    Ttc = np.matmul(np.linalg.inv(Tbt), Tbc)\n",
    "    for tname, Ttar in obj_dict.items():\n",
    "        Tcw = matmul_series(np.linalg.inv(Tbc), Tbt, SE3(np.identity(3), (0,0,table_g.dims[2]/2)))\n",
    "\n",
    "        kwargs = aruco_map[tname].get_geometry_kwargs()\n",
    "        Ttar = np.matmul(Tcw, align_z(np.matmul(np.linalg.inv(Tcw), Ttar)))\n",
    "        Ttar = fit_floor(Ttar, minz=-kwargs['dims'][2]/2, Tcw=Tcw)\n",
    "        Ttx = np.matmul(Ttc, Ttar)\n",
    "        kwargs.update(dict(name=tname, center=Ttx[:3,3], rpy=Rot2rpy(Ttx[:3,:3]), color=(0.0,0.0,1.0,1),\n",
    "                      link_name=\"base_link\", collision=True, parent=TABLE_NAME))\n",
    "        target_dict[tname] =gscene.create_safe(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcol_names = sorted([gname for gname in gscene.NAME_DICT.keys() \n",
    "                 if \"clock\" in gname and \"col\" in gname])\n",
    "clock_names = []\n",
    "\n",
    "TOOL_PUSH_HEIGHT = 0.05\n",
    "for gcol_name in gcol_names:\n",
    "    clock_col_g = gscene.NAME_DICT[gcol_name]\n",
    "    clock_g = gscene.NAME_DICT[clock_col_g.parent]\n",
    "    clock_dim = clock_col_g.dims\n",
    "    clock_name = clock_g.name\n",
    "    clock_names.append(clock_name)\n",
    "    push_point_list = []\n",
    "    for i in range(4):\n",
    "        R = Rot_axis_series([2, 3], [np.pi/2*i, np.pi/2])\n",
    "        point = np.round(np.multiply(clock_dim, -R[:,2])/2, 4)\n",
    "        point[1] = clock_dim[1]/2 - TOOL_PUSH_HEIGHT\n",
    "        ap_name = \"side{}\".format(i)\n",
    "        push_point_list.append(FramePoint(ap_name, clock_g, point=point, rpy=Rot2rpy(R), key=TOOL_PUSH_KEY))\n",
    "\n",
    "    dir_push = [0,0,1]\n",
    "    slide_point = SlidePoint(\"bottom_p\", clock_g, point=(0,clock_dim[1]/2-CLEARANCE,0), rpy=(np.pi/2,0,0), \n",
    "                             binded_on=table_b, dist_push_min=0.1, dist_push_max=0.3, dir_push=dir_push, key=TOOL_SLIDE_KEY)\n",
    "\n",
    "    clock_s = pscene.create_subject(oname=clock_name, gname=clock_name, _type=PushObject, \n",
    "                                  push_point_list=push_point_list, slide_point=slide_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waypoint_s = pscene.create_subject(oname=\"waypoints\", gname=TABLE_NAME, _type=WaypointTask,\n",
    "                                 action_points_dict={\n",
    "                                     tname: WayPoint(\n",
    "                                         tname, target, [0, 0, wp_g.dims[2] / 2], [0, 0, 0])\n",
    "                                     for tname, target in sorted(target_dict.items())\n",
    "                                 })\n",
    "\n",
    "point_brush, rpy_brush = (0,0,-brush_face.dims[2]/2), (0,0,0)\n",
    "brush_b = pscene.create_binder(BRUSH_NAME, BRUSH_NAME, WayAgent, point=point_brush, rpy=rpy_brush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [SAVE DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_DATA:\n",
    "    color, depth, Qcur = micp.get_image()\n",
    "    cam_pose = viewpoint.get_tf(Qcur)\n",
    "    dcam.ready_saving(*micp.get_camera_config())\n",
    "    dcam.save_scene(color, depth, cam_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_list = \\\n",
    "    [BindingChain(chair_name, \"bottom_p\", \"floor_ws\", \"floor_ws\") for chair_name in chair_names] \\\n",
    "    + [BindingChain(clock_name, \"bottom_p\", \"table\", \"table\") for clock_name in clock_names] \\\n",
    "    + [BindingChain(\"waypoints\", None, None, None)]\n",
    "initial_state = pscene.initialize_state(crob.get_real_robot_pose(), chain_list=chain_list)\n",
    "gscene.update_markers_all()\n",
    "print(pscene.subject_name_list)\n",
    "print(initial_state.node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "DEBUG = False\n",
    "inc.prepare()\n",
    "from_state = initial_state.copy(pscene)\n",
    "goal_nodes = [initial_state.node[:-1]+(waypoint_s.action_point_len,)]\n",
    "\n",
    "inc.search(from_state, goal_nodes, max_solution_count=1,\n",
    "           verbose=DEBUG, display=DEBUG, dt_vis=0.001, \n",
    "           timeout=1.0, timeout_loop=200, \n",
    "           multiprocess=not DEBUG, add_homing=False)\n",
    "time_ontable_planning = time.time() - time_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get snode schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snode_schedule = inc.get_best_schedule(at_home=False)\n",
    "return_state = initial_state.copy(pscene)\n",
    "return_state.Q = np.array(list(snode_schedule[-1].state.Q[:6]) + list(crob.home_pose[6:]))\n",
    "snode_schedule += inc.add_return_motion(snode_schedule[-1], initial_state=return_state)\n",
    "len(snode_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### play schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscene.set_object_state(initial_state)\n",
    "gscene.show_pose(initial_state.Q)\n",
    "inc.play_schedule(snode_schedule, period=0.002)\n",
    "pscene.set_object_state(snode_schedule[-1].state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start moving - set joint offset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.change_gain(**{\"q_off{}\".format(i_q): 0 for i_q, q_off_val in enumerate(QOFF_PANDA)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make trajectory safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_lims, acc_lims, dt_step = 0.5, 0.5, 0.02\n",
    "snode_schedule_safe = [snode_schedule[0].copy(pscene)]\n",
    "for snode, snode_pre in zip(snode_schedule[1:], snode_schedule[:-1]):\n",
    "    snames, _ = pscene.get_changing_subjects(snode.state, snode_pre.state)\n",
    "    if len(snames) > 1:\n",
    "        raise(RuntimeError(\"More than 1 subject change - {}\".format(snames)))\n",
    "    if len(snames) == 1:\n",
    "        subject = pscene.subject_dict[snames[0]]\n",
    "    else:\n",
    "        subject = None\n",
    "        \n",
    "    snode_cp = snode.copy(pscene)\n",
    "    rpairs = crob.get_robots_in_act(snode_cp.traj)\n",
    "    for rname, robot in rpairs:\n",
    "        if rname == ROBOT_NAME:\n",
    "            traj_simp = simplify_traj(snode.traj)\n",
    "            snode_cp.set_traj(calc_safe_trajectory(\n",
    "                dt_step, traj_simp, vel_lims=vel_lims, acc_lims=acc_lims)[1])\n",
    "            break\n",
    "    snode_cp.traj[:,6:] -= QOFF_PANDA\n",
    "    snode_cp.state.Q[6:] -= QOFF_PANDA\n",
    "    snode_schedule_safe.append(snode_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WebClient(ip='192.168.17.2', port=9990)\n",
    "\n",
    "mode_switcher = SimpleForceModeSwitcher(pscene, ROBOT_NAME, crob, wc, \n",
    "                                        force_delay=5, switch_delay=1, \n",
    "                                        log_force=True, DT=1.0/1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_switcher.force_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inc.execute_schedule(snode_schedule_safe, one_by_one=True, mode_switcher=mode_switcher)\n",
    "# inc.execute_schedule(snode_schedule_safe, one_by_one=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_f = len(mode_switcher.force_log)\n",
    "plt.figure(figsize=(10, 5*len_f))\n",
    "for i in range(len_f):\n",
    "    plt.subplot(len_f, 1, 1+i)\n",
    "    plt.plot(mode_switcher.force_log[i][:, 0], '.')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAT_DIR = os.path.join(RNB_PLANNING_DIR, \"data/disinf_exp_2Y\")\n",
    "try_mkdir(DAT_DIR)\n",
    "fpath = os.path.join(DAT_DIR, get_now()+\".csv\")\n",
    "np.savetxt(fpath, np.array(mode_switcher.force_log)[:, :,0], delimiter=\",\")\n",
    "save_json(fpath[:-4]+\"-time.json\", \n",
    "          {\"time_approach_planning\": time_approach_planning,\n",
    "          \"time_ontable_planning\": time_ontable_planning})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move to home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = raw_input(\"Press Enter to move to home\")\n",
    "if inp == \"\":\n",
    "    pmb0 = crob.robot_dict[\"pmb0\"]\n",
    "    panda_arm1 = crob.robot_dict[\"panda_arm1\"]\n",
    "    panda_arm1.joint_move_make_sure(HOME_POSE_DEFAULT[6:])\n",
    "    pmb0.joint_move_make_sure([0]*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 02.06\n",
    "\n",
    "### Detector\n",
    "* ,     v\n",
    "* point cloud visualization  0   \n",
    "* 90  \n",
    "\n",
    "### HW\n",
    "*    90x40x6mm L shape w. profile hole x 2 \n",
    "*   \n",
    "  - ?     ,     \n",
    "  - ?     ,  \n",
    "\n",
    "### Planner\n",
    "* 2       ()\n",
    "  -    ~15 ms\n",
    "*   view / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 01.31\n",
    "### data\n",
    "*    \n",
    "\n",
    "### Detector\n",
    "*    4  (  5 )\n",
    "*   \n",
    "\n",
    "### Planner\n",
    "*    -      -   \n",
    "*   \n",
    "\n",
    "### Anydesk    (  ?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise(RuntimeError(\"Testing script below here\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bt = table_g.get_tf(crob.home_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bc = viewpoint.get_tf(crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_ct = np.matmul(np.linalg.inv(T_bc), T_bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_tx = SE3(np.identity(3), (np.divide(table_g.dims, 2)-0.06)*[1,-1,0])\n",
    "T_bx =  np.matmul(T_bt, T_tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bm = gscene.get_tf(MOBILE_BASE, crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_mx = np.matmul(np.linalg.inv(T_bm), T_bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.add_highlight_axis(\"hl\", \"tbm\", T=T_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.add_highlight_axis(\"hl\", \"tmx\", T=T_mx, link_name=MOBILE_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.clear_highlight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(T_ct[:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = micp.last_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rot2rpy(Rot_axis(1, -np.pi/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_aruco_map_table():\n",
    "    dictionary = aruco.getPredefinedDictionary(aruco.DICT_6X6_250)\n",
    "    #     params = aruco.DetectorParameters_create()\n",
    "    aruco_map = ArucoMap(dictionary=dictionary, _dict={\n",
    "        'table1':MarkerSet('table1', dlevel=DetectionLevel.ENVIRONMENT, gtype=GEOTYPE.BOX, dims=(0.4,0.3,0.01),\n",
    "                          color=(0.9,0.9,0.9,0.2),\n",
    "                          _list=[\n",
    "                              ObjectMarker('table1', 231, 0.15, [0, 0., 0.0], (0, -0., 0.)),\n",
    "#                               ObjectMarker('table', 231, 0.15, [0.7, -0.4, 0.0], (0,0,0)),\n",
    "#                               ObjectMarker('table', 233, 0.15, [0.7+0.075, -0.4, 0.075], (-1.57079633, -0.,  0.))\n",
    "                          ]),\n",
    "        'table2':MarkerSet('table2', dlevel=DetectionLevel.ENVIRONMENT, gtype=GEOTYPE.BOX, dims=(0.4,0.3,0.01),\n",
    "                          color=(0.9,0.9,0.9,0.2),\n",
    "                          _list=[\n",
    "                              ObjectMarker('table2', 232, 0.15, [0.0, 0.0, 0.0], (0,0,0)),\n",
    "#                               ObjectMarker('table', 233, 0.15, [0.7+0.075, -0.4, 0.075], (-1.57079633, -0.,  0.))\n",
    "                          ]),\n",
    "        'table3':MarkerSet('table3', dlevel=DetectionLevel.ENVIRONMENT, gtype=GEOTYPE.BOX, dims=(0.4,0.3,0.01),\n",
    "                          color=(0.9,0.9,0.9,0.2),\n",
    "                          _list=[\n",
    "                              ObjectMarker('table3', 233, 0.15, [0.0, 0.0, 0.0], (0,0,0)),\n",
    "#                               ObjectMarker('table', 233, 0.15, [0.7+0.075, -0.4, 0.075], (-1.57079633, -0.,  0.))\n",
    "                          ])})\n",
    "    return aruco_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.aruco.marker_config import *\n",
    "\n",
    "aruco_map = get_aruco_map_table()\n",
    "\n",
    "cameraMatrix, distCoeffs, _ = micp.get_camera_config()\n",
    "color_img, _, Q_cur = micp.get_image()\n",
    "\n",
    "color_img = color_img.astype(np.uint8)\n",
    "obj_dict, corner_dict = aruco_map.get_object_pose_dict(color_img, cameraMatrix, distCoeffs)\n",
    "img_out = aruco_map.draw_objects(color_img, obj_dict, corner_dict, cameraMatrix, distCoeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tcm1 = obj_dict[\"table1\"]\n",
    "Tcm2 = obj_dict[\"table2\"]\n",
    "Tcm3 = obj_dict[\"table3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bc = viewpoint.get_tf(crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tbm1 = np.matmul(T_bc, Tcm1)\n",
    "Tbm2 = np.matmul(T_bc, Tcm2)\n",
    "Tbm3 = np.matmul(T_bc, Tcm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.add_highlight_axis(\"hl\", \"tbm2\", T=Tbm2)\n",
    "gscene.add_highlight_axis(\"hl\", \"tbm3\", T=Tbm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmb0 = crob.robot_dict[\"pmb0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tbm0 = gscene.get_tf(MOBILE_BASE, crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmb0.joint_move_make_sure([-1.0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(crob.get_real_robot_pose()[:6], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscene.show_pose(crob.get_real_robot_pose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_out[:,:,[2,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(micp.last_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporary - robot base detection for accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.detector.aruco.marker_config import *\n",
    "aruco_map = get_aruco_map()\n",
    "cameraMatrix, distCoeffs, _ = micp.get_camera_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "Qref = crob.get_real_robot_pose()\n",
    "gscene.show_pose(Qref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repeat changing Qdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdiff = 0\n",
    "Qnow = np.copy(Qref)\n",
    "Qnow[-1] = Qref[-1] + np.deg2rad(Qdiff)\n",
    "gscene.show_pose(Qnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = viewpoint.get_tf(Qnow)\n",
    "crob.joint_move_make_sure(Qnow)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img, _, Q_cur = micp.get_image()\n",
    "color_img = color_img.astype(np.uint8)\n",
    "obj_dict, corner_dict = aruco_map.get_object_pose_dict(color_img, cameraMatrix, distCoeffs)\n",
    "img_out = aruco_map.draw_objects(color_img, obj_dict, corner_dict, cameraMatrix, distCoeffs)\n",
    "T_cp = obj_dict[\"panda1\"]\n",
    "T_pc = viewpoint.get_tf(crob.get_real_robot_pose(), from_link=ROBOT_BASE)\n",
    "T_pp = np.matmul(T_pc, T_cp)\n",
    "np.round(T_pp, 3)\n",
    "res_dict[Qnow[-1]] = T_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qxyz = np.array([(q, T_pp[0,3], T_pp[1,3], T_pp[2,3])  for q, T_pp in sorted(res_dict.items())])\n",
    "plt.plot(np.rad2deg(qxyz[:,0]), qxyz[:,1], '-o')\n",
    "plt.plot(np.rad2deg(qxyz[:,0]), qxyz[:,2], '-o')\n",
    "plt.plot(np.rad2deg(qxyz[:,0]), qxyz[:,3], '-o')\n",
    "plt.legend(\"xyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporary - robot base detection for accuracy check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wc.change_controller(\"Hybrid_Null\")\n",
    "wc.change_controller(\"NRIC_PD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backup joint offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_off_bak = wc.gain_listed_dict[\"q_off\"]\n",
    "q_off_bak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set joint offset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.change_gain(**{\"q_off{}\".format(i_q):0 for i_q, q_off in enumerate(q_off_bak)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### restore joint offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.change_gain(**{\"q_off{}\".format(i_q):q_off for i_q, q_off in enumerate(q_off_bak)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change control mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.change_gain(switch_control0=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
