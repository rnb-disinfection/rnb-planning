{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "PROJ_DIR = os.environ[\"RNB_PLANNING_DIR\"]\n",
    "sys.path.append(os.path.join(PROJ_DIR, \"src\"))\n",
    "\n",
    "import SharedArray as sa\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from pkg.utils.utils import *\n",
    "\n",
    "args = DummyObject()\n",
    "args.model_path = \"None\"\n",
    "args.rtype=\"panda\"\n",
    "args.precision=\"FP16\"\n",
    "\n",
    "if args.model_path == \"None\":\n",
    "    args.model_path = None\n",
    "PRECISION = args.precision\n",
    "\n",
    "ok_to_go = False\n",
    "while not ok_to_go:\n",
    "    try:\n",
    "        prepared_p = sa.create(f\"shm://{args.rtype}.prepared\", (1,), dtype=np.bool)\n",
    "        ok_to_go = True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        robot_type_name = args.rtype\n",
    "        query_quit = sa.attach(\"shm://{}.query_quit\".format(robot_type_name))\n",
    "        query_quit[0] = True\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            sa.delete(\"shm://{}.grasp_img\".format(robot_type_name))\n",
    "            sa.delete(\"shm://{}.arm_img\".format(robot_type_name))\n",
    "            sa.delete(\"shm://{}.rh_vals\".format(robot_type_name))\n",
    "            sa.delete(\"shm://{}.result\".format(robot_type_name))\n",
    "            sa.delete(\"shm://{}.query_in\".format(robot_type_name))\n",
    "            sa.delete(\"shm://{}.response_out\".format(robot_type_name))\n",
    "            sa.delete(\"shm://{}.query_quit\".format(robot_type_name))\n",
    "        except:\n",
    "            pass\n",
    "prepared_p[0] = False\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "\n",
    "from pkg.utils.utils_python3 import *\n",
    "from pkg.controller.robot_config import RobotType\n",
    "from pkg.planning.filtering.lattice_model.data_utils import *\n",
    "import numpy as np\n",
    "int2rtypename = {v.value:v.name for v in RobotType}\n",
    "DATA_PATH = os.path.join(PROJ_DIR, \"data\")\n",
    "MODEL_PATH = os.path.join(PROJ_DIR, \"model\")\n",
    "LAT_MODEL_PATH = os.path.join(MODEL_PATH,\"latticized\")\n",
    "try_mkdir(MODEL_PATH)\n",
    "try_mkdir(LAT_MODEL_PATH)\n",
    "GRASP_FOLDER = \"grasp\"\n",
    "ARM10_FOLDER = \"arm_10\"\n",
    "ARM05_FOLDER = \"arm_05\"\n",
    "FULLS_FOLDER = \"full_scene\"\n",
    "\n",
    "ARM_FOLDER = ARM10_FOLDER\n",
    "GRASP_SHAPE = (20,20,20)\n",
    "ARM_SHAPE = (20,20,20)\n",
    "RH_MASK_SIZE = 512\n",
    "RH_MASK_STEP = 64\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "SERVER_PERIOD = 1e-3\n",
    "\n",
    "##\n",
    "# @class SharedLatticePredictor\n",
    "class SharedLatticePredictor:\n",
    "    ##\n",
    "    # @param ROBOT_TYPE_NAME robot type name\n",
    "    # @param model_path_rel relative model path from model/latticized/\n",
    "    def __init__(self, ROBOT_TYPE_NAME=\"indy7\", model_path_rel=None):\n",
    "        self.ROBOT_TYPE_NAME = ROBOT_TYPE_NAME\n",
    "        self.ROBOT_MODEL_ROOT = os.path.join(LAT_MODEL_PATH, self.ROBOT_TYPE_NAME)\n",
    "        if model_path_rel is None:\n",
    "            last_model = sorted(os.listdir(self.ROBOT_MODEL_ROOT))[-1]\n",
    "            last_save = sorted([item for item in os.listdir(os.path.join(self.ROBOT_MODEL_ROOT, last_model)) if item.startswith(\"model\")])[-1]\n",
    "            model_path_rel = os.path.join(last_model, last_save)\n",
    "        model_log_dir = os.path.join(self.ROBOT_MODEL_ROOT, model_path_rel)\n",
    "        model_log_dir_trt = os.path.join(self.ROBOT_MODEL_ROOT, model_path_rel.replace(\"model\", \"trt\")+\"-\"+PRECISION)\n",
    "        if not os.path.isdir(model_log_dir_trt):\n",
    "            print(\"==== Start converting ====\")\n",
    "            from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "            conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "            conversion_params = conversion_params._replace(precision_mode=PRECISION) # Set GPU temporary memory 4GB\n",
    "                \n",
    "            converter = trt.TrtGraphConverterV2(input_saved_model_dir=model_log_dir, conversion_params=conversion_params)\n",
    "            converter.convert()\n",
    "                \n",
    "            def my_input_fn():\n",
    "                grasp_img_t = tf.zeros((BATCH_SIZE,) + GRASP_SHAPE + (3,), dtype=tf.float32)\n",
    "                arm_img_t = tf.zeros((BATCH_SIZE,) + ARM_SHAPE + (1,), dtype=tf.float32)\n",
    "                rh_mask_t = tf.zeros((BATCH_SIZE, 54), dtype=tf.float32)\n",
    "                yield (grasp_img_t, arm_img_t, rh_mask_t)\n",
    "                \n",
    "            converter.build(input_fn=my_input_fn)\n",
    "            print(\"==== Conversion Done ====\")\n",
    "            converter.save(model_log_dir_trt)\n",
    "            print(\"==== Saved Converted model ====\")\n",
    "\n",
    "        saved_model_loaded = tf.saved_model.load(\n",
    "            model_log_dir_trt, tags=[tag_constants.SERVING])\n",
    "        graph_func = saved_model_loaded.signatures[\n",
    "            signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "        self.frozen_func = convert_variables_to_constants_v2(graph_func)\n",
    "\n",
    "#     @tf.function\n",
    "    def inference(self, images):\n",
    "        # training=False is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "#         predictions = self.model(images, training=False)\n",
    "        predictions = self.frozen_func(*images)[0].numpy()\n",
    "        return predictions\n",
    "\n",
    "    ##\n",
    "    # @brief Create an array in shared memory.\n",
    "    # @param prepared_p bool shared array (1,) to signal readiness\n",
    "    def start_server(self, prepared_p):\n",
    "        grasp_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\", (BATCH_SIZE,) + GRASP_SHAPE + (3,))\n",
    "        arm_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\", (BATCH_SIZE,) + ARM_SHAPE + (1,))\n",
    "        rh_vals_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\", (BATCH_SIZE, 2))\n",
    "        result_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.result\", (BATCH_SIZE, 2))\n",
    "        query_in = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\", (1,), dtype=np.bool)\n",
    "        response_out = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\", (1,), dtype=np.bool)\n",
    "        query_quit = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\", (1,), dtype=np.bool)\n",
    "        gtimer = GlobalTimer.instance()\n",
    "        gtimer.reset()\n",
    "        grasp_img_p[:] = 0\n",
    "        arm_img_p[:] = 0\n",
    "        rh_vals_p[:] = 0\n",
    "        result_p[:] = 0\n",
    "        query_in[0] = False\n",
    "        response_out[0] = False\n",
    "        query_quit[0] = False\n",
    "        rh_mask = np.zeros((BATCH_SIZE, 54))\n",
    "\n",
    "        print(\"============= wait for initialization ================\")\n",
    "        r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "        h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "        rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "        grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "        arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "        rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "        self.inference((grasp_img_t, arm_img_t, rh_mask_t))\n",
    "        print(\"=============== initialization done ==================\")\n",
    "        prepared_p[0] = True\n",
    "\n",
    "        try:\n",
    "            while not query_quit[0]:\n",
    "                if not query_in[0]:\n",
    "                    time.sleep(SERVER_PERIOD)\n",
    "                    continue\n",
    "                gtimer.tic(\"convert_tf\")\n",
    "                query_in[0] = False\n",
    "                ## TODO: inference depending on robot type\n",
    "                r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "                h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "                rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "                grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "                arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "                rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "                etime_ctf = gtimer.toc(\"convert_tf\")\n",
    "                gtimer.tic(\"inference\")\n",
    "                result = self.inference((grasp_img_t, arm_img_t, rh_mask_t))\n",
    "                for i_b in range(BATCH_SIZE):\n",
    "                    result_p[i_b] = result[i_b]\n",
    "                etime_inf = gtimer.toc(\"inference\")\n",
    "                print(\"convertin : {} ms\".format(round(etime_ctf, 2)))\n",
    "                print(\"inference : {} ms\".format(round(etime_inf, 2)))\n",
    "                response_out[0] = True\n",
    "        finally:\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.result\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_45130) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_38328) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_33548) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_669) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_33748) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_22007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_31464) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_35243) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_43118) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_6389) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_49107) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_25868) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_29540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1703) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_9636) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_1427) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_14429) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_36164) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_28066) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_31949) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_3944) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_39594) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_29852) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_1302) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_23007) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_18822) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_14161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_pruned_72161) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "slp = SharedLatticePredictor(ROBOT_TYPE_NAME=args.rtype, model_path_rel=args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= wait for initialization ================\n",
      "=============== initialization done ==================\n"
     ]
    }
   ],
   "source": [
    "self, prepared_p = slp, prepared_p\n",
    "\n",
    "grasp_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\", (BATCH_SIZE,) + GRASP_SHAPE + (3,))\n",
    "arm_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\", (BATCH_SIZE,) + ARM_SHAPE + (1,))\n",
    "rh_vals_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\", (BATCH_SIZE, 2))\n",
    "result_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.result\", (BATCH_SIZE, 2))\n",
    "query_in = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\", (1,), dtype=np.bool)\n",
    "response_out = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\", (1,), dtype=np.bool)\n",
    "query_quit = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\", (1,), dtype=np.bool)\n",
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "grasp_img_p[:] = 0\n",
    "arm_img_p[:] = 0\n",
    "rh_vals_p[:] = 0\n",
    "result_p[:] = 0\n",
    "query_in[0] = False\n",
    "response_out[0] = False\n",
    "query_quit[0] = False\n",
    "rh_mask = np.zeros((BATCH_SIZE, 54))\n",
    "\n",
    "print(\"============= wait for initialization ================\")\n",
    "r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "self.inference((grasp_img_t, arm_img_t, rh_mask_t))\n",
    "print(\"=============== initialization done ==================\")\n",
    "prepared_p[0] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convertin : 3.8 ms\n",
      "inference : 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "gtimer.tic(\"convert_tf\")\n",
    "query_in[0] = False\n",
    "## TODO: inference depending on robot type\n",
    "r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "etime_ctf = gtimer.toc(\"convert_tf\")\n",
    "gtimer.tic(\"inference\")\n",
    "result = self.inference((grasp_img_t, arm_img_t, rh_mask_t))\n",
    "for i_b in range(BATCH_SIZE):\n",
    "    result_p[i_b] = result[i_b]\n",
    "etime_inf = gtimer.toc(\"inference\")\n",
    "print(\"convertin : {} ms\".format(round(etime_ctf, 2)))\n",
    "print(\"inference : {} ms\".format(round(etime_inf, 2)))\n",
    "response_out[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convertin : 0.71 ms\n",
      "inference : 12.73 ms\n",
      "convertin : 0.85 ms\n",
      "inference : 12.6 ms\n",
      "convertin : 7.06 ms\n",
      "inference : 12.34 ms\n",
      "convertin : 0.82 ms\n",
      "inference : 11.65 ms\n",
      "convertin : 0.62 ms\n",
      "inference : 18.07 ms\n",
      "convertin : 0.67 ms\n",
      "inference : 12.76 ms\n",
      "convertin : 0.79 ms\n",
      "inference : 17.92 ms\n",
      "convertin : 0.6 ms\n",
      "inference : 12.03 ms\n",
      "convertin : 8.51 ms\n",
      "inference : 17.69 ms\n",
      "convertin : 1.11 ms\n",
      "inference : 11.9 ms\n",
      "convertin : 0.71 ms\n",
      "inference : 18.83 ms\n",
      "convertin : 0.68 ms\n",
      "inference : 12.64 ms\n",
      "convertin : 0.65 ms\n",
      "inference : 18.56 ms\n",
      "convertin : 0.59 ms\n",
      "inference : 13.36 ms\n",
      "convertin : 5.41 ms\n",
      "inference : 13.45 ms\n",
      "convertin : 0.71 ms\n",
      "inference : 22.18 ms\n",
      "convertin : 0.8 ms\n",
      "inference : 13.9 ms\n",
      "convertin : 0.82 ms\n",
      "inference : 13.61 ms\n",
      "convertin : 7.24 ms\n",
      "inference : 12.76 ms\n",
      "convertin : 0.78 ms\n",
      "inference : 12.86 ms\n",
      "convertin : 0.7 ms\n",
      "inference : 19.55 ms\n",
      "convertin : 0.75 ms\n",
      "inference : 12.41 ms\n",
      "convertin : 0.55 ms\n",
      "inference : 42.52 ms\n",
      "convertin : 0.81 ms\n",
      "inference : 20.0 ms\n",
      "convertin : 0.68 ms\n",
      "inference : 11.92 ms\n",
      "convertin : 0.79 ms\n",
      "inference : 12.91 ms\n",
      "convertin : 0.71 ms\n",
      "inference : 60.15 ms\n",
      "convertin : 0.69 ms\n",
      "inference : 19.54 ms\n",
      "convertin : 5.01 ms\n",
      "inference : 13.02 ms\n",
      "convertin : 2.82 ms\n",
      "inference : 12.87 ms\n",
      "convertin : 6.74 ms\n",
      "inference : 12.91 ms\n",
      "convertin : 4.28 ms\n",
      "inference : 12.31 ms\n",
      "convertin : 1.65 ms\n",
      "inference : 12.42 ms\n",
      "convertin : 3.56 ms\n",
      "inference : 11.82 ms\n",
      "convertin : 7.1 ms\n",
      "inference : 12.77 ms\n",
      "convertin : 4.01 ms\n",
      "inference : 13.55 ms\n",
      "convertin : 0.92 ms\n",
      "inference : 14.51 ms\n",
      "convertin : 0.88 ms\n",
      "inference : 14.5 ms\n",
      "convertin : 0.84 ms\n",
      "inference : 13.25 ms\n",
      "convertin : 1.15 ms\n",
      "inference : 13.38 ms\n",
      "convertin : 0.87 ms\n",
      "inference : 11.74 ms\n",
      "convertin : 4.5 ms\n",
      "inference : 13.71 ms\n",
      "convertin : 0.81 ms\n",
      "inference : 12.66 ms\n",
      "convertin : 0.81 ms\n",
      "inference : 12.73 ms\n",
      "convertin : 0.84 ms\n",
      "inference : 12.7 ms\n",
      "convertin : 0.81 ms\n",
      "inference : 12.18 ms\n",
      "convertin : 3.16 ms\n",
      "inference : 12.33 ms\n",
      "convertin : 0.89 ms\n",
      "inference : 12.07 ms\n",
      "convertin : 2.0 ms\n",
      "inference : 11.81 ms\n",
      "convertin : 3.07 ms\n",
      "inference : 11.96 ms\n",
      "convertin : 2.27 ms\n",
      "inference : 14.1 ms\n",
      "convertin : 1.53 ms\n",
      "inference : 13.5 ms\n",
      "convertin : 2.15 ms\n",
      "inference : 12.69 ms\n",
      "convertin : 3.58 ms\n",
      "inference : 12.46 ms\n",
      "convertin : 1.79 ms\n",
      "inference : 12.85 ms\n",
      "convertin : 4.93 ms\n",
      "inference : 12.68 ms\n",
      "convertin : 0.94 ms\n",
      "inference : 13.0 ms\n",
      "convertin : 2.55 ms\n",
      "inference : 13.13 ms\n",
      "convertin : 3.95 ms\n",
      "inference : 13.56 ms\n",
      "convertin : 0.82 ms\n",
      "inference : 12.62 ms\n",
      "convertin : 1.4 ms\n",
      "inference : 11.82 ms\n",
      "convertin : 2.92 ms\n",
      "inference : 13.41 ms\n",
      "convertin : 2.33 ms\n",
      "inference : 12.59 ms\n",
      "convertin : 3.44 ms\n",
      "inference : 14.16 ms\n",
      "convertin : 2.75 ms\n",
      "inference : 14.08 ms\n",
      "convertin : 0.73 ms\n",
      "inference : 12.19 ms\n",
      "convertin : 1.59 ms\n",
      "inference : 13.97 ms\n",
      "convertin : 0.69 ms\n",
      "inference : 11.96 ms\n",
      "convertin : 1.4 ms\n",
      "inference : 11.69 ms\n",
      "convertin : 0.76 ms\n",
      "inference : 13.54 ms\n",
      "convertin : 1.15 ms\n",
      "inference : 13.32 ms\n",
      "convertin : 2.4 ms\n",
      "inference : 12.2 ms\n",
      "convertin : 2.83 ms\n",
      "inference : 13.95 ms\n",
      "convertin : 4.53 ms\n",
      "inference : 13.55 ms\n",
      "convertin : 2.23 ms\n",
      "inference : 13.3 ms\n",
      "convertin : 2.23 ms\n",
      "inference : 12.64 ms\n",
      "convertin : 2.54 ms\n",
      "inference : 12.48 ms\n",
      "convertin : 2.47 ms\n",
      "inference : 12.39 ms\n",
      "convertin : 3.7 ms\n",
      "inference : 12.65 ms\n",
      "convertin : 7.02 ms\n",
      "inference : 12.22 ms\n",
      "convertin : 2.19 ms\n",
      "inference : 12.57 ms\n",
      "convertin : 1.32 ms\n",
      "inference : 13.4 ms\n",
      "convertin : 1.77 ms\n",
      "inference : 12.67 ms\n",
      "convertin : 1.74 ms\n",
      "inference : 14.13 ms\n",
      "convertin : 0.95 ms\n",
      "inference : 13.31 ms\n",
      "convertin : 0.83 ms\n",
      "inference : 14.75 ms\n",
      "convertin : 0.71 ms\n",
      "inference : 13.49 ms\n",
      "convertin : 3.42 ms\n",
      "inference : 13.08 ms\n",
      "convertin : 0.78 ms\n",
      "inference : 12.77 ms\n",
      "convertin : 0.65 ms\n",
      "inference : 12.04 ms\n",
      "convertin : 0.78 ms\n",
      "inference : 12.29 ms\n",
      "convertin : 0.47 ms\n",
      "inference : 21.6 ms\n",
      "convertin : 6.48 ms\n",
      "inference : 14.49 ms\n",
      "convertin : 0.81 ms\n",
      "inference : 13.77 ms\n",
      "convertin : 4.57 ms\n",
      "inference : 13.65 ms\n",
      "convertin : 0.52 ms\n",
      "inference : 11.85 ms\n",
      "convertin : 0.74 ms\n",
      "inference : 12.03 ms\n",
      "convertin : 0.67 ms\n",
      "inference : 58.65 ms\n",
      "convertin : 0.77 ms\n",
      "inference : 19.15 ms\n",
      "convertin : 6.28 ms\n",
      "inference : 12.83 ms\n"
     ]
    }
   ],
   "source": [
    "while not query_quit[0]:\n",
    "    if not query_in[0]:\n",
    "        time.sleep(SERVER_PERIOD)\n",
    "        continue\n",
    "    gtimer.tic(\"convert_tf\")\n",
    "    query_in[0] = False\n",
    "    ## TODO: inference depending on robot type\n",
    "    r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "    h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "    rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "    grasp_img_t = tf.constant(grasp_img_p, dtype=tf.float32)\n",
    "    arm_img_t = tf.constant(arm_img_p, dtype=tf.float32)\n",
    "    rh_mask_t = tf.constant(rh_mask, dtype=tf.float32)\n",
    "    etime_ctf = gtimer.toc(\"convert_tf\")\n",
    "    gtimer.tic(\"inference\")\n",
    "    result = self.inference((grasp_img_t, arm_img_t, rh_mask_t))\n",
    "    for i_b in range(BATCH_SIZE):\n",
    "        result_p[i_b] = result[i_b]\n",
    "    etime_inf = gtimer.toc(\"inference\")\n",
    "    print(\"convertin : {} ms\".format(round(etime_ctf, 2)))\n",
    "    print(\"inference : {} ms\".format(round(etime_inf, 2)))\n",
    "    response_out[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_tf: \t222.0 ms/102 = 2.178 ms (0.472/8.51)\n",
      "inference: \t1510.0 ms/102 = 14.808 ms (11.652/60.149)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.result\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "##\n",
    "# @class SharedLatticePredictor\n",
    "class SharedLatticePredictor:\n",
    "    ##\n",
    "    # @param ROBOT_TYPE_NAME robot type name\n",
    "    # @param model_path_rel relative model path from model/latticized/\n",
    "    def __init__(self, ROBOT_TYPE_NAME=\"indy7\", model_path_rel=None):\n",
    "        self.ROBOT_TYPE_NAME = ROBOT_TYPE_NAME\n",
    "        self.ROBOT_MODEL_ROOT = os.path.join(LAT_MODEL_PATH, self.ROBOT_TYPE_NAME)\n",
    "        if model_path_rel is None:\n",
    "            last_model = sorted(os.listdir(self.ROBOT_MODEL_ROOT))[-1]\n",
    "            last_save = sorted([item for item in os.listdir(os.path.join(self.ROBOT_MODEL_ROOT, last_model)) if item.startswith(\"model\")])[-1]\n",
    "            model_path_rel = os.path.join(last_model, last_save)\n",
    "        model_log_dir = os.path.join(self.ROBOT_MODEL_ROOT, model_path_rel)\n",
    "        self.model = tf.keras.models.load_model(model_log_dir)\n",
    "\n",
    "    @tf.function\n",
    "    def inference(self, images):\n",
    "        # training=False is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = self.model(images, training=False)\n",
    "        return predictions\n",
    "\n",
    "    ##\n",
    "    # @brief Create an array in shared memory.\n",
    "    # @param prepared_p bool shared array (1,) to signal readiness\n",
    "    def start_server(self, prepared_p):\n",
    "        grasp_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\", (BATCH_SIZE,) + GRASP_SHAPE + (3,))\n",
    "        arm_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\", (BATCH_SIZE,) + ARM_SHAPE + (1,))\n",
    "        rh_vals_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\", (BATCH_SIZE, 2))\n",
    "        result_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.result\", (BATCH_SIZE, 2))\n",
    "        query_in = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\", (1,), dtype=np.bool)\n",
    "        response_out = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\", (1,), dtype=np.bool)\n",
    "        query_quit = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\", (1,), dtype=np.bool)\n",
    "        grasp_img_p[:] = 0\n",
    "        arm_img_p[:] = 0\n",
    "        rh_vals_p[:] = 0\n",
    "        result_p[:] = 0\n",
    "        query_in[0] = False\n",
    "        response_out[0] = False\n",
    "        query_quit[0] = False\n",
    "        rh_mask = np.zeros((BATCH_SIZE, 54))\n",
    "\n",
    "        print(\"============= wait for initialization ================\")\n",
    "        r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "        h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "        rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "        self.inference([grasp_img_p, arm_img_p, rh_mask])\n",
    "        print(\"=============== initialization done ==================\")\n",
    "        prepared_p[0] = True\n",
    "\n",
    "        try:\n",
    "            while not query_quit[0]:\n",
    "                if not query_in[0]:\n",
    "                    time.sleep(SERVER_PERIOD)\n",
    "                    continue\n",
    "                query_in[0] = False\n",
    "                ## TODO: inference depending on robot type\n",
    "                r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "                h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "                rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "                result = self.inference([grasp_img_p, arm_img_p, rh_mask])\n",
    "                for i_b in range(BATCH_SIZE):\n",
    "                    result_p[i_b] = result[i_b]\n",
    "                response_out[0] = True\n",
    "        finally:\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.result\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\")\n",
    "            sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slp = SharedLatticePredictor(ROBOT_TYPE_NAME=rtype, model_path_rel=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = slp\n",
    "\n",
    "grasp_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\", (BATCH_SIZE,) + GRASP_SHAPE + (3,))\n",
    "arm_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\", (BATCH_SIZE,) + ARM_SHAPE + (1,))\n",
    "rh_vals_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\", (BATCH_SIZE, 2))\n",
    "result_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.result\", (BATCH_SIZE, 2))\n",
    "query_in = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\", (1,), dtype=np.bool)\n",
    "response_out = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\", (1,), dtype=np.bool)\n",
    "query_quit = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\", (1,), dtype=np.bool)\n",
    "prepared_p = sa.create(f\"shm://{rtype}.prepared\", (1,), dtype=np.bool)\n",
    "prepared_p[0] = False\n",
    "\n",
    "grasp_img_p[:] = 0\n",
    "arm_img_p[:] = 0\n",
    "rh_vals_p[:] = 0\n",
    "result_p[:] = 0\n",
    "query_in[0] = False\n",
    "response_out[0] = False\n",
    "query_quit[0] = False\n",
    "rh_mask = np.zeros((BATCH_SIZE, 54))\n",
    "\n",
    "print(\"============= wait for initialization ================\")\n",
    "r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "self.inference([grasp_img_p, arm_img_p, rh_mask])\n",
    "print(\"=============== initialization done ==================\")\n",
    "prepared_p[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "for _ in range(100):\n",
    "    with gtimer.block(\"origin\"):\n",
    "        self.inference([grasp_img_p, arm_img_p, rh_mask])\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call checker once to get data example. run below cell to return response so the checker can stop waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_in[0] = False\n",
    "response_out[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: inference depending on robot type\n",
    "r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "rh_mask[0] = np.concatenate([r_mask, h_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = slp.inference([grasp_img_p, arm_img_p, rh_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "for _ in range(1000):\n",
    "    with gtimer.block(\"inference\"):\n",
    "        result = slp.inference([grasp_img_p, arm_img_p, rh_mask])\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mulst call below to clear shared memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.grasp_img\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.arm_img\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.rh_vals\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.result\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.query_in\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.response_out\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.query_quit\")\n",
    "sa.delete(f\"shm://{ROBOT_TYPE_NAME}.prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
