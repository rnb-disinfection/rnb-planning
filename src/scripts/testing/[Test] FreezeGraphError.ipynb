{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt.trt_convert import TrtPrecisionMode\n",
    "from tensorflow.experimental.tensorrt import ConversionParams, Converter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "PROJ_DIR = os.environ[\"RNB_PLANNING_DIR\"]\n",
    "sys.path.append(os.path.join(PROJ_DIR, \"src\"))\n",
    "\n",
    "import SharedArray as sa\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from pkg.utils.utils import *\n",
    "\n",
    "args = DummyObject()\n",
    "args.model_path = \"None\"\n",
    "args.rtype=\"panda\"\n",
    "args.precision= TrtPrecisionMode.FP32\n",
    "\n",
    "if args.model_path == \"None\":\n",
    "    args.model_path = None\n",
    "PRECISION = args.precision\n",
    "\n",
    "from pkg.utils.utils_python3 import *\n",
    "from pkg.controller.robot_config import RobotType\n",
    "from pkg.planning.filtering.lattice_model.data_utils import *\n",
    "import numpy as np\n",
    "int2rtypename = {v.value:v.name for v in RobotType}\n",
    "DATA_PATH = os.path.join(PROJ_DIR, \"data\")\n",
    "MODEL_PATH = os.path.join(PROJ_DIR, \"model\")\n",
    "LAT_MODEL_PATH = os.path.join(MODEL_PATH,\"latticized\")\n",
    "try_mkdir(MODEL_PATH)\n",
    "try_mkdir(LAT_MODEL_PATH)\n",
    "GRASP_FOLDER = \"grasp\"\n",
    "ARM10_FOLDER = \"arm_10\"\n",
    "ARM05_FOLDER = \"arm_05\"\n",
    "FULLS_FOLDER = \"full_scene\"\n",
    "\n",
    "ARM_FOLDER = ARM10_FOLDER\n",
    "GRASP_SHAPE = (20,20,20)\n",
    "ARM_SHAPE = (20,20,20)\n",
    "RH_MASK_SIZE = 512\n",
    "RH_MASK_STEP = 64\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "SERVER_PERIOD = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "self, prepared_p = DummyObject, sa.create(f\"shm://{args.rtype}.prepared\", (1,), dtype=np.bool)\n",
    "self.ROBOT_TYPE_NAME=args.rtype\n",
    "\n",
    "grasp_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\", (BATCH_SIZE,) + GRASP_SHAPE + (3,))\n",
    "arm_img_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\", (BATCH_SIZE,) + ARM_SHAPE + (1,))\n",
    "rh_vals_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\", (BATCH_SIZE, 2))\n",
    "result_p = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.result\", (BATCH_SIZE, 2))\n",
    "query_in = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\", (1,), dtype=np.bool)\n",
    "response_out = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\", (1,), dtype=np.bool)\n",
    "query_quit = sa.create(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\", (1,), dtype=np.bool)\n",
    "gtimer = GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "grasp_img_p[:] = 0\n",
    "arm_img_p[:] = 0\n",
    "rh_vals_p[:] = 0\n",
    "result_p[:] = 0\n",
    "query_in[0] = False\n",
    "response_out[0] = False\n",
    "query_quit[0] = False\n",
    "rh_mask = np.zeros((BATCH_SIZE, 54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_TYPE_NAME=self.ROBOT_TYPE_NAME\n",
    "ROBOT_MODEL_ROOT = os.path.join(LAT_MODEL_PATH, ROBOT_TYPE_NAME)\n",
    "last_model = sorted(os.listdir(ROBOT_MODEL_ROOT))[-1]\n",
    "last_save = sorted([item for item in os.listdir(os.path.join(ROBOT_MODEL_ROOT, last_model)) if item.startswith(\"model\")])[-1]\n",
    "model_path_rel = os.path.join(last_model, last_save)\n",
    "model_log_dir = os.path.join(ROBOT_MODEL_ROOT, model_path_rel)\n",
    "model_log_dir_trt = os.path.join(ROBOT_MODEL_ROOT, model_path_rel.replace(\"model\", \"trt\")+\"-\"+PRECISION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_23488) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_27484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_11892) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_29937) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_39232) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_25291) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_5394) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_15339) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference__wrapped_model_9102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_37484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_24925) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_10019) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_grasp_layer_call_and_return_conditional_losses_27469) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_14891) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_arm_layer_call_and_return_conditional_losses_5432) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_20582) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_75) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_18373) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_layer_call_and_return_conditional_losses_17169) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dense_bn_1_layer_call_and_return_conditional_losses_20404) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_14593) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_19733) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_16862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_1_layer_call_and_return_conditional_losses_21778) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_dens1_ee_layer_call_and_return_conditional_losses_10977) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_layer_call_and_return_conditional_losses_28739) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_res_net_model_tp_layer_call_and_return_conditional_losses_2735) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_pruned_61559) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "# model_k = tf.keras.models.load_model(model_log_dir)\n",
    "# model_s = tf.saved_model.load(model_log_dir, \n",
    "#                               tags=[tf.saved_model.SERVING])\n",
    "    \n",
    "# converted_k = tf.keras.models.load_model(model_log_dir_trt)\n",
    "    \n",
    "converted_s = tf.saved_model.load(\n",
    "    model_log_dir_trt, tags=[tf.saved_model.SERVING])\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def inference_mk(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = model_k([grasp_img_t, arm_img_t, rh_mask_t], training=False)\n",
    "#     return predictions\n",
    "\n",
    "# @tf.function\n",
    "# def inference_ms(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = model_s([grasp_img_t, arm_img_t, rh_mask_t], training=False)\n",
    "#     return predictions\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def inference_ck(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = converted_k([grasp_img_t, arm_img_t, rh_mask_t])\n",
    "#     return predictions\n",
    "\n",
    "# @tf.function\n",
    "# def inference_cs(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = converted_s([grasp_img_t, arm_img_t, rh_mask_t])\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## original single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtimer.reset()\n",
    "# for _ in range(10):\n",
    "#     with gtimer.block(\"convert_tf\"):\n",
    "#         query_in[0] = False\n",
    "#         ## TODO: inference depending on robot type\n",
    "#         r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "#         h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "#         rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "#         grasp_img_t, arm_img_t, rh_mask_t = (\n",
    "#             tf.constant(grasp_img_p, dtype=tf.float32), \n",
    "#             tf.constant(arm_img_p, dtype=tf.float32), \n",
    "#             tf.constant(rh_mask, dtype=tf.float32))\n",
    "# #     with gtimer.block(\"model_k\"):\n",
    "# #         result_mk = model_k([grasp_img_t, arm_img_t, rh_mask_t], training=False)\n",
    "# #     with gtimer.block(\"inference_mk\"):\n",
    "# #         result_mki = inference_mk(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "# #     with gtimer.block(\"model_s\"):\n",
    "# #         result_ms = model_s([grasp_img_t, arm_img_t, rh_mask_t], training=False)\n",
    "# #     with gtimer.block(\"inference_ms\"):\n",
    "# #         result_msi = inference_ms(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "# #     with gtimer.block(\"converted_k\"):\n",
    "# #         result_ck = converted_k([grasp_img_t, arm_img_t, rh_mask_t])\n",
    "# #     with gtimer.block(\"inference_ck\"):\n",
    "# #         result_cki = inference_ck(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     with gtimer.block(\"converted_s\"):\n",
    "#         result_cs = converted_s([grasp_img_t, arm_img_t, rh_mask_t])\n",
    "#     with gtimer.block(\"inference_cs\"):\n",
    "#         result_csi = inference_cs(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     for i_b in range(BATCH_SIZE):\n",
    "#         result_p[i_b] = result_csi[i_b]\n",
    "#     response_out[0] = True\n",
    "\n",
    "# print(gtimer)\n",
    "# # print(\"result_mk: \\t\", result_mk[0].numpy())\n",
    "# # print(\"result_mki: \\t\", result_mki[0].numpy())\n",
    "# # print(\"result_ms: \\t\", result_ms[0].numpy())\n",
    "# # print(\"result_msi: \\t\", result_msi[0].numpy())\n",
    "# # print(\"result_ck: \\t\", result_ck[0].numpy())\n",
    "# # print(\"result_cki: \\t\", result_cki[0].numpy())\n",
    "# print(\"result_cs: \\t\", result_cs[0].numpy())\n",
    "# print(\"result_csi: \\t\", result_csi[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result saved\n",
    "```\n",
    "convert_tf: \t24.0 ms/10 = 2.387 ms (0.562/17.323)\n",
    "model_k: \t453.0 ms/10 = 45.301 ms (42.455/48.52)\n",
    "inference_mk: \t281.0 ms/10 = 28.089 ms (24.755/32.373)\n",
    "model_s: \t289.0 ms/10 = 28.858 ms (24.466/34.085)\n",
    "inference_ms: \t274.0 ms/10 = 27.358 ms (20.217/29.218)\n",
    "converted_k: \t270.0 ms/10 = 26.963 ms (17.71/30.198)\n",
    "inference_ck: \t277.0 ms/10 = 27.728 ms (21.448/33.427)\n",
    "converted_s: \t256.0 ms/10 = 25.561 ms (13.956/31.549)\n",
    "inference_cs: \t258.0 ms/10 = 25.777 ms (23.357/28.377)\n",
    "\n",
    "result_mk: \t [0.9048124 0.8932319]\n",
    "result_mki: \t [0.9048124 0.8932319]\n",
    "result_ms: \t [0.9048124 0.8932319]\n",
    "result_msi: \t [0.9048124 0.8932319]\n",
    "result_ck: \t [0.9048124 0.8932319]\n",
    "result_cki: \t [0.9048124 0.8932319]\n",
    "result_cs: \t [0.9048124 0.8932319]\n",
    "result_csi: \t [0.9048124 0.8932319]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert_variables_to_constants_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import convert_to_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_func_mk = model_k.signatures[\n",
    "#     tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "# graph_func_ms = model_s.signatures[\n",
    "#     tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "# graph_func_ck = converted_k.signatures[\n",
    "#     tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "graph_func_cs = converted_s.signatures[\n",
    "    tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frozen_func_mk = convert_to_constants.convert_variables_to_constants_v2(graph_func_mk)\n",
    "# frozen_func_ms = convert_to_constants.convert_variables_to_constants_v2(graph_func_ms)\n",
    "# frozen_func_ck = convert_to_constants.convert_variables_to_constants_v2(graph_func_ck)\n",
    "frozen_func_cs = convert_to_constants.convert_variables_to_constants_v2(graph_func_cs)\n",
    "\n",
    "# @tf.function\n",
    "# def inference_fmk(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = frozen_func_mk(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     return predictions\n",
    "\n",
    "# @tf.function\n",
    "# def inference_fms(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = frozen_func_ms(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     return predictions\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def inference_fck(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = frozen_func_ck(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     return predictions\n",
    "\n",
    "# @tf.function\n",
    "# def inference_fcs(grasp_img_t, arm_img_t, rh_mask_t):\n",
    "#     # training=False is only needed if there are layers with different\n",
    "#     # behavior during training versus inference (e.g. Dropout).\n",
    "#     predictions = frozen_func_cs(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_tf: \t26.0 ms/10 = 2.551 ms (0.715/17.726)\n",
      "frozen_func_cs: \t236.0 ms/10 = 23.639 ms (20.375/24.467)\n",
      "\n",
      "result_fcs: \t [[0.90481395 0.89324564]]\n"
     ]
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "for _ in range(10):\n",
    "    with gtimer.block(\"convert_tf\"):\n",
    "        query_in[0] = False\n",
    "        ## TODO: inference depending on robot type\n",
    "        r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "        h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "        rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "        grasp_img_t, arm_img_t, rh_mask_t = (\n",
    "            tf.constant(grasp_img_p, dtype=tf.float32), \n",
    "            tf.constant(arm_img_p, dtype=tf.float32), \n",
    "            tf.constant(rh_mask, dtype=tf.float32))\n",
    "#     with gtimer.block(\"frozen_func_mk\"):\n",
    "#         result_fmk = frozen_func_mk(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     with gtimer.block(\"inference_fmk\"):\n",
    "#         result_fmki = inference_fmk(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     with gtimer.block(\"frozen_func_ms\"):\n",
    "#         result_fms = frozen_func_ms(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     with gtimer.block(\"inference_fms\"):\n",
    "#         result_fmsi = inference_fms(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     with gtimer.block(\"frozen_func_ck\"):\n",
    "#         result_fck = frozen_func_ck(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     with gtimer.block(\"inference_fck\"):\n",
    "#         result_fcki = inference_fck(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "    with gtimer.block(\"frozen_func_cs\"):\n",
    "        result_fcs = frozen_func_cs(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "#     with gtimer.block(\"inference_fcs\"):\n",
    "#         result_fcsi = inference_fcs(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "    for i_b in range(BATCH_SIZE):\n",
    "        result_p[i_b] = result_fcs[i_b]\n",
    "    response_out[0] = True\n",
    "\n",
    "print(gtimer)\n",
    "# print(\"result_fmk: \\t\", result_fmk[0].numpy())\n",
    "# print(\"result_fmki: \\t\", result_fmki[0].numpy())\n",
    "# print(\"result_fms: \\t\", result_fms[0].numpy())\n",
    "# print(\"result_fmsi: \\t\", result_fmsi[0].numpy())\n",
    "# print(\"result_fck: \\t\", result_fck[0].numpy())\n",
    "# print(\"result_fcki: \\t\", result_fcki[0].numpy())\n",
    "print(\"result_fcs: \\t\", result_fcs[0].numpy())\n",
    "# print(\"result_fcsi: \\t\", result_fcsi[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results log\n",
    "```\n",
    "convert_tf: \t8.0 ms/10 = 0.78 ms (0.691/1.137)\n",
    "frozen_func_mk: \t226.0 ms/10 = 22.627 ms (21.287/25.226)\n",
    "inference_fmk: \t216.0 ms/10 = 21.615 ms (16.337/24.822)\n",
    "frozen_func_ms: \t193.0 ms/10 = 19.304 ms (11.226/24.701)\n",
    "inference_fms: \t220.0 ms/10 = 21.993 ms (19.922/23.384)\n",
    "frozen_func_ck: \t219.0 ms/10 = 21.94 ms (18.567/24.307)\n",
    "inference_fck: \t243.0 ms/10 = 24.276 ms (23.317/25.061)\n",
    "frozen_func_cs: \t215.0 ms/10 = 21.463 ms (18.58/23.41)\n",
    "inference_fcs: \t229.0 ms/10 = 22.895 ms (21.863/24.178)\n",
    "\n",
    "result_fmk: \t [[0.9048124 0.8932319]]\n",
    "result_fmki: \t [[0.9048124 0.8932319]]\n",
    "result_fms: \t [[0.9048124 0.8932319]]\n",
    "result_fmsi: \t [[0.9048124 0.8932319]]\n",
    "result_fck: \t [[0.9048144 0.8932461]]\n",
    "result_fcki: \t [[0.9048144 0.8932461]]\n",
    "result_fcs: \t [[0.90481347 0.89324504]]\n",
    "result_fcsi: \t [[0.90481347 0.89324504]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### low level test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = graph_func\n",
    "lower_control_flow=True\n",
    "aggressive_inlining=False\n",
    "\n",
    "\n",
    "    converter_data = convert_to_constants._FunctionConverterDataInEager(\n",
    "          func=func,\n",
    "          lower_control_flow=lower_control_flow,\n",
    "          aggressive_inlining=aggressive_inlining)\n",
    "    output_graph_def, converted_input_indices = convert_to_constants._replace_variables_by_constants(\n",
    "          converter_data=converter_data)\n",
    "\n",
    "    fronzen_func = convert_to_constants._construct_concrete_function(func, output_graph_def,\n",
    "                                                                     converted_input_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convertin : 0.22 ms\n",
      "inference : 45.58 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 35.05 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 34.7 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 19.09 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 22.58 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 21.32 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 34.26 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 30.9 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 29.55 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 36.96 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 37.66 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 34.23 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 39.5 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 33.8 ms\n",
      "convertin : 0.21 ms\n",
      "inference : 20.37 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 38.65 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 20.37 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 34.66 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 37.12 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 34.24 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 34.06 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 33.27 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 29.72 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 35.87 ms\n",
      "convertin : 0.1 ms\n",
      "inference : 32.21 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 24.3 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 40.41 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 23.99 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 32.72 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 21.17 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 44.63 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 31.4 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 18.87 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 31.31 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 39.47 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 36.11 ms\n",
      "convertin : 0.16 ms\n",
      "inference : 30.16 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 19.12 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 45.16 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 34.23 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 28.8 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 31.67 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 19.54 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 34.42 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 33.52 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 40.23 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 31.36 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 31.76 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 31.83 ms\n",
      "convertin : 0.16 ms\n",
      "inference : 20.4 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 39.79 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 18.84 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 31.03 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 23.96 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 20.91 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 30.88 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 37.62 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 43.09 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 23.13 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 33.58 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 19.18 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 33.08 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 31.54 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 33.51 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 30.96 ms\n",
      "convertin : 0.16 ms\n",
      "inference : 55.54 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 31.18 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 19.79 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 34.86 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 37.2 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 32.36 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 18.87 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 32.74 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 44.63 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 19.65 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 31.44 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 21.44 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 41.79 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 29.98 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 34.93 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 35.98 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 39.02 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 31.82 ms\n",
      "convertin : 0.09 ms\n",
      "inference : 30.77 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 32.57 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 33.47 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 30.8 ms\n",
      "convertin : 0.22 ms\n",
      "inference : 33.7 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 55.53 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 32.51 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 31.53 ms\n",
      "convertin : 0.2 ms\n",
      "inference : 36.42 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 31.84 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 37.58 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 30.98 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 19.77 ms\n",
      "convertin : 0.18 ms\n",
      "inference : 24.45 ms\n",
      "convertin : 0.19 ms\n",
      "inference : 32.61 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 30.94 ms\n",
      "convertin : 0.17 ms\n",
      "inference : 31.66 ms\n"
     ]
    }
   ],
   "source": [
    "gtimer=GlobalTimer.instance()\n",
    "gtimer.reset()\n",
    "while not query_quit[0]:\n",
    "    if not query_in[0]:\n",
    "        time.sleep(SERVER_PERIOD)\n",
    "        continue\n",
    "    gtimer.tic(\"convert_tf\")\n",
    "    query_in[0] = False\n",
    "    ## TODO: inference depending on robot type\n",
    "    r_mask = div_r_gaussian(rh_vals_p[0][0])\n",
    "    h_mask = div_h_gaussian(rh_vals_p[0][1])\n",
    "    rh_mask[0] = np.concatenate([r_mask, h_mask])\n",
    "    grasp_img_t, arm_img_t, rh_mask_t = (\n",
    "        tf.constant(grasp_img_p, dtype=tf.float32), \n",
    "        tf.constant(arm_img_p, dtype=tf.float32), \n",
    "        tf.constant(rh_mask, dtype=tf.float32))\n",
    "    etime_ctf = gtimer.toc(\"convert_tf\")\n",
    "    print(\"convertin : {} ms\".format(round(etime_ctf, 2)))\n",
    "    gtimer.tic(\"inference_0\")\n",
    "    result_inf = inference(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "    etime_inf = gtimer.toc(\"inference_0\")\n",
    "    print(\"inference : {} ms\".format(round(etime_inf, 2)))\n",
    "    gtimer.tic(\"inference_1\")\n",
    "    result_frz = fronzen_func(grasp_img_t, arm_img_t, rh_mask_t)\n",
    "    etime_inf = gtimer.toc(\"inference_1\")\n",
    "    print(\"frozen inf : {} ms\".format(round(etime_inf, 2)))\n",
    "    for i_b in range(BATCH_SIZE):\n",
    "        result_p[i_b] = result_inf[i_b]\n",
    "    response_out[0] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_tf: \t18.0 ms/100 = 0.182 ms (0.09/0.222)\n",
      "inference: \t3184.0 ms/100 = 31.837 ms (18.843/55.542)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = DummyObject()\n",
    "self.ROBOT_TYPE_NAME = \"panda\"\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.grasp_img\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.arm_img\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.rh_vals\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.result\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_in\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.response_out\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.query_quit\")\n",
    "sa.delete(f\"shm://{self.ROBOT_TYPE_NAME}.prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
