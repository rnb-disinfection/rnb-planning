{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection_list\n",
      "(False, False)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; } </style>\"))\n",
    "import matplotlib.pyplot as plt\n",
    "from pkg.marker_config import *\n",
    "from pkg.constraint_graph import *\n",
    "from pkg.constraint.constraint_action import *\n",
    "from pkg.constraint.constraint_object import *\n",
    "from pkg.constants import *\n",
    "from pkg.utils.plot_utils import *\n",
    "from pkg.utils.utils import *\n",
    "from pkg.environment_builder import *\n",
    "from pkg.ui.ui_broker import *\n",
    "from pkg.controller.combined_robot import *\n",
    "from pkg.controller.combined_robot import CombinedRobot, XYZ_RPY_ROBOTS_DEFAULT\n",
    "from pkg.data_collecting.sampling import *\n",
    "\n",
    "VISUALIZE = False\n",
    "graph = None\n",
    "SAMPLED_DATA = defaultdict(dict)\n",
    "UPDATE_DAT = True\n",
    "\n",
    "GLOBAL_FILENAME = \"global.json\"\n",
    "WORLD_FILENAME = \"world.json\"\n",
    "SCENE_FILENAME = \"scene.json\"\n",
    "DATA_PATH = \"./data\"\n",
    "\n",
    "gtimer = GlobalTimer.instance()\n",
    "elog = Logger()\n",
    "crob = CombinedRobot(connection_list=(False, False))\n",
    "\n",
    "CHECK_DICT = {}\n",
    "\n",
    "# ## Load Global params\n",
    "DATASET_LIST = sorted(filter(lambda x: x!=\"backup\", os.listdir(DATA_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene size: 3375 (15,15,15)\n"
     ]
    }
   ],
   "source": [
    "DATASET = DATASET_LIST[0]\n",
    "CHECK_DICT[DATASET] = {}\n",
    "CURRENT_PATH = os.path.join(DATA_PATH, DATASET)\n",
    "\n",
    "## Load global params\n",
    "GLOBAL_PARAMS = load_json(os.path.join(CURRENT_PATH, GLOBAL_FILENAME))\n",
    "WDH = GLOBAL_PARAMS[\"WDH\"]\n",
    "L_CELL = GLOBAL_PARAMS[\"L_CELL\"]\n",
    "RATIO_DIMS = GLOBAL_PARAMS[\"RATIO_DIMS\"]\n",
    "REACH_OFFSET_DICT = GLOBAL_PARAMS[\"REACH_OFFSET_DICT\"]\n",
    "GRIPPER_REFS = GLOBAL_PARAMS[\"GRIPPER_REFS\"]\n",
    "BASE_LINK = GLOBAL_PARAMS[\"BASE_LINK\"]\n",
    "S_F_RATIO = GLOBAL_PARAMS[\"S_F_RATIO\"]\n",
    "TIMEOUT = GLOBAL_PARAMS[\"TIMEOUT\"]\n",
    "\n",
    "CENTER = tuple(np.divide(WDH, 2, dtype=np.float))\n",
    "Ws, Ds, Hs = WDH\n",
    "Nw, Nd, Nh = Nwdh = int(Ws / L_CELL), int(Ds / L_CELL), int(Hs / L_CELL)\n",
    "L_MAX = L_CELL * RATIO_DIMS\n",
    "print(\"scene size: {} ({},{},{})\".format(Nw * Nd * Nh, Nw, Nd, Nh))\n",
    "\n",
    "# ## Load world\n",
    "WORLD_LIST = sorted(filter(lambda x: not x.endswith(\".json\"), os.listdir(CURRENT_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran0']/actuator[@name='indy0_motor0']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran1']/actuator[@name='indy0_motor1']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran2']/actuator[@name='indy0_motor2']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran3']/actuator[@name='indy0_motor3']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran4']/actuator[@name='indy0_motor4']\n",
      "Unknown tag \"hardwareInterface\" in /robot[@name='custom_robots']/transmission[@name='indy0_tran5']/actuator[@name='indy0_motor5']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"pkg.ui.dash_launcher\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "WORLD = WORLD_LIST[0]\n",
    "CHECK_DICT[DATASET][WORLD] = {}\n",
    "WORLD_PATH = os.path.join(CURRENT_PATH, WORLD)\n",
    "SAMPLED_DATA[\"WORLD\"] = load_json(os.path.join(WORLD_PATH, WORLD_FILENAME))\n",
    "Trbt_dict = SAMPLED_DATA[\"WORLD\"][\"Trbt_dict\"]\n",
    "reach_center_dict = {k: tuple(np.add(v[0], REACH_OFFSET_DICT[k])) for k, v in Trbt_dict.items()}\n",
    "\n",
    "cam = None\n",
    "# set urdf\n",
    "xcustom, JOINT_NAMES, LINK_NAMES, urdf_content = set_custom_robots(crob.robots_on_scene, Trbt_dict,\n",
    "                                                                   crob.custom_limits, start_rviz=VISUALIZE)\n",
    "ghnd = GeometryHandle(urdf_content)\n",
    "time.sleep(2)\n",
    "\n",
    "# set graph\n",
    "graph = ConstraintGraph(ghnd=ghnd, urdf_path=URDF_PATH, joint_names=JOINT_NAMES, link_names=LINK_NAMES,\n",
    "                        urdf_content=urdf_content, combined_robot=crob)\n",
    "graph.set_camera(cam)\n",
    "graph.set_cam_robot_collision(_add_cam_poles=False, color=(1, 1, 0, 0.3))\n",
    "if VISUALIZE: graph.set_rviz()\n",
    "\n",
    "# start UI\n",
    "ui_broker = UIBroker.instance()\n",
    "ui_broker.initialize(graph)\n",
    "ui_broker.start_server()\n",
    "\n",
    "# set rviz\n",
    "if VISUALIZE: graph.set_rviz(crob.home_pose)\n",
    "ui_broker.set_tables()\n",
    "\n",
    "for gripper in GRIPPER_REFS.values():\n",
    "    graph.register_binder(name=gripper['bname'], _type=FramedTool, point=gripper['tcp_ref'], rpy=[0, 0, 0],\n",
    "                          link_name=gripper['link_name'])\n",
    "graph.register_binder(name='base', _type=PlaceFrame, point=[0, 0, 0], rpy=[0, 0, 0], link_name=BASE_LINK)\n",
    "vtem = graph.ghnd.create_safe(name=\"virtual\", gtype=GEOTYPE.SPHERE, link_name=BASE_LINK,\n",
    "                              dims=(0, 0, 0), center=(0, 0, 0), rpy=(0, 0, 0), collision=False, display=False\n",
    "                              )\n",
    "graph.add_object(\"virtual\",\n",
    "                 SingleHandleObject(_object=vtem,\n",
    "                                    action_point=FramePoint(name=\"point\", _object=vtem, point=(0, 0, 0),\n",
    "                                                            rpy=(0, 0, 0), name_full=None)),\n",
    "                 binding=(\"point\", \"base\"))\n",
    "\n",
    "obj_list = []\n",
    "col_obj_list = []\n",
    "\n",
    "# ## Load scene\n",
    "SCENE_LIST = sorted(filter(lambda x: not x.endswith(\".json\"), os.listdir(WORLD_PATH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScENE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/tamp/.local/lib/python2.7/site-packages/dash/dash.py\", line 1716, in run_server\n",
      "    self.server.run(host=host, port=port, debug=debug, **flask_run_options)\n",
      "  File \"/home/tamp/.local/lib/python2.7/site-packages/flask/app.py\", line 990, in run\n",
      "    run_simple(host, port, self, **options)\n",
      "  File \"/home/tamp/.local/lib/python2.7/site-packages/werkzeug/serving.py\", line 1052, in run_simple\n",
      "    inner()\n",
      "  File \"/home/tamp/.local/lib/python2.7/site-packages/werkzeug/serving.py\", line 1005, in inner\n",
      "    fd=fd,\n",
      "  File \"/home/tamp/.local/lib/python2.7/site-packages/werkzeug/serving.py\", line 848, in make_server\n",
      "    host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n",
      "  File \"/home/tamp/.local/lib/python2.7/site-packages/werkzeug/serving.py\", line 740, in __init__\n",
      "    HTTPServer.__init__(self, server_address, handler)\n",
      "  File \"/usr/lib/python2.7/SocketServer.py\", line 420, in __init__\n",
      "    self.server_bind()\n",
      "  File \"/usr/lib/python2.7/BaseHTTPServer.py\", line 108, in server_bind\n",
      "    SocketServer.TCPServer.server_bind(self)\n",
      "  File \"/usr/lib/python2.7/SocketServer.py\", line 434, in server_bind\n",
      "    self.socket.bind(self.server_address)\n",
      "  File \"/usr/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 98] Address already in use\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SCENE = SCENE_LIST[0]\n",
    "CHECK_DICT[DATASET][WORLD][SCENE] = {}\n",
    "SCENE_PATH = os.path.join(WORLD_PATH, SCENE)\n",
    "SAMPLED_DATA[\"SCENE\"] = load_json(os.path.join(SCENE_PATH, SCENE_FILENAME))\n",
    "Q_s = np.array(SAMPLED_DATA[\"SCENE\"][\"Q_s\"])\n",
    "Q_s, links, link_verts, link_ctems, link_rads = sample_joint(graph, Q_s_loaded=Q_s)\n",
    "Q_s_dict = SAMPLED_DATA[\"SCENE\"][\"Q_s_dict\"]\n",
    "obj_dat = SAMPLED_DATA[\"SCENE\"][\"obj_dat\"]\n",
    "\n",
    "if VISUALIZE:\n",
    "    graph.show_pose(Q_s)\n",
    "    time.sleep(1)\n",
    "    graph.show_pose(Q_s)\n",
    "    time.sleep(1)\n",
    "    graph.show_pose(Q_s)\n",
    "for obj in obj_list: graph.remove_geometry(obj)\n",
    "for odat in obj_dat:\n",
    "    nbox, gtype, dims, color, center, rpy = odat[\"nbox\"], getattr(GEOTYPE, odat[\"gtype\"]), odat[\"dims\"], \\\n",
    "                                            odat[\"color\"], odat[\"center\"], odat[\"rpy\"]\n",
    "    obj = graph.ghnd.create_safe(\n",
    "        name=\"{}_{}_{}_{}\".format(gtype.name, *nbox), link_name=BASE_LINK, gtype=gtype,\n",
    "        center=center, rpy=rpy, dims=dims, color=color, display=True, collision=True, fixed=True)\n",
    "    obj_list.append(obj)\n",
    "    graph.add_marker(obj, vis=VISUALIZE)\n",
    "\n",
    "for obj in col_obj_list: graph.remove_geometry(obj)\n",
    "\n",
    "if VISUALIZE: graph.set_rviz()\n",
    "dcol = DataCollector(graph, GRIPPER_REFS, S_F_RATIO=S_F_RATIO)\n",
    "if VISUALIZE: graph.set_rviz()\n",
    "\n",
    "# planners\n",
    "mplan = MoveitPlanner(joint_names=graph.joint_names, link_names=graph.link_names, urdf_path=graph.urdf_path,\n",
    "                      urdf_content=graph.urdf_content,\n",
    "                      robot_names=graph.combined_robot.robot_names,\n",
    "                      binder_links=[v.object.link_name for v in graph.binder_dict.values()],\n",
    "                      ghnd=graph.ghnd)\n",
    "dual_mplan_dict = get_dual_planner_dict(GRIPPER_REFS, graph.ghnd, graph.urdf_content, graph.urdf_path,\n",
    "                                        graph.link_names, graph.combined_robot.robot_names)\n",
    "\n",
    "# ## Load action\n",
    "ACTION_LIST = sorted(filter(lambda x: x != SCENE_FILENAME, os.listdir(SCENE_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_names = graph.link_names\n",
    "joint_names = crob.joint_names\n",
    "joint_num = crob.joint_num\n",
    "IGNORE_CTEMS = [\"panda1_hand_Cylinder_1\", 'panda1_hand_Cylinder_2']\n",
    "joint_index_dict = {joint.name:None for joint in urdf_content.joints}\n",
    "joint_index_dict.update({jname:idx for idx, jname in zip(range(joint_num), joint_names)})\n",
    "centers = get_centers(Nwdh, L_CELL)\n",
    "merge_pairs = get_merge_pairs(ghnd)\n",
    "merge_paired_ctems(graph=graph, merge_pairs=merge_pairs, VISUALIZE=VISUALIZE)\n",
    "for cname in IGNORE_CTEMS:\n",
    "    graph.remove_geometry(graph.ghnd.NAME_DICT[cname])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc joint kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_links: \t3.0 ms/1 = 3.179 ms (3.179/3.179)\n",
      "T_chain: \t2.0 ms/1 = 2.285 ms (2.285/2.285)\n",
      "get_chain: \t0.0 ms/21 = 0.009 ms (0.004/0.016)\n",
      "test_joints: \t1.0 ms/1 = 0.716 ms (0.716/0.716)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "gtimer.tic(\"test_links\")\n",
    "Tlink_dict = {}\n",
    "chain_dict = {}\n",
    "Tj_arr = np.zeros((joint_num, 4, 4))\n",
    "Tj_inv_arr = np.zeros((joint_num, 4, 4))\n",
    "joint_axis_arr = np.zeros((joint_num,3))\n",
    "\n",
    "gtimer.tic(\"T_chain\")\n",
    "Tlink_dict = build_T_chain(link_names, Q_s_dict, urdf_content)\n",
    "gtimer.toc(\"T_chain\")\n",
    "\n",
    "for lname in link_names:\n",
    "    gtimer.tic(\"get_chain\")\n",
    "    jnames = filter(lambda x: x in joint_names, \n",
    "                    urdf_content.get_chain(root=BASE_LINK, tip=lname, joints=True, links=False))\n",
    "    gtimer.toc(\"get_chain\")\n",
    "    chain_dict[lname] = [1 if pj in jnames else 0 for pj in joint_names]\n",
    "gtimer.toc(\"test_links\")\n",
    "\n",
    "gtimer.tic(\"test_joints\")\n",
    "for i_j, jname in zip(range(joint_num), joint_names):\n",
    "    joint = urdf_content.joint_map[jname]\n",
    "    lname = joint.child\n",
    "    Tj_arr[i_j,:,:] = Tlink_dict[lname]\n",
    "    Tj_inv_arr[i_j,:,:] = SE3_inv(Tlink_dict[lname])\n",
    "    joint_axis_arr[i_j] = joint.axis\n",
    "gtimer.toc(\"test_joints\")\n",
    "print(gtimer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6539306640625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtimer.reset()\n",
    "gtimer.tic(\"calc_cell\")\n",
    "__p = centers.reshape(Nwdh+(1,3)) - Tj_arr[:,:3,3].reshape((1,1,1,joint_num,3))\n",
    "__w = np.sum(Tj_arr[:,:3,:3] * joint_axis_arr.reshape(joint_num, 1, 3), axis=-1).reshape((1,1,1,joint_num,3))\n",
    "__w = np.tile(__w, Nwdh+(1,1))\n",
    "__v = np.cross(__w, __p)\n",
    "xi = np.concatenate([__w, __v],axis=-1)\n",
    "gtimer.toc(\"calc_cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc ctems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224.67708587646484"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtimer.tic(\"calc_ctems\")\n",
    "ctem_names, ctem_TFs, ctem_dims, ctem_cells, ctem_links, ctem_joints, ctem_types = \\\n",
    "    defaultdict(list), defaultdict(list), defaultdict(list), defaultdict(list), defaultdict(list), defaultdict(list), dict()\n",
    "for ctem in ghnd:\n",
    "    if not ctem.collision:\n",
    "        continue \n",
    "    key = gtype_to_otype(ctem.gtype).name\n",
    "    ctem_names[key].append(ctem.name)\n",
    "    Ttem = np.matmul(Tlink_dict[ctem.link_name], ctem.Toff)\n",
    "    ctem_TFs[key].append(Ttem)\n",
    "    ctem_dims[key].append(ctem.dims)\n",
    "    ctem_cells[key].append(get_cell(Ttem[:3,3], L_CELL, Nwdh))\n",
    "    ctem_links[key].append(ctem.link_name)\n",
    "    ctem_joints[key].append(chain_dict[ctem.link_name])\n",
    "    ctem_types[key] = ctem.gtype\n",
    "\n",
    "    \n",
    "verts_dict = {}\n",
    "for key_cur in ctem_cells:\n",
    "    ctem_TFs[key_cur] = np.array(ctem_TFs[key_cur])\n",
    "    cell_array = np.array(ctem_cells[key_cur])\n",
    "    all_rearranged = False\n",
    "    while not all_rearranged:\n",
    "        all_rearranged = True\n",
    "        for cell in cell_array:\n",
    "            idxset = np.where(np.all(cell_array==cell, axis=-1))[0]\n",
    "            if len(idxset)>1:\n",
    "                all_rearranged = False\n",
    "                cell_array = rearrange_cell_array(cell_array, idxset, L_CELL, ctem_TFs[key_cur], centers)\n",
    "                break\n",
    "    ctem_cells[key_cur] = cell_array\n",
    "    gtype = ctem_types[key_cur]\n",
    "    TFs = ctem_TFs[key_cur]\n",
    "    dims = np.array(ctem_dims[key_cur])\n",
    "    default_vert = DEFAULT_VERT_DICT[gtype]\n",
    "    verts_dim = default_vert.reshape((1,-1,3))*dims.reshape((-1,1,3))\n",
    "    cell_array = ctem_cells[key_cur]\n",
    "    verts = np.zeros_like(verts_dim)\n",
    "    for iv in range(verts.shape[1]):\n",
    "        verts[:,iv,:] = matmul_md(TFs[:,:3,:3], verts_dim[:,iv,:,np.newaxis])[:,:,0]+TFs[:,:3,3]\n",
    "    verts_loc = (verts - (cell_array[:,np.newaxis,:]*L_CELL+L_CELL/2))\n",
    "    verts_dict[key_cur] = verts_loc\n",
    "gtimer.toc(\"calc_ctems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION = ACTION_LIST[0]\n",
    "print(\"[BEGIN] {} - {} - {} - {} ===============\".format(DATASET, WORLD, SCENE, ACTION))\n",
    "CHECK_DICT[DATASET][WORLD][SCENE][ACTION] = {}\n",
    "snode_dict_bak = {int(k): v for k, v in load_json(os.path.join(SCENE_PATH, ACTION)).items()}\n",
    "dcol.snode_dict = dcol.manager.dict()\n",
    "for k, v in snode_dict_bak.items():\n",
    "    dcol.snode_dict[k] = deepcopy(v)\n",
    "snode_keys = sorted(snode_dict_bak.keys())\n",
    "\n",
    "if snode_keys:\n",
    "    sk0 = snode_keys[0]\n",
    "    rname, tar, inhand_coll, obj_coll = \\\n",
    "        snode_dict_bak[sk0][\"rname1\"], snode_dict_bak[sk0][\"rname2\"], \\\n",
    "        snode_dict_bak[sk0][\"obj1\"][\"collision\"], snode_dict_bak[sk0][\"obj2\"][\"collision\"]\n",
    "else:\n",
    "    print(\"[END] {} - {} - {} - {} ===============\".format(DATASET, WORLD, SCENE, ACTION))\n",
    "    print(\"No Item\")\n",
    "    continue\n",
    "\n",
    "dcol.check_loop_mp(test_full_mp, GRIPPER_REFS=GRIPPER_REFS,  Q_s=Q_s, dual_mplan_dict=dual_mplan_dict, mplan=mplan, N_retry=N_retry_test, timeout=TIMEOUT)\n",
    "succ_old_list = np.array([snode_dict_bak[skey][\"success\"] for skey in snode_keys])\n",
    "succ_now_list = np.array([dcol.snode_dict[skey][\"succ_count\"]>0 for skey in snode_keys])\n",
    "\n",
    "if rname and tar:  # handover case\n",
    "    action_type = \"HANDOVER\"\n",
    "elif inhand_coll:  # place case\n",
    "    action_type = \"PLACE\"\n",
    "elif obj_coll:  # pick case\n",
    "    action_type = \"PICK\"\n",
    "else:\n",
    "    raise (RuntimeError(\"non-implemented case\"))\n",
    "\n",
    "check_results = succ_old_list==succ_now_list\n",
    "print(succ_old_list)\n",
    "print(succ_now_list)\n",
    "CHECK_DICT[DATASET][WORLD][SCENE][ACTION][\"action_type\"] = action_type\n",
    "CHECK_DICT[DATASET][WORLD][SCENE][ACTION][\"check_ratio\"] = np.mean(check_results)\n",
    "CHECK_DICT[DATASET][WORLD][SCENE][ACTION][\"succ_corrects\"] = np.mean(\n",
    "    check_results[np.where(succ_old_list)])\n",
    "CHECK_DICT[DATASET][WORLD][SCENE][ACTION][\"fail_corrects\"] = np.mean(\n",
    "    check_results[np.where(np.logical_not(succ_old_list))])\n",
    "CHECK_DICT[DATASET][WORLD][SCENE][ACTION][\"num\"] = len(check_results)\n",
    "\n",
    "if UPDATE_DAT:\n",
    "    for skey in snode_keys:\n",
    "        if not snode_dict_bak[skey][\"success\"] and dcol.snode_dict[skey][\"success\"]:\n",
    "            snode_dict_bak[skey][\"success\"] = dcol.snode_dict[skey][\"success\"]\n",
    "    save_json(os.path.join(SCENE_PATH, ACTION), snode_dict_bak)\n",
    "\n",
    "if VISUALIZE: graph.set_rviz()\n",
    "\n",
    "print(\"[END] {} - {} - {} - {} ===============\".format(DATASET, WORLD, SCENE, ACTION))\n",
    "elog.log(CHECK_DICT[DATASET][WORLD][SCENE][ACTION], \"{}-{}\".format(SCENE, ACTION), print_now=False)\n",
    "for k, v in CHECK_DICT[DATASET][WORLD][SCENE][ACTION].items():\n",
    "    print(\"{}: {}\".format(k, str(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pkg.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_FILENAME = \"global.json\"\n",
    "WORLD_FILENAME = \"world.json\"\n",
    "SCENE_FILENAME = \"scene.json\"\n",
    "DATA_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "12\n",
      "11\n",
      "58\n",
      "28\n",
      "41\n",
      "67\n",
      "19\n",
      "15\n",
      "8\n",
      "2\n",
      "6\n",
      "97\n",
      "33\n",
      "4\n",
      "1\n",
      "15\n",
      "17\n",
      "14\n",
      "11\n",
      "22\n",
      "0\n",
      "9\n",
      "0\n",
      "49\n",
      "5\n",
      "26\n",
      "2\n",
      "18\n",
      "29\n",
      "0\n",
      "8\n",
      "4\n",
      "0\n",
      "20\n",
      "6\n",
      "20\n",
      "18\n",
      "28\n",
      "31\n",
      "22\n",
      "21\n",
      "75\n",
      "31\n",
      "19\n",
      "9\n",
      "25\n",
      "14\n",
      "17\n",
      "6\n",
      "8\n",
      "69\n",
      "14\n",
      "20\n",
      "102\n",
      "32\n",
      "19\n",
      "21\n",
      "21\n",
      "22\n",
      "7\n",
      "13\n",
      "16\n",
      "8\n",
      "30\n",
      "17\n",
      "46\n",
      "42\n",
      "23\n",
      "40\n",
      "8\n",
      "11\n",
      "34\n",
      "12\n",
      "14\n",
      "12\n",
      "17\n",
      "7\n",
      "47\n",
      "26\n",
      "17\n",
      "3\n",
      "11\n",
      "7\n",
      "30\n",
      "29\n",
      "4\n",
      "35\n",
      "17\n",
      "25\n",
      "7\n",
      "15\n",
      "2\n",
      "0\n",
      "21\n",
      "16\n",
      "39\n",
      "31\n",
      "19\n",
      "43\n",
      "16\n",
      "39\n",
      "52\n",
      "30\n",
      "12\n",
      "4\n",
      "16\n",
      "24\n",
      "19\n",
      "21\n",
      "22\n",
      "46\n",
      "7\n",
      "16\n",
      "52\n",
      "13\n",
      "27\n",
      "57\n",
      "33\n",
      "18\n",
      "41\n",
      "32\n",
      "6\n",
      "16\n",
      "14\n",
      "15\n",
      "0\n",
      "27\n",
      "4\n",
      "3\n",
      "4\n",
      "11\n",
      "46\n",
      "20\n",
      "17\n",
      "43\n",
      "23\n",
      "25\n",
      "43\n",
      "19\n",
      "17\n",
      "44\n",
      "19\n",
      "16\n",
      "50\n",
      "22\n",
      "24\n",
      "42\n",
      "32\n",
      "16\n",
      "60\n",
      "35\n",
      "11\n",
      "38\n",
      "28\n",
      "8\n",
      "17\n",
      "9\n",
      "15\n",
      "0\n",
      "11\n",
      "10\n",
      "67\n",
      "26\n",
      "22\n",
      "34\n",
      "18\n",
      "10\n",
      "49\n",
      "3\n",
      "33\n",
      "48\n",
      "43\n",
      "20\n",
      "0\n",
      "8\n",
      "9\n",
      "54\n",
      "33\n",
      "24\n",
      "77\n",
      "26\n",
      "8\n",
      "26\n",
      "17\n",
      "20\n",
      "17\n",
      "22\n",
      "10\n",
      "8\n",
      "17\n",
      "10\n",
      "34\n",
      "14\n",
      "15\n",
      "27\n",
      "8\n",
      "6\n",
      "16\n",
      "20\n",
      "14\n",
      "13\n",
      "22\n",
      "20\n",
      "37\n",
      "34\n",
      "44\n",
      "77\n",
      "10\n",
      "7\n",
      "28\n",
      "21\n",
      "21\n",
      "27\n",
      "3\n",
      "5\n",
      "18\n",
      "8\n",
      "10\n",
      "20\n",
      "9\n",
      "4\n",
      "70\n",
      "28\n",
      "16\n",
      "16\n",
      "20\n",
      "21\n",
      "9\n",
      "1\n",
      "30\n",
      "80\n",
      "24\n",
      "19\n",
      "68\n",
      "22\n",
      "26\n",
      "4\n",
      "22\n",
      "16\n",
      "0\n",
      "23\n",
      "18\n",
      "30\n",
      "29\n",
      "20\n",
      "26\n",
      "20\n",
      "12\n",
      "55\n",
      "5\n",
      "28\n",
      "22\n",
      "35\n",
      "14\n",
      "42\n",
      "19\n",
      "19\n",
      "8\n",
      "13\n",
      "17\n",
      "12\n",
      "44\n",
      "24\n",
      "10\n",
      "9\n",
      "15\n",
      "7\n",
      "15\n",
      "12\n",
      "14\n",
      "13\n",
      "7\n",
      "6\n",
      "32\n",
      "13\n",
      "38\n",
      "14\n",
      "27\n",
      "62\n",
      "22\n",
      "13\n",
      "13\n",
      "16\n",
      "29\n",
      "62\n",
      "16\n",
      "18\n",
      "54\n",
      "13\n",
      "15\n",
      "85\n",
      "18\n",
      "9\n",
      "0\n",
      "13\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "count_all = 0\n",
    "DATASET_LIST = sorted(filter(lambda x: x!=\"backup\", os.listdir(DATA_PATH)))\n",
    "for DATASET in DATASET_LIST:\n",
    "    CURRENT_PATH = os.path.join(DATA_PATH, DATASET)\n",
    "    WORLD_LIST = sorted(filter(lambda x: not x.endswith(\".json\"), os.listdir(CURRENT_PATH)))\n",
    "    for WORLD in WORLD_LIST:\n",
    "        WORLD_PATH = os.path.join(CURRENT_PATH, WORLD)\n",
    "        SCENE_LIST = sorted(filter(lambda x: not x.endswith(\".json\"), os.listdir(WORLD_PATH)))\n",
    "        for SCENE in SCENE_LIST:\n",
    "            SCENE_PATH = os.path.join(WORLD_PATH, SCENE)\n",
    "            ACTION_LIST = sorted(filter(lambda x: x != SCENE_FILENAME, os.listdir(SCENE_PATH)))\n",
    "            for ACTION in ACTION_LIST:\n",
    "                snode_dict_bak = {int(k): v for k, v in load_json(os.path.join(SCENE_PATH, ACTION)).items()}\n",
    "                print(len(snode_dict_bak))\n",
    "                count_all += len(snode_dict_bak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6675"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
