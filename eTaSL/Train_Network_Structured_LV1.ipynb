{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test: 59522, 19215\n"
     ]
    }
   ],
   "source": [
    "from pkg.data_collecting.load_data import *\n",
    "\n",
    "JOINT_NUM = 13\n",
    "CONVERTED_PATH = CONVERTED_PATH_DEFAULT\n",
    "\n",
    "gtimer = GlobalTimer()\n",
    "# ## Load Global params\n",
    "DATASET_LIST = sorted(os.listdir(CONVERTED_PATH))\n",
    "trainset_num = None\n",
    "if trainset_num is not None:\n",
    "    TRAINSET_LIST =  DATASET_LIST[:trainset_num]\n",
    "    TESTSET_LIST = DATASET_LIST[trainset_num:]\n",
    "else:\n",
    "    TRAINSET_LIST = ['20201214-165211', '20201216-021416', '20201218-024611']\n",
    "    TESTSET_LIST = ['20201208-121454', '20201212-232318', '20201213-061207']\n",
    "data_loader = DataLoader(JOINT_NUM)\n",
    "train_set = data_loader.get_dataset_args(TRAINSET_LIST, JOINT_NUM)\n",
    "N_train = len(train_set)\n",
    "test_set = data_loader.get_dataset_args(TESTSET_LIST, JOINT_NUM)\n",
    "N_test = len(test_set)\n",
    "print(f'Train/Test: {N_train}, {N_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg.training.model import *\n",
    "\n",
    "# Create an instance of the model\n",
    "model = ResNetModelTP()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log path: logs/gradient_tape/20210108-202908\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logpath = os.path.join('logs','gradient_tape',current_time)\n",
    "train_log_dir = os.path.join(logpath, 'train')\n",
    "test_log_dir = os.path.join(logpath, 'test')\n",
    "model_log_dir = os.path.join(logpath, 'model_{}/')\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "shutil.copy(os.path.join('.','pkg','training','model.py' ), logpath)\n",
    "print(f'Log path: {logpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tamp/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/tamp/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_0/assets\n",
      "Epoch 1, Loss: 0.6378951668739319, Accuracy: 64.78326416015625, Test Loss: 0.6340115070343018, Test Accuracy: 66.02083587646484\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_1/assets\n",
      "Epoch 2, Loss: 0.6270196437835693, Accuracy: 66.65155029296875, Test Loss: 0.6305410861968994, Test Accuracy: 66.796875\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_2/assets\n",
      "Epoch 3, Loss: 0.6219231486320496, Accuracy: 67.36895751953125, Test Loss: 0.6265252828598022, Test Accuracy: 67.17707824707031\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_3/assets\n",
      "Epoch 4, Loss: 0.620100200176239, Accuracy: 67.46471405029297, Test Loss: 0.6234776377677917, Test Accuracy: 67.34375\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_4/assets\n",
      "Epoch 5, Loss: 0.6186288595199585, Accuracy: 67.69153594970703, Test Loss: 0.62273108959198, Test Accuracy: 67.57291412353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_5/assets\n",
      "Epoch 6, Loss: 0.6162452101707458, Accuracy: 67.88137817382812, Test Loss: 0.6204330325126648, Test Accuracy: 67.3125\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_6/assets\n",
      "Epoch 7, Loss: 0.6141014695167542, Accuracy: 68.19219970703125, Test Loss: 0.6195555329322815, Test Accuracy: 67.63541412353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_7/assets\n",
      "Epoch 8, Loss: 0.6105859875679016, Accuracy: 68.58870697021484, Test Loss: 0.6158196926116943, Test Accuracy: 67.95832824707031\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_8/assets\n",
      "Epoch 9, Loss: 0.6081119775772095, Accuracy: 68.83904266357422, Test Loss: 0.6173818707466125, Test Accuracy: 67.59375\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_9/assets\n",
      "Epoch 10, Loss: 0.6080238819122314, Accuracy: 68.7869644165039, Test Loss: 0.6181851029396057, Test Accuracy: 67.60416412353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_10/assets\n",
      "Epoch 11, Loss: 0.6057357788085938, Accuracy: 69.16666412353516, Test Loss: 0.6167185306549072, Test Accuracy: 67.9375\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_11/assets\n",
      "Epoch 12, Loss: 0.6044942736625671, Accuracy: 69.21371459960938, Test Loss: 0.6160966753959656, Test Accuracy: 67.91146087646484\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_12/assets\n",
      "Epoch 13, Loss: 0.5897236466407776, Accuracy: 70.43850708007812, Test Loss: 0.5760601162910461, Test Accuracy: 71.55728912353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_13/assets\n",
      "Epoch 14, Loss: 0.5501919984817505, Accuracy: 74.5043716430664, Test Loss: 0.5545680522918701, Test Accuracy: 74.10416412353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_14/assets\n",
      "Epoch 15, Loss: 0.5402567386627197, Accuracy: 75.57795715332031, Test Loss: 0.5543558597564697, Test Accuracy: 73.86458587646484\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_15/assets\n",
      "Epoch 16, Loss: 0.5350499153137207, Accuracy: 76.20295715332031, Test Loss: 0.5621880888938904, Test Accuracy: 73.61458587646484\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_16/assets\n",
      "Epoch 17, Loss: 0.526167631149292, Accuracy: 77.24462127685547, Test Loss: 0.5424637794494629, Test Accuracy: 75.27603912353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_17/assets\n",
      "Epoch 18, Loss: 0.5166386961936951, Accuracy: 78.27452850341797, Test Loss: 0.5397742390632629, Test Accuracy: 75.64583587646484\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_18/assets\n",
      "Epoch 19, Loss: 0.5117874145507812, Accuracy: 78.69791412353516, Test Loss: 0.5590847134590149, Test Accuracy: 74.171875\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_19/assets\n",
      "Epoch 20, Loss: 0.5077484846115112, Accuracy: 79.24899291992188, Test Loss: 0.5437095761299133, Test Accuracy: 75.21353912353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_20/assets\n",
      "Epoch 21, Loss: 0.5045129656791687, Accuracy: 79.5749282836914, Test Loss: 0.5389962196350098, Test Accuracy: 75.66145324707031\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_21/assets\n",
      "Epoch 22, Loss: 0.5024303197860718, Accuracy: 79.88239288330078, Test Loss: 0.5415822863578796, Test Accuracy: 75.45833587646484\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_22/assets\n",
      "Epoch 23, Loss: 0.4993749260902405, Accuracy: 80.26377868652344, Test Loss: 0.5394058227539062, Test Accuracy: 75.640625\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_23/assets\n",
      "Epoch 24, Loss: 0.4961390197277069, Accuracy: 80.4317855834961, Test Loss: 0.5347190499305725, Test Accuracy: 76.21875\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_24/assets\n",
      "Epoch 25, Loss: 0.4943769872188568, Accuracy: 80.74596405029297, Test Loss: 0.5382722020149231, Test Accuracy: 75.6875\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_25/assets\n",
      "Epoch 26, Loss: 0.49322670698165894, Accuracy: 80.86189270019531, Test Loss: 0.5376162528991699, Test Accuracy: 75.83853912353516\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_26/assets\n",
      "Epoch 27, Loss: 0.4901256263256073, Accuracy: 81.23320007324219, Test Loss: 0.5385798811912537, Test Accuracy: 75.94270324707031\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_27/assets\n",
      "Epoch 28, Loss: 0.48860490322113037, Accuracy: 81.40960693359375, Test Loss: 0.5340837836265564, Test Accuracy: 76.13020324707031\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_28/assets\n",
      "Epoch 29, Loss: 0.4875623881816864, Accuracy: 81.45161437988281, Test Loss: 0.5431066155433655, Test Accuracy: 75.640625\n",
      "INFO:tensorflow:Assets written to: logs/gradient_tape/20210108-202908/model_29/assets\n",
      "Epoch 30, Loss: 0.4856050908565521, Accuracy: 81.7456283569336, Test Loss: 0.5481384992599487, Test Accuracy: 75.015625\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_S = 0\n",
    "EPOCHS_E = 30\n",
    "BATCH_SIZE = 32\n",
    "LOG_STEP = 100\n",
    "\n",
    "for epoch in range(EPOCHS_S, EPOCHS_E):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    random.shuffle(train_set)\n",
    "    i_step = 0\n",
    "    scene_batch, success_batch = [], []\n",
    "    for scene_tuple in train_set:\n",
    "        i_step += 1\n",
    "        scene_data, success, skey = load_scene_data(*scene_tuple)\n",
    "        scene_batch.append(scene_data)\n",
    "        success_batch.append(success)\n",
    "        if i_step%BATCH_SIZE==0:\n",
    "            cbox, cbox_m, ccyl, ccyl_m, ibox, ibox_m, gbox, gbox_m = data_loader.separate_dat(np.array(scene_batch, dtype=np.float32))\n",
    "            train_step([cbox, cbox_m, ccyl, ccyl_m, ibox, ibox_m, gbox, gbox_m], np.array(success_batch, dtype=np.int))\n",
    "            scene_batch, success_batch = [], []\n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"train step - {}/{}        \".format(i_step, N_train), end = '\\r')\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    i_step = 0\n",
    "    scene_batch, success_batch = [], []\n",
    "    for scene_tuple in test_set:\n",
    "        i_step += 1\n",
    "        scene_data, success, skey = load_scene_data(*scene_tuple)\n",
    "        scene_batch.append(scene_data)\n",
    "        success_batch.append(success)\n",
    "        if i_step%BATCH_SIZE==0:\n",
    "            cbox, cbox_m, ccyl, ccyl_m, ibox, ibox_m, gbox, gbox_m = data_loader.separate_dat(np.array(scene_batch, dtype=np.float32))\n",
    "            test_step([cbox, cbox_m, ccyl, ccyl_m, ibox, ibox_m, gbox, gbox_m], np.array(success_batch,dtype=np.int))\n",
    "            scene_batch, success_batch = [], []\n",
    "        if i_step%LOG_STEP==0:\n",
    "            print(\"test step - {}/{}        \".format(i_step, N_test), end = '\\r')\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "            \n",
    "    model.save(model_log_dir.format(epoch))\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "        f'Test Loss: {test_loss.result()}, '\n",
    "        f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "* input stage batch norm 없애보기 - 미미한 향상\n",
    "* dense depth 조정, add layer를 concat으로 - trainset 위주의 미미한 향상\n",
    "* input stage kernel size 1로, feature size down, dropout - 상당한 향성\n",
    "* dropout 증강 - 미미한 변화\n",
    "* stage0~5 last feature size 절반 - 무변화\n",
    "* box preconv 통합, feature size 추가 축소 - 성능 하락\n",
    "* box preconv 분리 - 성능 복구\n",
    "* feature size 절반, batch size 128 - 미미한 성능 하락\n",
    "* feature size 복구, batch size 64 - 성능 복구 ~ 77% (20201224-122148)\n",
    "* input non-batchnorm 확대 - 차이 없음 ~ 77% (20201224-165237)\n",
    "* 인풋 수정, input bn 복구 - 성능 하락 ~ 73% (20210106-150839) - 데이터 로딩 실수, 분리된 파일들에 기존의 내부 카운팅으로 중복 로드\n",
    "* 인풋 joint limit 상대값, 데이터 디버그 - 하락 상태, 큰 차이 없음 -74% (20210107-033852) \n",
    "* 인풋 피쳐만 절반 - 전혀 학습X (20210107-172454)\n",
    "* 전반적 피쳐 확대 - 전전과 비등 (20210107-230440)\n",
    "* elu/sigmoid 적용 - 수렴 속도만 빨라짐 (20210108-064925)\n",
    "* swish 적용 -  (20210108-202908)\n",
    "\n",
    "\n",
    "* input stage batch norm 더 없애보기\n",
    "* fix data 비주얼로 검증해보기\n",
    "* non-fix train 결과로 fixed 결과에 테스트 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train log\n",
    "* dense bn for end stage: saturated output\n",
    "* dense batch norm for each stage: 74% for train, saturated for test\n",
    "* dense linear for each stage: 73% for train, saturated for test\n",
    "* dense bn relu - dense linear for each stage: 74% for train, saturated for test\n",
    "* dense bn relu - dense linear for each stage (size down): 74% for train, saturated for test\n",
    "* separate input - dense bn relu - dense linear for each stage : 50epoch - 98.5% for train, max 74% for test\n",
    "* separate input - dense bn relu - dense linear for each stage : 60k data - 95% for train, 75% for test\n",
    "* 32 batch - OOM\n",
    "* dense^2 relu/sigmoid for each stage: \n",
    "* dense^2 relu/sigmoid x2 for each stage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX= np.zeros((5,5,5,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX[:,:,:,:] = list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX[0,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use_bias=True\n",
    "```\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-143930/model.h5/assets\n",
    "Epoch 1, Loss: 0.6301059126853943, Accuracy: 67.04729461669922, Test Loss: 0.6941890120506287, Test Accuracy: 60.01933288574219\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-143930/model.h5/assets\n",
    "Epoch 2, Loss: 0.5641522407531738, Accuracy: 70.55376434326172, Test Loss: 1.1243842840194702, Test Accuracy: 58.13466262817383\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-143930/model.h5/assets\n",
    "Epoch 3, Loss: 0.4620269536972046, Accuracy: 77.59195709228516, Test Loss: 0.6866365671157837, Test Accuracy: 59.51997756958008\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-143930/model.h5/assets\n",
    "Epoch 4, Loss: 0.43595388531684875, Accuracy: 79.04708862304688, Test Loss: 2.0774402618408203, Test Accuracy: 52.75450897216797\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-143930/model.h5/assets\n",
    "Epoch 5, Loss: 0.4291463792324066, Accuracy: 80.04749298095703, Test Loss: 0.5646138787269592, Test Accuracy: 67.20361328125\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-143930/model.h5/assets\n",
    "Epoch 6, Loss: 0.4223867654800415, Accuracy: 79.8807601928711, Test Loss: 0.84770268201828, Test Accuracy: 54.961341857910156\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-143930/model.h5/assets\n",
    "Epoch 7, Loss: 0.41381269693374634, Accuracy: 80.5881118774414, Test Loss: 1.0013036727905273, Test Accuracy: 56.2983283996582\n",
    "train step - 6500/19801  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use_bias=False - 큰 차이 없음\n",
    "```\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-161530/model.h5/assets\n",
    "Epoch 1, Loss: 0.6417393088340759, Accuracy: 66.24393463134766, Test Loss: 0.6525431871414185, Test Accuracy: 64.90013122558594\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-161530/model.h5/assets\n",
    "Epoch 2, Loss: 0.5980429649353027, Accuracy: 69.05315399169922, Test Loss: 0.6825580596923828, Test Accuracy: 55.91172409057617\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-161530/model.h5/assets\n",
    "Epoch 3, Loss: 0.5077642202377319, Accuracy: 75.03031158447266, Test Loss: 0.7368553280830383, Test Accuracy: 62.12950897216797\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-161530/model.h5/assets\n",
    "Epoch 4, Loss: 0.47730717062950134, Accuracy: 76.97049713134766, Test Loss: 1.066005825996399, Test Accuracy: 56.459407806396484\n",
    "INFO:tensorflow:Assets written to: logs/gradient_tape/20201221-161530/model.h5/assets\n",
    "Epoch 5, Loss: 0.4632640480995178, Accuracy: 78.0820541381836, Test Loss: 0.769783079624176, Test Accuracy: 62.580543518066406\n",
    "train step - 12800/19801     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* use_biase=False, robot position sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
